<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>并发</title>
      <link href="/2024/04/05/%E5%B9%B6%E5%8F%91/"/>
      <url>/2024/04/05/%E5%B9%B6%E5%8F%91/</url>
      
        <content type="html"><![CDATA[<h1 id="并发编程核心概念"><a href="#并发编程核心概念" class="headerlink" title="并发编程核心概念"></a>并发编程核心概念</h1><ol><li>原子性</li></ol><p>​    所谓原子性即：一个或者多个操作，要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。</p><p>​     在整个操作过程中不会被线程调度器打断，如a&#x3D;1就是一个原子操作，但a++则不是一个原子操作，因为其内部会额外产生一个新的Integer对象。</p><p>​    举个例子，假设对一个32位的变量赋值，操作分为两步：低16位赋值、高16位赋值。当线程A对低16位数据写入成功后，线程A被中断。而此时另外的线程B去读取a的值，那么读取到的就是错误的数据。</p><p>​    在Java中的原子性操作包括：</p><ul><li>基本类型的读取和赋值操作，且赋值必须是数字赋值给变量，变量之间的相互赋值不是原子性操作。</li><li>所有引用的赋值操作。</li><li>java.concurrent.Atomic.*     包中所有原子操作类的一切操作。</li></ul><ol><li>可见性</li></ol><p>​    所谓可见性：即当多个线程访问同一个共享变量时，一个线程修改了该共享变量的值后，其他线程能够立即查看到修改后的值。</p><p>​     而如果要做到可见，Java中的volatile、synchronized、Lock都能保证可见性。如一个变量被volatile修饰后，表示当一个线程修改共享变量后，其会立即被更新到主内存中，其他线程读取共享变量时，会直接从主内存中读取。而synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的</p><p>修改刷新到主存当中。因此可以保证可见性。</p><ol><li>有序性</li></ol><p>​     所谓有序性：即程序执行的顺序会按照代码的先后顺序执行。</p><p>其可以理解为<strong>在本线程内，所有的操作都是有序的。而如果在A线程中观察B线程，所有的操作都是无序的</strong>。在JMM中为了提升程序的执行效率，允许编译器和处理器对<strong>指令重排序</strong>。对于单线程来说，指令重排并不会产生问题，而在多线程下则不可以。</p><p>在Java中可以通过synchronized和Lock来保证有序性，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。</p><p>另外还可以通过volatile来保证一定的有序性。最著名的例子就是单例模式的DCL（双重检查锁）。</p><h1 id="进程、线程"><a href="#进程、线程" class="headerlink" title="进程、线程"></a>进程、线程</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><ul><li>什么是进程</li></ul><p>进程可以理解为就是应用程序的启动实例。如微信、Idea、Navicat等，当打开它们后，就相当于开启了一个进程。每个进程都会在操作系统中拥有独立的内存空间、地址、文件资源、数据资源等。<strong>进程是资源分配和管理的最小单位</strong></p><p>线程从属于进程，是程序的实际执行者，一个进程中可以包含若干个线程，并且也可以把线程称为轻量级进程。每个线程都会拥有自己的计数器、堆栈、局部变量等属性，并且能够访问共享的内存变量。**线程是操作系统（CPU）调度和执行的最小单位。CPU会在这些线程上来回切换，让使用者感觉线程是在同时执行的。</p><p><strong>线程使用带来的问题</strong></p><p>​    有很多人都会存在一个误区，在代码中使用多线程，一定会为系统带来性能提升，这个观点是错误的。并发编程的目的是为了让程序运行的更快，但是，绝对不是说启动的线程越多，性能提升的就越大，其会受到很多因素的影响，如锁问题、线程状态切换问题、线程上下文切换问题，还会受到硬件资源的影响，如CPU核数。</p><p>什么叫做线程上下文切换</p><p>​    不管是在多核甚至单核处理器中，都是能够以多线程形式执行代码的，CPU通过给每个线程分配CPU时间片来实现线程执行间的快速切换。 所谓的时间片就是CPU分配给每个线程的执行时间，当某个线程获取到CPU时间片后，就会在一定时间内执行，当时间片到期，则该线程会进入到挂起等待状态。时间片一般为几十毫秒，通过在CPU的高速切换，让使用者感觉是在同时执行。</p><p>​    同时还要保证线程在切换的过程中，要记录线程被挂起时，已经执行了哪些指令、变量值是多少，那这点则是通过每个线程内部的程序计数器来保证。</p><p>​    简单来说：线程从挂起到再加载的过程，就是一次上下文切换。其是比较耗费资源的。</p><p>引起上下文切换的几种情况：</p><ul><li>时间片用完，CPU正常调度下一个任务。</li><li>被其他优先级更高的任务抢占。</li><li>执行任务碰到IO阻塞，调度器挂起当前任务，切换执行下一个任务。</li><li>用户代码主动挂起当前任务让出CPU时间。</li><li>多任务抢占资源，由于没有抢到被挂起。</li><li>硬件中断。</li></ul><p><strong>CPU</strong>时间片轮转机制*优化</p><p>​    之前已经提到了线程的执行，是依赖于CPU给每个线程分配的时间来进行。在CPU时间片轮转机制中，如果一个线程的时间片到期，则CPU会挂起该线程并给另一个线程分配一定的时间分片。如果进程在时间片结束前阻塞或结束，则 CPU 会立即进行切换。</p><p>​     时间片太短会导致频繁的进程切换，降低了 CPU 效率: 而太长又可能引起对短的交</p><p>互请求的响应变差。时间片为 <strong>100ms</strong> 通常是一个比较合理的折衷。</p><p>并行与并发的理解</p><p>并发即让多个任务能够<strong>交替</strong>执行，一般都会附带一个时间单位，也就是所谓的在单</p><p>位时间内的并发量有多少。</p><p>并行即让多个任务能够同时执行。比如说：你可以一遍上厕所，一遍吃饭。</p><p><strong>多线程的创建方式</strong></p><p>线程的实现方式有两种：继承Thread类、实现Runnable接口。但是有一些书籍或者文章会说有三种方式，即实现Callable接口。但通过该接口定义线程并不是Java标准的定义方式，而是基于</p><p>Future思想来完成。</p><p>Thread是对一个线程的抽象，而Runnable是对业务逻辑的抽象，并且Thread 可以接受任意一个 Runnable 的实例并执行。</p><p>优化：启动线程前，最好为这个线程设置特定的线程名称，这样在出现问题时，给开发人员一些提示，快速定位到问题线程。</p><p>线程中止</p><p>线程在正常下当run执行完，或出现异常都会让该线程中止。</p><p>理解suspend()、resume()、stop()</p><p>这三个方法对应的是暂停、恢复和中止。</p><p>但是三个已经在Java源码中被标注为过期方法。</p><p>当调用suspend()时，线程不会将当前持有的资源释放(如锁)，而是占有者资源进入到暂停状</p><p>态，这样的话，容易造成死锁问题的出现。</p><p>当调用stop()时，会<strong>立即停止run()中剩余的操作</strong>。因此可能会导致一些的工作得不到完成，如文件流，数据库等关闭。并且<strong>会立即释放该线程所持有的所有的锁</strong>，导致数据得</p><p>不到同步的处理，出现数据不一致的问题。</p><p>线程中止的安全且优雅姿势</p><p>​    Java对于线程安全中止设计了一个<strong>中断属性</strong>，其可以理解是线程的一个标识位属性。它用于表示一个运行中的线程是否被其他线程进行了中断操作。好比其他线程对这个线程打了一个招呼，告诉它你该中断了。通过**interrupt()**实现。</p><p>添加该方法后，会出现一个异常，但是可以发现并不会线程的继续执行。</p><p>​    线程通过检查自身是否被中断来进行响应，可以通过**isInterrupted()**进行判断，如果返回值为true，代表添加了中断标识，返回false，代表没有添加中断标识。通过它可以对线程进行中断操作。</p><p>对线程中断属性的判断，可以利用其进行线程执行的中断操作。</p><p>​    线程也可以通过静态方法<strong>Thread.interrupted()<strong>查询线程是否被中断，并对中断标识进行复位，如果该线程已经被添加了中断标识，当使用了该方法后，会将线程的中断标识由true改为false。同时要注意：</strong>处于死锁下的线程，无法被中断</strong></p><h2 id="进程和线程的区别"><a href="#进程和线程的区别" class="headerlink" title="进程和线程的区别"></a>进程和线程的区别</h2><p>进程是执行着的应用程序，而线程是进程内部的一个执行序列。一个进程可以有多个线程。线程又叫做轻量级进程。</p><p>**a.**<strong>地址空间和其它资源</strong>：进程间拥有独立内存，进程是资源分配的基本单位；线程隶属于某一进程，且同一进程的各线程间共享内存（资源），线程是cpu调度的基本单位。 进程间相互独立，同一进程的各线程间共享。某进程内的线程在其它进程不可见。</p><p>**b.**<strong>通信：</strong>进程间相互独立，通信困难，常用的方法有：管道，信号，套接字，共享内存，消息队列等；线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性。 </p><p>**c.**<strong>调度和切换</strong>：线程上下文切换比进程上下文切换要快。进程间切换要保存上下文，加载另一个进程；而线程则共享了进程的上下文环境，切换更快。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image001.jpg" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image002.jpg" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image004.jpg" class="" title="线 程 的 优 点 ：  。 一 个 进 程 中 可 以 同 时 存 在 个 线 程 ；  。 各 个 线 程 之 间 可 以 并 发 执 行 ；  。 各 个 线 程 之 间 可 以 共 享 地 址 空 间 和 文 件 等 资 源 ；  线 程 的 缺 点 ：  能 当 进 程 中 的 一 个 线 程 崩 溃 时 ， 会 导 致 其 所 属 进 程 的 所 有 线 程 崩 溃 。"><h2 id="线程创建方式"><a href="#线程创建方式" class="headerlink" title="线程创建方式"></a>线程创建方式</h2><p>实现Thread类</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image006.jpg" class="" title="img"><p>实现Runnbale接口</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image008.jpg" class="" title="img"><p><strong>实现</strong>Callable接口</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image010.jpg" class="" title="img"><p>为什么要有Runnable接口的出现？</p><p>1：通过继承Thread类的方式，可以完成多线程的建立。但是这种方式有一个局限性，如</p><p>果一个类已经有了自己的父类，就不可以继承Thread类，因为java单继承的局限性。 </p><p>可是该类中的还有部分代码需要被多个线程同时执行。这时怎么办呢？ </p><p>只有对该类进行额外的功能扩展，java就提供了一个接口Runnable。这个接口中定义了run</p><p>方法，其实run方法的定义就是为了存储多线程要运行的代码。</p><p>所以，通常创建线程都用第二种方式。 </p><p>因为实现Runnable接口可以避免单继承的局限性。</p><p>2：其实是将不同类中需要被多线程执行的代码进行抽取。将多线程要运行的代码的位置</p><p>单独定义到接口中。为其他类进行功能扩展提供了前提。 </p><p>所以Thread类在描述线程时，内部定义的run方法，也来自于Runnable接口。 </p><p>实现Runnable接口可以避免单继承的局限性。而且，继承Thread，是可以对Thread类中的方法，进行子类复写的。但是不需要做这个复写动作的话，只为定义线程代码存放位置</p><p>，实现Runnable接口更方便一些。所以Runnable接口将线程要执行的任务封装成了对象。</p><p>Thread和Runnable的联系与区别</p><p>1.Thread和Runnable都可以实现多线程（废话） </p><p>2.Thread是类，而Runnable是接口，这就是类和接口区别，类只能继承一次，而接口可以实现多个接口。 </p><p>3.Thread实现Runnable接口，这个可以查看Thread的源代码。 </p><p>4.最重要的分享资源功能，一般我们使用多线程就是快速解决资源问题。Runnable可以实现资源分享，类实现Runnable并不具备线程功能，必须通过new Thread(runabble子类)调用start()启动线程，所以我们通常new一个runnable的子类，启动多个线程解决资源问题。Thread是类所以我们每次new一个对象时候资源已经实例化了，不能资源共享，Thread类要实现资源共享，可以声明变量为static，类共享的可以解决。</p><p> 5.通过以上建议最好实现Runnable接口 实现多线程。</p><h2 id="线程操作常见方法"><a href="#线程操作常见方法" class="headerlink" title="线程操作常见方法"></a>线程操作常见方法</h2><ol><li>run()&amp;start()</li></ol><p>当线程执行了 start()方法后，才真正意义上的启动线程，其会让一个线程进入就绪状态等待分配CPU时间片，分到时间片后才会调用run()。注意，同一个线程的start()不能被重复调用，否则会出现异常，因为重复调用了，start方法，线程的state就不是new了，那么threadStatus就不等于0了。 </p><p>而run()则仅仅是一个普通方法，与类中的成员方法意义相同。在该方法中可以实现线程执行的业务逻辑。但并不会以异步的方式将线程启动，换句话说就是并不会去开启一个新的</p><p>线程。其可以单独执行，也可以重复执行。</p><ol><li>wait()、notify()</li></ol><p>wait()、notify()、notifyAll()是三个定义在Object类里的方法，可以用来控制线程的状</p><p>态。</p><p>注意：一定要在线程同步中使用,并且是同一个锁的资源**</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image012.gif" class="" title="img"><p>1）WaitThread首先获取对象锁。</p><p>2）WaitThread调用对象的wait()方法，放弃锁并进入对象的等待队列WaitQueue，进行等待状态。</p><p>3）由于WaitThread释放了对象锁，NotifyThread随机获取对象锁。</p><p>4）NotifyThread获取对象锁成功后，调用notify()或notifyAll()，将WaitThread从等待队列</p><p>WaitQueue移到同步队列</p><p>SynchronizedQueue，此时WaitThread为<strong>阻塞状态</strong>。</p><p>5）NotifyThread释放锁后，WaitThread再次获取锁并从wait()方法继续执行。</p><ol><li>等待通知范式</li></ol><p>等待方：</p><ul><li>获取对象锁。</li><li>如果条件不满足，那么调用对象的wait方法，被通知后仍要检查条件。</li><li>条件满足则执行对应逻辑。</li></ul><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image014.jpg" class="" title="img"><p>通知方：</p><p>- 获取对象锁。</p><p>- 改变条件。</p><p>- 通知等待在该对象上的线程。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image016.jpg" class="" title="img"><ol><li>wait与sleep区别</li></ol><p>* 对于sleep()方法，首先要知道该方法是属于Thread类中的。而wait()方法，则是属于</p><p>Object类中的。</p><p>* sleep()方法导致了程序暂停执行指定的时间，让出cpu调度其他线程，但是他的监控状态</p><p>依然保持者，当指定的时间到了又会自动恢复运行状态。</p><p> wait()是把控制权交出去，然后进入等待此对象的等待锁定池处于等待状态，只有针对此</p><p>对象调用notify()方法后本线程才进入对象锁定池准备获取对象锁进入运行状态。</p><p>* 在调用sleep()方法的过程中，线程不会释放锁。而当调用wait()方法的时候，线程会释放</p><p>锁。</p><ol><li>理解yield()</li></ol><p>​    当某个线程调用了这个方法后，该线程立即释放自己持有的时间片。线程会进入到就绪状态，同时CPU会重新选择一个线程赋予时间分片，但注意，调用了这个方法的线</p><p>程，也有可能被CPU再次选中赋予执行。</p><p>​    而且该方法不会释放锁。 如需释放锁的话，可以在调用该方法前自己手动释放。</p><ol><li>理解join()</li></ol><p>该方法的使用，在实际开发中，应用的是比较少的。但在面试中，常常伴随着产生一个问</p><p>题，如何保证线程的执行顺序？ 就可以通过该方法来设置。</p><p>使用:当线程调用了该方法后，线程状态会从就绪状态进入到运行状态。</p><p>每一个线程实现都持有前一个线程的引用。</p><p>当前线程需要等待previousThread线程终止之后才从thread.join返回。可以理解为，线程会在join处等待。</p><p>Thread.join其实底层是通过wait&#x2F;notifyall来实现线程的通信达到线程阻塞的目的；当线程执行结束以后，会触发两个事情，第一个是设置native线程对象为null、第二个是通过notifyall方法，让等待在previousThread对象锁上的wait方法被唤醒。</p><h2 id="线程优先级"><a href="#线程优先级" class="headerlink" title="线程优先级"></a>线程优先级</h2><p>线程优先级的<strong>范围是****1~10</strong>。一个线程的<strong>默认优先级是****5</strong>，可以在构建线程时，通过**setPriority()**修改该线程的优先级。优先级高的线程分配时间片的数量会高于优先级低的线程。</p><p>​    一般来说对于频繁阻塞的线程需要设置优先级高点，而偏重计算的线程优先级会设置低些，确保处理器不会被独占。</p><p>​    但<strong>注意，线程优先级不能作为线程执行正确性的依赖，因为不同的操作系统可能会忽略优先级的设置。</strong></p><h2 id="守护线程"><a href="#守护线程" class="headerlink" title="守护线程"></a>守护线程</h2><p>守护线程是一种支持型的线程，我们之前创建的线程都可以称之为用户线程。通过守护线程可以完成一些支持性的工作，如GC、分布式锁续期。守护线程会伴随着用户线程的结束而结束。</p><p>对于守护线程的创建，可以通过setDaemon()设置。</p><p>当线程实例没有被设置为守护线程时，该线程并不会随着主线程的结束而结束。但是当被设置为守护线程后，当主线程结束，该线程也会伴随着结束。同时守护线程不一定会执行finally代码块。所以当线程被设定为守护线程后，无法确保清理资源等操作一定会被执行。</p><h2 id="线程状态"><a href="#线程状态" class="headerlink" title="线程状态"></a>线程状态</h2><p><img src="/%E5%B9%B6%E5%8F%91/clip_image018.jpg" alt="img"><img src="/%E5%B9%B6%E5%8F%91/clip_image020.jpg" alt="img"></p><h2 id="线程安全活跃态问题以及竞态条件"><a href="#线程安全活跃态问题以及竞态条件" class="headerlink" title="线程安全活跃态问题以及竞态条件"></a>线程安全活跃态问题以及竞态条件</h2><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image022.jpg" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image024.jpg" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image026.jpg" class="" title="img"><h1 id="synchronized"><a href="#synchronized" class="headerlink" title="synchronized"></a><strong>synchronized</strong></h1><h2 id="synchronized-锁住的是什么"><a href="#synchronized-锁住的是什么" class="headerlink" title="synchronized****锁住的是什么"></a><strong>synchronized****锁住的是什么</strong></h2><p>总结：</p><p>静态方法：clss对象</p><p>普通方法：this对象</p><p>静态代码块：根据锁住的内容有所不同</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image028.gif" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image030.gif" class="" title="img"><p>对于synchronized，可以把其加在方法上或者类上，或者添加同步代码块。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image032.jpg" class="" title="img"><p>这种操作方式也可以叫做对象锁。</p><p>对于synchronized，也可以加载类上进行使用。此时可以把它称为<strong>类锁</strong>。此时加锁的就是一个class对象了。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image034.jpg" class="" title="img"><p>在使用synchronized时，建议锁定的范围，越小越好。否则的话，容易造成大量资源被锁定。</p><h2 id="synchronized是可重入锁吗"><a href="#synchronized是可重入锁吗" class="headerlink" title="synchronized是可重入锁吗"></a>synchronized是可重入锁吗</h2><p>2021年9月27日</p><p>synchronized底层是利用计算机系统mutex Lock实现的。每一个可重入锁都会关联一个线程ID和一个锁状态status。</p><p>当一个线程请求方法时，会去检查锁状态。</p><ul><li><ol><li>如果锁状态是0，代表该锁没有被占用，使用CAS操作获取锁，将线程ID替换成自己的线程ID。</li><li>如果锁状态不是0，代表有线程在访问该方法。此时，如果线程ID是自己的线程ID，如果是可重入锁，会将status自增1，然后获取到该锁，进而执行相应的方法；如果是非重入锁，就会进入阻塞队列等待。</li></ol></li></ul><p>在释放锁时，</p><ul><li><ol><li>如果是可重入锁的，每一次退出方法，就会将status减1，直至status的值为0，最后释放该锁。</li><li>如果非可重入锁的，线程退出方法，直接就会释放该锁。</li></ol></li></ul><p><a href="https://zhuanlan.zhihu.com/p/358828529">https://zhuanlan.zhihu.com/p/358828529</a></p><h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><p>在解释原理之前，首先需要知道什么是monitor。</p><p>我们可以把它理解为一个同步工具，也可以描述为一种同步机制，它通常被描述为一个对象。每一个Java对象都有成为Monitor的潜质，因为在Java的设计中 ，每一个Java对象自打娘胎里出来就带了一把看不见的锁，它叫做内部锁或者Monitor锁。Monitor 是线程私有的数据结构，每一个线程都有一个可用monitor record列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个monitor关联，同时monitor中有一个Owner字段存放拥有该锁的线程的唯一标志，表示该锁被这个线程占用。</p><p><strong>代码块：</strong>monitorenter指令插入到同步代码块的开始位置，monitorexit指令插入到同步代码块的结束位置，JVM需要保证每一个monitorenter都有一个monitorexit与之相对应。任何对象都有一个monitor与之相关联，当且一个monitor被持有之后，他将处于锁定状态。线程执行到monitorenter指令时，将会尝试获取对象所对应的monitor所有权。正常执行或者发生异常时会执行monitorexit指令，释放monitor所有权。</p><p><strong>方法：</strong>一个同步方法会在运行时常量池中的method_info结构体中存放ACC_SYNCHRONIZED标志符。当一个线程访问方法时，会去检查是否存在ACC_SYNCHRONIZED标志，如果存在，则先要获得对应的monitor锁，然后执行方法。当方法执行结束(不管是正常return还是抛出异常)都会释放对应的monitor锁。如果此时有其他线程也想要访问这个方法时，会因得不到monitor锁而阻塞。</p><p><a href="https://www.jianshu.com/p/5c4f441bf142">https://www.jianshu.com/p/5c4f441bf142</a></p><h2 id="锁对象"><a href="#锁对象" class="headerlink" title="锁对象"></a>锁对象</h2><p>synchronized用的锁会保存在<strong>Java对象头</strong>中。那什么是Java对象头呢？</p><p>一个Java对象在内存中是由三部分组成的：</p><p>- 对象头</p><p>- 实例数据</p><p>- 对齐填充字节</p><p>​    如果对象不是数组类型，则JVM用2字宽存储对象头。如果是数组类型，则用3字宽存储对象头。在32位虚拟机中，1字宽等于4字节，即32bit。在64位虚拟机中，1字宽相当于8字节，即64bit。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image036.gif" class="" title="img"><p>而对象头也是由三部分组成：</p><p>- MarkWord</p><p>- 类型指针</p><p>- 数组长度（只有数组对象有）</p><p>​    Mark Word用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程 ID、偏向时间戳等等。Java对象头一般占有两个机器码（在32位虚拟机中，1个机器码等于4字节，也就是32bit）。 </p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image038.gif" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image040.gif" class="" title="img"><p>类型指针，是对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。</p><p>实例数据</p><p>如果对象有属性字段，则这里会有数据信息。如果对象无属性字段，则这里就不会有数据。根据字段类型的不同占不同的字节，例如boolean类型占1个字节，int类型占4个字节等等</p><p>对齐数据</p><p>对象可以有对齐数据也可以没有。默认情况下，Java虚拟机堆中对象的起始地址需要对齐至8的倍数。如果一个对象用不到8N个字节则需要对其填充，以此来补齐对象头和实例数据占用内存之后剩余的空间大小。如果对象头和实例数据已经占满了JVM所分配的内存空间，那么就不用再进行对齐填充了。</p><p>所有的对象分配的字节总SIZE需要是8的倍数，如果前面的对象头和实例数据占用的总SIZE不满足要求，则通过对齐数据来填满。</p><p>为什么要对齐数据？字段内存对齐的其中一个原因，是让字段只出现在同一CPU的缓存行中。如果字段不是对齐的，那么就有可能出现跨缓存行的字段。也就是说，该字段的读取可能需要替换两个缓存行，而该字段的存储也会同时污染两个缓存行。这两种情况对程序的执行效率而言都是不利的。其实对其填充的最终目的是为了计算机高效寻址。</p><p>JVM中大家是否还记得对象在Suvivor中每熬过一次MinorGC，年龄就增加1，当它的年龄增加到一定程度后就会被晋升到老年代中，这个次数默认是15岁，有想过为什么是15吗？在Mark Word中可以发现标记对象分代年龄的分配的空间是4bit，而4bit能表示的最大数就是2^4-1 &#x3D; 15。</p><p><a href="https://www.cnblogs.com/jajian/p/13681781.html">https://www.cnblogs.com/jajian/p/13681781.html</a></p><p>Object o &#x3D; new Object()占多少个字节？</p><p>第一种解释：</p><p>object实例对象，占16个字节。</p><p>第二种解释：</p><p>Object o：普通对象指针（ordinary object pointer），占4个字节。</p><p>new Object()：object实例对象，占16个字节。</p><p>所以一共占：4+16&#x3D;20个字节。 </p><h2 id="Synchronized锁优化"><a href="#Synchronized锁优化" class="headerlink" title="Synchronized锁优化"></a>Synchronized锁优化</h2><ul><li><ol><li>自旋锁</li></ol></li></ul><p>线程的阻塞和唤醒需要CPU从用户态转为内核态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作，势必会给系统的并发性能带来很大的压力。同时我们发现在许多应用上面，对象锁的锁状态只会持续很短一段时间，为了这一段很短的时间频繁地阻塞和唤醒线程是非常不值得的。所以引入<strong>自旋锁</strong>（其实就是无意义的循环）。</p><p>所谓自旋锁，就是让该线程等待一段时间，不会被立即挂起，看持有锁的线程是否会很快释放锁。执行一段无意义的循环即可（自旋）。</p><p>如果持有锁的线程很快就释放了锁，那么自旋的效率就非常好，反之，自旋的线程就会白白消耗掉处理的资源，自旋等待的时间（自旋的次数）必须要有一个限度。</p><p>如果通过参数**-XX:preBlockSpin**来调整自旋锁的自旋次数，会带来诸多不便。假如我将参数调整为10，但是系统很多线程都是等你刚刚退出的时候就释放了锁（假如你多自旋一两次就可以获取锁），你是不是很尴尬。</p><ul><li><ol><li>自适应自旋锁</li></ol></li></ul><p>线程如果自旋成功了，那么下次自旋的次数会更加多，因为虚拟机认为既然上次成功了，那么此次自旋也很有可能会再次成功，那么它就会允许自旋等待持续的次数更多。反之，如果对于某个锁，很少有自旋能够成功的，那么在以后要或者这个锁的时候自旋的次数会减少甚至省略掉自旋过程，以免浪费处理器资源。</p><ul><li><ol><li>锁消除</li></ol></li></ul><p>锁消除发生在编译阶段，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，通过锁消除，可以节省毫无意义的请求锁时间。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image042.jpg" class="" title="img"><p>当前getString()中的StringBuffer是作为方法内部的局部变量，因此它不可能被多个线程同时访问，也就没有资源竞争，但是StringBuffer的append操作却需要执行同步操作:</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image044.gif" class="" title="img"><p>​    那么此时的同步锁相当于就是白白浪费系统资源。因此在编译时一旦JVM发现此种情况就会通过锁消除方式来优化性能。在JDK1.8中锁消除是自动开启的。</p><h2 id="锁升级过程"><a href="#锁升级过程" class="headerlink" title="锁升级过程"></a>锁升级过程</h2><p> 偏向锁</p><p><strong>1****）加锁</strong></p><ol><li>当线程初次执行到synchronized代码块（主要是线程ID）时，会通过自旋方式修改MarkWord的锁标志，代表锁对象为偏向锁。</li><li>执行完同步代码块后，线程并不会主动释放偏向锁。</li><li>当第二次执行同步代码块时，首先会判断MarkWord中的线程ID是否为当前线程。</li><li>如果是，则正常往下执行同步代码块。由于之前没有释放锁，这里也就不需要重新加锁。如果自始至终使用锁的线程只有一个，很明显偏向锁几乎没有额外开销，性能极高。</li><li>如果线程ID并未指向当前线程，则通过CAS操作替换MarkWork中的线程ID。如果替换成功，则执行同步代码块；如果替换失败，执行步骤6。</li><li>如果CAS替换失败，则表示有竞争。当到达全局安全点（safepoint）（当前程序什么都不干的时候）时获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码。（撤销偏向锁的时候会导致stop the world即什么都不干）</li></ol><p><strong>2****）撤销</strong></p><p>​    偏向锁的撤销在上述第六步中有提到。偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动去释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态，撤销偏向锁后恢复到未锁定（标志位为“01”）或轻量级锁（标志位为“00”）的状态。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image046.gif" class="" title="偏 向 锁 的 获 得 和 撤 销 流 程  线 程 1  对 象 头 中 MarkWord  线 程 2  访 问 同 步 快  无 锁 状 态  捡 查 对 象 头 是  否 存 储 了 线 程 1  Mark Word  访 问 同 步 快  偏 向 锁 状 态  将 对 象 头 M “ k  Tl 《 Epoch 《  word 中 的 线 程 》 D  检 查 对 象 头  指 向 自 己  是 否 存 储 了  线 程 2  执 行 同 步 体  c 替 换  Mark Word  不 成 功  暂 停 线 程  撤 销 偏 向 锁  撤 销 偏 向 锁  解 锁 ， 将 线 程  旧 设 为 空  0 《 01  恢 复 线 程"><p><strong>3****）使用场景</strong></p><p>​    始终只有一个线程在执行同步块，在它没有执行完释放锁之前，没有其它线程去执行同步块，在锁无竞争的情况下使用，一旦有了竞争就升级为轻量级锁，升级为轻量级锁的时候需要撤销偏向锁，撤销偏向锁的时候会导致stop the world操作； </p><p>​    在有锁竞争时，偏向锁会多做很多额外操作，尤其是撤销偏向所的时候会导致进入安全点，安全点会导致stw，导致性能下降；</p><p>轻量级锁</p><p>​    轻量级锁是由偏向锁升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，偏向锁就会升级为轻量级锁；</p><p>1）加锁</p><p>\1.  在进入同步代码块前，JVM会在当前线程的栈帧中创建用于存储锁记录的空间，并将对象头中的MarkWord复制到锁记录中。</p><p>\2.  然后线程尝试使用自旋将对象头中的MarkWord替换为指向锁记录的指针。</p><p>\3.  如果成功，当前线程获得轻量级锁，执行同步代码块。 如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。当自旋次数达到一定次数时，锁就会升级为重量</p><p>级锁，并阻塞线程。</p><p>2）解锁</p><p>​    解锁时，会使用自旋操作将锁记录替换回到对象头，相当于做一个对比。如果成功，表示没有竞争发生；如果失败，表示当前锁存在竞争，锁已经被升级为重量级锁，会</p><p>释放锁并唤醒等待的线程。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image048.gif" class="" title="Mark  CAStm  Mark Word  EMark Worde  CASH-4  Mark Word  Mark  HashCodelagel  0101  00  10  01  10  Ma rk Wordm  Mark Word"><p>重量级锁</p><p>​    重量级锁通过对象内部的监视器（monitor）实现，其中monitor的本质是依赖于底层操作系统的Mutex Lock实现，操作系统实现线程之间的切换需要从用户态到内核态的切换，切换成本非常高。</p><p>​    切换成本高的原因在于，当系统检查到是重量级锁之后，会把等待想要获取锁的线程阻塞，被阻塞的线程不会消耗CPU，但是阻塞或者唤醒一个线程，都需要通过操作系统来实现，也就是相当于从用户态转化到内核态，而转化状态是需要消耗时间的 。</p><p>​    简单来说就是：竞争失败后，线程阻塞，释放锁后，唤醒阻塞的线程，不使用自旋锁，不会那么消耗CPU，所以重量级锁适合用在同步块执行时间长的情况下。</p><p>锁的优缺点对比</p><table><thead><tr><th><strong>锁</strong></th><th><strong>优点</strong></th><th><strong>缺点</strong></th><th><strong>使用场景</strong></th></tr></thead><tbody><tr><td>偏向锁</td><td>加锁和解锁会存在CAS，没有额外的性能消耗，和执行非同步方法相比，仅存在纳秒级的差距</td><td>如果线程间存在锁竞争，会带来额外的锁撤销的消耗</td><td>只有一个线程访问同步块或者同步方法的场景</td></tr><tr><td>轻量级锁</td><td>竞争的线程不会阻塞，提高程序响应速度</td><td>若线程长时间抢不到锁，自旋会消耗CPU性能</td><td>追求响应时间。同步代码块执行非常快</td></tr><tr><td>重量级锁</td><td>线程竞争不使用自旋，不消耗CPU</td><td>线程阻塞，响应时间缓慢,在多线程下,频繁的获取释放锁，会带来巨大的性能消耗</td><td>追求吞吐量，同步块或者同步方法执行时间较长的场景</td></tr></tbody></table><p>小结</p><p><strong>偏向锁</strong>：在不存在多线程竞争情况下，默认会开启偏向锁。</p><p><strong>偏向锁升级轻量级锁</strong>：当一个对象持有偏向锁，一旦第二个线程访问这个对象，如果产生竞争，偏向锁升级为轻量级锁。</p><p><strong>轻量级锁升级重量级锁</strong>：一般两个线程对于同一个锁的操作都会错开，或者说稍微等待一下（自旋），另一个线程就会释放锁。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁膨胀为重量级锁，重量级锁使除了拥有锁的线程以外的线程都阻塞，防止CPU空转。</p><h1 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h1><p>造成死锁的原因</p><ul><li>当前线程<strong>拥有其他线程需要的</strong>资源</li><li>当前线程<strong>等待其他线程已拥有</strong>的资源</li><li><strong>都不放弃</strong>自己拥有的资源</li></ul><p>死锁演示</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image050.jpg" class="" title="public class DeadLock {  private static String valuel &#x3D; a&quot; private static String value2 &#x3D; b public static void args) { new DeadLock() .deadLock() ; private void deadLock() { Thread tI &#x3D; new try { System. out . running&quot; while synchronized System.out. lock valuel&quot;); RN! obi | Thread. sleep(3øøø) ; &#x2F;&#x2F; synchronized lock value2&quot;); }catch (Exception e){ e. printStackTrace() ; Thread t2 &#x3D; try { new System.out . running&quot; while synchronized System.out. lock value2&quot;); RN! obi | Thread. sleep(3øøø) ; &#x2F;&#x2F; synchronized Systen.out. lock valuel&quot; }catch (Exception e){ e. printStackTrace() ; tl.start(); %}&lt;p&gt;t2.start();&lt;&#x2F;p&gt;&lt;h1 id&#x3D;死锁排查&quot;&gt;&lt;a href&#x3D;#死锁排查 class&#x3D;headerlink title&#x3D;死锁排查&gt;&lt;&#x2F;a&gt;死锁排查&lt;&#x2F;h1&gt;&lt;p&gt; 通过JDK工具jps+jstack&lt;&#x2F;p&gt; &lt;p&gt;​ jps是jdk提供的一个工具，可以查看到正在运行的java进程&lt;&#x2F;p&gt; &lt;p&gt;​ jstack也是jdk提供的工具，可以查看java进程中线程堆栈信息。&lt;&#x2F;p&gt; &lt;p&gt;从输出的堆栈信息中可以发现：Found one Java-level deadLock。表示在这个程序中发现了死锁，后面的详细描述中已经指出了在22行和39行出现死锁。 那就可以根据这些信息快速定位到问题点进行优化处理。&lt;&#x2F;p&gt; &lt;p&gt; 通过JDK工具jconsole&lt;&#x2F;p&gt; &lt;p&gt;​ jconsole是JDK提供的一款可视化工具，可以更加方便的排查程序问题，如：内存溢出、死锁。&lt;&#x2F;p&gt; &lt;p&gt; 通过JDK工具VisualVM&lt;&#x2F;p&gt; &lt;p&gt;​ 其也是JDK提供的一款非常强大的程序问题检测工具，可以监控程序性能、查看JVM配置信息、堆栈信息。&lt;&#x2F;p&gt; &lt;p&gt;避免死锁的常见方法&lt;&#x2F;p&gt; &lt;p&gt;1）避免一个线程同时获取多个锁。&lt;&#x2F;p&gt; &lt;p&gt;2）避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。&lt;&#x2F;p&gt; &lt;p&gt;3）尝试使用定时锁，使用lock.tryLock(timeout)来替代使用内部锁机制。&lt;&#x2F;p&gt; &lt;p&gt;4）synchorized加锁&lt;&#x2F;p&gt; &lt;h1 id&#x3D;Volatile&gt;&lt;a href&#x3D;#Volatile class&#x3D;headerlink title&#x3D;Volatile&gt;&lt;&#x2F;a&gt;Volatile&lt;&#x2F;h1&gt;&lt;p&gt;不能保证共享变量的原子性&lt;&#x2F;p&gt; &lt;p&gt;volatile并不能保证原子性，因此在多线程下操作时，一个线程可能会读取到另外一个线程并未修改的数据。&lt;&#x2F;p&gt; &lt;p&gt;能够保证共享变量的可见性&lt;&#x2F;p&gt; &lt;p&gt;通过volatile修饰的变量，JMM并不会将其放入线程的本地内存，而是放入主内存中。从而该变量对于其他线程都是立即可见的。&lt;&#x2F;p&gt; &lt;p&gt;能够保证共享变量的有序性&lt;&#x2F;p&gt; &lt;p&gt;volatile能够禁止指令重排，因此能够在一定程度上保证有序性。当对volatile变量操作时，其前面的操作肯定全部已经执行完毕，其后面的操作肯定还没有执行。&lt;&#x2F;p&gt; &lt;p&gt;使用场景&lt;&#x2F;p&gt; &lt;p&gt;对其的使用必须同时满足下面两个条件才能保证在并发环境的线程安全：&lt;&#x2F;p&gt; &lt;ul&gt; &lt;li&gt;&lt;ul&gt; &lt;li&gt;- 对变量的写操作不依赖于当前值（比如 i++），或者说是单纯的变量赋值（boolean flag &#x3D; true）&lt;&#x2F;li&gt; &lt;li&gt;- 该变量没有包含在具有其他变量的不变式中，也就是说，不同的 volatile 变量之间，不能互相依赖。只有在状态真正独立于程序内其他内容时才能使用 volatile。&lt;&#x2F;li&gt; &lt;&#x2F;ul&gt; &lt;&#x2F;li&gt; &lt;&#x2F;ul&gt; &lt;p&gt;​ 同时volatile更适用于读多写少的场景。如有N个线程在读值，而只有一个线程在写值，则该值可以通过volatile修饰，即可保证多线程下的可见性，也可以保证变量的原子性。&lt;&#x2F;p&gt; &lt;p&gt;volatile一定能保证线程安全吗&lt;&#x2F;p&gt; &lt;p&gt;先说结论吧，volatile不能一定能保证线程安全。&lt;&#x2F;p&gt; &lt;p&gt;可见性不能保证操作的原子性，前面说过了count++不是原子性操作，会当做三步，先读取count的值，然后+1，最后赋值回去count变量。需要保证线程安全的话，需要使用synchronized关键字或者lock锁，给count++这段代码上锁：&lt;&#x2F;p&gt; &lt;p&gt;as-if-serial语义&lt;&#x2F;p&gt; &lt;p&gt;不管怎么重排序，（单线程）程序的执行结果不能被改变。&lt;&#x2F;p&gt; &lt;p&gt;什么是happen-before&lt;&#x2F;p&gt; &lt;p&gt; JMM可以通过happens-before关系向程序员提供跨线程的内存可见性保证（如果A线程的写操作a与B线程的读操作b之间存在happens-before关系，尽管a操作和b操作在不同的线程中执行，但JMM向程序员保证a操作将对b操作可见）。&lt;&#x2F;p&gt; &lt;p&gt;具体的定义为：&lt;&#x2F;p&gt; &lt;p&gt;1）如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。&lt;&#x2F;p&gt; &lt;p&gt;2）两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么这种重排序并不非法（也就是说，JMM允许这种重排序）。&lt;&#x2F;p&gt; &lt;p&gt;volatile禁止指令重排序的原理是什么&lt;&#x2F;p&gt; &lt;p&gt;首先要讲一下内存屏障，内存屏障可以分为以下几类：&lt;&#x2F;p&gt; &lt;p&gt;LoadLoad 屏障：对于这样的语句Load1，LoadLoad，Load2。在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。&lt;&#x2F;p&gt; &lt;p&gt;StoreStore屏障：对于这样的语句Store1， StoreStore， Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。&lt;&#x2F;p&gt; &lt;p&gt;LoadStore 屏障：对于这样的语句Load1， LoadStore，Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。&lt;&#x2F;p&gt; &lt;p&gt;StoreLoad 屏障：对于这样的语句Store1， StoreLoad，Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。&lt;&#x2F;p&gt; &lt;ul&gt; &lt;li&gt;&lt;ul&gt; &lt;li&gt;{% asset_img clip_image052.gif img"></li></ul></li></ul><p>在每个volatile读操作后插入LoadLoad屏障，在读操作后插入LoadStore屏障。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image054.gif" class="" title="preview"><h1 id="CAS"><a href="#CAS" class="headerlink" title="CAS"></a>CAS</h1><p>\1.   CAS概念</p><p>CAS（Compare and Swap），即比较并替换，是用于实现多线程同步的原子操作。</p><p>所谓原子操作是指不会被线程调度机制打断的操作。这种操作一旦开始，就一直运行到结束，中间不会有任何context switch（切换到另一个线程）。</p><p>​    实现原子操作可以使用锁，锁机制对于满足基本的原子需求是没问题的，但<strong>synchronized</strong>是基于阻塞的锁机制，也就是当一个线程拥有锁时，访问同一资源的其他线程需要等待，直到该线程释放锁。</p><p>​    同时基于<strong>synchronized</strong>实现原子操作也会出现很多问题。</p><ul><li><ul><li>优先级低的线程抢到锁，被阻塞的线程优先级很高很重要怎么办？</li><li>获得锁的线程一直不释放锁怎么办？</li><li>有大量的线程来竞争资源，则CPU会花费大量时间和资源来处理这些竞争。</li><li>死锁问题处理。</li></ul></li></ul><p>​    其实锁机制是一种较为粗糙，粒度比较大的机制，对于一些简单的需求，如计数器显得有点过于笨重。</p><p>\2.  CAS实现原理 </p><p>​    现代处理器基本都支持CAS指令，每一个CAS操作过程都包含三个运算符：<strong>内部地址****V</strong>、<strong>期望值****A</strong>、<strong>新值****B</strong>。操作时如果这个<strong>内存地址<strong><strong>V</strong></strong>上</strong>存放的值等于<strong>期望值****A</strong>，则将内存地址上的值修改为新值B，否则不做任何操作。常见的CAS循环其实就是在一个循环里不断的做CAS操作，直到成功为止。</p><p>​    CAS对于线程安全的实现，其是语言层面无任何处理，我们将其交CPU和内存完成，利用多核CPU的处理能力，实现硬件层面的阻塞，再加上volatile关键字的特性即可实现基于原子操作的线程安全。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image056.gif" class="" title="img"><p>\3.  悲观锁、乐观锁</p><p>悲观锁</p><p>悲观锁总是假设会出现最坏的情况，每次去获取数据时，都会认为别人会修改，所以每次在获取数据时都会上锁。这样别人想拿到这个数据就会阻塞，直到它获取到锁。在关系型数据库中就大量应用了这种锁机制，如行锁、表锁、读锁、写锁。都是在操作前先上锁。Java中<strong>synchronized</strong>就是很直观的体现。</p><p>乐观锁</p><p>乐观锁总是假设一直都是最好的情况。每次获取时都认为别人不会修改，所以不会上锁，但是在更新时会判断在此期间别人有没有更新这个数据，可以使用版本号实现。乐观锁适用于<strong>读多写少</strong>的场景。这样可以提升系统吞吐量，而CAS就是一种乐观锁的实现。</p><p>\4.   CAS的典型问题</p><p>ABA</p><p>一个线程a将数值改成了b，接着又改成了a，此时CAS认为是没有变化，其实是已经变化过了，这种过程就叫ABA问题。对于ABA问题的解决，常见的解决方式就是通过添加数据版本号实现</p><p>循环时间长开销大</p><p>CAS会基于CPU进行自旋操作，如果CAS失效，就会一直进行尝试，如果自旋时间过长，会给CPU带来巨大性能开销。在高并发下，compareAndSet会很大概率</p><p>失败，因此导致了CPU不断自旋，造成CPU性能浪费。</p><p>只能保证一个共享变量的原子操作</p><p>当对一个变量执行操作时，可以使用CAS循环方式保证原子操作，但对多个变量操作时，CAS则无法保证操作的原子性。因为对于一个内存地址来说，其内部只会存储一个变量。如果要对多个变量操作的话，则需要使用到锁或者进行合并(i&#x3D;2,j&#x3D;3 -&gt; 合并ij为一个变量 -&gt; 包装为一个引用类型 -&gt; 进行原子操作)。</p><h1 id="atomic原子操作类"><a href="#atomic原子操作类" class="headerlink" title="atomic原子操作类"></a>atomic原子操作类</h1><h2 id="原子更新基本类型"><a href="#原子更新基本类型" class="headerlink" title="原子更新基本类型"></a><strong>原子更新基本类型</strong></h2><p>AtomicInteger、AtomicBoolean、AtomicLong</p><p>1）**int addAndGet(i)**：以原子的方式将输入的数字与AtomicInteger里的值相加，并返回结果。</p><p>2）boolean compareAndSet(int expect, int update)：如果输入的数值等于预期值，则以原子方式将该值设置为输入的值</p><p>3）<strong>int incrementAndGet()<strong>：对原值+1，并返回操作后的值。类似与redis中的increment命令。相反的还有</strong>decrementAndGet()</strong></p><p>4）int getAndAdd(int delta)：原值加上指定值，并返回修改前的值。</p><p>5）int getAndSet(int newValue)：将原值修改为新值，并返回修改前的值。</p><p>6）**int getAndIncrement()**：原值加1，返回修改前的值。对应的还有getAndDecrement()</p><h2 id="原子更新数组"><a href="#原子更新数组" class="headerlink" title="原子更新数组"></a>原子更新数组</h2><p><strong>AtomicIntegerArray</strong>、<strong>AtomicLongArray</strong>、<strong>AtomicReferenceArray</strong>。</p><p>&#x2F;&#x2F;执行加法，第一个参数为数组的下标，第二个参数为增加的数量，返回增加后的结果</p><p>int addAndGet(int i, int delta)</p><p>&#x2F;&#x2F;对比修改，参1数组下标，参2原始值，参3修改目标值，成功返回true否则false</p><p>boolean compareAndSet(int i, int expect, int update)</p><p>&#x2F;&#x2F;参数为数组下标，将数组对应数字减少1，返回减少后的数据</p><p>int decrementAndGet(int i)</p><p>&#x2F;&#x2F; 参数为数组下标，将数组对应数字增加1，返回增加后的数据</p><p>int incrementAndGet(int i)</p><p>&#x2F;&#x2F;和addAndGet类似，区别是返回值是变化前的数据</p><p>int getAndAdd(int i, int delta)</p><p>&#x2F;&#x2F;和decrementAndGet类似，区别是返回变化前的数据</p><p>int getAndDecrement(int i)</p><p>&#x2F;&#x2F;和incrementAndGet类似，区别是返回变化前的数据</p><p>int getAndIncrement(int i)</p><p>&#x2F;&#x2F; 将对应下标的数字设置为指定值，第一个参数数组下标，第二个参数为设置的值，返回是变化前的数据 </p><p>getAndSet(int i, int newValue)</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image058.jpg" class="" title="img"><p>此时可以看到从AtomicIntegerArray获取的值与原传入数组的值不同。这是因为数组是通过构造方法传递，然后AtomicIntegerArray会将当前传入数组复制一份。因此当AtomicIntegerArray对内部数组元素进行修改时，不会影响原数组。</p><h2 id="原子更新引用类型"><a href="#原子更新引用类型" class="headerlink" title="原子更新引用类型"></a>原子更新引用类型</h2><p>通过CAS只能保证一个共享变量的原子操作，当多个的话，就需要使用到锁。如果要更新多个变量，就需要使用Atomic包中的三个类，分别为：</p><p><strong>AtomicReference</strong>(用于原子更新引用类型)、</p><p><strong>AtomicMarkableReference</strong>(用于原子更新带有标记位的引用类型)、<strong>AtomicStampedReference</strong>(用于原子更新带有版本号的引用类型)。</p><p><strong>AtomicMarkableReference</strong>可以用于解决CAS中的ABA的问题。</p><p><strong>AtomicStampedReference</strong>会基于版本号思想解决ABA问题，根据源码可知，其内部维护了一个Pair对象，<strong>Pair</strong>对象记录了对象引用和时间戳信息，实际使用的时候，要保证时间戳唯一，如果时间戳如果重复，还会出现<strong>ABA</strong>的问题。</p><p>AtomicStampedReference中的每一个引用变量都带上了pair.stamp这个时间戳，这样就可以解决CAS中的ABA的问题。</p><h2 id="原子更新字段类"><a href="#原子更新字段类" class="headerlink" title="原子更新字段类"></a>原子更新字段类</h2><p>当需要原子更新某个类里的某个字段时，就需要使用原子更新字段类。Atomic包下提供了3个类</p><p><strong>AtomicIntegerFieldUpdater</strong>(原子更新整型字段)、<strong>AtomicLongFieldUpdater</strong>(原子更新长整型字段)、<strong>AtomicReferenceFieldUpdater</strong>(原子更新引用类型字段)</p><p>原子更新字段类都是抽象类，每次使用都时候必须使用静态方法newUpdater创建一个更新器。原子更新类的字段的必须使用public volatile修饰符。</p><h2 id="JDK1-8新增原子类"><a href="#JDK1-8新增原子类" class="headerlink" title="JDK1.8新增原子类"></a>JDK1.8新增原子类</h2><p>LongAdder：长整型原子类</p><p>DoubleAdder：双浮点型原子类</p><p>LongAccumulator：类似LongAdder，但要更加灵活(要传入一个函数式接口)</p><p>DoubleAccumulator：类似DoubleAdder，但要更加灵活(要传入一个函数式接口)</p><p>以LongAdder为例，其内部提供的API基本上可以替换原先的AtomicLong。</p><p>​    LongAdder类似于AtomicLong是原子性递增或者递减类，AtomicLong已经通过CAS提供了非阻塞的原子性操作，相比使用阻塞算法的同步器来说性能已经很好了，但是JDK开发组并不满足，因为在非常高的并发请求下AtomicLong的性能不能让他们接受，虽然AtomicLong使用CAS但是CAS失败后还是通过无限循环的自旋锁不断尝试。</p><p>​    在高并发下N多线程同时去操作一个变量会造成大量线程CAS失败然后处于自旋状态，这大大浪费了cpu资源，降低了并发性。那么既然AtomicLong性能由于过多线程同时去竞争一个变量的更新而降低的，那么如果把一个变量分解为多个变量，让同样多的线程去竞争多个资源那么性能问题不就解决了？是的，JDK8提供的LongAdder就是这个思路。</p><p>在并发比较低的时候，LongAdder和AtomicLong的效果非常接近。但是当并发较高时，两者的差距会越来越大。</p><h1 id="示锁-Lock"><a href="#示锁-Lock" class="headerlink" title="示锁(Lock)"></a>示锁(Lock)</h1><h2 id="基础介绍"><a href="#基础介绍" class="headerlink" title="基础介绍"></a>基础介绍</h2><p>在程序中可以通过synchronized实现锁功能，对于它可以称为内置锁，是由Java语言层面直接为我们提供使用的。可以在程序中隐式的获取锁。但是对于它的使用方式是固化的，只能先获取再释放。而且在使用的过程中，当一个线程获取到某个资源的锁后，其他线程再要获取该资源则必须要进行等待。synchronized并没有提供中断或超时获取的操作。</p><p>为了解决这些问题，所以才出现了显示锁。在显示锁中其提供了三个很常见方法：lock()、unLock()、tryLock()。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image060.jpg" class="" title="lock. lock();  try(  lock.unLock();"><p>在 finally 块中释放锁，目的是保证在获取到锁之后，最终能够被释放。不要将获取锁的过程写在try块中，因为如果在获取锁（自定义锁的实现）时发生了异常，异常抛出的同时，也会导致锁无故释放。（因为一旦发生异常，就会走finally语句，如果这个异常（可能是用户自定义异常，用户可以自己处理）需要线程1来处理，但是接着执行了lock.unlock()语句导致了锁的释放。那么其他线程就可以操作共享资源。有可能破坏程序的执行结果）。</p><p>何时选择用synchronized还是Lock</p><p>如果在锁的使用过程中，不需要考虑尝试取锁或锁中断的这些特性的话。尽量使用synchronized。因为synchronized在现在的JDK中对于synchronized的优化是很多的。如锁优化升级。</p><p>同时synchronized要比显示锁的内存消耗要少。为什么呢？ 因为synchronized是一个语言层面的内容，而lock是一个接口，在使用Lock时需要获取其对象实例后才能进行操作。特别在锁很多的情况下，如没特殊需求，建议使用synchronized。</p><p>synchronized的使用要么作用在方法，要么作用在语句块。当出现异常后，代表脱离了执行的代码块，锁自然就会被释放。而显示锁本身是一个对象的实例，如果加锁后，没有进行释放的话，那么锁就会一直存在。</p><h2 id="ReentrantLock"><a href="#ReentrantLock" class="headerlink" title="ReentrantLock"></a>ReentrantLock</h2><h3 id="可重入"><a href="#可重入" class="headerlink" title="可重入"></a>可重入</h3><p>ReentrantLock可重入</p><p>ReentrantLock一般会把它称之为<strong>可重入锁</strong>，其是一种递归无阻塞的同步机制。它可以等同于synchronized的使用，但是ReentrantLock提供了比synchronized更强大、灵活的锁机制，可以减少死锁发生的概率。</p><p>简单来说就是：<strong>同一个线程对于已经获取的锁，可以多次继续申请到该锁的使用权</strong>。而 synchronized 关键字隐式的支持重进入，比如一个 synchronized修饰的递归方法，在方法执行时，执行线程在获取了锁之后仍能连续多次地获得该锁。ReentrantLock 在调用 lock()方法时，已经获取到锁的线程，能够再次调用lock()方法获取锁而不被阻塞。</p><p>​    其内部实现流程为：</p><ol><li>每个锁关联一个线程持有者和计数器，当计数器为0时表示该锁没有被任何线程持有，那么线程都会可能获得该锁而调用对应方法。</li><li>当某个线程请求成功后，JVM会记录锁的持有线程，并将计数器置为1，此时其他线程请求获取锁，则必须等待。</li><li>当持有锁的线程如果再次请求这个锁，就可以再次拿到这个锁，同时计数器递增。</li><li>当持有锁的线程退出同步代码块时，计数器递减，如果计数器为0，则释放该锁。</li></ol><p>synchronized可重入</p><p>当同一个线程调用多个同步方法时，当其第一次获取锁成功时，接着调用其他同步方法时，仍然可以继续向下调用，不会发生阻塞。实现了锁的可重入。</p><h3 id="公平锁与非公平锁"><a href="#公平锁与非公平锁" class="headerlink" title="公平锁与非公平锁"></a>公平锁与非公平锁</h3><p>在多线程并发执行中，当有多个线程同时来获取同一把锁，如果是按照谁等待时间最长，谁先获取锁，则代表这是一把公平锁。反之如果是随机获取的话，CPU时间片轮询到哪个线程，哪个线程就获取锁，则代表这是一把非公平锁。</p><p>那么公平锁和非公平锁哪个性能最好呢？ 答案是非公平锁的性能更好，因为其充分利用了CPU，减少了线程唤醒的上下文切换的时间。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image062.jpg" class="" title="ReentrantLock 中 的 公 平 锁 和 非 公 平 锁 的 底 层 实 现  首 先 不 管 是 公 平 锁 非 公 平 锁 。 它 们 的 底 层 实 现 都 会 使 用 AQS 来 洪 行 排 队 。 它 们 的 区 别 在 于 ： 线 程 在 使 用 》 。 鹵 〕 方 法 加 《 赶 如 果 是 公 平 锁 。 会 光 检  队 列 中 是 否 存 在 线 程 在 排 队 ， 如 果 有 线 悍 在 排 队 ， 贝 刂 当 前 线 也 进 行 排 队 ， 如 果 是 非 公 平 锁 ， 则 不 会 去 0 是 否 有 线 在 排 队 ， 而 是 白 接 竟 争  锁 。  不 管 是 公 平 锁 还 早 非 公 平 锁 ， 一 没 霓 争 到 锁 ， 都 会 行 排 队 ， 当 锁 释 放 时 ， 都 是 酶 排 在 吊 前 面 惺 ， 所 以 菲 平 锁 只 是 体 现 在 了 线 程 就 锁 阶  段 ， 而 没 有 体 现 在 线 程 被 埙 睚 阶 段 。  另 外 ， 入 顶， 不 管 是 公 平 还 皇 菲 公 平 锁 都 是 可 童 入"><p>在ReentrantLock和synchronized中，默认都为非公平锁。ReentrantLock可以通过参数将其开启使用公平锁。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image064.gif" class="" title="* Creates an instance of {@code ReentrantLock} with the  * given fairness policy.  * @param fair {@code true} if this Lock should use a fair ordering policy  public ReentrantLock(bootean fair) { sync &#x3D;  fair ? new FairSync()  new NonfairSync() ;"><p>参数：True 公平</p><p> 不传参 非公平</p><h3 id="ReentrantLock与synchronized的比较"><a href="#ReentrantLock与synchronized的比较" class="headerlink" title="**ReentrantLock与synchronized的比较"></a>**ReentrantLock与synchronized的比较</h3><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image066.jpg" class="" title="sychronized*QReentrantLockfiXBlJ  1. ReentrantLockH—ÎŠ  2.sychronizedžsĂtlffJjU@îłsgngtî,  4."><p><strong>相似点：</strong></p><p>​    都是以阻塞性方式进行加锁同步，也就是说如果当一个线程获得了对象锁，执行同步代码块，则其他线程要访问都要阻塞等待，直到获取锁的线程释放锁才能继续获取锁。</p><p><strong>不同点：</strong></p><ul><li>对于Synchronized来说，它是java语言的关键字，是原生语法层面的互斥，需要jvm实现。而ReentrantLock它是JDK 1.5之后提供的API层面的互斥锁，需要lock()和unlock()方法配合try&#x2F;finally语句块来完成。</li><li>Synchronized的使用比较方便简洁，并且由编译器去保证锁的加锁和释放，而ReenTrantLock需要手工声明来加锁和释放锁，为了避免忘记手工释放锁造成死锁，所以最好在finally中声明释放锁。</li><li>ReenTrantLock的锁粒度和灵活度要优于Synchronized。</li></ul><p>一、synchronized和lock的用法区别</p><p>synchronized：在需要同步的对象中加入此控制，synchronized可以加在方法上，也可以加在特定代码块中，括号中表示需要锁的对象。 </p><p>lock：需要显示指定起始位置和终止位置。一般使用ReentrantLock类做为锁，多个线程中必须要使用一个ReentrantLock类做为对象才能保证锁的生效。且在加锁和解锁处需要通过lock()和unlock()显示指</p><p>出。所以一般会在finally块中写unlock()以防死锁。 </p><p>二、synchronized和lock性能区别 </p><p>synchronized是托管给JVM执行的，而lock是java写的控制锁的代码。在Java1.5中，synchronize是性能低效的。因为这是一个重量级操作，需要调用操作接口，导致有可能加锁消耗的系统时间比加锁以外的操作还多。相比之下使用Java提供的Lock对象，性能更高一些。但是到了Java1.6，发生了变化。synchronize在语义上很清晰，可以</p><p>进行很多优化，有适应自旋，锁消除，锁粗化，轻量级锁，偏向锁等等。导致在Java1.6上synchronize的性能并不比Lock差。</p><p>据我所知，synchronized原始采用的是CPU悲观锁机制，即线程获得的是独占锁。独占锁意味着其他线程只能依靠阻塞来等待线程释放锁。而在CPU转换线程阻塞时会引起线程上下文切换，当有很多线程竞争锁的时候，会引起CPU频繁的上下文切换导致效率很低。 而Lock用的是乐观锁方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。乐观锁实现的机制就是CAS操作（Compare and Swap）。我们可以进一步研究ReentrantLock的源代码，会发现其中比较重要的获得锁的一个方法是compareAndSetState。这里其实就是调用的CPU提供的特殊指令。现代的CPU提供了指令，可以自动更新共享数据，而且能够检测到其他线程的干扰，而 compareAndSet() 就用这些代替了锁定。这个算法称作非阻塞算法，意思是一个线程的失败或者挂起不应该影响其他线程的失败或挂起的算法。</p><p><a href="https://blog.csdn.net/natian306/article/details/18504111">https://blog.csdn.net/natian306/article/details/18504111</a></p><h3 id="tryLock和lock的区别"><a href="#tryLock和lock的区别" class="headerlink" title="tryLock和lock的区别"></a>tryLock和lock的区别</h3><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image068.jpg" class="" title="i"><h2 id="ReentrantReadWriteLock"><a href="#ReentrantReadWriteLock" class="headerlink" title="ReentrantReadWriteLock"></a>ReentrantReadWriteLock</h2><p>ReentrantLock或synchronized都可以称之为<strong>独占锁、排他锁</strong>，可以理解为是悲观锁，这些锁在同一时刻只允许一个线程进行访问。但是对于互联网应用来说，绝大多数的场景都是读多写少，比例大概在10：1。按照数据库的场景来说，对于读多写少的处理，就会进行读写分离。</p><p>在读多写少的场景下，对于业务代码的处理，此时也可以考虑进行读写分别加锁的操作，此时就可以使用ReentrantReadWriteLock。其对ReadWriteLock接口进行实现，内部会维护一对锁，分别为读锁、写锁。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image070.gif" class="" title="img"><p><strong>读写锁特性</strong></p><ol><li>读操作不互斥，写操作互斥，读和写互斥。</li><li>公平性：支持公平性和非公平性。</li><li>重入性：支持锁重入。</li><li>锁降级：写锁能够降级成为读锁，遵循获取写锁、获取读锁在释放写锁的次序。读锁不能升级为写锁。</li></ol><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image072.gif" class="" title="img"><p><strong>读写锁实现原理</strong></p><p>ReentrantReadWriteLock实现接口ReadWriteLock，该接口维护了一对相关的锁，一个用于读操作，另一个用于写入操作。</p><p>ReadWriteLock定义了两个方法。readLock()返回用于读操作的锁，writeLock()返回用于写操作的锁。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image074.gif" class="" title="img"><p><strong>锁降级</strong></p><p>​    读写锁是支持锁降级的，但不支持锁升级。写锁可以被降级为读锁，但读锁不能被升级写锁。什么意思呢？简单来说就是<strong>获取到了写锁的线程能够再次获取到同一把锁的读锁</strong>，因为支持提到过ReentrantReadWriteLock这把锁内部是维护了两个锁的。 而<strong>获取到了读锁的线程不能再次获取同一把锁的写锁</strong>。</p><h2 id="StamptedLock"><a href="#StamptedLock" class="headerlink" title="StamptedLock"></a>StamptedLock</h2><p>StampedLock类是在JDK8引入的一把新锁，其是对原有ReentrantReadWriteLock读写锁的增强，增加了一个乐观读模式，内部提供了相关API不仅优化了读锁、写锁的访问，也可以让读锁与写锁间可以互相转换，从而更细粒度的控制并发。</p><h2 id="ReentrantReadWriteLock存在的问题"><a href="#ReentrantReadWriteLock存在的问题" class="headerlink" title="ReentrantReadWriteLock存在的问题"></a>ReentrantReadWriteLock存在的问题</h2><p>在使用读写锁时，还容易出现写线程饥饿的问题。主要是因为读锁和写锁互斥。比方说：当线程 A 持有读锁读取数据时，线程 B 要获取写锁修改数据就只能到队列里排队。此时又来了线程 C 读取数据，那么线程 C 就可以获取到读锁，而要执行写操作线程 B 就要等线程 C 释放读锁。由于该场景下读操作远远大于写的操作，此时可能会有很多线程来读取数据而获取到读锁，那么要获取写锁的线程 B 就只能一直等待下去，最终导致饥饿。</p><p>对于写线程饥饿问题，可以通过公平锁进行一定程度的解决，但是它是以牺牲系统吞吐量为代价的。</p><p><strong>StampedLock****特点</strong></p><p>1）获取锁的方法，会返回一个票据（stamp），当该值为0代表获取锁失败，其他值都代表成功。</p><p>2）释放锁的方法，都需要传递获取锁时返回的票据，从而控制是同一把锁。</p><p>3）StampedLock是<strong>不可重入的</strong>，如果一个线程已经持有了写锁，再去获取写锁就会造成死锁。</p><p>4）StampedLock提供了三种模式控制读写操作：写锁、悲观读锁、乐观读锁</p><p>写锁：</p><p>  使用类似于ReentrantReadWriteLock，是一把独占锁，当一个线程获取该锁后，其他请求线程会阻塞等待。 对于一条数据没有线程持有写锁或悲观读锁时，才可以获取到写锁，获取成功后会返回一个票据，当释放写锁时，需要传递获取锁时得到的票据。</p><p>悲观读锁：</p><p>  使用类似于ReentrantReadWriteLock，是一把共享锁，多个线程可以同时持有该锁。当一个数据没有线程获取写锁的情况下，多个线程可以同时获取到悲观读锁，当获取到后会返回一个票据，并且阻塞线程获取写锁。当释放锁时，需要传递获取锁时得到的票据。</p><p>乐观读锁：</p><p>  这把锁是StampedLock新增加的。可以把它理解为是一个悲观锁的弱化版。当没有线程持有写锁时，可以获取乐观读锁，并且返回一个票据。值得注意的是，它认为在获取到乐观读锁后，数据不会发生修改，获取到乐观读锁后，其并不会阻塞写入的操作。</p><p>  那这样的话，它是如何保证数据一致性的呢？ 乐观读锁在获取票据时，会将需要的数据拷贝一份，在真正读取数据时，会调用StampedLock中的API，验证票据是否有效。如果在获取到票据到使用数据这期间，有线程获取到了写锁并修改数据的话，则票据就会失效。 如果验证票据有效性时，当返回true，代表票据仍有效，数据没有被修改过，则直接读取原有数据。当返回flase，代表票据失效，数据被修改过，则重新拷贝最新数据使用。</p><p>  乐观读锁适用于一些很短的只读代码，它可以降低线程之间的锁竞争，从而提高系统吞吐量。但对于读锁获取数据结果必须要进行校验。</p><p>在StampedLock中读锁和写锁可以相互转换，而在ReentrantReadWriteLock中，写锁可以降级为读锁，而读锁不能升级为写锁。</p><h1 id="AQS"><a href="#AQS" class="headerlink" title="AQS"></a>AQS</h1><p>AQS(AbstractQueuedSynchronizer），即队列同步器。它是构建锁或者其他同步组件的基础框架（如ReentrantLock、ReentrantReadWriteLock、Semaphore等）</p><h2 id="CLH队列锁"><a href="#CLH队列锁" class="headerlink" title="CLH队列锁"></a><strong>CLH</strong>队列锁</h2><p>CLH队列锁即Craig, Landin, and Hagersten (CLH) locks。这是三个人的名字。 同时它也是现在PC机内部对于锁的实现机制。<strong>Java中的AQS就是基于CLH队列锁的一种变体实现。</strong></p><p>​    CLH 队列锁也是一种基于<strong>单向链表</strong>的可扩展、公平的<strong>自旋锁</strong>，申请线程仅仅在本地变量上自旋，它不断轮询前驱的状态，假设发现前驱释放了锁就结束自旋。</p><p>​    1）现在有一个队列，队列中的每一个QNode对应一个请求获取锁的线程，Qnode中包含两个属性，分别为myPred（前驱节点的引用）、locked（是否需要获取锁）</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image076.gif" class="" title="img"><p>​    2）当多个线程要请求获取锁时，则会按照请求顺序放入队列中。同时将myPred指向前驱节点的引用。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image078.gif" class="" title="img"><p>​    3）线程会对自己的myPred进行不断自旋查询，查看前驱节点是否释放锁。一旦发现前驱节点释放锁（locked属性变为false），则其会马上进行锁的获取。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image080.gif" class="" title="img"><p>​    4）当后续节点获取到锁后，则将原有的前驱节点从队列中移除。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image082.gif" class="" title="img"><h2 id="AQS的实现"><a href="#AQS的实现" class="headerlink" title="AQS的实现"></a>AQS的实现</h2><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image084.jpg" class="" title="四 、 谈 谈 你 对 AQS 的 理 解 。 AQS 如 何 实 现 可 重 入 锁 ？  1 ． QS 是 一 个 VA 线 片 同 步 的 眶 架 。 是 型 卜 中 很 多 锁 I 貝 的 以 现 眶 架 。  2 ． 中 ， 护 了 一 巪 05 和 一 个 线 程 沮 的 双 向 适 表 队 列 · 其 中 ， 这 臧 程 队 列 · 就 是 閹 来 线 陧 鼕 的 ， 而  訕 e 就 是 一 令 纟 I 象 用 来 厚 线 片 痱 从 或 者 行 的 。 在 不 同 的 巧 下 ， 有 不 用 的 0 义 ·  3 ， 在 可 0 人 锁 这 个 砀 到 下 ， 5 就 閹 来 不 力 过 的 次 数 · 0 标 丰 无 锁 ， 孬 一 次 ， 5 te 犹 加 1. 释 就 减 1 ·"><p>AQS本身是一个抽象类，其主要使用方式是继承，子类通过继承AQS并实现其内部定义的抽象方法。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image086.gif" class="" title="AbstractQueuedSynchronizer  Node  ConditionObject  static class initializer  try {  st...  AbstractQueuedSynchronizer0  getState0: int  setState(int): void  compareAndSetState(int, int): boolean  enq(Node): Node  addWaiter(Node): Node  setHead(Node): void  unparkSuccessor(Node): void  doReleaseShared0: void  setHeadAndPropagate(Node, int): void  cancelAcquire(Node): void  shouldParkAfterFailedAcquire(Node, Node): boole  selflnterrupt(): void  parkAndChecklnterrupt0: boolean  acquireQueued(Node, int): boolean  doAcquirelnterruptibly(int): void  doAcquireNanos(int, long): boolean  doAcquireShared(int): void  doAcquireSharedlnterruptibly(int): void  280  281  282  283  284  285  286  287  288  289  290  291  292  293  294  295  296  297  298  299  *  *  *  *  void signal()  public  public  sync .  @since 1.5  { sync. releaseShared(1);  void await() throws InterruptedException {  acquireSharedInterruptibty(1);  @author Doug Lea  public abstract class AbstractQueuedSynchronizer  extends AbstractOwnabteSynchronizer  implements java.io.Seriatizabte {  private static final tong serial VersionlJID  &#x3D; 7373984972572414691L;  * Creates a new {@code AbstractQueuedSynchronizer} instance  * with initial synchronization state of zero.  protected AbstractQueuedSynchronizer() {"><p>ReentrantLock、ReentrantReadWriteLock其内部其实都是基于AQS实现的。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image088.gif" class="" title="public class ReentrantLock implements Lock java.io. Serializabte {  private static final tong serial VersionlJID  &#x3D; 7373984872572414699L;  &#x2F; ** Synchronizer providing alt implementation mechanics  private final Sync sync;  * Base of synchronization control for this Lock. Subclassed  * into fair and nonfair versions below. Uses AQS state to  * represent the number of holds on the tock.  abstract static class Sync extends AbstractQueuedSynchronizer {  private static final tong serial VersionlJID - -  #10Ck}. The main reason for subclassing  * Performs {@tink  Lock  * is to allow fast path for nonfair version.  abstract void tock();"><p>他们两个并没有直接继承AQS，而是在其内部扩展了静态内部类来继承AQS。 这么做的原因，其思想就是通过区分使用者和实现者，来让使用者可以更加方便的完成对于锁的操作。</p><p>锁是面向使用者的，它定义了锁与使用者的交互实现方式，同时隐藏了实现细节。而AQS面向的是锁的实现者，其内部完成了锁的实现方式。从而通过区分锁和同步器让使用者和实现者能够更好的关注各自的领域。</p><p>AQS的设计模式使用的是<strong>模版设计模式</strong>。通过源码可以看到，在AQS中其并没有对方法进行具体实现，这些方法都是需要开发者自行来实现的。</p><p>模版设计模式在开发中涉及的非常多，简单来说就是：在一个方法中定义一个流程的骨架，对于流程的具体实现让其在子类中完成。以Spring为例，其内部就大量应用到了模版设计模式，如JDBCTemplate、RedisTemplate、RabbitTemplate等等。</p><p>AQS中的模版模式</p><p>其内部的模版方法大致可以分为三类：</p><ul><li>xxSharedxx：共享式获取与释放，如读锁。(共享锁就是多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改。)</li><li>acquire：独占式获取与释放，如写锁。(排他锁就是不能与其他所并存，如一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的其他锁)</li><li>查询同步队列中等待线程情况。</li></ul><p>AQS的同步状态</p><p>​    AQS对于锁的操作是通过同步状态切换来完成的，其有一个变量state，用于表示线程获取锁的状态。当state&gt;0时表示当前已有线程获取到了资源，当state &#x3D; 0时表示释放了资源。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image090.gif" class="" title="* The synchronization state.  private volatile int state;"><p>​    在多线程下，一定会有多个线程来同时修改state变量，所以在AQS中也提供了一些方法能够安全的对state值进行修改。分别为：</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image092.gif" class="" title="* Returns the current value of synchronization state.  * This operation has memory semantics of a {@code volatile} read.  * @return current state value  protected final int getState() {  return state;"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image094.gif" class="" title="* Sets the value of synchronization state.  * This operation has memory semantics of a {@code volatile} write.  * @param newState the new state value  protected final void setState(int newState) {  state  &#x3D; newState;"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image096.gif" class="" title="*  *  *  *  *  Atomically sets synchronization state to the given updated  value if the current state value equals the expected value.  This operation has memory semantics of a {@code volatile} read  and write.  @param expect the expected value  @param update the new value  @return {@code true} if SUCCeSSfUL. False return indicates that the actual  value was not equal to the expected value.  protected final boolean compareAndSetState(int expect, int update) {  &#x2F;&#x2F; See below for intrinsics setup to support this  return unsafe . compareAndSwapInt( o: this, state0ffset, expect, update) ;"><p> AQS实现原理</p><h3 id="Node节点"><a href="#Node节点" class="headerlink" title="Node节点"></a>Node节点</h3><p>​    之前提到过AQS是基于CLH队列锁的思想来实现的，其内部不同于CLH单向链表，而是使用的是<strong>双向链表</strong>。那么对于一个队列来说，其内部一定会通过一个节点来保存线程信息，如：前驱节点、后继节点、当前线程节点、线程状态这些信息。</p><p>​    根据源码可知，AQS内部定义一个Node对象用于存储这些信息。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image098.gif" class="" title="AbstractQueuedSynchronizer  Node  Node()  o  o  o  Node(Thread, Node)  Node(Thread, int)  isShared0: boolean  predecessor(): Node  SHARED: Node new Node()  EXCLUSIVE: Node null  CANCELLED: int  SIGNAL: int  CONDITION: int  PROPAGATE: int  waitStatus: int  prev: Node  next: Node  thread: Thread  nextWaiter: Node  -2  -3"><p><strong>两种线程等待模式：</strong></p><ul><li>SHARED：表示线程以<strong>共享模式等待锁</strong>，如读锁。</li><li>EXCLUSIVE：表示线程以<strong>独占模式等待锁</strong>，如写锁。<br> <strong>五种线程状态：</strong></li><li>初始Node对象时，默认值为0。</li><li>CANCELLED：表现线程获取锁的请求已经取消，值为1。</li><li>SINNAL：表现线程已经准备就绪，等待锁空闲给我，值为-1。</li><li>CONDITION：表示线程等待某一个条件被满足，值为-2。</li><li>PROPAGETE：当线程处于SHARED模式时，该状态才会生效，用于表示线程可以被共享传播，值为-3。<br> <strong>五个成员变量：</strong></li><li>waitStatus：表示线程在队列中的状态，值对应上述五种线程状态。</li><li>prev：表示当前线程的前驱节点。</li><li>next：表示当前线程的后继节点。</li><li>thread：表示当前线程。</li><li>nextWaiter：表示等待condition条件的节点。</li></ul><p>同时在AQS中还存在两个成员变量，head和tail，分别代表队首节点和队尾节点。</p><h3 id="节点在同步队列的操作"><a href="#节点在同步队列的操作" class="headerlink" title="节点在同步队列的操作"></a>节点在同步队列的操作</h3><p>​    在多线程并发争抢同步状态（锁）时，按照队列的FIFO原则，AQS会将获取锁失败的线程包装为一个Node放入队列尾部中。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image100.gif" class="" title="head  tail  Node  prev  next  Node  prev  ne  Node  rev  next"><p>​    对于加入队列的过程需要保证线程安全，AQS提供了一个基于CAS设置尾节点的方法<code>compareAndSetTail(Node expect,Node update)</code>。其需要传递当前期望的尾节点和当前节</p><p>点，当返回true，当前节点才与队列中之前的尾节点建立连接。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image102.gif" class="" title="Node  head  prev  next  tail  AQSßÅ5J  Node  prev  ne  Node  rev  next  Node  compareAndSetTail  c  mpareAndSet il  rev  next"><p>​    此时可以现头结点一定是获取锁成功的节点，头节点在释放锁时，会唤醒其后继节点。当后继节点获取锁成功后，则头节点的指针会指向该后继节点作为当前队列的头节</p><p>点，接着将原先的头结点从队列中移除。</p><p>​    对于该流程来说，只有一个线程能够获取到同步状态，因此不需要CAS进行保证。</p><p>只需要重新移动头部指针并断开原有引用连接即可。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image104.gif" class="" title="Node  compareAndSetTail  head  tail  AQSßÅ5J  Node  prev  ne  Node  prev  next  Node  rev  next  c mpareAndSet il  rev  next"><p>示例：</p><p>A线程进来了，当前窗口没有人，就会占用窗口（Thread &#x3D; ThreadA），并且state &#x3D; 1；</p><p>B线程进来的，不能占用窗口，队列为空，构建哨兵节点</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image106.jpg" class="" title="img"><p>构建完哨兵节点，在将B线程放入队列</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image108.jpg" class="" title="img"><p>c线程也是一样的操作，放到队列中</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image110.jpg" class="" title="img"><p>B还是会去抢占锁，还是失败后，就会调用park，真正去阻塞（真正在队列中等待）</p><p>c也一样</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image112.jpg" class="" title="img"><p>线程A调用unlock（）释放资源</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image114.jpg" class="" title="img"><p>这时候就会唤醒头节点的下一个节点（也就是B线程），B占用资源之后，就会将链表中的B节点编程哨兵节点，原哨兵会jc掉</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image115.jpg" class="" title="img"><p>这是原来的哨兵节点就是完全孤立的一个节点，此时 nodeB 作为新的哨兵节点</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image117.jpg" class="" title="img"><h1 id="Fork-Join分解合并框架"><a href="#Fork-Join分解合并框架" class="headerlink" title="Fork&#x2F;Join分解合并框架"></a>Fork&#x2F;Join分解合并框架</h1><p>同时其按照<strong>分而治之</strong>的思想，可以把一个大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架。</p><p>对于Fork&#x2F;Join框架的理解可以认为其由两部分组成，Fork就是把一个大任务切分为若干个子任务并行执行。Join就是合并这些子任务的执行结果，最后得到这个大任务的结果。</p><h3 id="工作窃取算法"><a href="#工作窃取算法" class="headerlink" title="工作窃取算法"></a>工作窃取算法</h3><p>即当前线程的 Task 已经全被执行完毕，则自动取到其他线程的 Task 池中取出 Task 继续执行。ForkJoinPool 中维护着多个线程（一般为 CPU 核数）在不断地执行 Task，每个线程除了执行自己任务列表内的 Task 之外，还会根据自己工作线程的闲置情况去获取其他繁忙的工作线程的 Task，如此一来就能能够减少线程阻塞或是闲置的时间，提高 CPU 利用率。</p><h3 id="Fork-Join的使用"><a href="#Fork-Join的使用" class="headerlink" title="Fork&#x2F;Join的使用"></a>Fork&#x2F;Join的使用</h3><p>基本概念</p><p>​    要使用Fork&#x2F;Join的话，首先需要有一个Pool。通过它可以来执行任务。 而每一个任务叫做ForkJoinTask，其内部提供了fork和join的操作机制。通常情况下开发者不需要直接继承ForkJoinTask，而是继承它的子类。分别为：</p><p>- <strong>RecursiveAction</strong>：返回没有结果的任务。</p><p>- **RecursiveTask<T>**：返回有结果的任务。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image119.gif" class="" title="img"><p>1）新建ForkJoinPool；</p><p>2）新建ForkJoinTask(RecursiveAction || RecursiveTask);</p><p>3）在任务中的compute方法，会根据自定义条件进行任务拆分，如果条件满足则执行任务，如果条件不满足则继续拆分任务。当所有任务都执行完，进行最终结果的汇总。</p><p>4）最终通过get或join获取数据结果。</p><p>(同步意味着以某种方式 “连接” 或 “依赖”。换句话说，两个同步任务必须彼此了解，并且一个任务必须以某种方式执行，这取决于另一个任务，例如等待启动直到另一个任务完成。 </p><p>异步意味着它们是完全独立的，无论是在启动还是执行中，都不能以任何方式考虑对方。)</p><h1 id="并发工具类"><a href="#并发工具类" class="headerlink" title="并发工具类"></a>并发工具类</h1><p>CountDownLatch、CyclicBarrier、Semaphore、Exchanger。通过他们可以在不同场景下完成一些特定的功能。</p><p>可完成异步转同步</p><h2 id="CountDownLatch闭锁"><a href="#CountDownLatch闭锁" class="headerlink" title="CountDownLatch闭锁"></a>CountDownLatch闭锁</h2><p>CountDownLatch一般会把它称之为<strong>闭锁</strong>，其<strong>允许一个或多个线程等待其他线程完成操作</strong>。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image121.gif" class="" title="img"><p>CountDownLatch内部是通过计数器实现，当执行到某个节点后，就会开始等待其他任务执行。每完成一个任务，计数器就会减一，当计数器等于0时，代表任务已全部完成，则恢复之前的等待线程继续向下运行。</p><p>使用场景</p><p>根据其工作的特性，使用的场景也是比较多的。假设现在要解析一个Excel文件，其内部会存在多个sheet (sheet就是excle中的一个工作表。)，则设定每个线程解析一个sheet，等到解析完所有sheet后。再进行后续操作。这就是一个很常见的场景。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image123.jpg" class="" title="img"><h2 id="CycliBarrier同步屏障"><a href="#CycliBarrier同步屏障" class="headerlink" title="CycliBarrier同步屏障"></a>CycliBarrier同步屏障</h2><p>CycliBarrier翻译过来叫做<strong>可循环的屏障</strong>。其可以实现当一组线程执行时，当到达某个屏障（同步点）被阻塞，直到最后一个线程到达屏障后，才会让这一组线程继续向下执行。 其内部也是基于计数器思想实现。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image125.gif" class="" title="img"><p>对于CycliBarrier来说，其在基本流程的基础上，也进行了一个扩展。查看源码可知，其构造函数不仅可以传入需要等待的线程数，同时还可以传入一个Runnable。对于这个runnable可以作为一个扩展任务来使用。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image127.gif" class="" title="img"><p>子线程与主线程间首先会进行相互等待，只有等到其他线程都执行完毕后，才能继续向下执行。因为主线程和子线程是由CPU来进行调度，所以顺序不可控。</p><p>此时如果将线程数由3改为4则会永久等待，因为没有第四个线程执行await()方法，即没有第四个线程到达屏障，所以之前到达屏障的三个线程都不会继续向下执行。</p><p>扩展实现</p><p>​    CyclicBarrier还提供了一个更高级的构造函数，不仅可以设置等待线程数量，同时还能够设置一个优先执行的Runnable，方便处理更为复杂的业务场景。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image129.gif" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image131.gif" class="" title="img"><p>与CountDownLatch的区别</p><p>1）CountDownLatch.await 一般阻塞工作线程，所有的进行预备工作的线程执行countDown，而 CyclicBarrier 通过工作线程调用 await 从而自行阻塞，直到所有工作线程达到指定屏障，再大家一起往下走。</p><p>2）在控制多个线程同时运行上，CountDownLatch 可以不限线程数量，而CyclicBarrier 是固定线程数。</p><h2 id="Semaphore信号量"><a href="#Semaphore信号量" class="headerlink" title="Semaphore信号量"></a>Semaphore信号量</h2><p>其可以用于做流量控制，通过控制同时访问资源的线程数量，从而保证资源能够被更加合理的使用，如连接资源。假设现在要获取几万个文件资源，那么现在可以开启若干线程进行并发读取。但是读取后还要把这些数据写入到数据库。而数据库连接现在只有100个，此时就需要人为干预，控制只有100个线程同时获取数据库连接资源保存数据。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image133.gif" class="" title="img"><h2 id="Exchanger交换器"><a href="#Exchanger交换器" class="headerlink" title="Exchanger交换器"></a>Exchanger交换器</h2><p>Exchanger是一个线程协作工具类，可以进行线程间的数据交换，但是只局限于两个线程间协作。它提供了一个同步点，在这个同步点，两个线程可以交换彼此的数据。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image135.gif" class="" title="img"><h2 id="CountDownLatch和Semaphore的区别"><a href="#CountDownLatch和Semaphore的区别" class="headerlink" title="CountDownLatch和Semaphore的区别"></a>CountDownLatch和Semaphore的区别</h2><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image137.jpg" class="" title="img"><h2 id="让ABC三个进程同时，依次，交错进行"><a href="#让ABC三个进程同时，依次，交错进行" class="headerlink" title="让ABC三个进程同时，依次，交错进行"></a>让ABC三个进程同时，依次，交错进行</h2><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image138.jpg" class="" title="img"><p>Semaphore</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image139.jpg" class="" title="img"><p>同时：</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image140.jpg" class="" title="img"><p>依次：</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image141.jpg" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image142.jpg" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image143.jpg" class="" title="img"><p>有序交错：</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image144.jpg" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image145.jpg" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image146.jpg" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image147.jpg" class="" title="img"><h2 id="如何对一个字符串进行快速排序"><a href="#如何对一个字符串进行快速排序" class="headerlink" title="如何对一个字符串进行快速排序"></a>如何对一个字符串进行快速排序</h2><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image149.jpg" class="" title="img"><h1 id="ThreadLocal"><a href="#ThreadLocal" class="headerlink" title="ThreadLocal"></a>ThreadLocal</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>ThreadLocal是多线程中对于解决线程安全的一个操作类，它会为每个线程都分配一个独立的线程副本**从而解决了变量并发访问冲突的问题。ThreadLocal比直接使用synchronized同步机制解决线程安全问题更简单，更方便，且结果程序拥有更高的并发性。</p><p>一个经典的例子，使用JDBC操作数据库时，会将每一个线程的Connection放入各自的ThreadLocal中，从而保证每个线程都在各自的 Connection 上进行数据库的操作，避免A线程关闭了B线程的连接。</p><p>ThreadLocal与Synchonized区别</p><p>ThreadLocal和Synchonized都用于解决多线程并发访问。Synchronized用于线程间的数据共享，而ThreadLocal则用于线程间的数据隔离。Synchronized通过锁机制使得变量在同一时刻只能被一个线程访问，而ThreadLocal为每一个线程提供一个变量副本，使得每个线程都只能对自己线程内部数据进行维护，从而实现共享数据的线程隔离。</p><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>在ThreadLocal内部维护了一个内部类ThreadLocalMap。而且在ThreadLocalMap中又维护了一个Entry内部类和一个Entry数组。实际上，在ThreadLocal内部的维护了一个ThreadLocalMap，<strong>每个线程持有一个ThreadLocalMap对象</strong>，在ThreadLocalMap中为每一个线程都维护了一个数组table，而这个数组中会通过<strong>下标</strong>来确定存储数据的位置。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image150.jpg" class="" title="img"><ul><li><strong>对于同一线程的不同<strong><strong>ThreadLocal</strong></strong>来讲，这些<strong><strong>ThreadLocal</strong></strong>实例共享一个<strong><strong>table</strong></strong>数组，然后每个<strong><strong>ThreadLocal</strong></strong>实例在数组中的下标值<strong><strong>i</strong></strong>是不同的。</strong></li><li>*<em>对于某一个</em><em><strong>ThreadLocal</strong></em><em>来讲，他的下标值</em><em><strong>i</strong></em><em>是确定的，在不同线程之间访问时访问的是不同的</em><em><strong>table</strong></em><em>数组的同一位置即都为</em><em>*<em>table[i]<strong><strong>，只不过这个不同线程之间的</strong></strong>table</em>*</em><em>是独立的。</em>*</li></ul><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image152.gif" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image154.gif" class="" title="img"><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>Spring采用Threadlocal来保证单个线程中的数据库操作使用的是同一个数据库连接，同时，采用这种方式可以使业务层使用事务时不需要感知并管理connection对象，通过传播级别管理多个事务配置之间的切换，挂起和恢复。在Spring内部中存在一个类<strong>TransactionSynchronizationManager</strong>，该类实现了事务管理与数据访问服务的解</p><p>耦，同时也保证了多线程环境下connection的线程安全问题。</p><p>ThreadLocal：Spring中@Transaction注解，Mybitis中分页的处理</p><p>线上日期错误</p><p>开发中经常会使用到SimpleDataFormat进行日期格式化，当调用SimpleDataFormat的parse方法进行日期解析时，会先调用SimpleDataFormat内部的Calendar.clear()，然后调用Calendar.add()，如果一个线程先调用了add()然后另一个线程又调用了clear()，这</p><p>时候parse方法解析的时间就不对了，最终导致部分用户的日期不对。</p><p>解决方案：对于这个问题的解决思路，就是让每个线程都拥有一个自己的SimpleDataFormat，可是直接new的方式性能并不好，此时就可以通过ThreadLocal进行解决，使用线程池加上ThreadLocal包装 SimpleDataFormat ，让每个线程有一个 SimpleDataFormat 的副本，从而解决了线程安全的问题，也提高了性能。</p><p>跨服务方法传参</p><p>在项目开发中，有可能存在一个线程横跨若干服务若干方法调用，经常需要传递一些状态性的信息，如用户认证信息等。如果要想完成这件事，其中一种方式可以通过Context上下文对象进行传参，但是通过上下文传参的话，有可能导致参数传不进去，所以通过ThreadLocal进行改造，当set完数据后，只要保证是在同一个线程中，则其他地方还需要get就可以了。</p><p> ThreadLocal经典问题-内存泄露</p><p>内存泄露：不会再被使用的对象或变量占用的内存不能被回收。</p><p> Java对象的四种引用类型</p><p>强引用：最为普通的引用方式，表示一个对象处于有用且必须的状态，如果一个对象具有强引用，则GC并不会回收它。即便堆中内存不足了，宁可出现</p><p>OOM，也不会对其进行回收</p><p>软引用：表示一个对象处于有用且非必须状态，如果一个对象处于软引用，在内存空间足够的情况下，GC机制并不会回收它，而在内存空间不足时，则会在OOM异常出现之间对其进行回收。但值得注意的是，因为GC线程优先级较低，软引用并不会立即被回收。（用于缓存）</p><p>弱引用：表示一个对象处于可能有用且非必须的状态。在GC线程扫描内存区域时，一旦发现弱引用，就会回收到弱引用相关联的对象。对于弱引用的回收，无关内存区域是否足够，一旦发现则会被回收。同样的，因为GC线程优先级较</p><p>低，所以弱引用也并不是会被立刻回收。（防止一些map的内存泄露，ThreadLocal防内存泄露）</p><p>虚引用：表示一个对象处于无用的状态。在任何时候都有可能被垃圾回收。虚</p><p>引用的使用必须和引用队列Reference Queue联合使用（专门用来管理堆外内存的，回收的时候给个信号，JVM里用来管理直接内存）</p><p>内存泄露原因分析</p><p>ThreadLocalMap中的Entry对象继承了WeakReference。其中key为使用弱引用的</p><p>ThreadLocal实例，value为线程变量的副本。</p><p>那么为什么要把key定义为使用弱引用的ThreadLocal呢？假设将key定义为强引用，回收ThreadLocal时，因为ThreadLocalMap还持有ThreadLocal的强引用，如果没有手动删除，ThreadLocal不会被回收，最终导致Entry内存泄漏。</p><p>为了避免该问题，则将key定义为弱引用，但是当GC时，则会造成因为key是弱引用，因此会被回收掉，但是value是强引用，仍然会存在，最终造成value的内存泄露。</p><p>如要避免ThreadLocal内存泄露的出现，也非常的简单。对于ThreadLocal的使</p><p>用，务必记得要在最后一步执行remove即可。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image156.jpg" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image158.jpg" class="" title="img"><h1 id="ThreadPoolExecutor线程池"><a href="#ThreadPoolExecutor线程池" class="headerlink" title="ThreadPoolExecutor线程池"></a>ThreadPoolExecutor线程池</h1><h2 id="线程池的优点和应用场景"><a href="#线程池的优点和应用场景" class="headerlink" title="线程池的优点和应用场景"></a>线程池的优点和应用场景</h2><ul><li><ul><li>降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。</li><li>提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。</li><li>提高线程的可管理性。线程是稀缺资源，要合理利用分配，通过线程池可以进行统一分配、调优和监控。</li></ul></li></ul><p><strong>一、线程池使用场景</strong></p><p>•单个任务处理时间短</p><p>•将需处理的任务数量大</p><p><strong>二、使用<strong><strong>Java</strong></strong>线程池好处</strong></p><p>*<em>1</em><em><strong>、使用</strong></em>*new Thread()**<strong>创建线程的弊端：</strong></p><p>•每次通过new Thread()创建对象性能不佳。</p><p>•线程缺乏统一管理，可能无限制新建线程，相互之间竞争，及可能占用过多系统资源导致死机或oom。</p><p>•缺乏更多功能，如定时执行、定期执行、线程<a href="https://so.csdn.net/so/search?q=%E4%B8%AD%E6%96%AD&spm=1001.2101.3001.7020">中断</a>。</p><p><strong>2<strong><strong>、使用</strong></strong>Java****线程池的好处：</strong></p><p>•重用存在的线程，减少对象创建、消亡的开销，提升性能。</p><p>•可有效控制最大并发线程数，提高系统资源的使用率，同时避免过多资源竞争，避免堵塞。</p><p>•提供定时执行、定期执行、单线程、并发数控制等功能。</p><p><strong>线程池的作用：</strong></p><p>线程池作用就是限制系统中执行线程的数量。</p><p>根 据系统的环境情况，可以自动或手动设置线程数量，达到运行的最佳效果；少了浪费了系统资源，多了造成系统拥挤效率不高。用线程池控制线程数量，其他线程排 队等候。一个任务执行完毕，再从队列的中取最前面的任务开始执行。若队列中没有等待进程，线程池的这一资源处于等待。当一个新任务需要运行时，如果线程池 中有等待的工作线程，就可以开始运行了；否则进入等待队列。</p><p><strong>为什么要用线程池:</strong></p><p>1.减少了创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务。</p><p>2.可以根据系统的承受能力，调整线程池中工作线线程的数目，防止因为消耗过多的内存，而把服务器累趴下(每个线程需要大约1MB内存，线程开的越多，消耗的内存也就越大，最后死机)。</p><h2 id="线程池状态"><a href="#线程池状态" class="headerlink" title="线程池状态"></a>线程池状态</h2><p>线程池存在五种状态：RUNNING、 SHUTDOWN,、STOP、TIDYING、TERMINATED。</p><p>RUNNING：处于RUNNING状态的线程池能够接受新任务，以及对新添加的任务进行处理。</p><p>SHUTDOWN：处于SHUTDOWN状态的线程池不可以接受新任务，但是可以对已添加的任务进行处理。</p><p>STOP：处于STOP状态的线程池不接收新任务，不处理已添加的任务，并且会中断正在处理的任务。</p><p>TIDYING：（tidying使整洁）当所有的任务已终止，线程池会变为TIDYING状态。当线程池变为TIDYING状态时，会执行钩子函数terminated()。terminated()在ThreadPoolExecutor类中是空的，若用户想在线程池变为TIDYING时，进行相应的处理；可以通过重载terminated()函数来实现。</p><p>TERMINATED：（terminated停止）线程池彻底终止的状态。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image160.gif" class="" title="img"><h2 id="线程池创建的各个参数含义"><a href="#线程池创建的各个参数含义" class="headerlink" title="线程池创建的各个参数含义"></a><strong>线程池创建的各个参数含义</strong></h2><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image162.gif" class="" title="img"><p><strong>corePoolSize****：</strong></p><p>​    核心线程数(线程池基本大小)，在没有任务需要执行的时候的线程池大小。当提交一个任务时，线程池创建一个新线程执行任务，直到线程数等于该参数。 如果当前线程数为该参数，后续提交的任务被保存到阻塞队列中，等待被执行。</p><p><strong>maximumPoolSize****：</strong></p><p>​    线程池中允许的最大线程数，线程池中的当前线程数目不会超过该值。如果当前阻塞队列满了，且继续提交任务，如果当前的线程数小于maximumPoolSize，则会新建线程来执行任务。</p><p><strong>keepAliveTime****：</strong></p><p>​     多余的线程没有任务执行之后，线程在线程池中最多待多久的时间才销毁，直到只剩下corePoolSize个线程为止。默认情况下，该参数只在线程数大于corePoolSize时才有用。</p><p><strong>TimeUnit****：</strong>参数keepAliveTime的时间单位，一共7种取值：天，小时，分钟，秒，毫秒，微妙，纳秒</p><p><strong>workQueue****：</strong></p><p>​    其必须是BolckingQueue有界阻塞队列，用于实现线程池的阻塞功能。当线程池中的线程数超过它的corePoolSize时，线程会进入阻塞队列进行阻塞等待。</p><p><strong>threadFactory</strong>：</p><p>​    用于设置创建线程的工厂。ThreadFactory的作用就是提供创建线程的功能的线程工厂。他是通过newThread()方法提供创建线程的功能，newThread()方法创建的线程都是“非守护线程”而且“线程优先级都是默认优先级”。（用户线程即运行在前台的线程,而守护线程是运行在后台的线程。）</p><p><strong>handler****：</strong></p><p>​    线程池拒绝策略。当阻塞队列满了，且没有空闲的工作线程，如果继续提交任务，则必须采取一种策略处理该任务。</p><p>AbortPolicy：默认策略，直接抛出异常。</p><p>CallerRunsPolicy：用调用者所在的线程执行任务。</p><p>DiscardOldestPolicy：丢去阻塞队列的头部任务，并执行当前任务。</p><p>DiscardPolicy：直接丢弃任务。</p><h2 id="线程池工作机制"><a href="#线程池工作机制" class="headerlink" title="线程池工作机制"></a>线程池工作机制</h2><ul><li><ol><li>如果当前运行的线程少于corePoolSize，则创建新线程来执行任务（执行这一步前，需要获取全局锁）。</li><li>如果运行的线程等于或多于corePoolSize，则将任务加入BlockingQueue。</li><li>如果无法将任务加入BlockingQueue，则创建新线程处理任务。</li><li>如果创建的新线程使当前运行的线程超出maximumPoolSize，任务将被拒绝。</li></ol></li></ul><h2 id="五种预定义线程池"><a href="#五种预定义线程池" class="headerlink" title="五种预定义线程池"></a>五种预定义线程池</h2><h3 id="FixedThreadPool"><a href="#FixedThreadPool" class="headerlink" title="FixedThreadPool"></a>FixedThreadPool</h3><p>创建使用固定线程数的线程池。适用于为了满足资源管理而需要限制当前线程数量</p><p>的场景。同时也适用于负载较重的服务器。其定义如下：</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image164.jpg" class="" title="img"><p><strong>nThreads</strong>：</p><p>FixedThreadPool 的 corePoolSize 和 maximumPoolSize 都被设置为创建FixedThreadPool 时指定的参数 nThreads。</p><p><strong>keepAliveTime</strong>：</p><p>此处设置为了0L，代表多于的空闲线程会被立即终止。</p><p><strong>LinkedBlockingQueue</strong>：</p><p>FixedThreadPool 使用有界队列 LinkedBlockingQueue 作为线程池的工作队列（队列的容量为 Integer.MAX_VALUE）。</p><h3 id="SingleThreadExecutor"><a href="#SingleThreadExecutor" class="headerlink" title="SingleThreadExecutor"></a>SingleThreadExecutor</h3><p>只会使用单个工作线程来执行一个无边界的队列。适用于保证顺序地执行各个人物，并且在任意时间点，不会有多个线程存在活动的应用场景。</p><p>corePoolSize 和 maximumPoolSize 被设置为 1。其他参数与 FixedThreadPool相同。SingleThreadExecutor 使用有界队列 LinkedBlockingQueue 作为线程池的工作队列（队列的容量为 Integer.MAX_VALUE）。</p><h3 id="CachedThreadPool"><a href="#CachedThreadPool" class="headerlink" title="CachedThreadPool"></a>CachedThreadPool</h3><p>​    其是一个大小无界的线程池，会根据需要创建新线程。适用于执行很多的短期异步</p><p>任务的小程序或者是负载较轻的服务器。</p><p>corePoolSize 被设置为 0，即 corePool 为空；maximumPoolSize 被设置为Integer.MAX_VALUE。这里把 keepAliveTime 设置为 60L，意味着 CachedThreadPool中</p><p>的空闲线程等待新任务的最长时间为60秒，空闲线程超过60秒后将会被终止。</p><p>FixedThreadPool 和 SingleThreadExecutor 使用有界队列 LinkedBlockingQueue作为线程池的工作队列。CachedThreadPool 使用没有容量的 SynchronousQueue作为线程池的工作队列，但 CachedThreadPool 的 maximumPool 是无界的。这意味着，如果主线程提交任务的速度高于 maximumPool 中线程处理任务的速度时，</p><p>CachedThreadPool 会不断创建新线程。极端情况下，CachedThreadPool 会因为创建过</p><p>多线程而耗尽 CPU 和内存资源。</p><h3 id="ScheduledThreadPoolExecutor"><a href="#ScheduledThreadPoolExecutor" class="headerlink" title="ScheduledThreadPoolExecutor"></a>ScheduledThreadPoolExecutor</h3><p>ScheduledThreadPoolExecutor，继承ThreadPoolExecutor且实现了ScheduledExecutorService接口，它就相当于提供了“延迟”和“周期执行”功能的ThreadPoolExecutor。它可另行安排在给定的延迟后运行命令，或者定期执行命令。它适用于为了满足资源管理的需求而需要限制后台线程数量的场景同时可以保证多任务的顺序执行。</p><p>在ScheduledThreadPoolExecutor的构造函数中，我们发现它都是利用ThreadLocalExecutor来构造的，唯一变动的地方就在于它所使用的阻塞队列变成了DelayedWorkQueue。</p><p>DelayedWorkQueue为ScheduledThreadPoolExecutor中的内部类，类似于延时队列和优先级队列。在执行定时任务的时候，每个任务的执行时间都不同，所以DelayedWorkQueue的工作就是按照执行时间的升序来排列，执行时间距离当前时间越近的任务在队列的前面（执行时间短的在前面），这样就可以保证每次出队的任务都是当前队列中执行时间最靠前的。</p><h3 id="WorkStealingPool"><a href="#WorkStealingPool" class="headerlink" title="WorkStealingPool"></a>WorkStealingPool</h3><p>其是JDK1.8中新增的线程池，利用所有运行的CPU来创建一个工作窃取的线程池，是对ForkJoinPool的扩展，适用于非常耗时的操作。</p><h2 id="阻塞队列"><a href="#阻塞队列" class="headerlink" title="阻塞队列"></a>阻塞队列</h2><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image166.jpg" class="" title="img"><ul><li><ol><li>ArrayBlockingQueue： 基于数组结构的<strong>有界阻塞队列</strong> ，按<strong>FIFO****（先进先出）原则</strong> 对任务进行排序。使用该队列，线程池中能创建的最大线程数为maximumPoolSize。</li><li>LinkedBlockingQueue： 基于链表结构的<strong>无界阻塞队列</strong> ，按<strong>FIFO****（先进先出）原则</strong> 对任务进行排序，吞吐量高于ArrayBlockingQueue。使用该队列，线程池中能创建的最大线程数为corePoolSize。<strong>静态工厂方法</strong> Executor.newFixedThreadPool()使用了这个队列。</li><li>SynchronousQueue： 一个<strong>不存储元素</strong> 的阻塞队列。添加任务的操作必须等到另一个线程的移除操作，否则添加操作一直处于阻塞状态。<strong>静态工厂方法</strong> Executor.newCachedThreadPool()使用了这个队列。</li><li>PriorityBlokingQueue： 一个<strong>支持优先级</strong> 的<strong>无界阻塞队列</strong> 。使用该队列，线程池中能创建的最大线程数为corePoolSize。</li><li><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image168.jpg" class="" title="img"></li></ol></li></ul><h2 id="线程池的submit和execute的区别"><a href="#线程池的submit和execute的区别" class="headerlink" title="线程池的submit和execute的区别"></a>线程池的submit和execute的区别</h2><p>\1. execute提交的方式</p><p>execute提交的方式只能提交一个Runnable的对象，且该方法的返回值是void，也即是提交后如果线程运行后，和主线程就脱离了关系了，当然可以设置一些变量来获取到线程的运行结果。并且当线程的执行过程中抛出了异常通常来说主线程也无法获取到异常的信息的，只有通过ThreadFactory主动设置线程的异常处理类才能感知到提交的线程中的异常信息。 </p><p>\2. submit提交的方式</p><p>submit提交的方式有如下三种情况</p><p>2.1  Future submit(Callable task);</p><p>这种提交的方式是提交一个实现了Callable接口的对象，Callable接口的定义如下</p><p>public interface Callable {</p><p>  &#x2F;**</p><p>   * Computes a result, or throws an exception if unable to do so.</p><ul><li></li></ul><p>   * @return computed result</p><p>   * @throws Exception if unable to compute a result</p><p>   *&#x2F;</p><p>  V call() throws Exception;</p><p>}</p><p>可以看到Callable接口和Runnable接口的定义很类似，只不过Runnable接口中是一个没有返回值的run方法，而Callable接口中是一个有返回值的call方法。</p><p>这种提交的方式会返回一个Future对象，这个Future对象代表这线程的执行结果，</p><p>当主线程调用Future的get方法的时候会获取到从线程中返回的结果数据。</p><p>如果在线程的执行过程中发生了异常，get会获取到异常的信息。 </p><p>Future.get方法是一个阻塞方法，当submit提交多个任务时，只有所有任务都完成后，才能使用get按照任务的提交顺序得到返回结果，所以一般需要使用future.isDone先判断任务是否全部执行完成，完成后再使用future.get得到结果。（也可以用get (long timeout, TimeUnit unit)方法可以设置超时时间，防止无限时间的等待） </p><h2 id="提交任务，线程池队列已满，会发生什么"><a href="#提交任务，线程池队列已满，会发生什么" class="headerlink" title="提交任务，线程池队列已满，会发生什么"></a>提交任务，线程池队列已满，会发生什么</h2><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image170.jpg" class="" title="img"><h2 id="线程池中线程复用原理"><a href="#线程池中线程复用原理" class="headerlink" title="线程池中线程复用原理"></a>线程池中线程复用原理</h2><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image172.jpg" class="" title="img"><h2 id="线程池调优"><a href="#线程池调优" class="headerlink" title="线程池调优"></a>线程池调优</h2><p><a href="https://mp.weixin.qq.com/s?__biz=MzUzMTA2NTU2Ng==&mid=2247487551&idx=1&sn=18f64ba49f3f0f9d8be9d1fdef8857d9&scene=21#wechat_redirect"><strong>①</strong> <strong>线程池的调优（线程池的合理配置）</strong></a></p><ul><li><ul><li>先从以下几个角度分析任务的特性：</li></ul></li><li><ul><li><strong>任务的性质：</strong> CPU 密集型任务、IO 密集型任务和混合型任务。</li><li><strong>任务的优先级：</strong> 高、中、低。</li><li><strong>任务的执行时间：</strong> 长、中、短。</li><li><strong>任务的依赖性：</strong> 是否依赖其他系统资源，如数据库连接。</li></ul></li><li><ul><li><strong>任务性质不同的任务可以用不同规模的线程池分开处理。</strong> 可以通过 Runtime.getRuntime().availableProcessors() 方法获得当前设备的 CPU 个数。</li></ul></li><li><ul><li><strong>CPU</strong> <strong>密集型任务</strong> 配置尽可能小的线程，如配置 N c p u + 1 N_{cpu}+1<em>N*<em>c</em></em> p*<em>u</em>+1 个线程的线程池。</li><li><strong>IO</strong> <strong>密集型任务</strong> 则由于线程并不是一直在执行任务，则配置尽可能多的线程，如2 ∗ N c p u 2<em>N_{cpu}2∗</em>N<strong>c</strong> p*<em>u</em>。</li><li><strong>混合型任务</strong> ，如果可以拆分，则将其拆分成一个 CPU 密集型任务和一个 IO 密集型任务。只要这两个任务执行的时间相差不是太大，那么分解后执行的吞吐率要高于串行执行的吞吐率；如果这两个任务执行时间相差太大，则没必要进行分解。</li></ul></li><li><ul><li><strong>优先级不同的任务</strong> 可以使用优先级队列 PriorityBlockingQueue 来处理，它可以让优先级高的任务先得到执行。但是，如果一直有高优先级的任务加入到阻塞队列中，那么低优先级的任务可能永远不能执行。</li><li><strong>执行时间不同的任务</strong> 可以交给不同规模的线程池来处理，或者也可以使用优先级队列，让执行时间短的任务先执行。</li><li><strong>依赖数据库连接池的任务</strong> ，因为线程提交 SQL 后需要等待数据库返回结果，线程数应该设置得较大，这样才能更好的利用 CPU。</li><li><strong>建议使用有界队列</strong> ，有界队列能增加系统的稳定性和预警能力。可以根据需要设大一点，比如几千。使用无界队列，线程池的队列就会越来越大，<strong>有可能会撑满内存，导致整个系统不可用</strong> 。</li></ul></li></ul><p><a href="https://mp.weixin.qq.com/s?__biz=MzUzMTA2NTU2Ng==&mid=2247487551&idx=1&sn=18f64ba49f3f0f9d8be9d1fdef8857d9&scene=21#wechat_redirect"><strong>②</strong> <strong>线程池的监控</strong></a></p><ul><li><ul><li>可以通过线程池提供的参数读线程池进行监控，有以下属性可以使用：</li></ul></li><li><ul><li>taskCount：线程池需要执行的任务数量，包括已经执行完的、未执行的和正在执行的。</li><li>completedTaskCount：线程池在运行过程中<strong>已完成的任务数量</strong> ，completedTaskCount &lt;&#x3D;      taskCount。</li><li>largestPoolSize：线程池<strong>曾经创建过的最大线程数量</strong> ，通过这个数据可以知道线程池是否满过。<strong>如等于线程池的最大大小</strong> ，则表示线程池曾经满了。</li><li>getPoolSize: 线程池的线程数量。如果线程池不销毁的话，池里的线程不会自动销毁，所以<strong>线程池的线程数量只增不减</strong> 。</li><li>getActiveCount：获取<strong>活动的</strong> 线程数。</li></ul></li><li><ul><li>通过<strong>继承线程池</strong> 并<strong>重写</strong> 线程池的 beforeExecute，afterExecute 和 terminated 方法，我们可以在任务执行前，执行后和线程池关闭前干一些事情。</li><li>如监控任务的平均执行时间，最大执行时间和最小执行时间等。<strong>这几个方法在线程池里是空方法</strong> ，</li></ul></li></ul><h1 id="java的内存模型（JMM）"><a href="#java的内存模型（JMM）" class="headerlink" title="java的内存模型（JMM）"></a>java的内存模型（JMM）</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>JMM就是Java内存模型(java memory model)。因为在不同的硬件生产商和不同的操作系统下，内存的访问有一定的差异，所以会造成相同的代码运行在不同的系统上会出现各种问题。所以<strong>java内存模型(JMM)屏蔽掉各种硬件和操作系统的内存访问差异，以实现让java程序在各种平台下都能达到一致的并发效果。</strong></p><p>Java内存模型规定<strong>所有的变量都存储在主内存</strong>中，包括实例变量，静态变量，但是不包括局部变量和方法参数。每个线程都有自己的工作内存，<strong>线程的工作内存保存了该线程用到的变量和主内存的副本拷贝，线程对变量的操作都在工作内存中进行</strong>。<strong>线程不能直接读写主内存中的变量</strong>。</p><p>不同的线程之间也无法访问对方工作内存中的变量。线程之间变量值的传递均需要通过主内存来完成。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image174.gif" class="" title="img"><p>每个线程的工作内存都是独立的，线程操作数据只能在工作内存中进行，然后刷回到主存。这是 Java 内存模型定义的线程基本工作方式。</p><p><a href="https://zhuanlan.zhihu.com/p/258393139%EF%BC%88%E9%92%88%E5%AF%B9%E4%BA%8E%E9%9D%A2%E8%AF%95%E5%AE%98%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%89%EF%BC%88%E9%87%8C%E9%9D%A2%E8%BF%98%E6%9C%89%E5%85%B3%E4%BA%8Evolatile%E5%85%B3%E9%94%AE%E5%AD%97%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%EF%BC%8C%E9%83%BD%E5%BE%88%E5%A5%BD%EF%BC%89">https://zhuanlan.zhihu.com/p/258393139（针对于面试官的问题）（里面还有关于volatile关键字的一些问题，都很好）</a></p><p><a href="https://zhuanlan.zhihu.com/p/29881777%EF%BC%88%E6%9B%B4%E8%AF%A6%E7%BB%86%EF%BC%8C%E9%92%88%E5%AF%B9%E4%BA%8E%E5%BA%95%E5%B1%82%EF%BC%89">https://zhuanlan.zhihu.com/p/29881777（更详细，针对于底层）</a></p><p>volatile内存屏障</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image176.jpg" class="" width="0"><h2 id="那JMM定义了什么"><a href="#那JMM定义了什么" class="headerlink" title="那JMM定义了什么"></a>那JMM定义了什么</h2><p>这个简单，整个Java内存模型实际上是围绕着三个特征建立起来的。分别是：原子性，可见性，有序性。这三个特征可谓是整个Java并发的基础。</p><p>原子性</p><p>原子性指的是一个操作是不可分割，不可中断的，一个线程在执行时不会被其他线程干扰。</p><p>面试官拿笔写了段代码，下面这几句代码能保证原子性吗？</p><p>int i &#x3D; 2;<br> int j &#x3D; i;<br> i++;<br> i &#x3D; i + 1;</p><p>第一句是基本类型赋值操作，必定是原子性操作。</p><p>第二句先读取i的值，再赋值到j，两步操作，不能保证原子性。</p><p>第三和第四句其实是等效的，先读取i的值，再+1，最后赋值到i，三步操作了，不能保证原子性。</p><p>JMM只能保证基本的原子性，如果要保证一个代码块的原子性，提供了monitorenter 和 moniterexit 两个字节码指令，也就是 synchronized 关键字。因此在 synchronized 块之间的操作都是原子性的。</p><p>可见性</p><p>可见性指当一个线程修改共享变量的值，其他线程能够立即知道被修改了。Java是利用volatile关键字来提供可见性的。 当变量被volatile修饰时，这个变量被修改后会立刻刷新到主内存，当其它线程需要读取该变量时，会去主内存中读取新值。而普通变量则不能保证这一点。</p><p>除了volatile关键字之外，final和synchronized也能实现可见性。</p><p>synchronized的原理是，在执行完，进入unlock之前，必须将共享变量同步到主内存中。</p><p>final修饰的字段，一旦初始化完成，如果没有对象逸出（指对象为初始化完成就可以被别的线程使用），那么对于其他线程都是可见的。</p><p>有序性</p><p>在Java中，可以使用synchronized或者volatile保证多线程之间操作的有序性。实现原理有些区别：</p><p>volatile关键字是使用内存屏障达到禁止指令重排序，以保证有序性。</p><p>synchronized的原理是，一个线程lock之后，必须unlock后，其他线程才可以重新lock，使得被synchronized包住的代码块在多线程之间是串行执行的。</p><h2 id="八种内存交互操作"><a href="#八种内存交互操作" class="headerlink" title="八种内存交互操作"></a>八种内存交互操作</h2><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image178.gif" class="" title="img"><ul><li><ul><li>lock(锁定)，作用于主内存中的变量，把变量标识为线程独占的状态。</li><li>read(读取)，作用于主内存的变量，把变量的值从主内存传输到线程的工作内存中，以便下一步的load操作使用。</li><li>load(加载)，作用于工作内存的变量，把read操作主存的变量放入到工作内存的变量副本中。</li><li>use(使用)，作用于工作内存的变量，把工作内存中的变量传输到执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。</li><li>assign(赋值)，作用于工作内存的变量，它把一个从执行引擎中接受到的值赋值给工作内存的变量副本中，每当虚拟机遇到一个给变量赋值的字节码指令时将会执行这个操作。</li><li>store(存储)，作用于工作内存的变量，它把一个从工作内存中一个变量的值传送到主内存中，以便后续的write使用。</li><li>write(写入)：作用于主内存中的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。</li><li>unlock(解锁)：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。</li></ul></li></ul><p>JMM对8种内存交互操作制定的规则吧：</p><ul><li><ul><li>不允许read、load、store、write操作之一单独出现，也就是read操作后必须load，store操作后必须write。</li><li>不允许线程丢弃他最近的assign操作，即工作内存中的变量数据改变了之后，必须告知主存。</li><li>不允许线程将没有assign的数据从工作内存同步到主内存。</li><li>一个新的变量必须在主内存中诞生，不允许工作内存直接使用一个未被初始化的变量。就是对变量实施use、store操作之前，必须经过load和assign操作。</li><li>一个变量同一时间只能有一个线程对其进行lock操作。多次lock之后，必须执行相同次数unlock才可以解锁。</li><li>如果对一个变量进行lock操作，会清空所有工作内存中此变量的值。在执行引擎使用这个变量前，必须重新load或assign操作初始化变量的值。</li><li>如果一个变量没有被lock，就不能对其进行unlock操作。也不能unlock一个被其他线程锁住的变量。</li><li>一个线程对一个变量进行unlock操作之前，必须先把此变量同步回主内存。</li></ul></li></ul><h1 id="JUC包"><a href="#JUC包" class="headerlink" title="JUC包"></a>JUC包</h1><h2 id="CopyOnWriteArrayList"><a href="#CopyOnWriteArrayList" class="headerlink" title="CopyOnWriteArrayList"></a>CopyOnWriteArrayList</h2><p>实现原理</p><p>我们都知道，集合框架中的ArrayList是非线程安全的，Vector虽是线程安全的，但由于简单粗暴的锁同步机制，性能较差。而CopyOnWriteArrayList则提供了另一种不同的并发处理策略。针对<em>读多写少</em>的并发场景，CopyOnWriteArrayList允许线程并发访问读操作，这个时候是没有加锁限制的，性能较高。而写操作的时候，则首先将容器复制一份，然后在新的副本上执行写操作，这个时候写操作是上锁的。结束之后再将原容器的引用指向新容器。注意，在上锁执行写操作的过程中，如果有需要读操作，会作用在原容器上。因此上锁的写操作不会影响到并发访问的读操作。</p><p>了解了实现原理，我们也能很容易总结出容器的优缺点。优点是读操作性能很高，无需任何同步措施，适用于读多写少的并发场景。缺点一是需要额外内存占用，毕竟每次写操作需要复制一份，数据量大时会对内存压力较大，可能会引起频繁的GC。二是无法保证强一致性，毕竟在复制写操作过程中，读和写分别作用在新老不同容器上。读操作虽然不会阻塞，但在这段时间内读取的还是老容器的数据</p><h1 id="异步转为同步的方式"><a href="#异步转为同步的方式" class="headerlink" title="异步转为同步的方式"></a>异步转为同步的方式</h1><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image179.jpg" class="" width="0">]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> 并发 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis</title>
      <link href="/2024/04/05/redis/"/>
      <url>/2024/04/05/redis/</url>
      
        <content type="html"><![CDATA[<h1 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h1><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><h3 id="数据结构及其使用场景"><a href="#数据结构及其使用场景" class="headerlink" title="数据结构及其使用场景"></a>数据结构及其使用场景</h3><img src="/2024/04/05/redis/clip_image002.jpg" class="" title="Redis 的 数 据 结 构 及 使 用 场 景  Re 的 数 哐 结 构 有 、  1. 孛 串 ： 可 以 庠 来 做 最 简 单 的 數 缓 存 ， 可 以 緩 存 某 个 徜 的 孛 符 牛 ， 也 可 以 緩 存 臬 个 json 格 詭 孛 符 串 ， № 分 布 式 锁 的 实 现 利 用 了 这 种 赦 据 砉 构 ， 还 包 茫 可 以 实 现  计 數 器 、 s “ n 共 亨 ． 分 布 式 旧  2 、 哈 希 表 ： 可 以 来 存 儲 一 些 key 一 va 心 e 对 。 史 适 合 用 来 存 储 对 象  圭 列 表 ： Redis 的 列 表 命 0 的 绢 合 ， 可 以 当 雪 栈 ， 也 可 以 当 做 队 列 来 使 ， 可 以 用 来 存 类 似 信 公 众 号 、 两 等 泊 0 流 数  4 ． 合 ； 和 歹 刂 表 类 似 《 也 可 以 存 賭 多 个 元 索 ， 但 是 不 能 里 复 ， 合 可 以 进 行 交 隼 ． 并 、 差 军 臊 作 ， 从 而 可 以 妾 现 类 似 ， 栊 和 早 人 共 同 关 汀 的 人 、 朋 友 苤 等 功 能  气 有 序 合 ： 合 是 无 序 的 。 有 序 合 可 以 设 置 顺 序 ， 可 以 来 实 现 排 行 榜 功 能"><p>Redis还有更高级得数据结构，比如：HyperLogLog、Geo、BloomFilter 这几个数据结构</p><p>String底层实现：</p><p>如果一个字符串对象保存的是整数值， 并且这个整数值可以用 long 类型来表示， 那么字符串对象会将整数值保存在字符串对象结构的 ptr 属性里面（将 void* 转换成 long ）， 并将字符串对象的编码设置为 int 。</p><p>如果字符串对象保存的是一个字符串值， 并且这个字符串值的长度大于 39 字节， 那么字符串对象将使用一个简单动态字符串（SDS）来保存这个字符串值， 并将对象的编码设置为 raw。</p><p>如果字符串对象保存的是一个字符串值， 并且这个字符串值的长度小于等于 39 字节， 那么字符串对象将使用 embstr 编码的方式来保存这个字符串值。</p><p>List底层实现：</p><p>列表对象的编码可以是 ziplist 或者 linkedlist 。</p><p>列吧表对象保存的所有字符串元素的长度都小于 64 字节并且保存的元素数量小于 512 个，使用 ziplist 编码；否则使用 linkedlist；</p><p>Hash底层实现:</p><p>哈希对象的编码可以是 ziplist 或者 hashtable 。</p><p>哈希对象保存的所有键值对的键和值的字符串长度都小于 64 字节并且保存的键值对数量小于 512 个，使用ziplist 编码；否则使用hashtable；</p><p>Set底层实现：</p><p>集合对象的编码可以是 intset 或者 hashtable 。</p><p>集合对象保存的所有元素都是整数值并且保存的元素数量不超过 512 个，使用intset编码；否则使用hashtable；</p><p>Sorted Set底层实现：</p><p>有序集合的编码可以是 ziplist 或者 skiplist</p><p>有序集合保存的元素数量小于 128 个并且保存的所有元素成员的长度都小于 64 字</p><p>节。使用 ziplist 编码；否则使用skiplist；</p><p>HyperLogLog</p><p>edis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。</p><p>在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基 数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。</p><p>但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。 </p><p>应用场景：</p><p>可以用来统计网站的登陆人数以及其他指标</p><p>GEO</p><p>基本概念： </p><p>在 Redis 3.2 版本中新增了一种叫 geo 的数据结构，它主要用来存储地理位置信息，并对存储的信息进行操作。 </p><p>使用： </p><p>geoadd 用于存储指定的地理空间位置，可以将一个或多个经度(longitude)、纬度</p><p>(latitude)、位置名称(member)添加到指定的 key 中。</p><p>BloomFilter</p><p>基本概念： </p><p>一种数据结构，是由一串很长的二进制向量组成，可以将其看成一个二进制数组。既然是二进制，那么里面存放的不是0，就是1，但是初始默认值都是0。他的主要作用是：判断一个元素是否在某个集合中。比如说，我想判断20亿的号码中是否存在某个号码，如果直接插DB，那么数据量太大时间会很慢；如果将20亿数据放到 缓存中，缓存也装不下。这个时候用 布隆过滤器 最合适了，布隆过滤器的原理是：</p><p>添加元素<br> 当要向布隆过滤器中添加一个元素key时，我们通过多个hash函数，算出一个值，然后将这个值所在的方格置为1。</p><img src="/2024/04/05/redis/clip_image004.gif" class="" title="img"><p>判断元素是否存在：<br> 判断元素是否存在，是先将元素经过多个hash函数计算，计算到多个下标值，然后判断这些下标对应的元素值是否都为1，如果存在不是 1 的，那么元素肯定不在集合中；如果都是 1，那么元素大概率在集合中，并不能百分之百肯定元素存在集合中，因为多个不同的数据通过hash函数算出来的结果是会有重复的，所以会存在某个位置是别的数据通过hash函数置为的1。<br> 总的来说：布隆过滤器可以判断某个数据一定不存在，但是无法判断一定存在。</p><p>布隆过滤器的优缺点：</p><p>优点：优点很明显，二进制组成的数组，占用内存极少，并且插入和查询速度都足够快。</p><p>缺点：随着数据的增加，误判率会增加；还有无法判断数据一定存在；另外还有一个重要缺点，无法删除数据。</p><p>应用场景：</p><p>解决缓存穿透问题：一般得查询场景都是先去查询缓存，如果缓存没有，那么就去 DB 查询，如果查到了，先存在 缓存 中，然后返回给调用方。如果查不到就返回空。这种情况如果有人频繁的请求缓存中没有得数据，比如id &#x3D; -1 得数据，那么会对 DB 造成极大得压力，这种情况就可以使用 redis 得布隆过滤器了，可以先将可能得id都</p><p>存在布隆过滤器中，当查询来的时候，先去布隆过滤器查，如果查不到直接返回，不请求缓存以及DB，如果存在 布隆过滤器 中，那么才去缓存中取数据。</p><p>黑名单校验：可以将黑名单中得ip放入到布隆过滤器中，这样不用每次来都去 db 中查询了。</p><h3 id="Hashmap"><a href="#Hashmap" class="headerlink" title="Hashmap"></a>Hashmap</h3><img src="/2024/04/05/redis/clip_image006.jpg" class="" title="di"><p>扩容时大小：ht[1] 哈希表大小为第一个大于等于 ht[0].used*2 的 2^n(2的n 次方幂) used：当前有多少个键值对</p><p>缩容时大小：ht[1] 哈希表大小为第一个大于等于 ht[0].used的 2^n(2的n 次方幂)</p><p>扩容的步骤如下：</p><p>1、为字典ht[1]哈希表分配合适的空间；</p><p>2、将ht[0]中所有的键值对rehash到ht[1]：rehash 指的是重新计算键的哈希值和索引值， 然后将键值对 放置到 ht[1] 哈希表的指定位置上；</p><p>3、当 ht[0] 包含的所有键值对都迁移到了 ht[1] 之后 （ht[0] 变为空表）， 释放 ht[0] ， 将 ht[1] 设置 为 ht[0] ， 并在 ht[1] 新创建⼀个空⽩哈希表， 为下⼀次 rehash 做准备。</p><p>哈希渐进式rehash的详细步骤：</p><p>1、为ht[1]分配空间，让字典同时持有ht[0]和ht[1]两个哈希表。</p><p>2、在字典中维持一个索引计数器变量rehashidx，并将它的指设置为0，表示rehash工作正式开始。</p><p>3、在rehash进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]，当rehash工作完成之后，程序将rehashidx属性的值加一。</p><p>4、随着字典操作的不断执行，最终在某个时间点，ht[0]的所有键值对都会被rehash至ht[1]，这时程序将rehashidx属性设置为-1，表示rehash已经操作完成 ，h[1]变为h[0]</p><p>在 Redis 的实现里，扩容缩容有三条规则：</p><p>当 Redis 没有进行 BGSAVE 相关操作，且 负载因子&gt;1的时候进行扩容。</p><p>当 Redis 进行 BGSAVE 相关操作,当负载因子&gt;5的时候，强行进行扩容。</p><p>当负载因子&lt;0.1的时候，进行缩容。</p><p>负载因子&#x3D;哈希表以保存节点数量 &#x2F; 哈希表的大小.</p><p> <em><strong>*Bgsave*</strong></em> 命令用于在后台异步保存当前数据库的数据到磁盘。</p><p><a href="https://juejin.cn/post/6844904049578377230#%E6%89%A9%E5%AE%B9%E4%B8%8E%E7%BC%A9%E5%AE%B9">https://juejin.cn/post/6844904049578377230#%E6%89%A9%E5%AE%B9%E4%B8%8E%E7%BC%A9%E5%AE%B9</a></p><h3 id="压缩列表ziplist"><a href="#压缩列表ziplist" class="headerlink" title="压缩列表ziplist"></a><strong>压缩列表</strong>ziplist</h3><p>ziplist是一种连续，无序的数据结构。压缩列表是 Redis 为了节约内存而开发的， 由一系列特殊编码的连续内存块组成的顺序型（sequential）数据结构。</p><p>组成</p><table><thead><tr><th>*******<em><strong>属性*</strong></em></th><th>*******<em><strong>类型*</strong></em></th><th>*******<em><strong>长度*</strong></em></th><th>*******<em><strong>用途*</strong></em></th></tr></thead><tbody><tr><td>zlbytes</td><td>uint_32t</td><td>4B</td><td>记录整个压缩列表占用的内存字节数：在对压缩列表进行内存重分配，  或者计算 zlend的位置时使用</td></tr><tr><td>zltail</td><td>uint_32t</td><td>4B</td><td>记录压缩列表表尾节点距离压缩列表的起始地址有多少字节：通过这个偏移量，程序无须遍历整个压缩列表就可以确定表尾节点的地址。</td></tr><tr><td>zllen</td><td>uint_16t</td><td>2B</td><td>记录了压缩列表包含的节点数量：  当这个属性的值小于UINT16_ MAX （65535）时，  这个属性的值就是压缩列表包含节点的数量； 当这个值等于 UINT16_MAX 时， 节点的真实数量需要遍历整个压缩列表才能计算得出。</td></tr><tr><td>entryX</td><td>列表节点</td><td>不定</td><td>压缩列表包含的各个节点，节点的长度由节点保存的内容决定。</td></tr><tr><td>zlend</td><td>uint_8t</td><td>1B</td><td>特殊值 0xFF （十进制 255 ），用于标记压缩列表的末端。</td></tr></tbody></table><p>压缩列表节点的构成　一个压缩列表可以包含任意多个节点（entry）， 每个节点可以保存一个字节数组或者一个整数值（小整数值或者长度比较短的字符串）。</p><p>（1）节点的 previous_entry_length 属性以字节为单位， 记录了压缩列表中前一个节点的长度</p><p>（2）节点的 encoding 属性记录了节点的 content 属性所保存数据的类型以及长度： </p><p>（3）节点的 content 属性负责保存节点的值， 节点值可以是一个字节数组或者整数， 值的类型和长度由节点的 encoding 属性决定。</p><h3 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h3><p><a href="https://www.cnblogs.com/lixinjie/p/a-post-about-skiplist.html">https://www.cnblogs.com/lixinjie/p/a-post-about-skiplist.html</a></p><img src="/2024/04/05/redis/clip_image008.jpg" class="" title="Rodis ,馝i&amp;h|,鹵미i뢰~ |馝i&amp;h|,鹵미i떖 曰中 用才*示″3%1. 而 ,鹵p|로  Ⅲ十Ⅳ4,″裹11,는『」糲붓념모.  L32  NULL  NULL  length  tan. :"><img src="/2024/04/05/redis/clip_image010.jpg" class="" title="img"><p>查找流程：</p><img src="/2024/04/05/redis/clip_image012.jpg" class="" title="没 们 0 以 诓 是 和 在 第 常 引 中 。 我 们 到 节 0 之 处 ． x 大 十 小 于 处 囟 的 朽 貞 乙 所 以 们 谚 n 旧  計 ． k 吸 旗 引 下 k 一 1 旗 引 · 在 苤 1 引 中 ． y 和 屙 只 有 3 书 点 （ 含 y 和 到 ． 所 以 ． 我 钔 在 k 一 1 吸 引 中 是 多  只 粼 历 3 个 白 。 欠 类 。 一 暇 引 星 多 只 靄 以 历 3 首 兯 貞 ，"><p>插入流程：</p><img src="/2024/04/05/redis/clip_image014.jpg" class="" title="· 懂 懒 鈿 詼 捍 ． 锈 合 适 入 0 “ 汀 0 分 分 “ e 相 同 ． 这 时 会 根 中 阐 字 凍 栉 ·  ． 阳 R 酊 川 止 e 旧 0 月 ． 独 出 适 入 的 0 内 0 数 产  ． 阳 谝 1 玩 的 新 堇 0 以 前 处 情 的 向 0 d 和 美 长 廢 卸 地 也 菪 新 鬲 凶 0 向 轟 d ．  · 貝 中 地 栌 了 蚋 饣 敷 地 和 阉 n update 數 用 记 录 的 一 过 言 ． 一 制 ； 小 斗 噕 入 “ 白 ． 巫 庸 ^ 0 “ 《 “ 效  记 灵 主 诬 00 上 一 虫 书 ， 以 便 十 最 肩 新 即 彐 n 伯 。"><img src="/2024/04/05/redis/clip_image016.jpg" class="" title="5 球 ist 节 点  蜘 翱 的 过 &#96; 的 都 是 盟 使 判 凸 0 万 法 的 。 先 垡 个 “ 》 “ 是 出 0 · 如 存 在 盟 斷 的 。 不 存 在 就 适 入  程 》 五 中 刂 是 ． 知 丰 伐 剁 了 酴 ． 冉 斷 ． 这 ， 0 会 做 蚋 内 ． 0 上 束 讲 酗 了 ． 在 R 弱 50  版 本 中 ． R 开 An@嘏 优 化 了 这 个 刊 程 ． 鬥 屮 锔 刂 星 知 生 判 断 这 个 " alt="是 酉 在 ． 处 墨 0 0 ，  后 山 整 希 表 5 舅 e 过 序 。 谊 就 不 靄 蚋 次 粼 河 程 ．"><img src="/2024/04/05/redis/clip_image018.jpg" class="" title="六 ． p 以 t 与 平 衡 树 、 咕 希 衮 的 比 较  的 全 Oil)  ， 0 必 的 据 侑 序 之 0 # 斗 娌 特 只 塑 卜 诠 》  黛 № 肝 河 以 就 匕 屮 励 恻 ：  Z 卉 3 ， 不 0 骷 印 压 0 忮"><h3 id="跳表和红黑树的对比-1"><a href="#跳表和红黑树的对比-1" class="headerlink" title="跳表和红黑树的对比_1"></a>跳表和红黑树的对比_1</h3><ul><li><ol><li>在做范围查找的时候，平衡树比 skiplist 操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在 skiplist 上进行范围查找就非常简单，只需要在找到小值之后，对第 1 层链表进行若干步的遍历就可以实现。</li><li>查找单个 key ， skiplist 和平衡树的时间复杂度都为 O(log n) ，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近 O(1) ，性能更高一些。所以我们平常使用的各种 Map 或 dictionary 结构，大都是基于哈希表实现的。</li><li>平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而 skiplist 的插入和删除只需要修改相邻节点的指针，操作简单又快速。</li><li>从内存占用上来说， skiplist 比平衡树更灵活一些。一般来说，平衡树每个节点包含 2 个指针（分别指向左右子树），而 skiplist 每个节点包含的指针数目平均为 1&#x2F;(1-p) ，具体取决于参数 p 的大小。如果像 Redis 里的实现一样，取 p&#x3D;1&#x2F;4 ，那么平均每个节点包含 1.33 个指针，比平衡树更有优势。</li><li>从算法实现难度上来比较， skiplist 比平衡树要简单得多。</li></ol></li></ul><h2 id="单线程还是多线程？"><a href="#单线程还是多线程？" class="headerlink" title="单线程还是多线程？"></a>单线程还是多线程？</h2><img src="/2024/04/05/redis/clip_image020.gif" class="" title="img"><h2 id="BIO，NIO，Epoll，IO多路复用"><a href="#BIO，NIO，Epoll，IO多路复用" class="headerlink" title="BIO，NIO，Epoll，IO多路复用"></a>BIO，NIO，Epoll，IO多路复用</h2><p>IO多路复用：单线程或单进程同时监测若干个文件描述符是否可以执行IO操作的能力。</p><p>普通IO:</p><img src="/2024/04/05/redis/clip_image021.jpg" class="" title="img"><p>BIO:同步阻塞</p><p>来一个连接新建一个线程处理</p><img src="/2024/04/05/redis/clip_image022.jpg" class="" title="img"><p>这是服务端程序：划线的地方都会阻塞程序：在接受连接（accept）的时候，若没有客户端连接，accept就会阻塞，有连接后运行，执行到read也会阻塞，因为没有客户端发送消息，发了消息后就会运行</p><p>问题：没法处理多个连接，只有轮训到accept的时候才能继续接受连接</p><img src="/2024/04/05/redis/clip_image023.jpg" class="" title="img"><p>开新线程处理：来一个请求开一个线程，会严重影响服务器性能  c10k问题：线程太多了</p><p>用线程池限制了线程数量：并发就会减弱，</p><img src="/2024/04/05/redis/clip_image024.jpg" class="" title="img"><p>还有一个严重的问题就是阻塞，客户端迟迟不发请求，那么就会影响造成线程开销浪费很多，每个线程处理一个连接，那么很多线程就一直阻塞着</p><p>NIO：同步非阻塞</p><p>简单版本：</p><img src="/2024/04/05/redis/clip_image025.jpg" class="" title="img"><p>设置socketChannel为非阻塞：即使客户端没有发数据，read函数不会阻塞</p><p>socketChannel会放在list中，轮训list</p><p>问题：10万个连接，只有100个有收发数据，那么每次需要循环10万个，造成了时间浪费</p><p>解决：令拿一个集合放那些有请求的连接：selector（多路复用器）</p><img src="/2024/04/05/redis/clip_image026.jpg" class="" title="img"><img src="/2024/04/05/redis/clip_image027.jpg" class="" title="img"><p>一个selectionkey对应着一个channel，通过selectionkey就能找到channel</p><p>selector.select会阻塞等待连接事件，当有连接时，则运行</p><p>select也会阻塞等待读写事件，当两个客户端发生了读写事件时，那么这时候selectionKeys集合里面就是两个，那么就可以轮训处理这两个事件</p><img src="/2024/04/05/redis/clip_image028.jpg" class="" title="img"><p>如果是连接事件，也会把客户端的socketChannel注册到selector，监听读写事件</p><img src="/2024/04/05/redis/clip_image029.jpg" class="" title="img"><p>其实创建的这个selector，linux操作系统返回的就是epoll，linux操作系统一切皆文件，返回的的epfd（ep file discription），就是epoll</p><img src="/2024/04/05/redis/clip_image030.jpg" class="" title="img"><p> AIO</p><img src="/2024/04/05/redis/clip_image032.jpg" class="" width="0"><img src="/2024/04/05/redis/clip_image034.jpg" class="" width="0"><img src="/2024/04/05/redis/clip_image036.jpg" class="" title="img"><p>epol_ctl才是真正监听事件的方法</p><p>fd：Channel的文件描述符</p><p>select监听事件</p><p>epoll_wait:阻塞等待事件的发生，有连接读写事件才会运行</p><p>channel放着连接，rdlist放着事件的列表</p><img src="/2024/04/05/redis/clip_image037.jpg" class="" title="img"><img src="/2024/04/05/redis/clip_image039.jpg" class="" title="img"><img src="/2024/04/05/redis/clip_image041.jpg" class="" title="img"><p>阻塞等待事件的发生</p><img src="/2024/04/05/redis/clip_image043.jpg" class="" title="img"><p>3者区别：select每次轮询连接集合，有上限，poll：每次轮询连接集合，无上限，epoll：每次轮询的是有事件发生的连接，无上限</p><h2 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h2><p><em><strong>*当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。*</strong></em></p><p>如果这是 slave node 初次连接到 master node，那么会触发一次 full resynchronization 全量复制。此时 master 会启动一个后台线程，开始生成一份 RDB 快照文件，</p><p>同时还会将从客户端 client 新收到的所有写命令缓存在内存中。RDB 文件生成完毕后， master 会将这个 RDB 发送给 slave，slave 会先写入本地磁盘，然后再从本地磁盘加载到内存中，</p><p>接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。</p><p>slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。</p><p><a href="https://www.cnblogs.com/renpingsheng/p/9796899.html">https://www.cnblogs.com/renpingsheng/p/9796899.html</a></p><img src="/2024/04/05/redis/clip_image045.jpg" class="" title="redis 主 从 复 制 的 核 心 原 理  河 过 行 “ of 品 0 或 设 0 引 ave 。 顷 。 让 一 个 服 器 去 0 制 另 一 个  蹇 。 瞎 底 可 以 讲 行 读 与 襻  怍 ， 当 与 慢 作 导 致 数 剖 1 会 自 劝 将 数 河 步 搶 从 数 库 。 而 从 数 00 一 是 只 读 的 ， 葑 豐 主 重 庵 同 步 过  的 数 0 。 一 个 扌 数 亏 可 以 有 多 个 从 数 0 库 ， 而 一 ， 个 M 只 能 有 一 个 扌 数 瞎 私  〔 月 主 节 白 通 过 bg “ “ 命 令 fork 子 进 程 进 行 RDB 恃 久 化 、 该 过 程 是 菲 簡 肖 〔 pu 、 内 山 轰 地 ． 硬 盘 ℃ 的  〔 扌 节 点 过 网 适 RD 日 又 件 友 送 从 点 ， 对 主 从 节 的 鬲 都 会 带 + 很 大 的 料 耗  司 从 节 中 空 老 数 ． 载 入 新 RD 日 文 件 围 过 程 犀 沮 藶 的 ， 应 窖 户 的 命 令 ： 如 果 从 0 执 行  bgrewriteaof, 也 会 諾 犟 外 肖 耗"><img src="/2024/04/05/redis/clip_image047.jpg" class="" title="地 一 次 次 行 0 枞  “ 劌 是 上 一 次 主  %asterüpsync  " alt="翩 表 示 扌 邗 运 行 》 D ． 。 e 示 当 航 主  ync(runid)(otfset)  0 行 ID ． 酬 1 是 当 前 从 书  点 刊 处"><h2 id="部分同步"><a href="#部分同步" class="headerlink" title="部分同步"></a>部分同步</h2><p>部分复制主要是 Redis 针对全量复制的过高开销做出的一种优化措施，使用 psync {runId} {offset} 命令实现。当从节点正在复制主节点时，如果出现网络闪断或者命令丢失等异常情况时，从节点会向主节点要求补发丢失的命令数据，如果主节点的复制积压缓冲区存在这部分数据则直接发送给从节点，这样就保证了主从节点复制的一致性。补发的这部分数据一般远远小于全量数据，所以开销很小。</p><img src="/2024/04/05/redis/clip_image049.jpg" class="" title="slave  2) Request  1)  3)  repl-backlog-  buffer  4) psync {offset} {runld}  master  5) CONTINUE"><p> 当主从节点之间网络出现中断时，如果超过了 repl-timeout 时间，主节点会认为从节点故障并中断复制连接。</p><p> 主从连接中断期间主节点依然响应命令，但因复制连接中断命令无法发送给从节点，不过主节点内部存在复制积压缓冲区( repl-backlog-buffer )，依然可以保存最近一段时间的写命令数据，默认最大缓存 1MB。</p><p> 当主从节点网络恢复后，从节点会再次连上主节点。</p><p> 当主从连接恢复后，由于从节点之前保存了自身已复制的偏移量和主节点的运行ID。因此会把它们作为 psync 参数发送给主节点，要求进行补发复制操作。</p><p> 主节点接到 psync 命令后首先核对参数 runId 是否与自身一致，如果一致，说明之前复制的是当前主节点；之后根据参数 offset 在自身复制积压缓冲区查找，如果偏移量之后的数据存在缓冲区中，则对从节点发送 +CONTINUE 响应，表示可以进行部分复制。</p><p> 主节点根据偏移量把复制积压缓冲区里的数据发送给从节点，保证主从复制进入正常状态。</p><img src="/2024/04/05/redis/clip_image051.jpg" class="" title="img"><h2 id="集群方案"><a href="#集群方案" class="headerlink" title="集群方案"></a>集群方案</h2><p>主从复制模式</p><p> Sentinel（哨兵）模式</p><p> Cluster 模式</p><p>*<strong>*<em><em><strong><strong>主从复制机制的目的有两个*</strong></strong></em>*</em></strong></p><p> 一个是读写分离，分担 “master” 的读写压力</p><p> 一个是方便做容灾恢复</p><p><img src="/redis/clip_image053.jpg" alt="从 服 务 器  主 服 务 器  创 建 快 照 、 缓 冲 快  [ 1 同 步 快 照 ]  載 入 、 解 析 快 照  缓 冲 快 照 同  [ 2 ． 同 步 与 缓 冲 ]  生 成 期 间 的 写 命 令  间 的 写 命 令  载 入 缓 冲  loop  从 服 务 器  [ 3 ． 同 步 增 量 ]  主 服 务 器 "></p><p>从数据库启动成功后，连接主数据库，发送 SYNC 命令；</p><p> 主数据库接收到 SYNC 命令后，开始执行 BGSAVE 命令生成 RDB 文件并使用缓冲区记录此后执行的所有写命令；</p><p> 主数据库 BGSAVE 执行完后，向所有从数据库发送快照文件，并在发送期间继续记录被执行的写命令；</p><p> 从数据库收到快照文件后丢弃所有旧数据，载入收到的快照；</p><p> 主数据库快照发送完毕后开始向从数据库发送缓冲区中的写命令；</p><p> 从数据库完成对快照的载入，开始接收命令请求，并执行来自主数据库缓冲区的写命令；（从数据库初始化完成）</p><p> 主数据库每执行一个写命令就会向从数据库发送相同的写命令，从数据库接收并执行收到的写命令（从数据库初始化完成后的操作）</p><p> 出现断开重连后，2.8之后的版本会将断线期间的命令传给重数据库，增量复制。</p><p> 主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。Redis 的策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。</p><p>*<strong>*<em><em><strong><strong>主从复制缺点*</strong></strong></em>*</em></strong></p><p> Redis不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复（也就是要人工介入）；</p><p> 主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性；</p><p> 如果多个 Slave 断线了，需要重启的时候，尽量不要在同一时间段进行重启。因为只要 Slave 启动，就会发送sync 请求和主机全量同步，当多个 Slave 重启的时候，可能会导致 Master IO 剧增从而宕机。</p><p> Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂；</p><p><em><strong>*Sentinel*<em><strong><strong>（哨兵）模式*</strong></strong></em>*</strong></em></p><p>*<strong>*<em><em><strong><strong>哨兵模式的作用*</strong></strong></em>*</em></strong></p><p> 通过发送命令，让 Redis 服务器返回监控其运行状态，包括主服务器和从服务器；</p><p> 当哨兵监测到 master 宕机，会自动将 slave 切换成 master ，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换主机；</p><p>一个哨兵进程对Redis服务器进行监控，也可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。</p><p>*<strong>*<em><em><strong><strong>故障切换的过程*</strong></strong></em>*</em></strong></p><p>假设主服务器宕机，哨兵1先检测到这个结果，系统并不会马上进行 failover 过程，仅仅是哨兵1主观的认为主服务器不可用，这个现象成为*****<em><strong><strong>主观下线*</strong></strong></em>*<em><strong>。当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行 failover 操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为</strong></em>**<em><strong><strong>客观下线*</strong></strong></em>****。这样对于客户端而言，一切都是透明的。</p><p>*<strong>*<em><em><strong><strong>哨兵模式的优缺点*</strong></strong></em>*</em></strong></p><p>*<strong>*<em><em><strong><strong>优点：*</strong></strong></em>*</em></strong></p><p> 哨兵模式是基于主从模式的，所有主从的优点，哨兵模式都具有。</p><p> 主从可以自动切换，系统更健壮，可用性更高(可以看作自动版的主从复制)。</p><p>*<strong>*<em><em><strong><strong>缺点：*</strong></strong></em>*</em></strong></p><p> Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。</p><p>*<strong>*Cluster*</strong> ***集群模式（***<em><strong>Redis*<em><strong><strong>官方）*</strong></strong></em>*</strong></em></p><p>实现了 Redis 的分布式存储，*******<em><strong>也就是说每台*</strong> <em><strong>Redis*</strong> <em><strong>节点上存储不同的内容*</strong></em></em></em>****。</p><p>*<strong>*<em><em><strong><strong>集群的数据分片*</strong></strong></em>*</em></strong></p><p>Redis 集群没有使用一致性 hash，而是引入了哈希槽【hash slot】的概念。</p><p>Redis 集群有16384 个哈希槽，每个 key 通过 CRC16 校验后对 16384 取模来决定放置哪个槽。集群的每个节点负责一部分hash槽，举个例子，比如当前集群有3个节点，那么：</p><p> 节点 A 包含 0 到 5460 号哈希槽</p><p> 节点 B 包含 5461 到 10922 号哈希槽</p><p> 节点 C 包含 10923 到 16383 号哈希槽</p><p><em><strong>*Redis*</strong> <em><strong>集群的主从复制模型*</strong></em></em><em>*</em>**</p><p>为了保证高可用，redis-cluster集群引入了主从复制模型，一个主节点对应一个或者多个从节点，当主节点宕机的时候，就会启用从节点。当其它主节点 ping 一个主节点 A 时，如果半数以上的主节点与 A 通信超时，那么认为主节点 A 宕机了。如果主节点 A 和它的从节点 A1 都宕机了，那么该集群就无法再提供服务了。</p><p><a href="https://juejin.cn/post/6844904178154897415">https://juejin.cn/post/6844904178154897415</a></p><h2 id="持久化机制"><a href="#持久化机制" class="headerlink" title="持久化机制"></a>持久化机制</h2><img src="/2024/04/05/redis/clip_image054.jpg" class="" title="img"><p>怎样保证子进程持久化的时候主进程会处理新的写请求时持久化不会乱：copyandwrite机制，主进程不会直接操作父子共享内存，而是数据复制出来执行，确保子进程是5:00的数据而不是5:01的数据</p><img src="/2024/04/05/redis/clip_image055.jpg" class="" title="img"><img src="/2024/04/05/redis/clip_image056.jpg" class="" title="img"><img src="/2024/04/05/redis/clip_image057.jpg" class="" title="img"><h2 id="内存淘汰机制"><a href="#内存淘汰机制" class="headerlink" title="内存淘汰机制"></a>内存淘汰机制</h2><p>通过定期删除和惰性删除并不能删掉redis中全部的过期key，所以需要通过另外的机制来确保内存的可用性</p><img src="/2024/04/05/redis/clip_image059.jpg" class=""><img src="/2024/04/05/redis/clip_image061.jpg" class="" width=""><h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><p>redis可以通过MULTI,EXEC,DISCARD,WATCH等命令来实现事务</p><img src="/2024/04/05/redis/clip_image063.jpg" class="" title="亻 吏 用 MULT 丨 命 令 后 可 以 输 入 多 个 命 令 。 Redis 不 会 立 即 执 行 这 些 命 令 ， 而 是 将 它 们 放 到 队 列 ， 当  调 用 了 EXEC 命 令 将 执 行 所 有 命 令 。"><p>Redis 是不⽀持 roll back 的，因⽽不满⾜原⼦性的（⽽且不满⾜持性）。</p><img src="/2024/04/05/redis/clip_image065.jpg" class="" title="你 可 以 将 Redis 中 的 事 务 就 理 解 为 S-Redis 事 务 提 供 了 厂 种 将 多 个 命 令 请 求 打 包 的 功 能 。 ． ． 燃 后  再 按 顺 序 执 行 打 包 的 所 有 命 令 ， 并 且 不 会 被 中 途 打 断 0"><h1 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h1><h2 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a><strong>缓存雪崩</strong></h2><p>缓存在某一个时刻出现大规模的key失效，大量的请求打在了数据库上面</p><p><strong>问题分析：</strong></p><p>两种可能：第一种是Redis宕机，第二种可能就是采用了相同的过期时间。</p><p>解决方案：</p><p>（1）事前：</p><p>① 均匀过期：设置不同的过期时间，让缓存失效的时间尽量均匀，避免相同的过期时间导致缓存雪崩，造成大量数据库的访问。</p><p>② 分级缓存：第一级缓存失效的基础上，访问二级缓存，每一级缓存的失效时间都不同。</p><p>③ 热点数据缓存永远不过期。</p><p>永不过期实际包含两层意思：</p><p>物理不过期，针对热点key不设置过期时间</p><p>逻辑过期，把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建</p><p>④ 保证Redis缓存的高可用，防止Redis宕机导致缓存雪崩的问题。可以使用 主从+ 哨兵，Redis集群来避免 Redis 全盘崩溃的情况。</p><p>（2）事中：</p><p>① 互斥锁：在缓存失效后，通过互斥锁或者队列来控制读数据写缓存的线程数量，比如某个key只允许一个线程查询数据和写缓存，其他线程等待。这种方式会阻塞其他的线程，此时系统的吞吐量会下降,那么我们可以在第一个查询数据的请求上使用一个 互斥锁来锁住它。其他的线程走到这一步拿不到锁就等着，等第一个线程查询到了数据，然后做缓存。后面的线程进来发现已经有缓存了，就直接走缓存。</p><p>② 使用熔断机制，限流降级。当流量达到一定的阈值，直接返回“系统拥挤”之类的提示，防止过多的请求打在数据库上将数据库击垮，至少能保证一部分用户是可以正常使用，其他用户多刷新几次也能得到结果。</p><p>（3）事后：</p><p>① 开启Redis持久化机制，尽快恢复缓存数据，一旦重启，就能从磁盘上自动加载数据恢复内存中的数据。</p><h2 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a><strong>缓存击穿</strong></h2><p>缓存击穿是某个热点的key失效</p><p><strong>问题分析：</strong></p><p>两个方面解决，第一是否可以考虑热点key不设置过期时间，第二是否可以考虑降低打在数据库上的请求数量。</p><p>解决方案：</p><p>热点数据缓存永远不过期。</p><p>互斥锁：在缓存失效后，通过互斥锁或者队列来控制读数据写缓存的线程数量，比如某个key只允许一个线程查询数据和写缓存，其他线程等待。这种方式会阻塞其他的线程，此时系统的吞吐量会下降</p><h2 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a><strong>缓存穿透</strong></h2><p>用户请求的数据在缓存中不存在即没有命中，同时在数据库中也不存在，导致用户每次请求该数据都要去数据库中查询一遍。</p><p><strong>问题分析：</strong></p><p>缓存穿透的关键在于在Redis中查不到key值，它和缓存击穿的根本区别在于传进来的key在Redis中是不存在的。</p><p>解决方案：</p><p>（1）软件层面防止</p><p>（2）将无效的key存放进Redis中,并设置其过期时间极短</p><p>（3）使用布隆过滤器</p><h2 id="缓存预热"><a href="#缓存预热" class="headerlink" title="缓存预热"></a>缓存预热</h2><p>缓存预热是指系统上线后，提前将相关的缓存数据加载到缓存系统。</p><p>缓存预热解决方案：</p><p>（1）数据量不大的时候，工程启动的时候进行加载缓存动作；</p><p>（2）数据量大的时候，设置一个定时任务脚本，进行缓存的刷新；</p><p>（3）数据量太大的时候，优先保证热点数据进行提前加载到缓存。</p><h2 id="缓存降级"><a href="#缓存降级" class="headerlink" title="缓存降级"></a><strong>缓存降级</strong></h2><p>缓存降级是指缓存失效或缓存服务器挂掉的情况下，不去访问数据库，直接返回默认数据或访问服务的内存数据。</p><p><a href="https://blog.csdn.net/a745233700/article/details/88088669">https://blog.csdn.net/a745233700/article/details/88088669</a></p><h2 id="如何保证Redis和数据库的数据一致"><a href="#如何保证Redis和数据库的数据一致" class="headerlink" title="如何保证Redis和数据库的数据一致"></a><strong>如何保证Redis和数据库的数据一致</strong></h2><img src="/2024/04/05/redis/clip_image067.jpg" class="" title="img"><img src="/2024/04/05/redis/clip_image069.jpg" class="" title="img"><p><em><strong>*删缓存失败了怎么办：重试机制*</strong></em></p><p>方案1：</p><img src="/2024/04/05/redis/clip_image071.jpg" class="" title="需 要 删 除 的  消 息 队 列  3 、 需 要 删 的 key  （ * ） 2 、 删 除 缓 存 失 败  缓 存  业 务 代 码  5 、 重 试 删 除 操 作  1 、 更 新 数 据 库  数 据 库"><p>流程如下所示</p><p>（1）更新数据库数据；</p><p>（2）缓存因为种种问题删除失败</p><p>（3）将需要删除的 key 发送至消息队列</p><p>（4）自己消费消息，获得需要删除的 key</p><p>（5）继续重试删除操作，直到成功</p><p>方案2：</p><img src="/2024/04/05/redis/clip_image073.jpg" class="" title="消 息 队 列  7 、 操 作 的 数 据 以 及  （ 8 ） 5 、 删 除 缓 存 失 败  菲 业 务 代 码  、 操 作 的 数 据 以 及  8 、 重 试 删 除 操 作  4 、 提 取 出 操 作 的 数 据 以 及 key  订 Nbinlog  程 序  3 、 产 生 b og 操 作 日 志  binloga  志  2 、 写 入 binlo  缓 存  业 务 代 码  1 、 更 新 数 据 库  数 据 库"><p>流程如下图所示：</p><p>（1）更新数据库数据</p><p>（2）数据库会将操作信息写入 binlog 日志当中</p><p>（3）订阅程序提取出所需要的数据以及 key</p><p>（4）另起一段非业务代码，获得该信息</p><p>（5）尝试删除缓存操作，发现删除失败</p><p>（6）将这些信息发送至消息队列</p><p>（7）重新从消息队列中获得该数据，重试操作。</p><p><a href="https://xie.infoq.cn/article/47241d099404a1565e168fad4">https://xie.infoq.cn/article/47241d099404a1565e168fad4</a></p><p><a href="https://segmentfault.com/a/1190000037611692%E5%8F%A6%E4%B8%80%E7%A7%8D%E6%80%9D%E8%B7%AF">https://segmentfault.com/a/1190000037611692另一种思路</a></p><p>第三种方案：异步更新缓存(基于订阅binlog的同步机制)</p><p>技术整体思路：</p><p>MySQL binlog增量订阅消费+消息队列+增量数据更新到redis</p><p>1）读Redis：热数据基本都在Redis</p><p>2）写MySQL:增删改都是操作MySQL</p><p>3）更新Redis数据：MySQ的数据操作binlog，来更新到Redis</p><p>3.1）数据操作主要分为两大块：</p><p>一个是全量(将全部数据一次写入到redis)</p><p>一个是增量（实时更新）</p><p>这里说的是增量,指的是mysql的update、insert、delate变更数据。</p><p>3.2）读取binlog后分析 ，利用消息队列,推送更新各台的redis缓存数据。</p><p>这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。</p><p>其实这种机制，很类似MySQL的主从备份机制，因为MySQL的主备也是通过binlog来实现的数据一致性。</p><p>使用实例：canel</p><h2 id="设计一个分布式锁"><a href="#设计一个分布式锁" class="headerlink" title="设计一个分布式锁"></a><strong>设计一个分布式锁</strong></h2><img src="/2024/04/05/redis/clip_image074.jpg" class="" title="img"><img src="/2024/04/05/redis/clip_image075.jpg" class="" title="img"><img src="/2024/04/05/redis/clip_image076.jpg" class="" title="img"><img src="/2024/04/05/redis/clip_image077.jpg" class="" title="img"><img src="/2024/04/05/redis/clip_image078.jpg" class="" title="img"><img src="/2024/04/05/redis/clip_image079.jpg" class="" title="img"><h2 id="如何配置key的过期时间，实现原理是什么"><a href="#如何配置key的过期时间，实现原理是什么" class="headerlink" title="如何配置key的过期时间，实现原理是什么"></a>如何配置key的过期时间，实现原理是什么</h2><img src="/2024/04/05/redis/clip_image080.jpg" class="" title="img"><p>SETEX KEY_NAME TIMEOUT VALUE</p><p><strong>原理：时间事件</strong></p><p>Redis的时间事件分为两类：</p><ol><li>定时事件：让一段程序在指定的时间之后执行一次。</li><li>周期性事件：让一段程序每隔指定时间就执行一次。</li></ol><p>一个时间事件主要由以下三个属性组成：</p><ol><li>id：服务器为时间事件创建的全局唯一ID（标识号）。ID号按从小到大的顺序递增。</li><li>when：毫秒精度的UNIX时间戳。记录了时间事件到达时间。</li><li>timeProc：时间处理器，一个函数。当时间事件到达时，服务器就会调用相应的处理器来处理事件。<br>     服务器将所有时间都放在一个无序列表中，每当时间事件执行器运行时，它遍历整个链表查找所有已到达的时间事件，并调用相应的时间处理器。<br>     无序指的是不按照when属性值进行排序，由于新创建的时间事件是插入到链表的表头，所以链表中时间事件是按照id属性降序排序的。</li></ol><p>一个保存了三个时间事件链表的例子：</p><img src="/2024/04/05/redis/clip_image082.jpg" class="" title="time event  1385877600030  events  time Proc  handler 3  t ime event  1385877600000  q)  handler 2  time event  hen 1385877600010 handier 1 %}&lt;p&gt;注： 由于没有按照执行时间进行排序，所以时间事件执行器运行时，它必须遍历链表中的所有时间事件，这样才能确保服务器中所有已到达的时间事件都会被处理。&lt;&#x2F;p&gt;&lt;h1 id&#x3D;开放性问题&quot;&gt;&lt;a href&#x3D;#开放性问题 class&#x3D;headerlink title&#x3D;开放性问题&gt;&lt;&#x2F;a&gt;开放性问题&lt;&#x2F;h1&gt;&lt;h2 id&#x3D;为什么性能非常高&gt;&lt;a href&#x3D;#为什么性能非常高 class&#x3D;headerlink title&#x3D;为什么性能非常高&gt;&lt;&#x2F;a&gt;&lt;strong&gt;为什么性能非常高&lt;&#x2F;strong&gt;&lt;&#x2F;h2&gt;&lt;p&gt;Redis性能非常高的原因主要有以下几点：&lt;&#x2F;p&gt; &lt;p&gt;- 内存存储：Redis是使用内存(in-memeroy)存储,没有磁盘IO上的开销&lt;&#x2F;p&gt; &lt;p&gt;- 单线程实现：Redis使用单个线程处理请求，避免了多个线程之间线程切换和锁资源争用的开销&lt;&#x2F;p&gt; &lt;p&gt;- 非阻塞IO：Redis使用多路复用IO技术，在poll，epool，kqueue选择最优IO实现&lt;&#x2F;p&gt; &lt;p&gt;- 优化的数据结构：Redis有诸多可以直接应用的优化数据结构的实现，应用层可以直接使用原生的数据结构提升性能&lt;&#x2F;p&gt; &lt;p&gt;&lt;a href&#x3D;https:&#x2F;&#x2F;segmentfault.com&#x2F;a&#x2F;1190000022088928&gt;https:&#x2F;&#x2F;segmentfault.com&#x2F;a&#x2F;1190000022088928&lt;&#x2F;a&gt;&lt;&#x2F;p&gt; {% asset_img clip_image083.jpg img"><img src="/2024/04/05/redis/clip_image084.jpg" class="" title="img"><p>时间处理器：看是读事件还是写事件</p><img src="/2024/04/05/redis/clip_image085.jpg" class="" title="img"><p>并发量数据</p><p>单机压测</p><p>我本地试了一下</p><p>环境：windows10 64位、i5 8250U + 8G 内存。 redis单实例</p><p>1、先打开redis， 执行以下命令</p><p>.&#x2F;redis-benchmark -r 1000000 -n 2000000 -t get,set,lpush,lpop -P 16 -q</p><img src="/2024/04/05/redis/clip_image087.jpg" class="" title="å¨è¿éæå¥å¾çæè¿°"><p>14万左右并发</p><p>截一张官网的测试结果：</p><img src="/2024/04/05/redis/clip_image089.jpg" class="" title="å¨è¿éæå¥å¾çæè¿°"><p>55万并发</p><p>看来是我的电脑垃圾了…</p><p>原文链接：<a href="https://blog.csdn.net/sishenhzy/article/details/100918712">https://blog.csdn.net/sishenhzy/article/details/100918712</a></p><h2 id="海量数据下如何快速查找一条记录"><a href="#海量数据下如何快速查找一条记录" class="headerlink" title="海量数据下如何快速查找一条记录"></a><strong>海量数据下如何快速查找一条记录</strong></h2><img src="/2024/04/05/redis/clip_image091.gif" class="" title="img"><h2 id="为什么使用缓存？"><a href="#为什么使用缓存？" class="headerlink" title="为什么使用缓存？"></a>为什么使用缓存？</h2><p>高性能</p><p>对于更新频率不高并且读取频率比较大的数据，没必要每次都读取数据库。第一次读取以后，将数据放入缓存，后面再读取数据则直接从缓存获取，提高系统性能。</p><p>高并发</p><p>数据库本身并发量是非常有限的，mysql的qps一般是几千左右，如果所有请求都直接打到数据库，数据库很有可能会直接挂掉。Redis是直接基于内存进行操作的，天生就是支持高并发。根据上一篇的压测结果，单机redis并发都是几十万级别的，并发相当高。</p><p>原文链接：<a href="https://blog.csdn.net/sishenhzy/article/details/101029114">https://blog.csdn.net/sishenhzy/article/details/101029114</a></p><h2 id="在项目中是如何使用缓存的"><a href="#在项目中是如何使用缓存的" class="headerlink" title="在项目中是如何使用缓存的"></a>在项目中是如何使用缓存的</h2><p>对于项目中一些读取频率比较高的，同时数据改变频率比较小的数据，可以放入缓存中，提高并发和性能。如果数据发生改变，更新数据库的同时更新缓存。</p><p>比如电商的详情页数据，项目中接口的返回结果等等</p><p>来自 <a href="https://blog.csdn.net/sishenhzy/article/details/101029114?spm=1001.2014.3001.5501">https://blog.csdn.net/sishenhzy/article/details/101029114?spm=1001.2014.3001.5501</a></p><h2 id="使用缓存的不良后果？"><a href="#使用缓存的不良后果？" class="headerlink" title="使用缓存的不良后果？"></a>使用缓存的不良后果？</h2><p>缓存与数据库双写不一致</p><p>缓存雪崩、缓存穿透</p><p>缓存并发竞争</p><p>来自 <a href="https://blog.csdn.net/sishenhzy/article/details/101029114?spm=1001.2014.3001.5501">https://blog.csdn.net/sishenhzy/article/details/101029114?spm=1001.2014.3001.5501</a></p><h2 id="Memcached？"><a href="#Memcached？" class="headerlink" title="Memcached？"></a>Memcached？</h2><p><a href="https://www.cnblogs.com/aspnethot/articles/1861336.html"><strong>什么是<strong><strong>Memcached</strong></strong>？</strong></a></p><p>先看看下面几个概念：</p><p><strong>Memory</strong>：内存存储，不言而喻，速度快，对于内存的要求高，不指出的话所缓存的内容非持久化。对于CPU要求很低，所以常常采用将Memcached服务端和一些CPU高消耗Memory低消耗应用部属在一起。</p><p><strong>Cache</strong>：在ASP.NET中已经可以实现对页面局部进行缓存，而使用Memcached的缓存比 ASP.NET的局部缓存更加灵活，可以缓存任意的对象，不管是否在页面上输出。ASP.NET的缓存是基于本地（单机）的，受到服务器空闲内存空间的限制，以及多台web服务器本地缓存的同步，但是没有网络存取的延迟。而Memcached最大的优点是可以分布式的部署，这对于大规模应用来 说 也是必不可少的要求。最初的缓存做法是在线程内对对象进行缓存，但这样进程间就无法共享缓存，命中率非常低，导致缓存效率极低。后来出现了共享内存的缓 存，多个进程或者线程共享同一块缓存，但毕竟还是只能局限在一台机器上，多台机器做相同的缓存同样是一种资源的浪费，而且命中率也比较低。</p><p><strong>分布式扩展</strong>：Memcached的很突出一个优点，就是采用了可分布式扩展的模式。可以将部属在一台机器上的多个Memcached服务实例或者部署在多个机器上的Memcached服务器组成一个虚拟的服务端，对于调用者来说完全屏蔽和透明。提高的单机器的内存利用率。</p><p><strong>Socket****通信</strong>：传输内容的大小以及序列化的问题需要注意，虽然Memcached通常会被放置到内网作为Cache，Socket传输速率应该比较高（当前支持TCP和UDP两种模式，同时根据客户端的不同可以选择调用方式），但是序列化成本和带宽成本还是需要注意。这里也提一下序列化，对于对象序列化的性能往往让大家头痛，但是如果对于同一类的Class对象序列化传输，第一次序列化时间比较长，后续就会优化，其实也就是说序列化最大的消耗不是对象序列化，而是类的序列化。因此在Memcached中保存的往往是较小的内容。</p><p><strong>Memcached</strong> <strong>原理</strong></p><p>Memcached是一个独立的，高性能的，分布式的内存对象缓存系统。通过在内存里维护一个统一的巨大的hash表，它能够用来存储各种格式的数据，包括图像、视 频、文件以及数据库检索的结果等。它的缓存是一种分布式的，也就是可以允许不同主机上的多个用户同时访问这个缓存系统， 这种方法不仅解决了共享内存只能是单机的弊端，同时也解决了数据库检索的压力，最大的优点是提高了访问获取数据的速度！Memcached 使用libevent(网络接口的封装)来进行网络并发连接的处理，能够保持在很大并发情况下，仍旧能够保持快速的响应能力互联网公司使用代表：Sina,Sohu,Yahoo,Twitter等等。</p><p>Memcached的机制就是一个很简单的Cache，把东西放进去，然后可以取出来，如果发现所提供的Key没有命中，那么就很直白的告诉你，你这个key没有任何对应的东西在缓存里，去数据库或者其他地方取，当你在外部数据源取到的时候，可以直接将内容置入到Cache中，这样下次就可以命中了。这里会提到怎么去同步这些数据，两种方式，一种就是在你修改了以后立刻更新Cache内容，这样就会即时生效。另一种是说容许有失效时间，到了失效时间，自然就会将内容删除，此时再去去的时候就会命中不了，然后再次将内容置入Cache，用来更新内容。后者用在一些时时性要求不高，写入不频繁的情况。刚才我们提到Memcached 的传输协议，因此传输的数据必须序列化，C# class里使用[Serializable]标示，并且为了性能，Memcached Client采用了压缩的机制使传输的数据更小。其实Memcached服务端本身是单实例的，只是在客户端实现过程中可以根据存储的主键作分区存储，而这个区就是Memcached服务端的一个或者多个实例</p><p>内存分配机制：首先要说明的是Memcached支持最大的存储对象为1M。它的内存分配比较特殊，但是这样的分配方式其实也是对于性能考虑的，简单的分配机制可以更容易回收再分配，节省对于CPU的使用。这里用一个酒窖比喻来说明这种内存分配机制，首先在Memcached起来的时候可以通过参数设置使用的总共的Memory，当你第一次往Memcached存储数据时, Memcached会去申请1MB的内存, 把该块内存称为一个slab, 也称为一个page, 如果可以存储这个数据的最佳的chunk大小为128B,那么Memcached会把刚申请的slab以128B为单位进行分割成8192块. 当这页slab的所有chunk都被用完时,并且继续有数据需要存储在128B的chunk里面时,如果已经申请的内存小于最大可申请内存10MB 时, Memcached继续去申请1M内存,继续以128B为单位进行分割再进行存储;如果已经无法继续申请内存,那么Memcached会先根据LRU 算法把队列里面最久没有被使用到的chunk进行释放后,再将该chunk用于存储. 这个就是建造一个酒窖，然后在有酒进入的时候，首先申请（通常是1M）的空间，用来建酒架，酒架根据这个酒瓶的大小分割酒架为多个小格子安放酒瓶，将同样大小范围内的酒瓶都放置在一类酒架上面。例如20cm半径的酒瓶放置在可以容纳20-25cm的酒架A上，30cm半径的酒瓶就放置在容纳25-30cm的酒架B上。回收机制也很简单，首先新酒入库，看看酒架是否有可以回收的地方，如果有直接使用，如果没有申请新的地方，如果申请不到，采用配置的过期策略。这个特点来看，如果要放的内容大小十分离散，同时大小比例相差梯度很明显，那么可能对于使用空间来说不好，可能在酒架A上就放了一瓶酒，但占用掉了一个酒架的位置。</p><p>为了避免使用Memcached时出现异常, 使用Memcached的项目需要注意:</p><p>\1. 不能往Memcached存储一个大于1MB的数据.</p><p>\2. 往Memcached存储的所有数据,如果数据的大小分布于各种chunk大小区间,从64B到1MB都有,可能会造成内存的极大浪费以及Memcached的异常.</p><p>举个例子:</p><p>Memcached最大可申请内存为2M, 你第一次存储一个10B的数据,那么Memcached会申请1MB的内存,以64B进行分割然后存储该数据, 第二次存储一个90B的数据,那么Memcached会继续申请1M的内存,以128B进行分割然后存储该数据, 第三次如果你想存储一个150B的数据, 如果可以继续申请内存, Memcached会申请1M内存以256B的大小进行分割, 但是由于最大可申请仅仅为2MB,所以会导致该数据无法存储.</p><p>数据过期方式</p><p>• Lazy Expiration</p><p>Memcached内部不会监视记录是否过期，而是在get时查看记录的时间戳，检查记录是否过</p><p>期。这种技术被称为lazy（惰性）expiration。因此，Memcached不会在过期监视上耗费</p><p>CPU时间。</p><p>• LRU</p><p>Memcached会优先使用已超时的记录的空间，但即使如此，也会发生追加新记录时空间不</p><p>足的情况，此时就要使用名为 Least Recently Used（LRU）机制来分配空间。顾名思</p><p>义，这是删除“最近最少使用”的记录的机制。因此，当Memcached的内存空间不足时</p><p>（无法从slab class 获取到新的空间时），就从最近未被使用的记录中搜索，并将其空</p><p>间分配给新的记录。从缓存的实用角度来看，该模型十分理想。</p><p>分布式</p><p>假设有3个客户端1, 2, 3，3台Memcached A, B, C：</p><p>Client 1想把数据”barbaz”以key “foo”存储。Client 1首先参考节点列表（A, B, C），计算key “foo”的哈希值，假设Memcached B被选中。接着，Client 1直接connect到Memcached B，通过key “foo”把数据”barbaz”存储进去。Client 2使用与Client 1相同的客户端库（意味着key的哈希算法相同），也拥有同样的Memcached列表（A, B, C）。于是，经过相同的哈希计算，Client 2计算出key “foo”在Memcached B上，然后它直接请求Memcached B，得到数据”barbaz”。</p><p><strong>Memcached****的使用场合</strong></p><p>当运行在单独的Web服务器上，你可以很容易地清除一个已经确认被改变了的缓存。可惜，ASP.NET没有一个很好的方法来支持多服务器。每个服务器上的缓存都对其他缓存的改变一无所知。ASP.NET允许通过基于文件系统和数据库表的触发器取消一个缓存。然而，这也存在问题，比如数据库触发器需要使用昂贵的轮询，以及触发器本身冗长的编程。好像.NET4.0有了新的解决方法。我们还有别的选择，Memcached就一种。但是Memcached不是万能的，它也不是适用在所有场合。 Memcached是“分布式”的内存对象缓存系统，那么就是说，那些不需要“分布”的，不需要共享的，或者干脆规模小到只有一台服务器的应用， Memcached不会带来任何好处，相反还会拖慢系统效率，因为网络连接同样需要资源，即使是UNIX本地连接也一样。Memcached本地读写速度要比直接ASP.NET缓存(IIS进程)内存慢很多倍，请看下面的测试数据。可见，如果只是 本地级缓存，使用Memcached是非常不划算的。Memcached在很多时候都是作为数据库前端cache使用的。因为它比数据库少了很多SQL解析、磁盘操作等开销，而且它是使用内存来管理数据的， 所以它可以提供比直接读取数据库更好的性能，在大型系统中，访问同样的数据是很频繁的，Memcached可以大大降低数据库压力，使系统执行效率提升。Memcached也经常作为服务器之间数据共享的存储媒介，存储一些系统的共享数据。</p><p>需要注意的是，Memcached使用内存管理数据，所以它是易失的，当服务器重启，或者Memcached进程中止，数据便会丢失，所以 Memcached不能用来持久保存数据。很多人的错误理解，Memcached的性能非常好，好到了内存和硬盘的对比程度，它的实际瓶颈在于网络连接，它和使用磁盘的数据库系统相比，好处在于它本身非常“轻”，因为没有过多的开销和直接 的读写方式，它可以轻松应付非常大的数据交换量，，Memcached进程本身并不占用多少CPU资源的情况。如果web系统采用ASP.NET缓存 + Memcached的方式。性能将会有个不错的提升。</p><p>ASP.NET缓存：本地的，速度更快，一般将highly  common的数据或者程序控制数据用ASP.NET缓存。</p><p>Memcached：存一些来自数据库的数据或者web服务器的共享数据。</p><h2 id="redis-和-memcached-有啥区别？"><a href="#redis-和-memcached-有啥区别？" class="headerlink" title="redis 和 memcached 有啥区别？"></a>redis 和 memcached 有啥区别？</h2><p>redis 支持复杂的数据结构</p><p>redis 相比 memcached 来说，拥有更多的数据结构，能支持更丰富的数据操作。如果需要缓存能够支持更复杂的结构和操作， redis 会是不错的选择。</p><p>redis 原生支持集群模式</p><p>在 redis3.x 版本中，便能支持 cluster 模式，而 memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。</p><p>性能对比</p><p>由于 redis 只使用单核，而 memcached 可以使用多核，所以平均每一个核上 redis 在存储小数据时比 memcached 性能更高。而在 100k 以上的数据中，memcached 性能要高于 redis。虽然 redis 最近也在存储大数据的性能上进行优化，但是比起 memcached，还是稍有逊色。</p><p>原文链接：<a href="https://blog.csdn.net/sishenhzy/article/details/101061787">https://blog.csdn.net/sishenhzy/article/details/101061787</a></p><h1 id="Redis实际应用场景"><a href="#Redis实际应用场景" class="headerlink" title="Redis实际应用场景"></a><strong>Redis</strong>实际应用场景</h1><p>最新的项目列表：</p><p>一个队列，左进右出，放的永远是最新的一个数据</p><p>排行榜应用，取TOP N操作</p><p>   这个需求与上面需求的不同之处在于，取最新N个数据的操作以时间为权重，这个是以某个条件为权重，比如按顶的次数排序，这时候就需要我们的sorted set出马了，将你要排序的值设置成sorted set的score，将具体的数据设置成相应的value，每次只需要执行一条ZADD命令即可。</p><p>计数：点击次数</p><p>分布式锁（string）：setnx</p><p>消息队列（list）：在list里面一边进，一边出即可</p>]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MYSQL</title>
      <link href="/2024/04/05/MYSQL/"/>
      <url>/2024/04/05/MYSQL/</url>
      
        <content type="html"><![CDATA[<h1 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a>MVCC</h1><img src="/2024/04/05/MYSQL/clip_image002.gif" class="" title="img"><p>已提交读的readview：每次生成最新的    可重复读的readview：沿用事务中上一次的</p><img src="/2024/04/05/MYSQL/clip_image004.gif" class="" title="img"><img src="/2024/04/05/MYSQL/clip_image006.gif" class="" title="img"><p>事务只有在update的时候才能生成事务id，select的时候，比对规则是针对版本链中的id是否符合比对规则</p><img src="/2024/04/05/MYSQL/clip_image008.gif" class="" title="img"><img src="/2024/04/05/MYSQL/clip_image010.gif" class="" title="img"><p>同一时刻不同事务中同样的查询语句可能查到不同的数据（select1中和select2中最后一条语句）</p><p>下面是对于删除情况的说明，并且是对于select2的说明</p><p>删除数据数据库文件并未变小</p><img src="/2024/04/05/MYSQL/clip_image002-1712316816560.gif" class="" title="img"><h1 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h1><p>索引类型</p><img src="/2024/04/05/MYSQL/clip_image014.gif" class="" title="img"><p><a href="https://www.jianshu.com/p/bf30c2b9a0cf">https://www.jianshu.com/p/bf30c2b9a0cf</a></p><h3 id="聚集索引-聚簇索引"><a href="#聚集索引-聚簇索引" class="headerlink" title="聚集索引 -聚簇索引"></a>聚集索引 -聚簇索引</h3><img src="/2024/04/05/MYSQL/clip_image016.gif" class="" title="必 闰 一 个 主 0 到 的 ： key  就 引 是 甴 是 聚 集 存 一 - 如 累 在 刨 表 的 的 定 7 主 ． 鄺 么 y 就 是  玉 姬 ． 果 玉 姬 · 么 y 就 是 一 ． 知  臨 一 谜 也 有 那 么 y 匭 是 字 莎 的 " alt="。 wid  叫 的 0 是 」 学 哮 引"><p>聚簇索引（聚集索引）：聚簇索引是一种数据存储方式，InnoDB的聚簇索引就是按照主键顺序构建 B+Tree结构。B+Tree 的叶子节点就是行记录，行记录和主键值紧凑地存储在一起。 这也意味着 InnoDB 的主键索引就是数据表本身，它按主键顺序存放了整张表的数据，占用的空间就是整个表数据量的大小。通常说 的<strong>主键索引</strong>就是聚集索引。</p><p>InnoDB的表要求必须要有聚簇索引：</p><p>（1）如果表定义了主键，则主键索引就是聚簇索引</p><p>（2）如果表没有定义主键，则第一个非空unique列作为聚簇索引</p><p>（3）否则InnoDB会从建一个隐藏的row-id作为聚簇索引</p><h3 id="辅助索引"><a href="#辅助索引" class="headerlink" title="辅助索引"></a>辅助索引</h3><p>InnoDB辅助索引，也叫作二级索引，是根据索引列构建 B+Tree结构。但在 B+Tree 的叶子节点中只存了索引列和主键的信息。二级索引占用的空间会比聚簇索引小很多， 通常创建辅助索引就是为了提升查询效率。一个表InnoDB只能创建一个聚簇索引，但可以创建多个辅助索引。</p><p>与InnoDB表存储不同，MyISAM数据表的索引文件和数据文件是分开的，被称为非聚簇索引结 构。</p><h3 id="覆盖索引回表"><a href="#覆盖索引回表" class="headerlink" title="覆盖索引回表"></a>覆盖索引回表</h3><img src="/2024/04/05/MYSQL/clip_image018.gif" class="" title="img"><p>所有列建索引是不是查询更快，不是的，粒度会太小，索引的维护成本会增加，在索引上的操作会变多</p><h3 id="唯一索引和非唯一索引（普通索引）"><a href="#唯一索引和非唯一索引（普通索引）" class="headerlink" title="唯一索引和非唯一索引（普通索引）"></a>唯一索引和非唯一索引（普通索引）</h3><ul><li><p>唯一索引是这样一种索引，它通过确保表中没有两个数据行具有完全相同的键值来帮助维护数据完整性。为包含数据的现有表创建唯一索引时，会检查组成索引键的列或表达式中的值是否唯一。如果该表包含具有重复键值的行，那么索引创建过程会失败。为表定义了唯一索引之后，每当在该索引内添加或更改键时就会强制执行唯一性。此强制执行包括插入、更新、装入、导入和设置完整性以命名一些键。除了强制数据值的唯一性以外，唯一索引还可用来提高查询处理期间检索数据的性能。</p></li><li><p>非唯一索引不用于对与它们关联的表强制执行约束。相反，非唯一索引通过维护频繁使用的数据值的排序顺序，仅仅用于提高查询性能。</p></li></ul><h3 id="全文索引"><a href="#全文索引" class="headerlink" title="全文索引"></a>全文索引</h3><p>通过建立倒排索引,可以极大的提升检索效率,解决判断字段是否包含的问题. 例如: 有title字段,需要查询所有包含 “政府”的记录. 需要 like “%政府%”方式查询,查询速度慢,当查询包含”政府” OR “中国”的需要是,sql难以简单满足.全文索引就可以实现这个功能.</p><p><a href="https://zhuanlan.zhihu.com/p/88275060">https://zhuanlan.zhihu.com/p/88275060</a></p><h2 id="索引数据结构的选择"><a href="#索引数据结构的选择" class="headerlink" title="索引数据结构的选择"></a>索引数据结构的选择</h2><img src="/2024/04/05/MYSQL/clip_image020.gif" class="" title="img"><img src="/2024/04/05/MYSQL/clip_image022.gif" class="" title="img"><img src="/2024/04/05/MYSQL/clip_image024.gif" class="" title="img"><img src="/2024/04/05/MYSQL/clip_image026.gif" class="" title="img"><img src="/2024/04/05/MYSQL/clip_image028.gif" class="" title="img"><p>二叉树：不适合存储，没有规律，不适合查找</p><p>二叉搜索树：虽然可以二分查找，但是插入数据若是升序或降序则时间复杂度则降级为O(N)</p><p>AVL:在二叉搜索树的基础上最长子树和最短子树相差不超过1——-查找效率高的，但是插入效率很低，因为平衡条件太严格</p><img src="/2024/04/05/MYSQL/clip_image030.gif" class="" title="img"><p>红黑树：:最长子树不能超过最短子树的2倍——随着数据的增多，深度越来越深</p><p>红黑树就是介于完全不平衡和完全平衡之间的一种二叉树，通过每个节点有红黑两种颜色、从节点到任意叶子节点会经过相同数量的黑色节点等一系列规则，实现了【树的层数最大也只会有两倍的差距】，这样既能提高插入和删除的效率，又能让树相对平衡从而有还不错的查询效率。从整体上讲，红黑树就是一种中庸之道的二叉树。</p><img src="/2024/04/05/MYSQL/clip_image032.gif" class="" title="img"><p>B树：</p><img src="/2024/04/05/MYSQL/clip_image034.gif" class="" title="img"><p>一个磁盘块为16KB，假设索引不占空间，只有data占空间，一个data占1KB，那么一个磁盘块能存16条数据，3层B树最多能存16×16×16&#x3D;4096条数据，远远不够</p><p>B+树：</p><img src="/2024/04/05/MYSQL/clip_image036.gif" class="" title="img"><p>假设p1和28共占10B，磁盘块16kB可以放16<em>1024&#x2F;10个数据索引，那么3层总共能放（16</em>1024&#x2F;10）<em>（16</em>1024&#x2F;10）*16个数据，所以要用B+树</p><p>索引一般B+树层数为3-4层：由数据量决定</p><img src="/2024/04/05/MYSQL/clip_image038.gif" class="" title="img"><p>两种引擎B+树的区别：</p><img src="/2024/04/05/MYSQL/clip_image040.gif" class="" title="img"><p>所有文件先开始都在硬盘，加载的时候才在内存</p><p>数据只存一份，即使是创建了两个索引，当在普通字段创建索引时，比如下图是在name字段创建索引，叶子节点放的是主键值，还需要到主键B+树中去查找数据</p><img src="/2024/04/05/MYSQL/clip_image042.gif" class="" title="img"><img src="/2024/04/05/MYSQL/clip_image044.gif" class="" title="img"><h2 id="简述索引对于数据库性能的影响"><a href="#简述索引对于数据库性能的影响" class="headerlink" title="简述索引对于数据库性能的影响"></a>简述索引对于数据库性能的影响</h2><img src="/2024/04/05/MYSQL/clip_image046.gif" class="" title="索 引 可 以 极 大 的 提 高 数 据 的 查 速 度 ．  通 过 使 用 索 引 ， 可 以 旺 0 洵 的 过 程 中 ， 使 用 优 化 隐 藏 器 ， 提 高 系 统 性 能 。  但 是 会 降 低 适 入 、 删 除 、 更 新 表 的 速 度 ， 因 为 在 执 行 这 些 写 操 作 时 ， 还 要 悍 作 索 引 文 件  索 引 需 要 占 物 理 空 间 ， 除 了 数 据 表 占 数 据 空 间 之 外 ， 每 一 个 索 引 还 要 占 一 定 的 物 理 空 间 ． 如 果 要 建 立 聚 簇 索 引 ， 那  么 需 要 的 空 间 就 会 更 大 ， 如 果 非 聚 索 引 很 多 ， 一 旦 聚 隼 索 引 改 变 ， 那 么 所 有 非 聚 隼 索 引 都 会 跟 变 。"><p>优化隐藏：一般地，对查询语句，查询处理器创建了可以提高性能的执行规划。然而，如果对某一个特定的查询语句例如检索、插入、删除、修改，查询处理器没有创建最好的执行规划，那么用户可以在查询语句中增加优化隐藏来影响查询处理器创建出最优的执行规划。优化隐藏就是指在执行查询语句、使用多表连接检索或者指定查询语句操作的对象表时，明确地指出应该使用的查询方法、连接算法或者对表的操作方式。当使用优化隐藏时，一定要认真考虑优化隐藏对性能的影响。在SQL Server 7.0中，提供了三种类型的优化隐藏，即查询优化隐藏、连接优化隐藏和表优化隐藏。<a href="https://zhidao.baidu.com/question/39271452.html">https://zhidao.baidu.com/question/39271452.html</a></p><h2 id="索引设计原则"><a href="#索引设计原则" class="headerlink" title="索引设计原则"></a>索引设计原则</h2><img src="/2024/04/05/MYSQL/clip_image048.gif" class="" title="img"><h2 id="创建索引时用int类型还是varchar类型"><a href="#创建索引时用int类型还是varchar类型" class="headerlink" title="创建索引时用int类型还是varchar类型"></a>创建索引时用int类型还是varchar类型</h2><p>占用空间小就用：若用varchar表示它的长度是多少个字节，如果你的varchar小于4个字节，那么就用varchar，如果varchar大于4个字节，那么就用int。</p><h2 id="页：最小的逻辑单元"><a href="#页：最小的逻辑单元" class="headerlink" title="页：最小的逻辑单元"></a>页：最小的逻辑单元</h2><img src="/2024/04/05/MYSQL/clip_image050.gif" class="" title="img"><h2 id="最左匹配原则"><a href="#最左匹配原则" class="headerlink" title="最左匹配原则"></a><strong>最左匹配原则</strong></h2><img src="/2024/04/05/MYSQL/clip_image052.gif" class="" title="img"><p>本质上第一个字段是有序的，第二个单看是无序的，结合第一个看是有序的（第一个一样的时候，第二个就是有序的）</p><h2 id="索引下推"><a href="#索引下推" class="headerlink" title="索引下推"></a><strong>索引下推</strong></h2><img src="/2024/04/05/MYSQL/clip_image054.gif" class="" title="select · 行 0mtab | e 1 虻 " alt="n 虻 一 ？ 出 记 09e 一 ？  y ， q07 」 有 的 个 恃 ：  引 ． 卜 准 之 前  索 引 下  先 n “ 匾 去 存 銠 引 中 吧 敷 巴 就 然 岵 0 "><p>主键递增</p><img src="/2024/04/05/MYSQL/clip_image056.gif" class="" title="img"><p>递增的话直接向后面追加就好了，不会影响之前的目录结构</p><p><strong>无特殊需求下Innodb建议使用与业务无关的自增ID作为主键</strong></p><p>InnoDB引擎使用聚集索引，数据记录本身被存于主索引（一颗B+Tree）的叶子节点上。这就要求同一个叶子节点内（大小为一个内存页或磁盘页）的各条数据记录按主键顺序存放，因此每当有一条新的记录插入时，MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子（InnoDB默认为15&#x2F;16），<strong>则开辟一个新的页（节点）</strong></p><p>1、如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。</p><p>这样就会形成一个紧凑的索引结构，近似顺序填满。<strong>由于每次插入时也不需要移动已有数据，因此效率很高，也不会增加很多开销在维护索引上。</strong></p><p>2、 如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置</p><p>此时MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。</p><p>在使用InnoDB存储引擎时，如果没有特别的需要，请永远使用一个与业务无关的自增字段作为主键。</p><img src="/2024/04/05/MYSQL/clip_image058.jpg" class="" title="img"><h2 id="代理主键与然主键"><a href="#代理主键与然主键" class="headerlink" title="代理主键与然主键"></a>代理主键与然主键</h2><p>代理主键是指与业务无关且能唯一标识数据库中记录,一般是数据库自动生成的,比如mysql可以使用auto_increment,Sql2000可以使用identity生成方式,oracle可以使用sequence生成方式 自然主键指业务相关,由用户指定,且能唯一标识数据库中的任意一条记录</p><h2 id="文件的存储"><a href="#文件的存储" class="headerlink" title="文件的存储"></a><strong>文件的存储</strong></h2><img src="/2024/04/05/MYSQL/clip_image060.gif" class="" title="img"><p>MySQL可以不指定主键建表吗，背后的逻辑是什么</p><p>如果没有主动设置主键，就会选一个不包含NULL的第一个唯一索引列作为主键列，并把它用作一个聚集索引。如果没有这样的索引就会使用行号生成一个聚集索引，把它当做主键，这个行号6bytes，自增。可以用select _rowid from table来查询</p><h1 id="mysql建唯一索引后重复插入会报错，解决方法"><a href="#mysql建唯一索引后重复插入会报错，解决方法" class="headerlink" title="mysql建唯一索引后重复插入会报错，解决方法"></a><strong>mysql</strong>建唯一索引后重复插入会报错，解决方法</h1><p>insert ignore 能忽略重复数据，只插入不重复的数据。</p><p>replace into 和 insert … on duplicate key update，都是替换原有的重复数据，区别在于replace into是删除原有的行后，再插入新行，如有自增id，这个会造成自增id的改变；insert … on duplicate key update在遇到重复行时，会直接更新原有的行，具体更新哪些字段怎么更新，取决于update后的语句。</p><p><a href="https://blog.csdn.net/u012660464/article/details/117416047">https://blog.csdn.net/u012660464/article/details/117416047</a></p><h2 id="自适应哈希"><a href="#自适应哈希" class="headerlink" title="自适应哈希"></a>自适应哈希</h2><p>InnoDB存储引擎会自动对个索引页上的查询进行监控，如果能够通过使用自适应哈希索引来提高查询效率，其便会自动创建自适应哈希索引，不需要开发人员或运维人员进行任何设置操作。自适应哈希索引是对innodb的缓冲池的B+树页进行创建，不是对整张表创建，因此速度很快。</p><p>Innodb存储引擎会监控对表上二级索引的查找，如果发现某二级索引被频繁访问(最近连续被访问三次的数据)，二级索引成为热数据，建立哈希索引可以带来速度的提升，自适应哈希索引通过缓冲池的B+树构造而来，因此建立的速度很快。</p><p>特点</p><p>1、无序，没有树高</p><p>2、降低对二级索引树的频繁访问资源</p><p>索引树高&lt;&#x3D;4，访问索引：访问树、根节点、叶子节点</p><p>3、自适应</p><p>3、缺陷</p><p>1、hash自适应索引会占用innodb buffer pool；</p><p>2、自适应hash索引只适合搜索等值的查询，如select * from table where index_col&#x3D;’xxx’，而对于其他查找类型，如范围查找，是不能使用的；</p><p>3、极端情况下，自适应hash索引才有比较大的意义，可以降低逻辑读。</p><p>来自 <a href="https://www.cnblogs.com/geaozhang/p/7252389.html">https://www.cnblogs.com/geaozhang/p/7252389.html</a></p><h1 id="innoDB锁算法"><a href="#innoDB锁算法" class="headerlink" title="innoDB锁算法"></a>innoDB锁算法</h1><img src="/2024/04/05/MYSQL/clip_image062.gif" class="" title="img"><img src="/2024/04/05/MYSQL/clip_image064.gif" class="" title="iii"><p>InnoDB通过给索引项加锁来实现行锁，如果没有索引，则通过隐藏的聚簇索引来对记录加锁。如果操作不通过索引条件检索数据，InnoDB 则对表中的所有记录加锁，实际效果就和表锁一样。</p><img src="/2024/04/05/MYSQL/clip_image066.gif" class="" title="iii"><ul><li>例如一个索引有10,11,13,20这四个值。InnoDB可以根据需要使用Record Lock将10，11，13，20四个索引锁住，也可以使用Gap Lock将(-∞,10)，(10,11)，(11,13)，(13,20)，(20, +∞)五个范围区间锁住。Next-Key Locking类似于上述两种锁的结合，它可以锁住的区间有为(-∞,10]，(10,11]，(11,13]，(13,20]，(20, +∞)，可以看出它即锁定了一个范围，也会锁定记录本身。<br> 详细： <a href="https://zhuanlan.zhihu.com/p/66676020">https://zhuanlan.zhihu.com/p/66676020</a></li></ul><p>乐观锁：</p><p>乐观锁不是数据库自带的，需要我们自己去实现。乐观锁是指操作数据库时(更新操作)，想法很乐观，认为这次的操作不会导致冲突，在操作数据时，并不进行任何其他的特殊处理（也就是不加锁），而在进行更新后，再去判断是否有冲突了。</p><p>通常实现是这样的：在表中的数据进行操作时(更新)，先给数据表加一个版本(version)字段，每操作一次，将那条记录的版本号加1。也就是先查询出那条记录，获取出version字段,如果要对那条记录进行操作(更新),则先判断此刻version的值是否与刚刚查询出来时的version的值相等，如果相等，则说明这段期间，没有其他程序对其进行操作，则可以执行更新，将version字段的值加1；如果更新时发现此刻的version值与刚刚获取出来的version的值不相等，则说明这段期间已经有其他程序对其进行操作了，则不进行更新操作。</p><h1 id="数据引擎"><a href="#数据引擎" class="headerlink" title="数据引擎"></a>数据引擎</h1><img src="/2024/04/05/MYSQL/clip_image068.gif" class="" title="img"><p>innodb在5.6版本之后支持全文检索，MyISAM支持全文检索</p><p>innodb索引叶子节点直接存放数据，而MyISAM存放地址</p><h1 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h1><img src="/2024/04/05/MYSQL/clip_image070.gif" class="" title="img"><h2 id="Innodb如何实现事务"><a href="#Innodb如何实现事务" class="headerlink" title="Innodb如何实现事务"></a>Innodb如何实现事务</h2><img src="/2024/04/05/MYSQL/clip_image072.jpg" class="" title="Innodt*tButter Pool, LogButfer, Redo Log, Undo  1. POOI*  2. HlfiupdateiËEJ,  3. %FÀLogBuffercta  4.  6,"><h2 id="四大特性（ACID）以及实现原理"><a href="#四大特性（ACID）以及实现原理" class="headerlink" title="四大特性（ACID）以及实现原理"></a>四大特性（ACID）以及实现原理</h2><p>1.一致性</p><p>从数据库层面，数据库通过原子性、隔离性、持久性来保证一致性。也就是说ACID四大特性之中，C(一致性)是目的，A(原子性)、I(隔离性)、D(持久性)是手段，是为了保证一致性，数据库提供的手段。一致性是事务追求的最终目标，数据库必须要实现AID三大特性，才有可能实现一致性。例如，原子性无法保证，显然一致性也无法保证，除了数据库层面的保障，一致性的实现也需要应用层面进行保障。</p><p>2.Mysql怎么保证原子性的？</p><p>利用Innodb的undo log。undo log名为回滚日志，是实现原子性的关键，当事务回滚时能够撤销所有已经成功执行的sql语句，他需要记录你要回滚的相应日志信息。undo log记录了这些回滚需要的信息，当事务执行失败或调用了rollback，导致事务需要回滚，便可以利用undo log中的信息将数据回滚到修改之前的样子。</p><p>3.Mysql怎么保证隔离性的？</p><p>利用的是锁和MVCC机制。至于MVCC,即多版本并发控制(Multi Version Concurrency Control),一个行记录数据有多个版本对快照数据，这些快照数据在undo log中。如果一个事务读取的行正在做DELELE或者UPDATE操作，读取操作不会等行上的锁释放，而是读取该行的快照版本。</p><p>4.Mysql怎么保证持久性的？</p><p>利用Innodb的redo log。Mysql是先把磁盘上的数据加载到内存中，在内存中对数据进行修改，再刷回磁盘上。如果此时突然宕机，内存中的数据就会丢失。于是，决定采用redo log解决上面的问题。当做数据修改的时候，不仅在内存中操作，还会在redo log中记录这次操作。当事务提交的时候，会将redo log日志进行刷盘(redo log一部分在内存中，一部分在磁盘上)。当数据库宕机重启的时候，会将redo log中的内容恢复到数据库中，再根据undo log和binlog内容决定回滚数据还是提交数据。</p><p>采用redo log的好处？</p><p>其实好处就是将redo log进行刷盘比对数据页刷盘效率高，具体表现如下</p><ul><li>redo log体积小，毕竟只记录了哪一页修改了啥，因此体积小，刷盘快。</li><li>redo log是一直往末尾进行追加，属于顺序IO。效率显然比随机IO来的快。</li></ul><p><a href="https://blog.csdn.net/weixin_30649859/article/details/95897520">https://blog.csdn.net/weixin_30649859/article/details/95897520</a></p><h2 id="4个隔离级别及其实现原理"><a href="#4个隔离级别及其实现原理" class="headerlink" title="4个隔离级别及其实现原理"></a><strong>4</strong>个隔离级别及其实现原理</h2><p> 1.读未提交（READ UNCOMMITTED）</p><p>​    压根儿就不加锁，所以根本谈不上什么隔离效果，可以理解为没有隔离。</p><p> 2.读提交 （READ COMMITTED）</p><p>​    在RC级别中，数据的读取都是不加锁的，但是数据的写入、修改和删除是需要加锁的。</p><img src="/2024/04/05/MYSQL/clip_image074.jpg" class="" title="img"><p>​    如果是没有索引的class_name呢？update class_teacher set teacher_id&#x3D;3 where class_name &#x3D; ‘初三一班’; 那么MySQL会给整张表的所有数据行的加行锁。</p><p>附加：但在实际使用过程当中，MySQL做了一些改进，在MySQL Server过滤条件，发现不满足后，会调用unlock_row方法，把不满足条件的记录释放锁 (违背了二段锁协议的约束)。这样做，保证了最后只会持有满足条件记录上的锁，但是每条记录的加锁操作还是不能省略的。</p><p> 3.可重复读 （REPEATABLE READ）</p><p>​     a.解决可重复读问题</p><p>在InnoDB中，会在每行数据后添加两个额外的隐藏的值来实现MVCC，这两个值一个记录这行数据何时被创建，另外一个记录这行数据何时过期（或者被删除）。 在实际操作中，存储的并不是时间，而是事务的版本号，每开启一个新事务，事务的版本号就会递增。 在可重读Repeatable reads事务隔离级别下：</p><p> SELECT时，读取创建版本号&lt;&#x3D;当前事务版本号，删除版本号为空或&gt;当前事务版本号。</p><p> INSERT时，保存当前事务版本号为行的创建版本号</p><p> DELETE时，保存当前事务版本号为行的删除版本号</p><p> UPDATE时，插入一条新纪录，保存当前事务版本号为行创建版本号，同时保存当前事务版本号到原来删除的行</p><p>​    b.为了解决当前读中的幻读问题，MySQL事务使用了Next-Key锁:</p><p>​    Innodb将这段数据分成几个个区间(negative infinity, 5],(5,30],(30,positive infinity)；</p><p>​    update class_teacher set class_name&#x3D;‘初三四班’ where teacher_id&#x3D;30;不仅用行锁，锁住了相应的数据行；同时也在两边的区间，（5,30]和（30，positive infinity），都加入了gap锁。这样事务B就无法在这个两个区间insert进新数据。行锁防止别的事务修改或删除，GAP锁防止别的事务新增，行锁和GAP锁结合形成的的Next-Key锁共同解决了RR级别在写数据时的幻读问题。</p><p>​    如果使用的是没有索引的字段，比如update class_teacher set teacher_id&#x3D;7 where class_name&#x3D;‘初三八班（即使没有匹配到任何数据）’,那么会给全表加入gap锁。同时，它不能像上文中行锁一样经过MySQL Server过滤自动解除不满足条件的锁，因为没有索引，则这些字段也就没有排序，也就没有区间。除非该事务提交，否则其它事务无法插入任何数据。</p><img src="/2024/04/05/MYSQL/clip_image076.jpg" class="" title="img"><p>4.串行化 （SERIALIZABLE）</p><p>​    这个级别很简单，读加共享锁，写加排他锁，读写互斥。使用的悲观锁的理论，实现简单，数据更加安全，但是并发能力非常差。</p><img src="/2024/04/05/MYSQL/clip_image078.gif" class="" title="img"><p>并发访问的问题还有：丢失更新 当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，会发生丢失更新问题。每个事务都不知道其它事务的存在。最后的更新将重写由其它事务所做的更新，这将导致数据丢失。</p><p>例如，两个编辑人员制作了同一文档的电子复本。每个编辑人员独立地更改其复本，然后保存更改后的复本，这样就覆盖了原始文档。最后保存其更改复本的编辑人员覆盖了第一个编辑人员所做的更改。如果在第一个编辑人员完成之后第二个编辑人员才能进行更改，则可以避免该问题。</p><p><a href="https://tech.meituan.com/2014/08/20/innodb-lock.html">https://tech.meituan.com/2014/08/20/innodb-lock.html</a> 美团</p><p><a href="https://www.cnblogs.com/fengzheng/p/12557762.html">https://www.cnblogs.com/fengzheng/p/12557762.html</a> 博客</p><h1 id="三大log日志"><a href="#三大log日志" class="headerlink" title="三大log日志"></a>三大log日志</h1><h2 id="Binlog"><a href="#Binlog" class="headerlink" title="Binlog"></a>Binlog</h2><p><strong>1.Row格式</strong></p><p>  此格式不记录sql语句上下文相关信息，仅保存哪条记录被修改。</p><p>优点： binlog中可以不记录执行的sql语句的上下文相关的信息，仅需要记录那一条记录被修改成什么了。所以Row格式的日志内容会非常清楚的记录下每一行数据修改的细节。</p><p>缺点:所有的执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，这样<strong>可能会产生大量的日志内容</strong>,比如一条update语句或者一条alter语句，修改多条记录，则binlog中每一条修改都会有记录，每条记录都发生改变，那么该表每一条记录都会记录到日志中，这样造成binlog日志量会很大。</p><p><strong>2.Statement格式</strong></p><p>  该格式下每一条会修改数据的sql都会记录在binlog中。</p><p>优点：不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能。它相比row模式能节约很多性能与日志量，具体节约的多少取决于应用的SQL情况。正常同一条记录修改或者插入row格式所产生的日志量还小于Statement产生的日志量，考虑到整表删除等一些大量数据操作，ROW格式会产生大量日志，所以总体来讲statement模式会稍微好一些。</p><p>缺点：由于记录的只是执行语句，为了这些语句能在slave上正确运行，因此还必须记录每条语句在执行的时候的一些相关信息，以保证所有语句能在slave得到和在master端执行时候相同的结果。</p><p><strong>3.Mixed格式</strong></p><p>  该格式是以上两种level的混合使用，一般的语句修改使用statment格式保存binlog，当statement无法完成主从复制的操作时(涉及一些函数时)，则采用Row格式保存binlog,MySQL会根据执行的每一条具体的sql语句来区分对待记录的日志形式，也就是在Statement和Row之间选择一种.新版本的MySQL中队Row模式也被做了优化，并不是所有的修改都会以Row模式来记录，像遇到表结构变更的时候就会以statement模式来记录。至于update或者delete等修改数据的语句，还是会记录所有行的变更。<a href="https://cloud.tencent.com/developer/article/1533697">https://cloud.tencent.com/developer/article/1533697</a></p><h1 id="SQL调优"><a href="#SQL调优" class="headerlink" title="SQL调优"></a>SQL调优</h1><h2 id="⼀条SQL语句在MySQL中如何执⾏"><a href="#⼀条SQL语句在MySQL中如何执⾏" class="headerlink" title="⼀条SQL语句在MySQL中如何执⾏"></a>⼀条SQL语句在MySQL中如何执⾏</h2><img src="/2024/04/05/MYSQL/clip_image080.gif" class="" title="qpouu" alt="wesp4w  01  00"><p>MySQL 主要分为 Server 层和引擎层，Server 层主要包括连接器、查询缓存、分析器、优化器、执行器，同时还有一个日志模块（binlog），这个日志模块所有执行引擎都可以共用,redolog 只有 InnoDB 有。</p><p>•引擎层是插件式的，目前主要包括，MyISAM,InnoDB,Memory 等。</p><p>•SQL 等执行过程分为两类，一类对于查询等过程如下：权限校验—》查询缓存—》分析器—》优化器—》权限校验—》执行器—》引擎</p><p>•对于更新等语句执行流程如下：分析器—-》权限校验—-》执行器—》引擎—redo log prepare—》binlog—》redo log commit</p><p><a href="https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247485097&idx=1&sn=84c89da477b1338bdf3e9fcd65514ac1&chksm=cea24962f9d5c074d8d3ff1ab04ee8f0d6486e3d015cfd783503685986485c11738ccb542ba7&token=79317275&lang=zh_CN%23rd">https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&amp;mid=2247485097&amp;idx=1&amp;sn=84c89da477b1338bdf3e9fcd65514ac1&amp;chksm=cea24962f9d5c074d8d3ff1ab04ee8f0d6486e3d015cfd783503685986485c11738ccb542ba7&amp;token=79317275&amp;lang=zh_CN%23rd</a></p><p>​    注：redolog是宕机后数据恢复用的，用来支持事务的，binlog是主从复制的时候用的</p><img src="/2024/04/05/MYSQL/clip_image082.gif" class="" title="这 里 肯 定 有 同 学 会 问 ， 为 什 么 要 用 两 个 日 志 模 块 ， 用 一 个 日 志 模 块 不 行 吗 ？  这 是 因 为 最 开 始 MySQL 并 没 与 InnoDB 引 擎 〔 InnoDB 引 擎 是 其 他 公 司 以 插 件 形 式 插 入  MySQL 的 〕 ， MySQL 自 带 的 引 擎 是 MylSAM, 但 是 我 们 知 道 redolog 是 InnoDB 引 擎 特 有  的 ， 其 他 存 储 引 擎 都 没 有 ， 这 就 导 致 会 没 有 crash-safe 的 能 力 (crash-safe 的 能 力 即 使 数 据  库 发 生 异 常 重 启 ， 之 前 提 交 的 记 录 都 不 会 丢 失 〕 ， binlog 日 志 只 能 用 来 归 档 。  并 不 是 说 只 用 一 个 日 志 模 块 不 可 以 ， 只 是 InnoDB 引 擎 就 是 通 过 redo log 来 支 持 事 务 的 。  那 么 ， 又 会 有 同 学 问 ， 我 用 两 个 日 志 模 块 ， 但 是 不 要 这 么 复 杂 行 不 行 ， 为 什 么 redolog 要  引 入 prepare 预 提 交 状 态 ？ 这 里 我 们 用 反 证 法 来 说 明 下 为 什 么 要 这 么 做 ？  先 写 redo 10g 直 接 提 交 ， 然 后 写 binlog, 假 设 写 完 redolog 后 ， 机 器 挂 了 ， binlog 日  志 没 有 被 写 入 ， 那 么 机 器 重 启 后 ， 这 台 机 器 会 通 过 redo log 恢 复 数 据 ， 但 是 这 个 时 候  bingog 并 没 有 记 录 该 数 据 ， 后 续 进 行 机 器 备 份 的 时 候 ， 就 会 丢 失 这 一 条 数 据 ， 同 时 主  从 同 步 也 会 丢 失 这 一 条 数 据 。  先 写 binlog, 然 后 %redolog, 假 设 写 完 了 binlog, 机 器 异 常 重 启 了 ， 由 于 没 有 redo  log, 本 机 是 无 法 恢 复 这 一 条 记 录 的 ， 但 是 binlog 又 有 记 录 ， 那 么 和 上 面 同 样 的 道 理 ，  就 会 产 生 数 据 不 一 致 的 情 况 。  如 果 采 用 redo log 两 阶 段 提 交 的 方 式 就 不 一 样 了 ， 写 完 binglog 后 ， 然 后 再 提 交 redo log  就 会 防 止 出 现 上 述 的 问 题 ， 从 而 保 证 了 数 据 的 一 致 性 。 那 么 问 题 来 了 ， 有 没 有 一 个 极 端 的  情 况 呢 ？ 假 设 redolog 处 于 预 提 交 状 态 ， binglog 也 己 经 写 完 了 ， 这 个 时 候 发 生 了 异 常 重 启  会 怎 么 样 呢 ？ 这 个 就 要 依 赖 于 MySQL 的 处 理 机 制 了 ， MySQL 的 处 理 过 程 如 下 ．  · 判 断 redolog 是 否 完 整 ， 如 果 判 断 是 完 整 的 ， 就 立 即 提 交 。  如 果 redolog 只 是 预 提 交 但 不 是 commit 状 态 ， 这 个 时 候 就 会 去 判 断 binlog 是 否 完  整 ， 如 果 完 整 就 提 交 redolog, 不 完 整 就 回 滚 事 务 。  这 样 就 解 决 了 数 据 一 致 性 的 问 题 。"><p>我们该如何进行sql优化呢， 首先我们需要知道，sql优化其实主要是解决查询的优化问题，所以我们先从数据库的查询开始入手，下面这幅图显示了查询的执行路径：</p><p>　① 客户端将查询发送到服务器；</p><p>　② 服务器检查查询缓存，如果找到了，就从缓存中返回结果，否则进行下一步。</p><p>　③ 服务器解析，预处理。</p><p>　④ 查询优化器优化查询</p><p>　⑤ 生成执行计划，执行引擎调用存储引擎API执行查询</p><p>　⑥服务器将结果发送回客户端。</p><img src="/2024/04/05/MYSQL/clip_image084.gif" class="" title="Amen"><p><strong>查询缓存</strong> 在解析一个查询语句之前，如果查询缓存是打开的，那么MySQL会优先检查这个查询是否命中查询缓存中的数据，如果命中缓存直接从缓存中拿到结果并返回给客户端。这种情况下，查询不会被解析，不用生成执行计划，不会被执行。</p><p><strong>语法解析和预处理器</strong> MySQL通过关键字将SQL语句进行解析，并生成一棵对应的“解析树”。MySQL解析器将使用MySQL语法规则验证和解析查询。</p><p><strong>查询优化器</strong> 语法树被校验合法后由优化器转成查询计划，一条语句可以有很多种执行方式，最后返回相同的结果。优化器的作用就是找到这其中最好的执行计划。</p><p><strong>查询执行引擎</strong> 在解析和优化阶段，MySQL将生成查询对应的执行计划，MySQL的查询执行引擎则根据这个执行计划来完成整个查询。最常使用的也是比较最多的引擎是MyISAM引擎和InnoDB引擎。mysql5.5开始的默认存储引擎已经变更为innodb了。</p><h2 id="SQL语句执⾏得很慢的原因有哪些？"><a href="#SQL语句执⾏得很慢的原因有哪些？" class="headerlink" title="SQL语句执⾏得很慢的原因有哪些？"></a>SQL语句执⾏得很慢的原因有哪些？</h2><p>1、大多数情况下很正常，偶尔很慢，则有如下原因</p><p>(1)数据库在刷新脏页，例如 redo log 写满了需要同步到磁盘。</p><p>(2)执行的时候，遇到锁，如表锁、行锁。</p><p>2、这条 SQL 语句一直执行的很慢，则有如下原因。</p><p>(1)</p><img src="/2024/04/05/MYSQL/clip_image086.gif" class="" title="img"><p>（2）没有用上索引：例如该字段没有索引；由于对字段进行运算、函数操作导致无法用索引。</p><p>（3）</p><img src="/2024/04/05/MYSQL/clip_image088.gif" class="" title="． 如 果 对 语 句 的 优 化 已 经 无 氵 去 进 行 ， 可 以 考 虑 表 中 的 数 据 量 是 否 太 大 ， 如 果 是 的 话 可 以 进 行 横 向 或 者 纵 向 的 分  表 。"><p>(4)数据库选错了索引。</p><p><a href="https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247485185&idx=1&sn=66ef08b4ab6af5757792223a83fc0d45&chksm=cea248caf9d5c1dc72ec8a281ec16aa3ec3e8066dbb252e27362438a26c33fbe842b0e0adf47&token=79317275&lang=zh_CN%23rd">https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&amp;mid=2247485185&amp;idx=1&amp;sn=66ef08b4ab6af5757792223a83fc0d45&amp;chksm=cea248caf9d5c1dc72ec8a281ec16aa3ec3e8066dbb252e27362438a26c33fbe842b0e0adf47&amp;token=79317275&amp;lang=zh_CN%23rd</a></p><img src="/2024/04/05/MYSQL/clip_image090.gif" class="" title="1 、 数 据 库 在 刷 新 脏 页 (flush) 我 也 无 奈 啊  当 我 们 要 往 数 据 库 插 入 一 条 数 据 、 或 者 要 电 新 一 条 数 据 的 时 候 ， 我 们 知 道 数 据 库 会 在 内 存 中 把 对 应 字 段 的 数 据 更  新 了 ， 但 是 电 新 之 后 ， 这 些 更 新 的 字 段 并 不 会 马 上 同 步 持 久 化 到 磁 盘 中 去 ， 而 是 把 汶 些 更 新 的 记 录 写 入 到 red o  log 日 记 中 去 ， 等 到 空 闲 的 时 候 ， 在 通 过 redo log 里 的 日 记 把 最 新 的 数 据 同 步 到 磁 盘 中 去 。  当 内 存 数 据 页 跟 磁 盘 数 据 页 内 容 不 一 致 的 时 候 ， 我 们 称 这 个 内 存 页 为 “ 脏 页 。 内 存 数 据 与 入 到 磁 盘 后 ， 内 存 和 磁 盘 上 的 数 据 页 的 内 容 就 一 致 了 ， 称 为 “ 干 净 页 。  刷 页 有 下 面 4 种 场 景 （ 后 两 种 不 用 太 关 注 “ 性 能 问 题 ） ： · red 引 。 g 写 满 了 ： redo log 里 的 容 量 是 有 限 的 ， 如 果 数 据 库 一 直 很 忙 ， 电 新 又 很 频 繁 ， 汶 个 时 候 redo log 很 快 就 会 被 写 满 了 ， 汶 个 时 候 就 没 办 法 等 到 空 闲 的 时 候 冉 把 数 据 同 步 到 磁 盘 的 ， 只 能 暂 停 其 他 操 作 ， 全 身 心 来 把 数 据 同 步 到 磁 盘 中 去 的 ， 而 汶 个 时 候 ， 就 会 粤 致 我 们 平 时 正 常 的 SQL 语 句 突 然 执 行 的 很 慢 ， 所 以 说 ， 数 据 库 在 在 同 步 数 据 到 磁 盘 的 时 候 ， 就 有 可 能 导 致 我 们 的 SQL 语 句 执 行 的 很 悒 了 。 · 内 存 不 够 用 了 ： 如 果 一 次 查 i 旬 较 多 的 数 据 ， 恰 好 碰 到 所 查 数 据 页 不 在 内 存 中 时 ， 需 要 申 请 内 存 ， 而 此 时 恰 好 内 存 不 足 的 时 候 就 需 要 淘 汰 一 部 分 内 存 数 据 页 ， 如 果 是 干 净 页 ， 就 直 接 释 放 ， 如 果 恰 好 是 脏 页 就 需 要 刷 脏 《 页 · MySQL 认 为 系 统 “ 空 闲 ” 的 时 候 ： 这 时 系 统 没 什 么 压 力 。 · MYSQL 正 常 关 闭 的 时 候 ： 这 时 候 ， MYSQL 会 把 内 存 的 脏 页 都 flush 到 磁 盘 上 ， 这 样 下 次 MYSQL 启 动 的 时 候 ， 就 可 以 直 接 从 磁 盘 上 读 数 据 ， 启 动 速 度 会 很 快 0 %}{% asset_img clip_image092.gif&quot; img"><img src="/2024/04/05/MYSQL/clip_image094.gif" class="" title="数 据 库 自 己 选 错 索 引 了"><img src="/2024/04/05/MYSQL/clip_image096.gif" class="" title="所 以 呢 ， 系 统 是 有 可 能 走 全 表 扫 描 而 不 走 索 引 的 。 那 系 统 是 怎 么 判 断 昵 ？  判 断 来 源 于 系 统 的 预 测 ， 也 就 是 说 ， 如 果 要 走 c 字 段 索 引 的 话 ， 系 统 会 预 测 走 c 字 段 索 引 大 概 需 要 扫 庙 多 少 行 。  如 果 预 测 到 要 扫 描 的 行 数 很 多 ， 它 可 能 就 不 走 索 引 而 直 接 扫 庙 全 表 了 。"><img src="/2024/04/05/MYSQL/clip_image098.gif" class="" title="系 统 是 通 过 索 引 的 区 分 度 来 判 断 的 ， 一 个 索 引 上 不 同 的 值 越 多 ， 意 味 巷 出 现 相 同 数 值 的 索 引 越 少 ， 意 味 巷 索 引 的  区 分 度 越 高 。 我 们 也 把 区 分 度 称 之 为 基 数 ， 即 区 分 度 越 高 ， 基 数 越 大 。 所 以 呢 ， 基 数 越 大 ， 意 味 巷 符  合 100 &lt; c and c &lt; 10000 议 ． 个 条 亻 牛 的 彳 亍 娄 攵 越 少 。"><img src="/2024/04/05/MYSQL/clip_image100.gif" class="" title="系 统 当 然 是 不 会 漏 历 全 部 来 获 得 一 个 索 引 的 基 数 的 ， 代 价 太 大 了 ， 索 引 系 统 是 涌 过 谝 历 部 分 数 据 ， 也 就 是 通 过 采  样 的 方 式 ， 来 预 测 索 引 的 基 数 的 。  扯 了 这 么 多 ， 重 点 的 来 了 ， 居 然 是 采 样 ， 那 就 有 可 能 出 现 失 误 的 情 况 ， 也 就 是 说 ， c 议 个 索 引 的 基 数 实 际 上 是 很  大 的 ， 但 是 采 样 的 时 候 ， 却 很 不 幸 ， 把 汶 个 索 引 的 基 数 预 测 成 很 小 。 例 如 你 采 样 的 那 一 部 分 数 据 刚 好 基 数 很 小 ，  然 后 就 误 以 为 索 引 的 基 数 很 小 。 然 后 就 呵 呵 ， 系 统 就 不 走 （ 索 引 了 ， 直 接 走 全 部 扫 描 了 。"><h2 id="数据库调优"><a href="#数据库调优" class="headerlink" title="数据库调优"></a>数据库调优</h2><p>常规调优的思路</p><p>针对业务周期性的卡顿，例如在每天10-11点业务特别慢，但是还能够使用，过了这段时间就好了。</p><ul><li><ol><li>开启*****<em><strong><strong>慢查询日志*</strong></strong></em>****，运行一天</li><li>查看slowlog，分析slowlog，分析出查询慢的语句。</li><li>按照一定优先级，进行一个一个的排查所有慢语句。</li><li>分析top sql，进行explain调试，查看语句执行时间。</li><li>调整索引或语句本身。</li></ol></li></ul><p>开启*<strong>*<em><em><strong><strong>慢查询日志*</strong></strong></em>*</em></strong></p><ul><li><ol><li>使用explain关键字可以模拟优化器执行SQL查询语句</li><li>查看表的读取顺序</li><li>查看数据库读取操作的操作类型</li><li>查看哪些索引有可能被用到</li><li>查看哪些索引真正被用到</li><li>查看表之间的引用</li><li>查看表中有多少行记录被优化器查询</li><li>type&#x3D;&#x3D;显示的是访问类型，是较为重要的一个指标，结果值从最好到最坏依次是<br>  system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null      &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range(尽量保证)      &gt; index &gt; ALL<br>  &#x3D;&#x3D;ref&#x3D;&#x3D; ：非唯一性索引扫描，返回匹配某个单独值的所有行，本质上也是一种索引访问，它返回所有符合条件的行。<br>  explain select * from t1 where col1&#x3D;’zs1’;<br>  &#x3D;&#x3D;range&#x3D;&#x3D; : 只检索给定范围的行, 使用一个索引来选择行.key列显示的是真正使用了哪个索引,一般就是在where条件中使用between,&gt;,&lt;,in 等范围的条件,这种在索引范围内的扫描比全表扫描要好,因为它只在某个范围中扫描,不需要扫描全部的索引<br>  explain select * from t1 where id between 1 and 10;</li><li>key&#x3D;&#x3D;查询过程中真正使用的索引，如果为null，则表示没有使用索引 </li><li>key_len&#x3D;&#x3D;索引中使用的字节数，可通过该列计算查询中使用的索引的长度，长度越短越好。</li><li>rows&#x3D;&#x3D;根据表统计信息及索引选用的情况,估算找出所需记录要读取的行数 (有多少行记录被优化器读取) ,越少越好</li></ol></li></ul><h2 id="索引失效情况"><a href="#索引失效情况" class="headerlink" title="索引失效情况"></a>索引失效情况</h2><ul><li>最左前缀法则(如果索引了多列，要遵守*****<em><strong><strong>最左前缀法则*</strong></strong></em>****。指的是查询从索引的最左前列开始并且不跳过索引中的列。)</li><li>不在索引列上做任何操作（计算、函数、(自动or手动)类型转换），如果做的话，会导致索引失效而转向******，如果非要操作数据，那么就使用冗余列，存与索引一样的数据值，去操作冗余列。</li><li>存储引擎不能使用索引中范围条件(****between*<em><strong><strong>、*</strong></strong></em>&lt;******、******&gt;******、***<em><strong>in*<em><strong><strong>等*</strong></strong></em>*</strong></em>)右边的列(范围条件右边与范围条件使用的同一个组合索引，右边的才会失效。若是不同索引则不会失效)。EXPLAIN SELECT * FROM staffs WHERE name &#x3D; ‘July’ AND age &gt; 25     AND pos &#x3D; ‘dev’; – 范围之后的索引失效:即pos没用到索引</li><li>减少select *，使用哪些字段查哪些字段。</li><li>mysql5.7 在使用不等于(!&#x3D; 或者&lt;&gt;)的时候无法使用索引会导致全表扫描。但8.0不会。</li><li>like以%开头(‘%abc…’)mysql索引失效会变成全表扫描的操作</li><li>字符串不加单引号索引失效 ( 底层进行转换使索引失效，使用了函数造成索引失效)（隐式类型转换）</li></ul><p>EXPLAIN SELECT * FROM staffs WHERE NAME &#x3D; 987</p><p>一般在开发中，当要进行调优时，需要有一定的依赖信息，可以通过show status like ‘Handler_read%’;查看索引的使用情况。</p><img src="/2024/04/05/MYSQL/clip_image101.jpg" class="" title="Variable  Handler  Handler  Handler  Handler  Handler  Handler  Handler  name  read first  read key  read last  read neR  ready rev  read rnd  read rnd neR  Value  12352"><p>****handler_read_key****：这个值越大说明使用索引查询到的次数越多。</p><p>****handler_read_rnd_next****：这个值越高，说明查询低效。</p><h1 id="Mysql主从复制"><a href="#Mysql主从复制" class="headerlink" title="Mysql主从复制"></a>Mysql主从复制</h1><p>binlog是记录所有数据库表结构变更（例如CREATE、ALTER TABLE…）以及表数据修改（INSERT、UPDATE、DELETE…）的二进制日志。</p><p>复制的基本过程如下：</p><p>- 从节点上的I&#x2F;O 进程连接主节点，并请求从指定日志文件的指定位置（或者从最开始的日志）之后的日志内容；</p><p>- 主节点接收到来自从节点的I&#x2F;O请求后，通过负责复制的I&#x2F;O进程根据请求信息读取指定日志指定位置之后的日志信息，返回给从节点。返回信息中除了日志所包含的信息之外，还包括本次返回的信息的bin-log file 的以及bin-log position；从节点的I&#x2F;O进程接收到内容后，将接收到的日志内容更新到本机的relay log中，并将读取到的binary log文件名和位置保存到master-info 文件中，以便在下一次读取的时候能够清楚的告诉Master“我需要从某个bin-log 的哪个位置开始往后的日志内容，请发给我”；</p><p>- Slave 的 SQL线程检测到relay-log 中新增加了内容后，会将relay-log的内容解析成在主节点上实际执行过的操作，并在本数据库中执行。</p><p><a href="https://zhuanlan.zhihu.com/p/50597960">https://zhuanlan.zhihu.com/p/50597960</a></p><h1 id="大数据"><a href="#大数据" class="headerlink" title="大数据"></a>大数据</h1><h2 id="大数据量的分页查询怎么优化"><a href="#大数据量的分页查询怎么优化" class="headerlink" title="大数据量的分页查询怎么优化"></a>大数据量的分页查询怎么优化</h2><p>（1）使用子查询优化：这种方式先定位偏移位置的 id，然后往后查询，这种方式适用于 id 递增的情况。 看重一条数据的id</p><p> select * from orders_history where type&#x3D;8 limit 100000,1; select * from orders_history where type&#x3D;8 and id&gt;&#x3D;(select id from orders_history where type&#x3D;8 limit 100000,1) limit 100; </p><p>（2）使用 id 限定优化：这种方式假设数据表的id是<strong>连续递增</strong>的，则我们根据查询的页数和查询的记录数可以算出查询的id的范围，可以使用 id between and 来查询： 看重id的范围</p><p> select * from orders_history where type&#x3D;2 and id between 1000000 and 1000100 limit 100; select * from orders_history where id &gt;&#x3D; 1000001 limit 100; select * from orders_history where id in(select order_id from trade_2 where goods &#x3D; ‘pen’)limit 100; </p><p>（3）使用临时表优化：可以考虑使用临时存储的表来记录分页的id，使用分页的id来进行 in 查询。这样能够极大的提高传统的分页查询速度，尤其是数据量上千万的时候。</p><p>主键递增且数据有序。其实就是利用B+树的原理进行的，因为在Innodb存储引擎中，数据是通过B+树进行存储，叶子节点存储的是主键id，另外子查询中也用到了覆盖索引。</p><p><a href="https://segmentfault.com/a/1190000038856674">https://segmentfault.com/a/1190000038856674</a></p><h2 id="分库分表，以及可能遇到的问题"><a href="#分库分表，以及可能遇到的问题" class="headerlink" title="分库分表，以及可能遇到的问题"></a>分库分表，以及可能遇到的问题</h2><p><em><strong>*1.垂直分表：拆分是基于关系型数据库中的“列”（字段）进行的。通常情况，某个表中的字段比较多，可以新建立一张“扩展表”，将不经常使用或者长度较大的字段拆分出去放到“扩展表”中。*</strong></em></p><img src="/2024/04/05/MYSQL/clip_image103.gif" class="" title="img"><p><em><strong>*2.水平分表：水平分表也称为横向分表，比较容易理解，就是将表中不同的数据行按照一定规律分布到不同的数据库表中（这些表保存在同一个数据库中），这样来降低单表数据量，优化查询性能。最常见的方式就是通过主键或者时间等字段进行 Hash 和取模后拆分。*</strong></em></p><img src="/2024/04/05/MYSQL/clip_image105.gif" class="" title="img"><p><em><strong>*3.垂直分库*</strong></em></p><p>垂直分库在“微服务”盛行的今天已经非常普及了。基本的思路就是按照业务模块来划分出不同的数据库，而不是像早期一样将所有的数据表都放到同一个数据库中。</p><img src="/2024/04/05/MYSQL/clip_image107.gif" class="" title="img"><p><em><strong>*4.水平分库分表*</strong></em></p><p>水平分库分表与上面讲到的水平分表的思想相同，唯一不同的就是将这些拆分出来的表保存在不同的数据中。这也是很多大型互联网公司所选择的做法。</p><img src="/2024/04/05/MYSQL/clip_image109.gif" class="" title="img"><p><em><strong>*分库分表的难点：*</strong></em></p><p>垂直分库带来的问题和解决思路：</p><p><em><strong>*1.跨库 join 的问题：在拆分之前，系统中很多列表和详情页所需的数据是可以通过 sql join 来完成的。而拆分后，数据库可能是分布式在不同实例和不同的主机上，join 将变得非常麻烦。而且基于架构规范，性能，安全性等方面考虑，一般是禁止跨库 join 的。那该怎么办呢？首先要考虑下垂直分库的设计问题，如果可以调整，那就优先调整。如果无法调整的情况，以下总结几种常见的解决思路，并分析其适用场景。*</strong></em></p><p>（1）全局表</p><p>所谓全局表，就是有可能系统中所有模块都可能会依赖到的一些表。比较类似我们理解的“数据字典”。为了避免跨库 join 查询，我们可以将这类表在其他每个数据库中均保存一份。同时，这类数据通常也很少发生修改（甚至几乎不会），所以也不用太担心“一致性”问题。</p><p>（2）字段冗余</p><p>举个电商业务中很简单的场景：</p><p>“订单表”中保存“卖家 Id”的同时，将卖家的“Name”字段也冗余，这样查询订单详情的时候就不需要再去查询“卖家用户表”。字段冗余能带来便利，是一种“空间换时间”的体现。比较适合依赖字段较少的情况。最复杂的还是数据一致性问题，这点很难保证，如果卖家修改了 Name 之后，是否需要在订单信息中同步更新呢？数据同步：定时 A 库中的 tab_a 表和 B 库中 tbl_b 有关联，可以定时将指定的表做同步。当然，同步本来会对数据库带来一定的影响，需要性能影响和数据时效性中取得一个平衡。</p><p>（3）系统层组装</p><p>在系统层面，通过调用不同模块的组件或者服务，获取到数据并进行字段拼装。简单字段组装的情况下，我们只需要先获取“主表”数据，然后再根据关联关系，调用其他模块的组件或服务来获取依赖的其他字段（如例中依赖的用户信息），最后将数据进行组装。</p><p>常见的分片策略有随机分片和连续分片这两种</p><img src="/2024/04/05/MYSQL/clip_image111.jpg" class="" title="连 续 分 片  随 机 分 片  2015 &#x2F; 01 ． 2015 ／ 12  2016 &#x2F; 01 ． 2016 ／ 12  100D1 20000  Data Node2  Data  Data ， de2"><p>1.连续分片：（1）范围查找方便。（2）扩容方便。（3）存在数据热点问题，当需要使用分片字段进行范围查找时，连续分片可以快速定位分片进行高效查询，大多数情况下可以有效避免跨分片查询的问题。后期如果想对整个分片集群扩容时，只需要添加节点即可，无需对其他分片的数据进行迁移。但是，连续分片也有可能存在数据热点的问题，就像图中按时间字段分片的例子，有些节点可能会被频繁查询压力较大，热数据节点就成为了整个集群的瓶颈。而有些节点可能存的是历史数据，很少需要被查询到。</p><p>2.随机分片：（1）数据分布均匀，不容易出现热点和并发访问的瓶颈。（2）扩容起来需要迁移旧的数据。（3）跨分片查询复杂。随机分片其实并不是随机的，也遵循一定规则。通常，我们会采用 Hash 取模的方式进行分片拆分，所以有些时候也被称为离散分片。随机分片的数据相对比较均匀，不容易出现热点和并发访问的瓶颈。但是，后期分片集群扩容起来需要迁移旧的数据。使用一致性 Hash 算法（jianshu.com&#x2F;p&#x2F;528ce5cd7e8f）能够很大程度的避免这个问题，所以很多中间件的分片集群都会采用一致性 Hash 算法。离散分片也很容易面临跨分片查询的复杂问题。</p><p>历史数据迁移的问题。一般做法就是通过程序先读出历史数据，然后按照指定的分片规则再将数据写入到各个分片节点中。</p><p><em><strong>*跨分片技术问题：*</strong></em></p><p><em><strong>*1.跨分片的排序分页：为了最终结果的准确性，我们需要在不同的分片节点中将数据进行排序并返回，并将不同分片返回的结果集进行汇总和再次排序，最后再返回给用户。*</strong></em></p><img src="/2024/04/05/MYSQL/clip_image002-1712317803722.gif" class="" width="0"><p>如果想取出第 10 页数据，情况又将变得复杂很多，如下图所示：</p><img src="/2024/04/05/MYSQL/clip_image115.gif" class="" title="000 , T000T 0 丨"><p>很显然，这样的操作是比较消耗资源的，用户越往后翻页，系统性能将会越差。</p><p>2.跨分片的函数处理</p><p>在使用 Max、Min、Sum、Count 之类的函数进行统计和计算的时候，需要先在每个分片数据源上执行相应的函数处理，然后再将各个结果集进行二次处理，最终再将处理结果返回。</p><p>3.跨分片 join：</p><p>（1）全局表</p><p>全局表的概念之前在“垂直分库”时提过。基本思想一致，就是把一些类似数据字典又可能会产生 join 查询的表信息放到各分片中，从而避免跨分片的 join。</p><p>（2）ER 分片</p><p>在关系型数据库中，表之间往往存在一些关联的关系。如果我们可以先确定好关联关系，并将那些存在关联关系的表记录存放在同一个分片上，那么就能很好的避免跨分片 join 问题。</p><img src="/2024/04/05/MYSQL/clip_image117.gif" class="" title="tbl_ord«  Data Nodel  tbl order  ID:I  ID:2  Data Node2  tbl order  ID:3  tbl_orderdetail  Data Nodel  tbl orderdetail  order " alt="D:l  order 10:2  Data Node2  tbl orderdetail  order ID:3  order ID•.4"><p>垂直：<a href="https://www.infoq.cn/article/key-steps-and-likely-problems-of-split-table">https://www.infoq.cn/article/key-steps-and-likely-problems-of-split-table</a></p><p>水平：<a href="https://www.infoq.cn/article/key-steps-and-likely-problems-of-horizontal-split-table">https://www.infoq.cn/article/key-steps-and-likely-problems-of-horizontal-split-table</a></p><h2 id="“跨库分页查询”的四种方案"><a href="#“跨库分页查询”的四种方案" class="headerlink" title="“跨库分页查询”的四种方案"></a>“跨库分页查询”的四种方案</h2><p><strong>方法一：全局视野法</strong></p><p>（1）将order by time offset X limit Y，改写成order by time offset 0 limit X+Y</p><p>（2）服务层对得到的N*(X+Y)条数据进行内存排序，内存排序后再取偏移量X后的Y条记录</p><p>这种方法随着翻页的进行，性能越来越低。</p><p><strong>方法二：业务折衷法-禁止跳页查询</strong></p><p>（1）用正常的方法取得第一页数据，并得到第一页记录的time_max</p><p>（2）每次翻页，将order by time offset X limit Y，改写成order by time where time&gt;$time_max limit Y</p><p>以保证每次只返回一页数据，性能为常量。</p><p><strong>方法三：业务折衷法-允许模糊数据</strong></p><p>（1）将order by time offset X limit Y，改写成order by time offset X&#x2F;N limit Y&#x2F;N</p><p><strong>方法四：二次查询法    X&#x3D;1000  Y&#x3D;5</strong></p><p>（1）将order by time offset X limit Y，改写成order by time offset X&#x2F;N limit Y</p><p>（2）找到最小值time_min</p><p>（3）between二次查询，order by time between $time_min and $time_i_max</p><p>（4）设置虚拟time_min，找到time_min在各个分库的offset，从而得到time_min在全局的offset</p><p>（5）得到了time_min在全局的offset，自然得到了全局的offset X limit Y</p><p><a href="https://www.w3cschool.cn/architectroad/architectroad-cross-database-paging.html">https://www.w3cschool.cn/architectroad/architectroad-cross-database-paging.html</a></p><h2 id="一致性Hash"><a href="#一致性Hash" class="headerlink" title="一致性Hash"></a>一致性Hash</h2><p>对2的32次方取模</p><img src="/2024/04/05/MYSQL/clip_image119.jpg" class="" title="img"><p>*<strong>*<em><em><strong><strong>容错性：一台宕机了只用移动部分数据*</strong></strong></em>*</em></strong></p><p>*<strong>*<em><em><strong><strong>可扩展性：增加一台只用移动部分数据*</strong></strong></em>*</em></strong></p><p>*<strong>*<em><em><strong><strong>数据倾斜问题：虚拟节点机制*</strong></strong></em>*</em></strong></p><p>一致性Hash算法引入了虚拟节点机制，即对每一个服务器节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体操作可以为服务器IP或主机名后加入编号来实现。</p><img src="/2024/04/05/MYSQL/clip_image121.jpg" class="" title="img"><img src="/2024/04/05/MYSQL/clip_image123.jpg" class="" title="img"><h1 id="零星问题"><a href="#零星问题" class="headerlink" title="零星问题"></a>零星问题</h1><h2 id="Buffer-Pool"><a href="#Buffer-Pool" class="headerlink" title="Buffer Pool"></a>Buffer Pool</h2><p>1.Buffer Pool 的大小</p><p>缓冲池（Buffer Pool）的默认大小为 128M，可通过 innodb_buffer_pool_size 参数来配置。</p><p>2.Buffer Pool 的结构</p><p>当 SQL 执行时，用到的相关表的数据行，会将这些数据行都缓存到 Buffer Pool 中。但是我们可以想象一下，如果像上面的机制那么简单，那么如果是分页的话，不断地查询就要不断地将磁盘文件中数据页的数据缓存到 Buffer Pool 中了，那么这时候缓存池这个机制就显得没什么用了，每次查询还是会有一次或者多次的磁盘IO。</p><p><a href="https://www.cnblogs.com/Howinfun/p/12327490.html">https://www.cnblogs.com/Howinfun/p/12327490.html</a></p><h2 id="OLAP，OLTP"><a href="#OLAP，OLTP" class="headerlink" title="OLAP，OLTP"></a>OLAP，OLTP</h2><img src="/2024/04/05/MYSQL/clip_image125.gif" class="" title="img"><h2 id="内连接，左外连接，右外连接区别"><a href="#内连接，左外连接，右外连接区别" class="headerlink" title="内连接，左外连接，右外连接区别"></a>内连接，左外连接，右外连接区别</h2><p>内连接：左表右表都匹配的才显示</p><p>左外连接：左表全部显示</p><p>右外连接：右边全部显示</p><img src="/2024/04/05/MYSQL/clip_image127.jpg" class="" title="ヨ 3 内 達 接  用 辺 表 的 紀 景 去 は 配 右 辺 表 的 記 , 知 果 符 合 的 第 製 示 . ! 从 表 - 外 &#x3D; 主 表 ま  ヨ 31 物 式 内 ま 接  ・ 式 内 蓬 接 ー れ 不 刊 JO 美 靆 字 . 第 件 使 Ⅲ 、 VHERE 指 定  S E L E C T ヤ 段 名 F RO M 左 表 石 表 KH ERE 件  72 201392 ・ 24  2 第 ハ  36 ー 2010-1292  4 白 告 物  和 0 2015 ・ 1097  1 発 澱 第  」 」 2 豊 式 内 接  ・ 暃 示 内 連 接 ー 侵 Ⅱ ER 」 0 - - - 気 第 可 以 省 略 INNER  ロ 「 C ー 〒 取 を 「 R 0M 表 卩 N N 「 引 」 冂 、 も ま 、  ・ 査 洶 唐 物 的 信 は , 品 示 員 」 - 名 , 性 , - に 和 所 を 的 日 名 称 , 我 引 友 調 眠 合 2 張 疉 イ 能  査 臨 出 需 要 的 数 , 使 川 内 接  5 を ド 機  リ 定 査 試 第 表  堂 0 一 空 強 ま  1 ~ 00 ~ 0 ー 3-0 ~ - ~ 4  : 阯 0 え 0 ー 0 , -0 :  ー 000 ー 00 ! ・ 0 ! - 叶  4 0 ~ い 0 い"><img src="/2024/04/05/MYSQL/clip_image129.jpg" class="" title="2 ）  3 ）  4 ）  5 ）  确 定 表 连 猛 条 0 。 员 Il 表 ． d 卸 t_ &#x3D; 部 门 表 的 数 撫 才 是 有 效 的  3 生  定 条 ， 我 们 0 山 的 是 庸 的 俗 息 ， tAT.*.name•ym• 改 变 中 》 T 数 0 ， 我 们 让 在 行 动 定 查 的 字 段 ， 〕 0 n dept d 3 0 生 查 的 唐 慚 的 信 息 ． 是 小 员 T 难 名 ， 别 ， alary" alt=",d. 0000 200 巴 - -0 巴 T.q 和 所 的 汔 冂 名 称 from e ， 30 的 事 0 的 我 们 发 埂 表 名 有 点 长 ， 可 以 蝓 表 取 名 ， 是 示 的 字 段 名 也 用 别 名 ． 、 g n 性 刷 join dept d 、 部 门 名 字 。 。 0 工 0 身 工 地 名 」 乸 ！ ． 工 ， d 过 n 以 m 色 都 门 名 称 0 3 且 3 总 内 接 0 河 0 1 ） 2 》 3 ， 4 》 确 定 直 询 些 表 确 定 表 连 接 的 条 0 确 定 查 的 条 # 确 定 香 啕 字 以 %}{% asset_img clip_image131.jpg&quot; · 左 外 连 接 ！ WOLEFTOUTERJOIN„.ON. OUTER 可 以 省 鹉  ;ELECT ， FROM 左 表 LEFTIOUIER) 」 OIN 右 0 、 条 件  边 &amp; 的 记 飛 去 邝 配 0 的 记 2 巛 如 鑾 合 釜 的 則 是 示 则 ． 小 N ULL  可 以 理 解 为 ； 内 迕 接 的 基 础 一 上 保 证 左 表 的 全 是 示 《 左 羲 是 部 门 ， 右 表 员 工 》  一 在 訕 〕 表 中 增 加 一 个 能 部  过 售 到 0 ；  ntO dept 《 0000 } v 1u00  dept;  ． 使 用 内 连 接 0 杰  dept d inner  」 。 in  emp  dept id ． ，  ． 用 左 外 连 接 壹  fæ dept 0 left 力 0  黑 马 程 庳 员  苤 0 下  改 賣 中 国 跹 禹 。 我 们 正 在 行  离 满 》 T 0 身  男 女 身 勇  1200 2013 一 02 ” 24  S00 湖 以 03 以 以  9000 200 ！ 一 0 ， ” 0 巴  3 0 务  5000 IS -10-0 ，  用 左 边 表 的 记 录 去 匹 配 右 边 表 的 记 录 ． 如 里 符 合 条 件 的 则 昱 不 ； 否 是 ， 显 不 N 酰 L  可 以 垤 解 为 ： 在 内 连 接 的 基 础 上 保 左 表 的 数 躯 全 部 显 示"><img src="/2024/04/05/MYSQL/clip_image133.jpg" class="" title="· 右 外 连 猛 ！ 使 用 RIGHT OUTERJOIN ． “ 创 OUTER 可 以 省 略  1 「 LECT ， 糗 名 厂 RO 左 R" alt="GHTIOLJTERIJOIN 右 ON  引 不 的 &amp; 的 记 去 卜 配 的 记 录 ． 如 製 苻 合 性 的 小 ！ 舌 。  可 以 理 为 ！ 在 内 猛 的 基 0 上 证 右 表 的 数 巛 全 部 是 示  是 示 NIAL  一 员 T 表 中 加 一 个 员 T.  5 咱  ． 在 员 工 表 中 堵 加 一 个 员 工  ． 用 内 连 0  from dept  一 侵 用 右 外 连 接 查 询  财 务 蕊  《 n 七 11 ，  in  5 妩 满  1200 0 ！ 3 一 02 一 2 《  的 ； 00 ， -0 ， ” 就  ， 000 ： 015 一 ． 01  冫 0 訁 3-0 冫  ， 。 男 ， ， 6 6 下 ， 。 2013 ． 12 ． 0 5 "><h2 id="MySQL表设计要注意什么？"><a href="#MySQL表设计要注意什么？" class="headerlink" title="MySQL表设计要注意什么？"></a>MySQL表设计要注意什么？</h2><p>问题1:为什么一定要设一个主键？ </p><p>回答:因为你不设主键的情况下，innodb也会帮你生成一个隐藏列，作为自增主键。所以啦，反正都要生成一个主键，那你还不如自己指定一个主键，在有些情况下，就能显式的用上主键索引，提高查询效率！</p><p>问题2:主键是用自增还是UUID?</p><p> 回答:肯定答自增啊。innodb 中的主键是聚簇索引。如果主键是自增的，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。如果不是自增主键，那么可能会在中间插入，就会引发页的分裂，产生很多表碎片！</p><p>自增主键用完了怎么办</p><p>把自增主键的类型改为BigInt类型就好了</p><p>线上怎么修改列的数据类型的？</p><p>方式一:使用mysql5.6+提供的在线修改功能</p><p>方式二:借助第三方工具gh-ost</p><p>方式三：改从库表结构，然后主从切换</p><p>因为自增主键我们用int类型，一般达不到最大值，我们就分库分表了，所以不曾遇见过！”</p><p><a href="https://mp.weixin.qq.com/s?__biz=MzIwMDgzMjc3NA==&mid=2247484464&idx=1&sn=f783fc5f7fe3d7714247c3c21d0a93f6&chksm=96f66659a181ef4fa02303b4974031b3f40bc1bdd76bad31a60fbaa54f2e63e62fcede88e4cd&scene=21#wechat_redirect">https://mp.weixin.qq.com/s?__biz=MzIwMDgzMjc3NA==&amp;mid=2247484464&amp;idx=1&amp;sn=f783fc5f7fe3d7714247c3c21d0a93f6&amp;chksm=96f66659a181ef4fa02303b4974031b3f40bc1bdd76bad31a60fbaa54f2e63e62fcede88e4cd&amp;scene=21#wechat_redirect</a></p><p>问题3：表示枚举的字段为什么不用enum类型？ </p><p>回答:在工作中表示枚举的字段，一般用tinyint类型。 那为什么不用enum类型呢？下面两个原因 (1)ENUM类型的ORDER BY操作效率低，需要额外操作 (2)如果枚举值是数值，有陷阱</p><p>tinyint类型代表一个字节，如果一个数字大小超过一个字节，则无法保存。</p><img src="/2024/04/05/MYSQL/clip_image135.jpg" class="" title="CREATE TABLE test (foobar ENUM( " alt="0"><p>问题4：货币字段用什么类型? </p><p>回答:如果货币单位是分，可以用Int类型。如果坚持用元，用Decimal(DECIMAL数据类型用于要求非常高的精确度的计算中)。 千万不要答float和double，因为float和double是以二进制存储的，所以有一定的误差。 打个比方，你建一个列如下</p><img src="/2024/04/05/MYSQL/clip_image137.jpg" class="" title="CREATE TABLE (  price" alt="DEFAULT NULL,  ) ENGINE&#x3D;1nnoDB DEFAULT CHARSET&#x3D;utf8"><p>然后insert给price列一个数据为1234567.23，你会发现显示出来的数据变为1234567.25，精度失准！</p><p>问题6:时间字段用什么类型? </p><p>回答:此题无固定答案，应结合自己项目背景来答！把理由讲清楚就行！</p><p> (1)varchar，如果用varchar类型来存时间，优点在于显示直观。但是坑的地方也是挺多的。比如，插入的数据没有校验，你可能某天就发现一条数据为2013111的数据，请问这是代表2013年1月11日，还是2013年11月1日？ 其次，做时间比较运算，你需要用STR_TO_DATE等函数将其转化为时间类型，你会发现这么写是无法命中索引的。数据量一大，是个坑！</p><p>(2)timestamp，该类型是四个字节的整数，它能表示的时间范围为1970-01-01 08:00:01到2038-01-19 11:14:07。2038年以后的时间，是无法用timestamp类型存储的。 但是它有一个优势，timestamp类型是带有时区信息的。一旦你系统中的时区发生改变，例如你修改了时区</p><p>SET TIME_ZONE &#x3D;”america&#x2F;new_york”;</p><p>你会发现，项目中的该字段的值自己会发生变更。这个特性用来做一些国际化大项目，跨时区的应用时，特别注意！</p><p>(3)datetime，datetime储存占用8个字节，它存储的时间范围为1000-01-01 00:00:00 ~ 9999-12-31 23:59:59。显然，存储时间范围更大。但是它坑的地方在于，他存储的是时间绝对值，不带有时区信息。如果你改变<a href="https://cloud.tencent.com/solution/database?from=10680">数据库</a>的时区，该项的值不会自己发生变更！</p><p>(4)bigint，也是8个字节，自己维护一个时间戳，表示范围比timestamp大多了，就是要自己维护，不大方便。</p><p>问题7:为什么不直接存储图片、音频、视频等大容量内容?</p><p> 回答:我们在实际应用中，都是用HDFS来存储文件。然后mysql中，只存文件的存放路径。mysql中有两个字段类型被用来设计存放大容量文件，也就是text和blob类型。但是，我们在生产中，基本不用这两个类型！ 主要原因有如下两点</p><p>(1)Mysql内存临时表不支持TEXT、BLOB这样的<a href="https://cloud.tencent.com/solution/bigdata?from=10680">大数据</a>类型，如果查询中包含这样的数据，在排序等操作时，就不能使用内存临时表，必须使用磁盘临时表进行。导致查询效率缓慢</p><p>(2)binlog内容太多。因为你数据内容比较大，就会造成binlog内容比较多。大家也知道，主从同步是靠binlog进行同步，binlog太大了，就会导致主从同步效率问题！</p><p>因此，不推荐使用text和blob类型！</p><p>问题8:字段为什么要定义为NOT NULL? </p><p>回答:OK，这问题从两个角度来答 (1)索引性能不好</p><p>Mysql难以优化引用可空列查询，它会使索引、索引统计和值更加复杂。可空列需要更多的存储空间，还需要mysql内部进行特殊处理。可空列被索引后，每条记录都需要一个额外的字节，还能导致MYisam 中固定大小的索引变成可变大小的索引。</p><p>(2)查询会出现一些不可预料的结果</p><img src="/2024/04/05/MYSQL/clip_image139.jpg" class="" title="id  3  5  7  select count(name) from table 2;  name  null  null"><p><a href="https://cloud.tencent.com/developer/article/1468442">https://cloud.tencent.com/developer/article/1468442</a></p><h2 id="范式"><a href="#范式" class="headerlink" title="范式"></a>范式</h2><p>范式：</p><p>第一范式（1NF）：</p><p>数据库表的每一列都是不可分割的原子数据项</p><p>第二范式（2NF）</p><p>非码属性必须完全依赖于候选码</p><p>第三范式（3NF）</p><p>在2NF基础上，任何非主<a href="https://baike.baidu.com/item/%E5%B1%9E%E6%80%A7">属性</a>不依赖于其它非主属性（在2NF基础上消除传递依赖）</p><p>巴斯-科德范式（BCNF）Boyce-Codd Normal Form（巴斯-科德范式）</p><p>在3NF基础上，任何非主属性不能对主键子集依赖（在3NF基础上消除对主码子集的依赖）</p>]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> MYSQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JVM</title>
      <link href="/2024/04/05/JVM/"/>
      <url>/2024/04/05/JVM/</url>
      
        <content type="html"><![CDATA[<h1 id="JVM"><a href="#JVM" class="headerlink" title="JVM"></a>JVM</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>JVM全称Java Virtual Machine，即Java虚拟机。它本身是一个虚拟计算机。Java虚拟机基于二进制字节码执行，由一套字节码指令集、一组寄存器、一个栈、一个垃圾回收堆、一个方法区等组成。JVM屏蔽了与操作系统平台相关的信息，从而能够让Java程序只需要生成能够在JVM上运行的字节码文件。通过该机制实现的跨平台性。因此这也是为什么说Java能够做到“一处编译、处处运行”的原因。</p><h2 id="JVM生命周期"><a href="#JVM生命周期" class="headerlink" title="JVM生命周期"></a>JVM生命周期</h2><p>JVM的生命周期分为三个阶段，分别为：启动、运行、死亡。</p><p>- <strong>启动：</strong></p><p> 当启动一个Java程序时，JVM的实例就已经产生。对于拥有main函数的类就是JVM实例运行的起点。</p><p>- <strong>运行：</strong></p><p> main()方法是一个程序的初始起点，任何线程均可由在此处启动。在JVM内部有两种线程类型，分别为：用户线程和守护线程。JVM通常使用的是守护线程，而main()使用的则是用户线程。守护线程会随着用户线程的结束而结束。</p><p>- <strong>死亡：</strong></p><p> 当程序中的用户线程都中止，JVM才会退出。</p><h2 id="内存结构"><a href="#内存结构" class="headerlink" title="内存结构"></a>内存结构</h2><p>内存是非常重要的系统资源，是硬盘和 CPU 的中间仓库及桥梁，承载着操作系统和应用程序的实时运行。JVM 内存结构规定了 Java 在运行过程中内存申请、分配、管理的策略，保证了 JVM 的高效稳定运行。</p><img src="/2024/04/05/JVM/clip_image002.gif" class="" title="img"><img src="/2024/04/05/JVM/clip_image004.gif" class="" title="img"><img src="/2024/04/05/JVM/clip_image006.gif" class="" title="img"><p><strong>虚拟机栈：</strong></p><p>​    线程私有的，虚拟机栈对应方法调用到执行完成的整个过程。保存执行方法时的<strong>局部变量、动态连接信息、方法返回地址信息</strong>等等。方法开始执行的时候会进栈，方法执行完会出栈【相当于清空了数据】。不需要进行GC。</p><p>Java 虚拟机栈会出现两种错误： StackOverFlowError 和 OutOfMemoryError 。</p><p>StackOverFlowError ： 若 Java 虚拟机栈的内存⼤⼩不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最⼤深度的时候，就抛出 StackOverFlowError 错误。 </p><p>OutOfMemoryError ： 若 Java 虚拟机堆中没有空闲内存，并且垃圾回收器也⽆法提供更多内存的话。就会抛出 OutOfMemoryError 错误。</p><p><strong>本地方法栈：</strong></p><p>​    与虚拟机栈类似。本地方法栈是为虚拟机<strong>执行本地方法时提供服务的</strong>。不需要进行GC。本地方法一般是由其他语言编写。</p><p><strong>程序计数器：</strong></p><p>​    线程私有的。内部保存的字节码的行号。用于记录正在执行的字节码指令的地址。</p><p>\1. 字节码解释器通过改变程序计数器来依次读取指令，从⽽实现代码的流程控制，如：顺序执 ⾏、选择、循环、异常处理。</p><p>\2. 在多线程的情况下，程序计数器⽤于记录当前线程执⾏的位置，从⽽当线程被切换回来的时候能够知道该线程上次运⾏到哪⼉了</p><p>注意：程序计数器是唯⼀⼀个不会出现 OutOfMemoryError 的内存区域，它的⽣命周期随着线 程的创建⽽创建，随着线程的结束⽽死亡。</p><p>​    java虚拟机对于多线程是通过线程轮流切换并且分配线程执行时间。在任何的一个时间点上，一个处理器只会处理执行一个线程，如果当前被执行的这个线程它所分配的执行时间用完了【挂起】。处理器会切换到另外的一个线程上来进行执行。并且这个线程的执行时间用完了，接着处理器就会又来执行被挂起的这个线程。</p><p>​    那么现在有一个问题就是，当前处理器如何能够知道，对于这个被挂起的线程，它上一次执行到了哪里？那么这时就需要从程序计数器中来回去到当前的这个线程他上一次执行的行号，然后接着继续向下执行。</p><p>​    程序计数器是JVM规范中唯一一个没有规定出现OOM的区域，所以这个空间也不会进行GC。</p><p><strong>本地内存：</strong></p><p>​    它又叫做<strong>堆外内存</strong>，线程共享的区域，本地内存这块区域是不会受到JVM的控制的，也就是说对于这块区域是不会发生GC的。因此对于整个java的执行效率是提升非常大的。</p><p><strong>堆：</strong></p><p>​    线程共享的区域。主要用来保存<strong>对象实例，数组</strong>等，当堆中没有内存空间可分配给实例，也无法再扩展时，则抛出OutOfMemoryError异常。</p><p>​    在JAVA7中堆内会存在<strong>年轻代、老年代和方法区</strong>**(<strong><strong>永久代</strong></strong>)**。</p><p>​    1）Young区被划分为三部分，Eden区和两个大小严格相同的Survivor区，其中，Survivor区间中，某一时刻只有其中一个是被使用的，另外一个留做垃圾收集时复制对象用。在Eden区变满的时候， GC就会将存活的对象移到空闲的Survivor区间中（先移动到s0,等到再次满，移动到s1，再次满移动到s0），根据JVM的策略，在经过几次垃圾收集后，任然存活于Survivor的对象将被移动到Tenured（长期保有的，老年代）区间。</p><p>​    2）Tenured区主要保存生命周期长的对象，一般是一些老的对象，当一些对象在Young复制转移一定的次数以后，对象就会被转移到Tenured区。</p><p>​    3）Perm代主要保存<strong>保存的类信息、静态变量、常量、编译后的代码</strong>，在java7中堆上方法区会受到GC的管理的。方法区【永久代】是有一个大小的限制的。如果大量的动态生成类，就会放入到方法区【永久代】，很容易造成OOM。</p><p>​    为了避免方法区出现OOM，所以在java8中将堆上的方法区【永久代】给移动到了本地内存上，重新开辟了一块空间，叫做<strong>元空间</strong>。那么现在就可以避免掉OOM的出现了。</p><h2 id="元空间-MetaSpace-介绍"><a href="#元空间-MetaSpace-介绍" class="headerlink" title="元空间(MetaSpace)介绍"></a><strong>元空间</strong>(MetaSpace)介绍</h2><p>在 HotSpot JVM 中，永久代（ ≈ 方法区）中用于存放类和方法的元数据以及常量池，比如Class 和 Method。每当一个类初次被加载的时候，它的元数据都会放到永久代中。</p><p>​    永久代是有大小限制的，因此如果加载的类太多，很有可能导致永久代内存溢出，即OutOfMemoryError，为此不得不对虚拟机做调优。</p><p><strong>Java 8</strong> <strong>中</strong> <strong>PermGen</strong> <strong>为什么被移出</strong> <strong>HotSpot JVM</strong> <strong>了？</strong></p><p>移除永久代是为融合HotSpot JVM与 JRockit VM而做出的努力，因为JRockit没有永久代，不需要配置永久代。</p><p>1）由于 PermGen 内存经常会溢出，引发OutOfMemoryError，因此 JVM 的开发者希望这一块内存可以更灵活地被管理，不要再经常出现这样的 OOM。</p><p>1、字符串存在永久代中，容易出现性能问题和内存溢出。</p><p>2、类及方法的信息等比较难确定其大小，因此对于永久代的大小指定比较困难，太小容易出现永久代溢出，太大则容易导致老年代溢出。</p><p>3、永久代会为 GC 带来不必要的复杂度，并且回收效率偏低。</p><p>2）移除 PermGen 可以促进 HotSpot JVM 与 JRockit VM 的融合，因为 JRockit 没有永久代。</p><p>​    准确来说，Perm 区中的字符串常量池被移到了堆内存中是在 Java7 之后，Java 8 时，PermGen 被元空间代替，其他内容比如<strong>类元信息、字段、静态属性、方法、常量</strong>等都移动到元空间区。比如 java&#x2F;lang&#x2F;Object 类元信息、静态属性 System.out、整型常量等。</p><p>​    元空间的本质和永久代类似，都是对 JVM 规范中方法区的实现。不过元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。因此，默认情况下，元空间的大小仅受本地内存限制。</p><h1 id="类加载器"><a href="#类加载器" class="headerlink" title="类加载器"></a>类加载器</h1><h2 id="Java文件编译执行的过程"><a href="#Java文件编译执行的过程" class="headerlink" title="Java文件编译执行的过程"></a>Java文件编译执行的过程</h2><p>要想理解类加载器的话，务必要先清楚对于一个Java文件，它从编译到执行的整个过程。</p><img src="/2024/04/05/JVM/clip_image008.gif" class="" title=".class  MethodArea&#x2F;MetaSpace  VM Stack  ClassLoader  Program Counter  Register  Heap  Native Method Stack"><ul><li>类加载器：用于装载字节码文件(.class文件)</li><li>运行时数据区：用于分配存储空间</li><li>执行引擎：执行字节码文件或本地方法</li><li>垃圾回收器：用于对JVM中的垃圾内容进行回收</li></ul><h2 id="类加载过程"><a href="#类加载过程" class="headerlink" title="类加载过程"></a>类加载过程</h2><img src="/2024/04/05/JVM/clip_image010.gif" class="" title="img"><p>解析：使栈中指针指向堆中变量</p><p>初始化：程序员写的初始化代码（自己写的静态代码块）</p><h2 id="一个对象从加载到JVM，再到被GC清楚，都经历了什么过程？"><a href="#一个对象从加载到JVM，再到被GC清楚，都经历了什么过程？" class="headerlink" title="一个对象从加载到JVM，再到被GC清楚，都经历了什么过程？"></a>一个对象从加载到JVM，再到被GC清楚，都经历了什么过程？</h2><img src="/2024/04/05/JVM/clip_image012.jpg" class="" title="一 个 对 象 从 加 载 到 」 VM ， 再 到 被 G （ 清 除 ， 都 经 历 了 什 么 过 程 ？  method( ClassLoaderDem01 们 ew （ Loade " alt="0em010 ； 匚 对 （  1 ． 用 户 创 窪 一 个 对 象 的 NM 首 先 需 到 方 法 区 找 的 年 的 类 型 僖 息 ． 然 再 创 对 象 ．  乙 周 M 要 买 例 化 一 1 ． 矧 象 ． 首 先 要 在 堆 当 中 先 创 建 一 对 ． &gt; # 初 处 化 状  土 的 首 先 会 冲 堆 内 存 中 新 芏 什 0 然 经 波 一 次 Min 酣 GC, 对 如 果 存 ． 就 会 进 人 S 区 ， 秆 启 续 的 0 次 GC  中 。 如 果 的 一 0 存 活 ， 就 会 苻 S 区 回 贝 ， 刨 移 动 一 次 。 加 1. 巧 多 大 年 龄 才 会 移 入 者 年 代 ？ 年 是 大 1 憩 一  的 后 ， 对 象 转 入 老 代 。  生 当 方 法 执 行 适 薟 旨 的 栈 中 的 計 会 先 蜍 绰 ，  堆 中 的 对 象 ， 以 F GC, 就 会 發 吓 记 为 圾 。 然 0 發 G （ 线 溝 许 椏 ·"><p>1.中：每一个对象有一个markword，中有一个class point 指向元空间中的class信息</p><p>对象有可能分配在栈中，生命周期会很简单</p><h2 id="类加载器种类"><a href="#类加载器种类" class="headerlink" title="类加载器种类"></a>类加载器种类</h2><p>类加载器根据各自加载范围的不同，划分为四种类加载器：</p><p>- <strong>启动类加载器(BootStrap ClassLoader)：</strong></p><p> 该类并不继承ClassLoader类，其是由C++编写实现。用于加载<strong>JAVA_HOME&#x2F;jre&#x2F;lib</strong>目录下的类库。</p><p>- <strong>扩展类加载器(ExtClassLoader)：</strong></p><p> 该类是ClassLoader的子类，主要加载<strong>JAVA_HOME&#x2F;jre&#x2F;lib&#x2F;ext</strong>目录中的类库。</p><p>- <strong>应用类加载器(AppClassLoader)：</strong></p><p> 该类是ClassLoader的子类，主要用于加载<strong>classPath</strong>下的类，也就是加载开发者自己编写的Java类。</p><p>- <strong>自定义类加载器：</strong></p><p> 开发者自定义类继承ClassLoader，实现自定义类加载规则。</p><p>上述三种类加载器的层次结构如下如下：</p><img src="/2024/04/05/JVM/clip_image014.gif" class="" title="img"><p>​    类加载器的体系并不是“继承”体系，而是<strong>委派体系</strong>，类加载器首先会到自己的parent中查找类或者资源，如果找不到才会到自己本地查找。类加载器的委托行为动机是为了避免相同的类被加载多次。</p><h2 id="类加载模型"><a href="#类加载模型" class="headerlink" title="类加载模型"></a>类加载模型</h2><p>在JVM中，对于类加载模型提供了三种，分别为全盘加载、双亲委派、缓存机制。</p><p>- <strong>全盘加载：</strong></p><p>​    即当一个类加载器负责加载某个Class时，该Class所依赖和引用的其他Class也将由该类加载器负责载入，除非显示指定使用另外一个类加载器来载入。</p><p>- <strong>双亲委派：</strong></p><p>​    即先让父类加载器试图加载该Class，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类。简单来说就是，某个特定的类加载器在接到加载类的请求时，首先将加载任务委托给父加载器，依次递归，如果父加载器可以完成类加载任务，就成功返回；只有父加载器无法完成此加载任务时，才自己去加载。</p><p>- <strong>缓存机制：</strong></p><p>​    会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区中搜寻该Class，只有当缓存区中不存在该Class对象时，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓冲区中。从而可以理解为什么修改了Class后，必须重新启动JVM，程序所做的修改才会生效的原因。</p><p>双亲委派解析</p><img src="/2024/04/05/JVM/clip_image016.gif" class="" title="img"><p>Ext是App的父加载器，Boot是ext的父加载器   并不是父类，并不是继承关系</p><p>J<strong>VM</strong>为什么采用双亲委派机制</p><p>1）通过双亲委派机制可以避免某一个类被重复加载，当父类已经加载后则无需重复加载，保证唯一性。</p><p>2）为了安全，保证类库API不会被修改</p><img src="/2024/04/05/JVM/clip_image018.gif" class="" title="img"><p>出现该信息是因为由双亲委派的机制，java.lang.String的在启动类加载器(Bootstrap classLoader)得到加载，因为在核心jre库中有其相同名字的类文件，但该类中并没有main方法。这样就能防止恶意篡改核心API库。</p><h2 id="自定义类加载器"><a href="#自定义类加载器" class="headerlink" title="自定义类加载器"></a>自定义类加载器</h2><p>​    对于自定义类加载器的实现也是很简单，只需要继承ClassLoader类，覆写findClass方法即可。</p><p>编写一个测试实体类，接着生成该类的字节码文件。</p><p>当存在.java文件时，根据双亲委派机制，显示当前类加载器为AppClassLoader，而当将.java文件删除时，则显示使用的是自定义的类加载器。</p><h1 id="垃圾回收机制"><a href="#垃圾回收机制" class="headerlink" title="垃圾回收机制"></a>垃圾回收机制</h1><h2 id="java的GC与内存泄漏"><a href="#java的GC与内存泄漏" class="headerlink" title="java的GC与内存泄漏"></a><strong>java</strong>的GC与内存泄漏</h2><p>Java有了GC为什么还会出现内存泄漏问题？</p><p>\1. 静态集合类泄漏</p><p>静态集合类像HashMap，Vector等的使用最容易出现内存泄漏，静态变量的声明周期与应用程序一直，所有的对象Object也不能内释放，因为被其他对象引用着。</p><p>\2. 单例造成的泄漏</p><p>单例对象在初始化后将在JVM的整个生命周期中存在（以静态变量的方式），如果单例对象持有外部的引用，那么这个对象将不能被JVM正常回收，导致内存泄漏。</p><p>3.各种连接</p><p>数据库连接，网络连接，IO连接等没有显式调用close()关闭，会导致内存泄漏。</p><p>4.监听器的使用</p><p>在释放对象的同时，没有删除相应监听器，也会造成内存泄漏。</p><p>在Java语言中，GC Root包括以下几种对象：</p><ol><li>虚拟机栈中引用的对象</li><li>本地方法栈中JNI引用的对象</li><li>方法区中类静态成员变量引用的对象</li><li>方法区中常量引用的对象</li></ol><h2 id="垃圾定位"><a href="#垃圾定位" class="headerlink" title="垃圾定位"></a>垃圾定位</h2><h3 id="引用计数法"><a href="#引用计数法" class="headerlink" title="引用计数法"></a>引用计数法</h3><ol><li>引用计数法</li></ol><p>​    一个对象被引用了一次，在当前的对象头上递增一次引用次数，如果这个对象的引用次数为0，代表这个对象可回收</p><p>循环引用的话，则引用计数法就会失效</p><img src="/2024/04/05/JVM/clip_image020.gif" class="" title="img"><p>虽然a和b都为null，但是由于a和b存在循环引用，这样a和b永远都不会被回收。</p><p>优点：</p><ul><li>实时性较高，无需等到内存不够的时候，才开始回收，运行时根据对象的计数器是否为0，就可以直接回收。</li><li>在垃圾回收过程中，应用无需挂起。如果申请内存时，内存不足，则立刻报OOM错误。</li><li>区域性，更新对象的计数器时，只是影响到该对象，不会扫描全部对象。</li></ul><p>缺点：</p><ul><li>每次对象被引用时，都需要去更新计数器，有一点时间开销。 </li><li><strong>浪费</strong>CPU资源，即使内存够用，仍然在运行时进行计数器的统计。</li><li><strong>无法解决循环引用问题，会引发内存泄露</strong>。（最大的缺点）</li></ul><h3 id="可达性分析算法"><a href="#可达性分析算法" class="headerlink" title="可达性分析算法"></a>可达性分析算法</h3><p>会存在一个根节点【GC Roots】，引出它下面指向的下一个节点，再以下一个节点节点开始找出它下面的节点，依次往下类推。直到所有的节点全部遍历完毕。</p><img src="/2024/04/05/JVM/clip_image022.gif" class="" title="img"><p>​    M,N这两个节点是可回收的，但是<strong>并不会马上的被回收！！</strong> 对象中存在一个方法【finalize】。当对象被标记为可回收后，当发生GC时，首先<strong>会判断这个对象是否执行了finalize方法</strong>，如果这个方法还没有被执行的话，那么就会先来执行这个方法，接着在这个方法执行中，可以设置当前这个对象与GC ROOTS产生关联，那么这个方法执行完成之后，GC会再次判断对象是否可达，如果仍然不可达，则会进行回收，如果可达了，则不会进行回收。</p><p>​    finalize方法对于每一个对象来说，只会执行一次。如果第一次执行这个方法的时候，设置了当前对象与RC ROOTS关联，那么这一次不会进行回收。 那么等到这个对象第二次被标记为可回收时，那么该对象的finalize方法就不会再次执行了。</p><p>## GC ROOTS：</p><p>​    <strong>虚拟机栈中引用的对象</strong></p><p>​    <strong>本地方法栈中引用的对象</strong></p><p>​    <strong>方法区中类静态属性引用的对象</strong></p><p>​    <strong>方法区中常量引用对象</strong></p><h2 id="垃圾回收算法"><a href="#垃圾回收算法" class="headerlink" title="垃圾回收算法"></a>垃圾回收算法</h2><h3 id="标记清除算法"><a href="#标记清除算法" class="headerlink" title="标记清除算法"></a>标记清除算法</h3><p>标记清除算法，是将垃圾回收分为2个阶段，分别是<strong>标记和清除</strong>。</p><p>1.根据可达性分析算法得出的垃圾进行标记</p><p>2.对这些标记为可回收的内容进行垃圾回收</p><img src="/2024/04/05/JVM/clip_image024.gif" class="" title="img"><img src="/2024/04/05/JVM/clip_image026.gif" class="" title="img"><p>可以看到，标记清除算法解决了引用计数算法中的循环引用的问题，没有从root节点引用的对象都会被回收。</p><p>同样，标记清除算法也是有缺点的：</p><ul><li>效率较低，<strong>标记和清除两个动作都需要遍历所有的对象</strong>，并且在GC时，<strong>需要停止应用程序</strong>，对于交互性要求比较高的应用而言这个体验是非常差的。</li><li>（<strong>重要</strong>）通过标记清除算法清理出来的内存，碎片化较为严重，因为被回收的对象可能存在于内存的各个角落，所以清理出来的内存是不连贯的。</li></ul><h3 id="复制算法"><a href="#复制算法" class="headerlink" title="复制算法"></a>复制算法</h3><p>新生代的垃圾回收算法：大部分对象都不会存活，所以在新生代中使用复制算法较为高效</p><p>复制算法的核心就是，<strong>将原有的内存空间一分为二，每次只用其中的一块</strong>，在垃圾回收时，将正在使用的对象复制到另一个内存空间中，然后将该内存空间清空，交换两个内存的角色，完成垃圾的回收。</p><p>​    如果内存中的垃圾对象较多，需要复制的对象就较少，这种情况下适合使用该方式并且效率比较高，反之，则不适合。 </p><img src="/2024/04/05/JVM/clip_image028.gif" class="" title="img"><img src="/2024/04/05/JVM/clip_image030.gif" class="" title="img"><p>1）将内存区域分成两部分，每次操作其中一个。</p><p>2）当进行垃圾回收时，将正在使用的内存区域中的存活对象移动到未使用的内存区域。当移动完对这部分内存区域一次性清除。</p><p>3）周而复始。</p><p>优点：</p><p>- 在垃圾对象多的情况下，效率较高</p><p>- 清理后，内存无碎片</p><p>缺点：</p><p>- 分配的2块内存空间，在同一个时刻，只能使用一半，内存使用率较低</p><h3 id="标记整理算法"><a href="#标记整理算法" class="headerlink" title="标记整理算法"></a>标记整理算法</h3><p>老年代的垃圾回收算法：大部分对象可能会继续存活下去</p><p>标记压缩算法是在标记清除算法的基础之上，做了优化改进的算法。和标记清除算法一样，也是从根节点开始，对对象的引用进行标记，在清理阶段，并不是简单的直接清理可回收对象，而是将存活对象都向内存另一端移动，然后清理边界以外的垃圾，从而解决了碎片化的问题。</p><img src="/2024/04/05/JVM/clip_image032.gif" class="" title="img"><img src="/2024/04/05/JVM/clip_image034.gif" class="" title="img"><p>1）标记垃圾。</p><p>2）需要清除向右边走，不需要清除的向左边走。</p><p>3）清除边界以外的垃圾。</p><p>优缺点同标记清除算法（标记需要遍历所有的对象，并且在GC时，需要停止应用程序），解决了标记清除算法的碎片化的问题，同时，标记压缩算法多了一步，对象移动内存位置的步骤，其效率也有有一定的影响。</p><h3 id="分代收集算法"><a href="#分代收集算法" class="headerlink" title="分代收集算法"></a>分代收集算法</h3><p>在java8时，堆被分为了两份：<strong>新生代和老年代【<strong><strong>1</strong></strong>：<strong><strong>2</strong></strong>】</strong>，在java7时，还存在一个永久代。</p><img src="/2024/04/05/JVM/clip_image036.gif" class="" title="Eden  (8&#x2F;10)  f rom  (1&#x2F;10)  Young  to  (1&#x2F;10)  Old"><p>对于新生代，内部又被分为了三个区域。Eden区，S0区，S1区【8：1：1】</p><p>当对新生代产生GC：MinorGC【young GC】</p><p>当对老年代产生GC：FullGC【OldGC】</p><p>3.2.4.1 工作机制</p><p>1）当创建一个对象的时候，那么这个对象会被分配在新生代的Eden区。当Eden区要满了时候，触发YoungGC。</p><p>2）当进行YoungGC后，此时在Eden区存活的对象被移动到S0区，并且<strong>当前对象的年龄会加</strong>1，清空Eden区。</p><p>3）当再一次触发YoungGC的时候，会把Eden区中存活下来的对象和S0中的对象，移动到S1区中，这些对象的年龄会加1，清空Eden区和S0区。</p><p>4）当再一次触发YoungGC的时候，会把Eden区中存活下来的对象和S1中的对象，移动到S0区中，这些对象的年龄会加1，清空Eden区和S1区。</p><p>3.2.4.2 对象何时晋升到老年代</p><p>1）对象的年龄达到了某一个限定的值（<strong>默认<strong><strong>15</strong></strong>岁</strong>，CMS默认6岁 ），那么这个对象就会进入到老年代中。</p><p>2）大对象。</p><p>3）如果在Survivor区中相同年龄的对象的所有大小之和超过Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代。</p><p>当老年代满了之后，<strong>触发</strong>FullGC<strong>。</strong>FullGC同时回收新生代和老年代，当前只会存在一个FullGC的线程进行执行，其他的线程全部会被挂起。</p><h1 id="垃圾收集器"><a href="#垃圾收集器" class="headerlink" title="垃圾收集器"></a>垃圾收集器</h1><img src="/2024/04/05/JVM/clip_image038.gif" class="" title="img"><h2 id="串行垃圾收集器"><a href="#串行垃圾收集器" class="headerlink" title="串行垃圾收集器"></a>串行垃圾收集器</h2><p>### Serial收集器</p><p>​    <strong>串行垃圾收集器</strong>，作用于<strong>新生代</strong>。是指使用单线程进行垃圾回收，<strong>采用复制算法</strong>。垃圾回收时，只有一个线程在工作，并且java应用中的所有线程都要暂停，等待垃圾回收的完成。这种现象称之为STW（Stop-The-World）。<strong>其应用在年轻代</strong></p><p>​    对于交互性较强的应用而言，这种垃圾收集器是不能够接受的。因此一般在Javaweb应用中是不会采用该收集器的。</p><img src="/2024/04/05/JVM/clip_image040.gif" class="" title="img"><p><strong>Serial Old****收集器</strong></p><p>​    其是运行于<strong>老年代的单线程</strong>Serial收集器，<strong>采用标记</strong>**-**<strong>整理算法</strong>，主要是给Client模式下的虚拟机使用。</p><h2 id="并行垃圾收集器"><a href="#并行垃圾收集器" class="headerlink" title="并行垃圾收集器"></a>并行垃圾收集器</h2><p>### ParallelNew收集器</p><p>  并行垃圾收集器在串行垃圾收集器的基础之上做了改进，<strong>采用复制算法</strong>。将单线程改为了多线程进行垃圾回收，这样可以缩短垃圾回收的时间。（这里是指，并行能力较强的机器）。但是对于其他的行为（收集算法、stop the world、对象分配规则、回收策略等）同Serial收集器一样。其也是应用在年轻代。<strong>JDK8默认使用此垃圾回收器</strong></p><p>​    当然了，并行垃圾收集器在收集的过程中也会暂停应用程序，这个和串行垃圾回收器是一样的，只是并行执行，速度更快些，暂停的时间更短一些。</p><img src="/2024/04/05/JVM/clip_image042.gif" class="" title="img"><p>### 3.4.3 Parallel Scavenge收集器</p><p>​    其是一个应用于<strong>新生代</strong>的<strong>并行</strong>垃圾回收器，<strong>采用复制算法</strong>。它的目标是达到一个可控的吞吐量（吞吐量&#x3D;运行用户代码时间 &#x2F;（运行用户代码时间+垃圾收集时间））即虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，吞吐量就是99%。这样可以高效率的利用CPU时间，尽快完成程序的运算任务，适合在后台运算而不需要太多交互的任务。</p><p>- 停顿时间越短对于需要与用户交互的程序来说越好，良好的响应速度能提升用户的体验。</p><p>- 高吞吐量可以最高效率地利用CPU时间，尽快地完成程序的运算任务，主要适合在后台运算而不太需要太多交互的任务。</p><p>### Parallel Old收集器</p><p>​    其是一个应用于老年代的并行垃圾回收器，<strong>采用标记-整理算法</strong>。在注重吞吐量及CPU资源敏感的场合，都可以优先考虑Parallel Scavenge+Parallel Old收集器。</p><h2 id="CMS（并发）垃圾收集器"><a href="#CMS（并发）垃圾收集器" class="headerlink" title="CMS（并发）垃圾收集器"></a>CMS（并发）垃圾收集器</h2><p>CMS全称 Concurrent Mark Sweep，是一款<strong>并发</strong>的、使用<strong>标记-清除</strong>算法的垃圾回收器，该回收器是<strong>针对老年代垃圾回收的</strong>，是一款以获取最短回收停顿时间为目标的收集器，停顿时间短，用户体验就好。<strong>其最大特点是在进行垃圾回收时，应用仍然能正常运行。</strong> </p><p>CMS垃圾回收器的执行过程如下：</p><img src="/2024/04/05/JVM/clip_image044.gif" class="" title="img"><p>1)初始标记(Initial Mark)：仅仅标记GC Roots能直接关联到的对象，速度快，但是需要“Stop The World”</p><p>2)并发标记(Concurrent Mark)：就是进行追踪引用链的过程，可以和用户线程并发执行。</p><p>3)重新标记(Remark)：修正并发标记阶段因用户线程继续运行而导致标记发生变化的那部分对象的标记记录，比初始标记时间长但远比并发标记时间短，需要“Stop The World”</p><p>4)并发清除(Concurrent Sweep)：清除标记为可以回收对象，可以和用户线程并发执行</p><p>​    由于整个过程耗时最长的并发标记和并发清除都可以和用户线程一起工作，所以总体上来看，CMS收集器的内存回收过程和用户线程是并发执行的。</p><p>#### 3.4.6.2 CMS收集器缺点</p><p>​    对于CMS收集器的有三个：</p><p>- 对CPU资源敏感：</p><p>​    并发收集虽然不会暂停用户线程，但因为占用CPU资源，仍会导致系统吞吐量降低、响应变慢</p><p>​    CMS的默认收集线程数量是&#x3D;(CPU数量+3)&#x2F;4。当CPU数量多于4个，收集线程占用的CPU资源多于25%，对用户程序影响可能较大；不足4个时，影响更大，可能无法接受。</p><p>- 无法处理浮动垃圾：</p><p>​    所谓浮动垃圾即在并发清除时，用户线程新产生的垃圾叫浮动垃圾。并发清除时需要预留一定的内存空间，不能像其他收集器在老年代几乎填满再进行收集。如果CMS预留内存空间无法满足程序需要，就会出现一次”Concurrent Mode Failure”失败。这时JVM启用后备预案：临时启用Serail Old收集器，而导致另一次Full GC的产生。</p><p>- 垃圾回收算法导致内存碎片：</p><p>​    因为CMS收集器采用标记-清除算法，因此会导致垃圾从内存中被清除后，会出现内存空间碎片化。这样会导致分配大内存对象时，无法找到足够的连续内存，从而需要提前触发另一次Full GC动作。</p><h2 id="G1垃圾收集器"><a href="#G1垃圾收集器" class="headerlink" title="G1垃圾收集器"></a>G1垃圾收集器</h2><p> 概述</p><p>对于垃圾回收器来说，前面的三种要么一次性回收年轻代，要么一次性回收老年代。而且现代服务器的堆空间已经可以很大了。为了更加优化GC操作，所以出现了G1。</p><p>​    它是一款<strong>同时应用于新生代和老年代、采用标记-整理算法、软实时、低延迟、可设定目标(最大STW停顿时间)<strong>的垃圾回收器，用于代替CMS，适用于较大的堆(&gt;4~6G)，</strong>在JDK9之后默认使用G1</strong>。</p><p>G1的设计原则就是简化JVM性能调优，开发人员只需要简单的三步即可完成调优：</p><p>\1. 第一步，开启G1垃圾收集器</p><p>\2. 第二步，设置堆的最大内存</p><p>\3. 第三步，可设定目标，设置最大的停顿时间（stw）默认是250ms</p><h3 id="G1的内存布局"><a href="#G1的内存布局" class="headerlink" title="G1的内存布局"></a>G1的内存布局</h3><p>G1垃圾收集器相对比其他收集器而言，最大的区别在于它<strong>取消了年轻代、老年代的物理划分</strong>。</p><img src="/2024/04/05/JVM/clip_image046.gif" class="" title="img"><p>​    取而代之的是将堆划分为<strong>若干个区域（<strong><strong>Region</strong></strong>）</strong>，这些区域中包含了有<strong>逻辑上的年轻代、老年代区域</strong>。这样做的好处就是，我们再也不用单独的空间对每个代进行设置了，不用担心每个代内存是否足够。</p><p>​    此时可以看到，现在出现了一个<strong>新的区域****Humongous</strong>，它本身属于老年代区。当现在出现了一个巨大的对象，超出了分区容量的一半，则这个对象会进入到该区域。如果一个H区装不下一个巨型对象，那么G1会寻找连续的H分区来存储。为了能找到连续的H区 ，有时候不得不启动Full GC。</p><p>​    同时G1会估计每个Region中的垃圾比例，优先回收垃圾较多的区域。</p><img src="/2024/04/05/JVM/clip_image048.gif" class="" title="img"><p>​    在G1划分的区域中，年轻代的垃圾收集依然采用<strong>暂停所有应用线程的方式</strong>，将存活对象拷贝到老年代或者Survivor空间，G1收集器通过将<strong>对象从一个区域复制到另外一个区域，完成了清理工作</strong>。</p><p>​    这就意味着，在正常的处理过程中，G1完成了堆的压缩（至少是部分堆的压缩），这样也就不会有cms内存碎片问题的存在了。</p><h3 id="垃圾回收基本概念"><a href="#垃圾回收基本概念" class="headerlink" title="垃圾回收基本概念"></a>垃圾回收基本概念</h3><img src="/2024/04/05/JVM/clip_image050.gif" class="" title="img"><p>Collection Set回收集合</p><img src="/2024/04/05/JVM/clip_image052.gif" class="" title="img"><img src="/2024/04/05/JVM/clip_image054.gif" class="" title="img"><img src="/2024/04/05/JVM/clip_image056.gif" class="" title="img"><p>card table：一个region又划分为一个一个区域</p><p>对应内存空间发生改变：比如给空间中的引用赋值的时候，就会把这个区域标记为dirty</p><p>rememberedSet：region2中的rememberedSet就记录着指向region1部分，因为region1中存在着指向region2的引用，通过rememberedSet就能找到region1</p><p>时间换空间：因为现代堆空间很大，所以是值得的</p><img src="/2024/04/05/JVM/clip_image057.gif" class="" title="img"><p>更新指针时：引用发生变化时</p><img src="/2024/04/05/JVM/clip_image059.gif" class="" title="img"><p>refinement线程：优化线程</p><p>更新RS：region1中存在引用指向region2的对象，这时更新的是region2的RS</p><p>三种模式垃圾回收模式： <strong>young GC、Mixed GC、Full GC</strong>。在不同的条件下被触发。</p><h3 id="Young-GC"><a href="#Young-GC" class="headerlink" title="Young GC"></a>Young GC</h3><p>发生在年轻代的GC算法，一般对象（除了巨型对象）都是在eden region（区）中分配内存，当所有eden region被耗尽无法申请内存时，就会触发一次young gc，这种触发机制和之前的young gc差不多，执行完一次young gc，活跃对象会被拷贝到survivor region或者晋升到old region中，空闲的region会被放入空闲列表中，等待下次被使用。</p><img src="/2024/04/05/JVM/clip_image061.gif" class="" title="img"><p>fully young GC：完全的年轻代GC</p><p>Evacuation：疏散    构建CS：构建回收集合</p><p>Object Copy：把Eden和Survivor区中的对象复制到另一个Survivor区</p><p>update RS的目的就是把R set中更新成最新的状态，知道哪些老年代的引用指向了该对象，因为要进行复制算法</p><p>##### 为什么年轻代一般都使用的copy</p><p>(1) 年轻代 回收效率高 </p><p>(2) 年轻代 一般不会很大 </p><p>以上2点其实都是根据它的特点来的: 朝生夕死.</p><p>使用copy的原因是 它快, 不需要额外的压缩, 没有碎片. 它的缺点就是空间利用率会低一些. 但是本身年轻代不会太大, 所以这个缺点也就不是很严重.</p><img src="/2024/04/05/JVM/clip_image063.gif" class="" title="img"><p>程序员设置的GC时间如果十分严格，G1实在达不到，就会减少年轻代Region数量，也会减少暂停时间，如果太频繁进行GC，那么CPU占用就会增加，造成吞吐量降低。</p><img src="/2024/04/05/JVM/clip_image065.gif" class="" title="img"><h3 id="Mixed-GC（OldGC）"><a href="#Mixed-GC（OldGC）" class="headerlink" title="Mixed GC（OldGC）"></a>Mixed GC（OldGC）</h3><img src="/2024/04/05/JVM/clip_image067.gif" class="" title="img"><img src="/2024/04/05/JVM/clip_image069.gif" class="" title="img"><img src="/2024/04/05/JVM/clip_image071.gif" class="" title="img"><img src="/2024/04/05/JVM/clip_image073.gif" class="" title="img"><p>首先把GCROOT标为黑色，将与GCROOT相连的对象标为灰色，灰色放进一个队列，然后挨个取出来，标记为黑色，并把与这个相连的标记为灰色，直到所以都为黑的</p><p>错标记和漏标记的问题如下：</p><img src="/2024/04/05/JVM/clip_image074.jpg" class="" title="img"><p>A：黑色 B：灰色    C：白色</p><p>在并发标记阶段，引用可能发生了变化：这样的话C永远都标记不到，会被回收，因为A是黑色表示自己和成员变量都被标记了，但C确实没有被标记</p><img src="/2024/04/05/JVM/clip_image075.jpg" class="" title="img"><p>解决方法：</p><p>把A标为灰色：并发标记时把A变为灰色</p><img src="/2024/04/05/JVM/clip_image076.jpg" class="" title="img"><p>G1的解决方案：</p><img src="/2024/04/05/JVM/clip_image077.jpg" class="" title="img"><p>提供了一个快照，保存了没有被标记的region</p><img src="/2024/04/05/JVM/clip_image079.gif" class="" title="img"><p>piggy-backed on young GC 骑在young GC的头上，表明old GC里包含young GC</p><p>当越来越多的对象晋升到老年代old region时，为了避免堆内存被耗尽，虚拟机会触发一个混合的垃圾收集器，即<strong>mixed gc</strong>，该算法并不是一个old gc，除了回收整个young region，还会回收一部分的old region，这里需要注意：<strong>是一部分老年代，而不是全部老年代</strong>，可以选择哪些old region进行收集，从而可以对垃圾回收的耗时时间进行控制。</p><p>​    在CMS中，当老年代的使用率达到80%就会触发一次cms gc。在G1中，mixed gc也可以通过-XX:InitiatingHeapOccupancyPercent设置阈值，*<em>默认为</em>***45%**。当老年代大小占整个堆大小百分比达到该阈值，则触发mixed gc。</p><p>其执行过程和cms类似：</p><ol><li>initial mark: 初始标记过程，整个过程STW，标记了从GC     Root可达的对象。</li><li>concurrent marking: 并发标记过程，整个过程gc     collector线程与应用线程可以并行执行，标记出GC Root可达对象衍生出去的存活对象，并收集各个Region的存活对象信息。</li><li>remark: 最终标记过程，整个过程STW，标记出那些在并发标记过程中遗漏的，或者内部引用发生变化的对象。（保证安全的标记，保证找到的对象都是活对象）</li><li>clean up: 垃圾清除过程，不进行老年代垃圾回收的拷贝，如果发现一个Region中没有存活对象，则把该Region加入到空闲列表中。</li><li><img src="/2024/04/05/JVM/clip_image081.gif" class="" title="img"></li></ol><img src="/2024/04/05/JVM/clip_image083.gif" class="" title="img"><h3 id="Full-GC"><a href="#Full-GC" class="headerlink" title="Full GC"></a>Full GC</h3><p>如果对象内存分配速度过快，mixed gc来不及回收，导致老年代被填满，就会触发一次full gc，G1的full gc算法就是单线程执行的serial old gc，会导致异常长时间的暂停时间，需要进行不断的调优，尽可能的避免full gc.</p><p>为何这么多垃圾回收器：因为内存不断扩大，回收越来越复杂</p><h3 id="G1的最佳实践"><a href="#G1的最佳实践" class="headerlink" title="G1的最佳实践"></a>G1的最佳实践</h3><p><strong>不断调优暂停时间指标</strong></p><p> 通过<strong>XX:MaxGCPauseMillis&#x3D;x</strong>可以设置启动应用程序暂停的时间，G1在运行的时候会根据这个参数选择CSet来满足响应时间的设置。一般情况下这个值设置到100ms或者200ms都是可以的(不同情况下会不一样)，但如果设置成50ms就不太合理。暂停时间设置的太短，就会导致出现G1跟不上垃圾产生的速度。最终退化成Full GC。所以对这个参数的调优是一个持续的过程，逐步调整到最佳状态。</p><p><strong>不要设置新生代和老年代的大小</strong></p><p> G1收集器在运行时候会调整新生代和老年代的大小。通过改变代的大小来调整对象晋升的速度以及晋升年龄，从而达到我们为收集器设置的暂停时间目标。设置了新生代大小相当于放弃了G1为我们做的自动调优。我们需要做的只是设置整个堆内存的大小，剩下的交给G1自己去分配各个代的大小。</p><h2 id="G1相对CMS的优势"><a href="#G1相对CMS的优势" class="headerlink" title="G1相对CMS的优势"></a>G1相对CMS的优势</h2><p>G1相对CMS的优势：</p><p>1、G1在压缩空间方面有优势。</p><p>2、G1通过将内存空间分成区域（Region）的方式避免内存碎片的问题。</p><p>3、Eden、Survivor、Old区不再固定，在内存使用效率上来说更灵活。</p><p>4、G1可以通过设置预期停顿时间（Pause Time）来控制垃圾收集时间，避免应用雪崩现象。</p><p>5、G1在回收内存后会马上同时做合并空闲内存的工作，而CMS默认是在STW(stop the world)的时候做。</p><p>6、G1会在young GC中使用，而CMS只能在老年代中使用。</p><p>G1适合的场景：</p><p>1、服务端多核CPU、JVM内存占用较大的应用。</p><p>2、应用在运行过程中会产生大量的内存碎片，需要经常压缩空间。</p><p>3、想要更可控、可预期的GC停顿周期；防止高并发下应用的雪崩现象。</p><h2 id="ZGC"><a href="#ZGC" class="headerlink" title="ZGC"></a><strong>ZGC</strong></h2><img src="/2024/04/05/JVM/clip_image085.jpg" class="" width="0"><p>ZGC只有三个STW阶段：<strong>初始标记</strong>，<strong>再标记</strong>，<strong>初始转移</strong>。其中，初始标记和初始转移分别都只需要扫描所有GC Roots，其处理时间和GC Roots的数量成正比，一般情况耗时非常短；再标记阶段STW时间很短，最多1ms，超过1ms则再次进入并发标记阶段。即，ZGC几乎所有暂停都只依赖于GC Roots集合大小，停顿时间不会随着堆的大小或者活跃对象的大小而增加。与ZGC对比，G1的转移阶段完全STW的，且停顿时间随存活对象的大小增加而增加。</p><p>ZGC通过着色指针和读屏障技术，解决了转移过程中准确访问对象的问题，实现了并发转移。大致原理描述如下：并发转移中“并发”意味着GC线程在转移对象的过程中，应用线程也在不停地访问对象。假设对象发生转移，但对象地址未及时更新，那么应用线程可能访问到旧地址，从而造成错误。而在ZGC中，应用线程访问对象将触发“读屏障”，如果发现对象被移动了，那么“读屏障”会把读出来的指针更新到对象的新地址上，这样应用线程始终访问的都是对象的新地址。那么，JVM是如何判断对象被移动过呢？就是利用对象引用的地址，即着色指针。</p><p><a href="https://zhuanlan.zhihu.com/p/170572432">https://zhuanlan.zhihu.com/p/170572432</a></p><h1 id="开放性问题"><a href="#开放性问题" class="headerlink" title="开放性问题"></a>开放性问题</h1><p>系统运行过程中出现fullGC，怎么排查，什么情况出现fullGC</p><p>top – jstate – map工具</p><img src="/2024/04/05/JVM/clip_image087.gif" class="" title="img"><img src="/2024/04/05/JVM/clip_image089.gif" class="" title="img"><img src="/2024/04/05/JVM/clip_image091.gif" class="" title="img"><img src="/2024/04/05/JVM/clip_image093.gif" class="" title="img"><p><a href="https://blog.csdn.net/xiaoxiaole0313/article/details/104285018/">https://blog.csdn.net/xiaoxiaole0313/article/details/104285018/</a></p><h1 id="零星知识"><a href="#零星知识" class="headerlink" title="零星知识"></a>零星知识</h1><h2 id="指针碰撞和空闲列表"><a href="#指针碰撞和空闲列表" class="headerlink" title="指针碰撞和空闲列表"></a>指针碰撞和空闲列表</h2><p>假设Java堆中内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离，这种分配方式称为“指针碰撞”（Bump thePointer）。如果Java堆中的内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录，这种分配方式称为“空闲列表”（FreeList） </p><h2 id="内存分配担保机制"><a href="#内存分配担保机制" class="headerlink" title="内存分配担保机制"></a>内存分配担保机制</h2><p>在现实社会中，借款会指定担保人，就是当借款人还不起钱，就由担保人来还钱。</p><p>在JVM的内存分配时，也有这样的<strong>内存分配担保机制</strong>。就是当在新生代无法分配内存的时候，把新生代的对象转移到老生代，然后把新对象放入腾空的新生代。</p><h1 id="比较好的博客"><a href="#比较好的博客" class="headerlink" title="比较好的博客"></a>比较好的博客</h1><p>Java GC（垃圾回收机制）面试讲解</p><p><strong>总结的较好：</strong> <a href="https://www.cnblogs.com/dmzna/p/12913458.html">https://www.cnblogs.com/dmzna/p/12913458.html</a></p><p><strong>讲的较细：</strong> <a href="https://www.cnblogs.com/leesf456/p/5218594.html">https://www.cnblogs.com/leesf456/p/5218594.html</a></p>]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> JVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>集合</title>
      <link href="/2024/04/05/%E9%9B%86%E5%90%88/"/>
      <url>/2024/04/05/%E9%9B%86%E5%90%88/</url>
      
        <content type="html"><![CDATA[<h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image002.gif" class="" title="img"><h2 id="常用的数据结构"><a href="#常用的数据结构" class="headerlink" title="常用的数据结构"></a>常用的数据结构</h2><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image004.gif" class="" title="Linear  Data Structure  Non-linear  Data Structure  (Array)  (Linked List)  (Stack)  (Queue)  (Tree)  (Heap)  (Hashing)  (Graph)"><p>详细见 链接  <a href="https://blog.csdn.net/QLeelq/article/details/113694455">https://blog.csdn.net/QLeelq/article/details/113694455</a></p><h2 id="HashMap"><a href="#HashMap" class="headerlink" title="HashMap"></a>HashMap</h2><h3 id="JDK7HashMap"><a href="#JDK7HashMap" class="headerlink" title="JDK7HashMap"></a>JDK7HashMap</h3><p>在JDK7中其底层是由<strong>数组+链表</strong>构成，数组被分成一个个桶(bucket)，通过哈希值决定了键值对在这个数组中的位置。哈希值相同的键值对，会以链表形式进行存储。每一个键值对会以一个Entry实例进行封装，内部存在四个属性：key，value，hash值，和用于单向链表的next。</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image006.gif" class="" title="entry  key,value,hash  entry  key,value,hash  entry  key,value,hash  entry  key,value,hash  entry  key,value,hash  entry  key,value,hash  entry  key,value,hash  entry  key,value,hash"><p>当对HashMap初始化时，其构造函数中需要传入两个参数：<strong>initialCapacity</strong>、<strong>loadFactor</strong></p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image008.gif" class="" title="public HashMap(int  initialCapacitv ,  float  0.75  toadFactor) {"><p>hashMap中还有一个变量：<strong>threshold</strong>（扩容阈值。计算公式：<strong>capacity * load factor</strong>）</p><p>添加数据过程（put）</p><ol><li>在第一个元素插入HashMap时做一次数组的初始化，先确定初始的数组大小，并计算数组扩容的阈值。（创建hashmap的时候数组并没有被初始化，put的时候才初始化的）</li><li>使用key进行Hash值计算，<strong>然后通过</strong> <strong>(n - 1) &amp; hash</strong> <strong>判断当前元素存放的位置（这里的</strong> <strong>n</strong> <strong>指的是数组的长度）</strong>，用于确定当前键值对要放入哪个Bucket中。（为什么采取与运算：1.采用模运算会造成大量的哈希冲突，导致哈希散列不均匀，某一桶中链表长度过长，造成查询效率大幅下降。2.与运算本身性能要比模运算高）</li><li>找到Bucket后，<strong>如果当前位置存在元素的话，就判断该元素与要存入的元素的</strong> <strong>hash</strong> <strong>值以及</strong> <strong>key</strong> <strong>是否相同</strong>；如果没有重复，则将此Entry放入链表的<strong>头部</strong>。如果键相同值不相同的话，直接更新。（进行比较key值是否相同，若是不同则向后遍历，直到找到相同的为止。找到后进行元素的替换，若是找不到就新生成一个Entry，entry对象的next指向上面获取的位置i，头插）</li><li>在插入新值时，如果当前Buckets数组大小达到了阈值，则触发扩容。扩容后，为原大小的两倍。<strong>扩容时会产生一个新的数组替换原来的数组，并将原来数组中的值迁移到新数组中</strong>。</li></ol><p> JDK7的HashMap扩容流程</p><p>1）当调用HashMap的put方法时，其内部会调用addEntry方法添加元素。</p><p>2）在addEntry中，如果条件满足则调用resize方法进行扩容。扩展为原大小的两倍。</p><p>3）在resize方法中，会调用transfer方法根据新的容量去创建新的Entry数组，命名</p><p>为newTable。</p><p>4）在transfer方法中会轮询原table中的每一个Entry重新计算其在新Table上的位置，并以链表形式连接</p><p>5）当全部轮询完毕，则在resize方法中将原table替换为新table。</p><p> JDK7hashMap死循环解析</p><p>当进行rehash时，会造成hashMap出现死循环，原因就在于其内部会形成一个循环链表。 该问题在JDK8之后得以解决，但是仍然不推荐在多线程环境下直接使用HashMap，因为有可能会造成数据丢失，建议使用ConcurrentHashMap。</p><h3 id="JDK8HashMap"><a href="#JDK8HashMap" class="headerlink" title="JDK8HashMap"></a>JDK8HashMap</h3><p>Hashmap结构</p><p>由<strong>数组+链表+红黑树</strong>组成。这么做的原因是因为：之前查找元素需要遍历链表，时间复杂度取决于链表的长度。</p><p>为了优化这部分的开销，在JDK中，如果链表中元素大于等于8个，则将链表转换为红黑树（前提是桶的大小达到64，否则会先对桶进行扩容）；当红黑树中元素小于等于6个，则将红黑树转为链表。从而降低查询与添加的时间复杂度。</p><p>put流程</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image012.gif" class="" title="HashMap put 容"><p>即使不会出现死循环，但是通过源码看到put&#x2F;get方法都没有加同步锁，多线程情况最容易出现的就是：无法保证上一秒put的值，下一秒get的时候还是原值，所以线程安全还是无法保证。</p><p>1、put的时候导致的多线程数据不一致。</p><p>这个问题比较好想象，比如有两个线程A和B，首先A希望插入一个key-value对到HashMap中，首先计算记录所要落到的桶的索引坐标，然后获取到该桶里面的链表头结点，此时线程A的时间片用完了，而此时线程B被调度得以执行，和线程A一样执行，只不过线程B成功将记录插到了桶里面，假设线程A插入的记录计算出来的桶索引和线程B要插入的记录计算出来的桶索引是一样的，那么当线程B成功插入之后，线程A再次被调度运行时，它依然持有过期的链表头但是它对此一无所知，以至于它认为它应该这样做，如此一来就覆盖了线程B插入的记录，这样线程B插入的记录就凭空消失了，造成了数据不一致的行为。</p><h3 id="扩展知识点"><a href="#扩展知识点" class="headerlink" title="扩展知识点"></a>扩展知识点</h3><p><a href="onenote:#扩展知识点&section-id={D17A0EA0-97AB-4A0A-AACE-F95D62D7DAFC}&page-id={BC978001-A2DC-40EE-89CB-914759A07A3C}&object-id={F678C236-2E0C-4EE5-8AC0-12C26A1DF70D}&E&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/集合数据结构.one">jdk 7 与 jdk 8 中关于HashMap的对比 </a></p><p><a href="onenote:#扩展知识点&section-id={D17A0EA0-97AB-4A0A-AACE-F95D62D7DAFC}&page-id={BC978001-A2DC-40EE-89CB-914759A07A3C}&object-id={55423992-526C-4784-8BBA-FD5DB4809446}&24&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/集合数据结构.one">HashMap 的buckets长度为什么永远是 2 的幂次方</a></p><p><a href="onenote:#扩展知识点&section-id={D17A0EA0-97AB-4A0A-AACE-F95D62D7DAFC}&page-id={BC978001-A2DC-40EE-89CB-914759A07A3C}&object-id={55423992-526C-4784-8BBA-FD5DB4809446}&37&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/集合数据结构.one">HashMap负载因子为什么是0.75</a></p><p><a href="onenote:#扩展知识点&section-id={D17A0EA0-97AB-4A0A-AACE-F95D62D7DAFC}&page-id={BC978001-A2DC-40EE-89CB-914759A07A3C}&object-id={55423992-526C-4784-8BBA-FD5DB4809446}&4F&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/集合数据结构.one">为什么JDK8采用红黑树，而不采用平衡二叉树</a></p><p><a href="onenote:#扩展知识点&section-id={D17A0EA0-97AB-4A0A-AACE-F95D62D7DAFC}&page-id={BC978001-A2DC-40EE-89CB-914759A07A3C}&object-id={55423992-526C-4784-8BBA-FD5DB4809446}&58&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/集合数据结构.one">为什么链表转红黑树的阈值是8</a></p><p><a href="onenote:#扩展知识点&section-id={D17A0EA0-97AB-4A0A-AACE-F95D62D7DAFC}&page-id={BC978001-A2DC-40EE-89CB-914759A07A3C}&object-id={A6C72C1B-17D8-4C69-AFF1-58FCC6E79936}&12&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/集合数据结构.one">为什么要用链地址法解决冲突_1</a></p><p>jdk 7 与 jdk 8 中关于HashMap的对比</p><ul><li>8时红黑树+链表+数组的形式，当桶内元素大于8时，便会树化</li><li>1.7 table在创建hashmap时分配空间，而1.8在put的时候分配，如果table为空，则为table分配空间。</li><li>在发生冲突，插入链中时，7是头插法，8是尾插法。</li></ul><p>HashMap 的buckets长度为什么永远是 2 的幂次方</p><p>​    为了能让存储更加高效，尽量的避免key冲突，让数据尽量均匀的进行分布，因此采用了hash值计算的方式，hash值的范围为-2147483648 到 2147483647。在这40亿的空间中，总的来说一般很难出现碰撞。但是这么大的空间，不可能一次性全部装入内存中，所以不能直接使用这块空间。因此才会对数组长度进行取模运算，根据余数用来对应数组的下标，来确定当前用于存放数据的位置。计算公式就是<code>(n-1)&amp;hash</code>。所以buckets的长度才永远为2的幂次方。（其实就是按位“与”的时候，每一位都能 &amp;1 ，也就是和1111……1111111进行与运算）</p><p>​    取模运算不用<code>hash%length</code>，而使用<code>(length-1)&amp;hash</code>，是因为<code>&amp;</code>采用二进制进行操作，比 <code>%</code> 的运算效率高。</p><p> “当容量一定是2^n时，h &amp; (length - 1) &#x3D;&#x3D; h % length” . 按位运算特别快 </p><p>对于length &#x3D; 16, 对应二进制”1 0000”, length-1&#x3D;”0 1111” </p><p>假设此时h &#x3D; 17 . </p><p>(1) 使用”h % length”, 也就是”17 % 16”, 结果是1 . </p><p>(2) 使用”h &amp; (length - 1)”, 也就是 “1 0001 &amp; 0 1111”, 结果也是1 . </p><p>我们会发现, 因为”0 1111”低位都是”1”, 进行”&amp;”操作, 就能成功保留”1 0001”对应的低位, 将高位的都丢弃, 低位是多少, 最后结果就是多少 . </p><p>刚好低位的范围是”0~15”, 刚好是长度为length&#x3D;16的所有索引 . </p><p> HashMap负载因子为什么是0.75</p><p>负载因子是和扩容机制有关的。扩容公式为：数组容量*负载因子&#x3D;扩容阈值。 当buckets数组达到阈值时，则会进行扩容操作。那么为什么在hashMap中不管是JDK7还是JDK8对于扩容因子都定义为0.75呢？</p><p>​    HashMap总的来说就是一个数据结构，那数据结构就是为了节省空间和时间。那负载因子的作用就是为了节省空间和时间的。</p><p>​    <strong>假设负载因子的值为1.0</strong>。那么结合扩容公式可知，当buckets桶数组全部用完之后才会进行扩容。因为在扩容时，hash冲突是无法避免的。因此当负载因子为1.0时，在进行扩容时，会出现更多的hash冲突，可能导致链表长度或红黑树高度会变得更长或更高，导致查询效率的降低。因此负载因子过大，虽然保证了空间，但牺牲了时间。</p><p>​    <strong>假设负载的值为0.5</strong>。那么结合扩容公式可知，当buckets数组使用一半时，就会触发扩容。因为数组中的元素少，所以出现hash冲突的几率也会变少，所以链表长度或者是红黑树的高度就会降低，从而提升了查询效率。但是这样的话，空间利用率又降低了。原本只要1M就能存储的数据，现在则需要2M。所以负载因子太小，虽然时间效率提升了，但是空间利用率降低了。</p><p> 为什么JDK8采用红黑树，而不采用平衡二叉树</p><p>因为平衡二叉树条件太苛刻了，需要一直进行整棵树的平衡进行左旋或右旋的操作，红黑树相对来讲调整的少点，只要达到黑平衡即可。并且红黑树对于节点的增删和查找效率都是较为中肯的。</p><p>为什么链表转红黑树的阈值是8</p><p>因为红黑树的平均查找长度是log(n)，长度为8的时候，平均查找长度为3，如果继续使用链表，平均查找长度为8&#x2F;2&#x3D;4，这才有转换为树的必要。链表长度如果是小于等于6，6&#x2F;2&#x3D;3，虽然速度也很快的，但是转化为树结构和生成树的时间并不会太短。因此8是一个较为合理的值。</p><p>为什么要用链地址法解决冲突</p><p>开放地址法:当冲突发生的时候，通过查找数组的一个空位，将数据插入进去，而不再用hash函数计算获取数的下标，这个方法就叫做开发地址法；</p><p>缺点：数据的长度是有限的，但我们可能会往数组里面添加很多数据进去，数组总有被填满的时候，那样开发地址法也不管用了</p><p>链地址法：第一次定位数组中的位置，第二次去到链表中，调用链表的查找方法进行查找</p><h2 id="ConcurrentHashMap"><a href="#ConcurrentHashMap" class="headerlink" title="ConcurrentHashMap"></a>ConcurrentHashMap</h2><p>ConcurrentHashMap是一个线程安全且高效的HashMap。在并发下，推荐使用其替换HashMap。对于它的使用也非常的简单，除了提供了线程安全的get和put之外，它还提供了一个非常有用的方法<strong>putIfAbsent</strong>，如果传入的键值对已经存在，则返回存在的value，不进行替换； 如果不存在，则添加键值对，返回null。</p><h3 id="JDK7的ConcurrentHashMap"><a href="#JDK7的ConcurrentHashMap" class="headerlink" title="JDK7的ConcurrentHashMap"></a>JDK7的ConcurrentHashMap</h3><p>基础结构</p><p>![next  Segment<a href="%E9%9B%86%E5%90%88/clip_image014.gif">OJ  Segment[l ]  Segment[2]  Segment[3]  Segment[4]  Segment[14]  Segment[15]  next  next  next  next  next </a></p><p>一个ConcurrentHashMap里包含一个Segment数组，结构与HashMap类似（数组+链表）。一个Segment中包含一个HashEntry数组，每个HashEntry就是链表的元素。</p><p>​    Segment是ConcurrentHashMap实现的很核心的存在，Segment翻译过来就是一段，一般把它称之为<strong>分段锁</strong>。它继承了ReentrantLock，在ConcurrentHashMap中相当于锁的角色，在多线程下，不同的线程操作不同的segment。只要锁住一个 segment，其他剩余的Segment依然可以操作。这样只要保证每个 Segment 是线程安全的，我们就实现了全局的线程安全。</p><p>构造方法和初始化</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image016.gif" class="" title="* Creates a new, empty map with a default initial capacity (16),  * toad factor (0.75) and concurrencyLevet (16) .  public ConcurrentHashMap() {"><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image018.gif" class="" title="public ConcurrentHashMap(int initiatCapacity,  float toadFactor, int concurrencyLevet) {  if (toadFactor &gt; O) Il initiatCapacity &lt; @ Il concurrencyLevet O)"><p>​    根据其构造函数可知，map的容量默认为16，负载因子为0.75。这两个都与原HashMap相同，但不同的在于，其多个参数**concurrencyLevel(<strong><strong>并发级别</strong></strong>)**，通过该参数可以用来确定Segment数组的长度并且不允许扩容，默认为16。</p><p>​    并发度设置过小会带来严重的锁竞争问题；如果过大，原本位于一个segment内的访问会扩散到不同的segment中，导致查询命中率降低，引起性能下降。</p><p>get()</p><p>1）根据key计算出对应的segment</p><p>2）获取segment下的HashEntry数组</p><p>3）遍历获取每一个HashEntry进行比对。</p><p>注意：整个get过程没有加锁，而是通过volatile保证可以拿到最新值。</p><p>put()</p><p>初始化segment，因为ConcurrentHashMap初始化时只会初始化segment[0]，对于其他的segment，在插入第一个值的时候再进行初始化。经过计算后，将对应的segment完成初始</p><p>化。</p><p>向下调用ensureSegment方法，其内部可以通过cas保证线程安全（初始化的时候保证初始化线程安全），让多线程下只有一个线程可以成功。</p><p>在put方法中当初始化完Segment后，会调用一个put的重载方法进行键值对存放。首先会调用tryLock()尝试获取锁，node为null进入到后续流程进行键值对存放；如果没有获取到锁，则调用scanAndLockForPut()自旋等待获得锁。</p><p>在scanAndLockForPut()方法中首先会根据链表进行遍历，如果遍历完毕仍然找不到与key相同的HashEntry，则提前创建一个HashEntry。当tryLock一定次数后仍然无法获得锁，则主动通过lock申请锁。</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image020.jpg" class="" title="void lock 0  茯 得 锁 。  如 果 锁 不 可 用 ， 则 当 前 线 程 将 辇 拜 以 进 行 线 程 度 ， # 处 于 休 眠 状 态 ， 直 到 获 取 锁 。"><p>在获得锁后，segment对链表进行遍历，如果某个 HashEntry 节点具有相同的 key，则更新该 HashEntry 的 value 值，否则新建一个节点将其插入链表头部。</p><p>如果节点总数超过阈值，则调用rehash()进行扩容。</p><h3 id="JDK8的ConcurrentHashMap"><a href="#JDK8的ConcurrentHashMap" class="headerlink" title="JDK8的ConcurrentHashMap"></a>JDK8的ConcurrentHashMap</h3><p>与JDK7的区别</p><p>​    在JDK1.8中对于ConcurrentHashMap也进行了升级，主要优化点如下：</p><p>1）JDK7中使用CAS+Reentrant（CAS用于初始化segment时，Reentrant用于锁定segment）保证并发更新的安全，而在JDK8是通过CAS+synchronized保证。因为synchronized拥有了优化，在低粒度加锁下，synchronized并不比Reentrant差；在大量数据操作下，对于JVM的内存压力，基于API的ReentrantLock会开销更多的内存。</p><p>2）JDK7的底层使用segment+数组+链表组成。而在JDK8中抛弃了segment，转而使用数组+链表+红黑树的形式实现，从而让锁的粒度能够更细，进一步减少并发冲突的概率；同时也提高的数据查询效率。</p><p>3）在JDK7中的HashEntry在JDK8中变为Node，当转化为红黑树后，变为TreeNode。转换的规则与hashMap相同，当链表长度大于等于8则转换为红黑树，当红黑树的深度小于等于6则转换为链表。</p><p>核心属性</p><p>Node类：用于存储键值对。其与JDK7中的HashEntry属性基本相同。</p><p>TreeNode类：树节点类，当链表长度大于等于8，则转换为TreeNode。与hashMap不同的地方在于，它并不是直接转换为红黑树，而是把这些节点放在TreeBin对象中，由TreeBin完成红黑树的包装。</p><p>TreeBin类：负责TreeNode节点包装，它代替了TreeNode的根节点，也就是说在实际的数组中存放的是TreeBin对象，而不是TreeNode对象。</p><p>sizeCtl属性：用于控制table的初始化和扩容。-1表示正在初始化，-N表示由N-1个线程正在进行扩容，0为默认值表示table还没被初始化，正数表示初始化大小或Map中的元素达到这个数量时，则需要扩容了。</p><p>get()</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image022.gif" class="" title="public V get(Object key) {  Node&lt;K, tab; Node&lt;K,V&gt; e, p; int n, eh; K ek;  &#x3D; spread(key . hashCode()) ; itÄhashfÄ  int h  tab. length) &gt; @ fifihash{ÄfiäküN  if ( (tab  &#x3D; table) (n &#x3D;  (e &#x3D; tabAt(tab,  i" alt="(n - 1) &amp; h)) null) {  if ( (eh  &#x3D; e. hash)  if ( (ek  -z key Il (ek !&#x3D; null &amp;&amp; key . equals(ek)))  return e. vat;  else if (eh &lt; O)  return (p  &#x3D; e. find(h, key)) !&#x3D; null ? p. vat : null;  _ &#x3D; e.next) null) {  while ( (e  if (e. hash h &amp;&amp;  return e. vat;  return null;  -z key Il (ek !&#x3D; null &amp;&amp; key . equals(ek))))"><p>put()</p><p>如果table为空，初始化table</p><p>如果table不为空，但是没有元素，通过CAS向Node数组中存值</p><p>若扩容操作，当前线程协助扩容</p><p>如果table不为空，且有元素，基于synchronized锁住数组中的元素</p><p>与hashTable的区别</p><p>​    Hashtable的任何操作都会把整个表锁住，是阻塞的。好处是总能获取最实时的更新，比如说线程A调用putAll写入大量数据，期间线程B调用get，线程B就会被阻塞，直到线程A完成putAll，因此线程B肯定能获取到线程A写入的完整数据。坏处是所有调用都要排队，竞争越激烈效率越低。 更注重安全。</p><p>​    ConcurrentHashMap 是设计为非阻塞的。在更新时会局部锁住某部分数据，但不会把整个表都锁住。同步读取操作则是完全非阻塞的。好处是在保证合理的同步前提下，效率很高。坏处 是严格来说读取操作不能保证反映最近的更新。例如线程A调用putAll写入大量数据，期间线程B调用get，则只能get到目前为止已经顺利插入的部分数据。更注重性能。</p><h2 id="ArrayList"><a href="#ArrayList" class="headerlink" title="ArrayList"></a>ArrayList</h2><p>ArrayList概述</p><p>1）ArrayList是可以动态增长和缩减的索引序列，它<strong>是基于数组实现</strong>的List类。</p><p>2）该类封装了一个动态再分配的Object[]数组，每一个类对象都有一个capacity属性，表示</p><p>它们所封装的Object[]数组的长度，当向ArrayList中添加元素时，该属性值会自动增加。</p><p>3）ArrayList的用法和Vector向类似，但是Vector是一个较老的集合，具有很多缺点，不建</p><p>议使用。</p><p>另外，ArrayList和Vector的区别是：ArrayList是线程不安全的，当多条线程访问同一个ArrayList集合时，程序需要手动保证该集合的同步性，而Vector则是线程安全的。</p><p>4）ArrayList和Collection的关系：</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image024.gif" class="" title="LteraL0r I  {List Iteratorl  LCoIIectionl  List I  AbstractL ist  ArrayList  AbstraetColleetion"><p>数据结构</p><p>底层的数据结构就是数组，数组元素类型为Object类型，即可以存放所有类型数据。我们对ArrayList类的实例的所有的操作底层都是基于数组的。</p><p>常用方法：</p><p>get方法</p><p>由于底层是数组实现的，先检查下索引是否越界，然后直接返回对应索引位置的元素即可。</p><p>set方法</p><p>校验索引是否越界</p><p>根据index获取指定位置的元素</p><p>用传入的element替换index位置的元素</p><p>返回index位置原来的元素</p><p>add(E e)：</p><p>调用ensureCapacityInternal方法（下文有详解），如果数组还没初始化，则进行初始化；如果已经初始化了，则将modCount+1（统计计算了多少次），并校验添加元素后是否需要扩容。</p><p>在elementData数组尾部添加元素即可（size位置）。</p><p>add(int index, E element)：</p><p>检查索引是否越界，再调用ensureCapacityInternal方法，将modCount+1，并校验添加元素后是否需要扩容。</p><p>将index位置及之后的所有元素向右移动一个位置（为要添加的元素腾出1个位置）。</p><p>将index位置设置为element元素，并将size+1。</p><p>remove(int index)：</p><p>检查索引是否越界，将modCount+1，拿到索引位置index的原元素。</p><p>计算需要移动的元素个数。</p><p>如果需要移动，将index+1位置及之后的所有元素，向左移动一个位置。</p><p>将size-1位置的元素赋值为空（因为上面将元素左移了，所以size-1位置的元素为重复的，将其移除）。</p><p>remove(Object o)：</p><p>如果入参元素为空，则遍历数组查找是否存在元素为空，如果存在则调用fastRemove将该元素移除，并返回true表示移除成功。</p><p>如果入参元素不为空，则遍历数组查找是否存在元素与入参元素使用equals比较返回true，如果存在则调用fastRemove将该元素移除，并返回true表示移除成功。</p><p>否则，不存在目标元素，则返回false。</p><p>fastRemove(int index)：跟remove(int index)类似</p><p>将modCount+1，并计算需要移动的元素个数。</p><p>如果需要移动，将index+1位置及之后的所有元素，向左移动一个位置。</p><p>将size-1位置的元素赋值为空（因为上面将元素左移了，所以size-1位置的元素为重复的，将其移除）</p><p>clear方法</p><p>遍历数组将所有元素清空即可。</p><p>ArrayList动态扩容的全过程。</p><p>如果通过无参构造的话，初始数组容量为0，当真正对数组进行添加时，才真正分配容量。每次按照1.5倍（位运算）的比率通过copeOf的方式扩容。 在JKD1.6中实现是，如果通过无参构造的话，初始数组容量为10，每次通过copeOf的方式扩容后容量为原来的1.5倍</p><p>例如：数组长度为10，有20个数据要添加，在第10个添加完之后，添加第11个数</p><p>时，数组扩容为15（101.5），当添加第16个数时，数组扩容为22（151.5）</p><p>（原数组长度为0，则扩容后为10，minCapacity为10）</p><p>有参构造直接就是容量，传进5，创建容量为5的数组</p><p>（原数组长度为1，则扩容后为2，minCapacity为2）</p><p>（原数组长度为4，则扩容后为6，minCapacity为5）</p><p>补充：</p><p>Arrays.copyOf()方法返回的数组是新的数组对象，原数组对象仍是原数组对象，不变，该拷贝不会影响原来的数组。copyOf()的第二个自变量指定要建立的新数组长度，如果新数组的长度超过原数组的长度，则保留数组默认值.</p><h2 id="LinkedList"><a href="#LinkedList" class="headerlink" title="LinkedList"></a>LinkedList</h2><p>链表和数组对比</p><table><thead><tr><th></th><th><strong>数组</strong></th><th><strong>链表</strong></th></tr></thead><tbody><tr><td>内存地址</td><td>连续的内存空间</td><td>非连续的内存空间</td></tr><tr><td>数据长度</td><td>长度固定，一般不可动态扩容</td><td>长度可动态变化</td></tr><tr><td>增删效率</td><td>低，需要移动被修改元素之后的所有元素</td><td>高，只需要修改指针指向</td></tr><tr><td>查询效率</td><td>高，可用过数组名和下标直接访问</td><td>低，只能通过遍历节点依次查询</td></tr><tr><td>数据访问方式</td><td>随机访问</td><td>顺序访问</td></tr></tbody></table><p>数据结构</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image026.gif" class="" title="first  last"><p>LinkedList底层使用的双向链表结构，有一个头结点和一个尾结点，双向链表意味着我们可以从头开始正向遍历，或者是从尾开始逆向遍历，并且可以针对头部和尾部进行相应的操作。</p><p>特性</p><p>　1）异步，也就是非线程安全</p><p>　2）双向链表。由于实现了list和Deque接口，能够当作队列来使用。</p><p>　　链表：查询效率不高，但是插入和删除这种操作性能好。</p><p>　3）是顺序存取结构</p><p>类的属性</p><p>LinkedList：一个头结点、一个尾结点、一个表示链表中实际元素个数的变量。</p><p>构造方法</p><p>1）空参构造函数</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image028.jpg" class="" title="Constructs an empty list.  public LinkedList() {"><p>2）有参构造函数</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image030.jpg" class="" title="&#x2F; c cp inked Li stij*_ 0  public LinkedList(C011ection&lt;? extends E&gt; c) {  this();  addA11 (c) ;"><p>内部类（Node）</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image032.jpg" class="" title="／ ／ 根 据 前 面 介 绍 双 向 涟 表 就 知 道 这 个 代 表 什 么 了 ， linked List 的 奥 秘 就 在 这 里 c  private static Class Node&lt;E&gt; {  E item; ／ &#x2F; 据 域 （ 当 前 壭 点 的 值 ）  Node&lt;E &gt; next; &#x2F; &#x2F; 后 组 （ 指 向 当 前 一 个 壭 点 的 后 一 个 壭 点 ）  Node&lt;E &gt; prev; &#x2F; &#x2F; 前 （ 指 向 当 前 壭 点 的 前 一 个 壭 点 ）  ／ &#x2F; 构 造 函 i, 赋 值 前 后 组  Node(Node&lt;E&gt; prev, E element,  Node&lt;E&gt; next) {  this  this  this  ． Item  ． next  element;  n ext ．  prev;"><p>说明：内部类Node就是实际的结点，用于存放实际元素的地方。　</p><p> 核心方法</p><p>1 add函数用于向LinkedList中添加一个元素，并且添加到链表尾部。具体添加到尾部的逻辑是由linkLast函数完成的。</p><p>LinkLast()：判断是不是一开始链表中就什么都没有，如果没有，则newNode就成为了第一个节点，first和last都要指向它。正常的在最后一个节点后追加，那么原先的最后一个节点的next就要指向现在真正的最后一个节点，原先的最后一个节点就变成了倒数第二个节点。</p><p>2 remove(Object o)：我们可以知道，如果我们要移除的值在链表中存在多个一样的值，那么我们会移除index最小的那个，也就是最先找到的那个值，如果不存在这个值，那么什么也不做</p><p>3 get(index)：这里查询使用的是先从中间分一半查找：判断index在前半部分还是后半部分，若在前半部分，则遍历前半部分即可</p><p>4 indexOf(Object o)：遍历查找</p><p>总结</p><p>1）linkedList本质上是一个双向链表，通过一个Node内部类实现的这种链表结构。</p><p>2）能存储null值 </p><p>3）跟arrayList相比较，就真正的知道了，LinkedList在删除和增加等操作上性能好，而ArrayList在查询的性能上好</p><p> 4）从源码中看，它不存在容量不足的情况</p><p> 5）linkedList不光能够向前迭代，还能像后迭代，并且在迭代的过程中，可以修改值、添加值、还能移除值。 </p><p>6）linkedList不光能当链表，还能当队列使用，这个就是因为实现了Deque接口。</p><h2 id="Stack"><a href="#Stack" class="headerlink" title="Stack"></a>Stack</h2><p>Stack是栈。它的特性是：先进后出(FILO, First In Last Out)。java工具包中的Stack是继承于Vector(矢量队列)的，由于Vector是通过数组实现的，这就意味着，Stack也是通过数组实现的，而非链表。当然，我们也可以将LinkedList当作栈来使用。</p><p>Push()</p><p>pop()</p><p>peek()</p><p>empty()</p><p>search(Object o)：查找“元素o”在栈中的位置：由栈底向栈顶方向数</p><h2 id="队列-优先队列"><a href="#队列-优先队列" class="headerlink" title="队列_优先队列"></a>队列_优先队列</h2><p>队列是一种先进先出的数据结构。</p><p>优先队列（Priority Queue）</p><p>优先队列与普通队列的区别：普通队列遵循先进先出的原则；优先队列的出队顺序与入队顺序无关，与优先级相关。</p><p>优先队列可以使用队列的接口，只是在实现接口时，与普通队列有两处区别，一处在于优先队列出队的元素应该是优先级最高的元素，另一处在于队首元素也是优先级最高的元素。</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image034.jpg" class="" title="优 先 阝 人 列 也 可 以 使 不 同 的 底 层 实 现 ， 不 同 底 层 实 现 时 间 复 杂 度 如 下 ：  优 先 队 列  普 通 线 性 结 构  顺 序 线 性 结 构  堆  入 队  0 （ 1 ）  O(n)  O(logn)  出 队 （ 拿 出 最 大 元 素 ）  O(n)  0(1)  O(logn)"><h2 id="树"><a href="#树" class="headerlink" title="树"></a>树</h2><p>二叉树、二叉搜索树、平衡二叉树、红黑树、B树、B+树</p><p>平衡二叉树：左右子树的高度相差不超过1的树。</p><p>平衡因子：某节点的左子树与右子树的高度(深度)差即为该节点的平衡因子（BF,Balance Factor），平衡二叉树中不存在平衡因子大于1的节点。在一棵平衡二叉树中，节点的平衡</p><p>因子只能取-1、1或者0。</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image036.jpg" class="" title="强 平 衡 二 叉 树 和 弱 平 衡 二 叉 树 有 什 么 区 别  强 平 衡 二 叉 树 AVL 树 。 弱 平 衡 二 叉 树 就 是 我 们 说 的 红 黑 树 ．  1 攣 VL 树 I 黑 树 对 于 平 衡 的 裎 度 更 加 严 格 。 在 相 同 点 的 肯 兄 下 ， AVL 树 的 高 度 低 于 红 黑 树  艺 红 黑 树 中 增 加 了 一 十 点 颜 色 的 念  工 AVL 树 的 旋 转 悍 作 上 红 甲 树 的 旋 转 悍 作 更 耗 时"><p>红黑树：</p><p>是树的数据结构中最为重要的一种。Java的容器TreeSet、TreeMap均使用红黑树实现。JDK1.8中HashMap中也加入了红黑树。每个节点都带有颜色属性，颜色为<strong>红色</strong>或<strong>黑色</strong>。除了二叉查找树一般要求以外，对于任何有效的红黑树还增加了如下的额外要求:</p><p>1）节点要么是黑色要么是红色。</p><p>2）根结点一定是黑色的。</p><p>3）每个叶子节点都带有两个空(NIL)的黑色节点。</p><p>4）每个红色节点的两个子节点一定是黑色，因此不会存在两个连续的红色节点，红色节</p><p>点的父节点一定是黑色节点。</p><p>5）从任一节点到它所能到达的叶子节点的所有路径都包含相同数目的黑色节点。从而达到黑色平衡。（平衡二叉树是一个完美平衡的树，红黑树是非完美平衡树，但是一个完美</p><p>的黑色平衡二叉查找树）。实现了【树的层数最大也只会有两倍的差距】</p><p>B树：</p><p>意义：数据量是远大于内存大小的，那我们在查找数据时并不能将全部数据同时加载至内存。既然不能全部加载至内存中就只能逐步的去加载磁盘中某个页，简而言之就是逐一的去加载磁盘，加数据分块的加载至内存进行查找与比较。</p><p>通过查找过程可以看出，磁盘IO次数与树的高度相关，在最坏情况下，磁盘IO次数等于树的高度。由于磁盘IO过程是相对耗时效率较低的，因此，在设计数据存储结构时需要降低树的高度，即将一棵“瘦高”的树变得“矮胖”。     当数据数目相同，在保持有序前提下，降低树高度，只需将节点中存储的key值增加，即二叉搜索树中每个节点只有一个数据元素，而在B树中每个节点可以有多个数据元素。</p><p>定义：</p><p>B树也成B-树。它是一颗多路平衡查找树（所有的叶子节点拥有相同的高度）。当描述一颗B树时需要指定它的<strong>阶数</strong>，阶数表示一个节点最多有多少个孩子节点，一般用字母</p><p>m表示。当m取2时，就是一颗二叉查找树。</p><p>要定义一颗m阶的B树，需要遵循以下五条原则：</p><p>1）根节点最少可以只有一个元素，且至少要有两个子节点。</p><p>2）每个节点最多有m-1个元素。</p><p>3）非根节点至少有(m&#x2F;2)-1个元素。m&#x2F;2要进行向上取整，如m&#x2F;2&#x3D;1.5&#x3D;2。</p><p>4）每个结点中的元素都按照从小到大的顺序排列，每个元素的左子树中的所有元素都小</p><p>于它，而右子树中的所有元素都大于它。</p><p>5）所有叶子节点都位于同一层，相当于根节点到每个叶子节点的长度相同。</p><p>查找：B树的查找其实是对二叉搜索树查找的扩展， 与二叉搜索树不同的地方是，B-树中每个节点有不止一棵子树。在B-树中查找某个结点时，需要先判断要查找的结点在哪棵子树上，然后在结点中逐个查找目标结点。B树的查找过程相对简单，与二叉搜索树类似，</p><p>因此不再赘述。</p><p>插入：</p><p>​    B树的插入操作是指在树种插入一条新记录，即（key, value）的键值对。如果B树中已存在需要插入的键值对，则用需要插入的value替换旧的value。若B树不存在这个</p><p>key，则一定是在叶子结点中进行插入操作。</p><p>插入流程如下：</p><p>1）根据要插入的key的值，对B树执行查找操作，查找到待插入数据的当前节点位置。</p><p>2）判断<strong>当前节点key的个数是否小于等于m-1</strong>，若满足，则直接插入数据。</p><p>3）若不满足，以<strong>节点中间的key</strong>为中心分裂成<strong>左右两部分</strong>，然后将这个<strong>中间的key插入到父节点中</strong>，这个key的左子树指向分裂后的左半部分，这个key的右子树指向分</p><p>裂后的右半部分，然后将当前节点指向父节点，继续执行第三步。</p><p>删除</p><p>1）如果当前需要删除的key位于非叶子结点，则用距离最近的后继key覆盖要删除的key。然后在后继key所在的子支中删除该后继key。此时后继key一定位于叶子节点上，这个过程和二叉搜索树删除节点的方式类似。</p><p>2）删除这个记录后，若<strong>该节点key个数大于等于(m&#x2F;2)-1</strong>，结束删除操作。</p><p>3）如果不是，则<strong>如果兄弟节点key个数大于(m&#x2F;2)-1</strong>，则父节点中的key下移到该节</p><p>点，兄弟节点中的一个key上移，删除操作结束。</p><p>4）否则，将父节点中的key下移与当前节点及它的兄弟节点中的key合并，形成一个新的节点。原父节点中的key的两个孩子指针就变成了一个孩子指针，指向这个新节点。然后</p><p>当前节点的指针指向父节点，重复步骤2。</p><p>B+树</p><p>定义</p><p>1）B+树包含2种类型的结点：内部结点（也称索引结点）和叶子结点。</p><p>2）根结点本身即可以是内部结点，也可以是叶子结点。根结点的关键字个数最少可以只</p><p>有1个。</p><p>3）B+树与B树最大的不同是内部结点不保存数据，只用于索引，所有数据（或者说记录</p><p>）都保存在叶子结点中。</p><p>4） m阶B+树表示了<strong>内部结点最多有m-1个关键字</strong>，阶数m同时限制了**叶子结点最多</p><p>存储m-1个数据。</p><p>5）内部结点中的key都按照从小到大的顺序排列，对于内部结点中的一个key，左树中的所有key都小于它，右子树中的key都大于等于它。叶子结点中的数据也按照key的大小排列。</p><p>6）<strong>每个叶子结点都存有相邻叶子结点的指针</strong>，叶子结点本身依关键字的大小自小而</p><p>大顺序链接。</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image038.gif" class="" title="索 引 节 点 ， 只 含 有 key  不 含 数 *Édata  ta data d  叶 子 节 点 ，  含 有 key ， 又  含 有 数 *Édata  根 节 点 ， 可 以 有 一 个 key  叶 子 节 点 采 用  链 表 形 式 链 接  data d"><p>特点</p><p>1）索引节点的key值均会出现在叶子节点中。</p><p>2）索引节点中的key值在叶子节点中或者为最大值或者为最小值。</p><p>3）叶子节点使用单链表的形式链接起来。</p><p>性能分析</p><p><strong>查找性能</strong></p><p> 1）在相同数量的待查数据下，B+树查找过程中需要调用的磁盘IO操作要少于普通B-树。由于B+树所在的磁盘存储背景下，因此B+树的查找性能要好于B-树。 </p><p> 2）B+树的查找效率更加稳定，因为所有叶子结点都处于同一层中，而且查找所有关键字都必须走完从根结点到叶子结点的全部历程。因此同一颗B+树中，任何关键字的查找比较次数都是一样的。而B树的查找是不稳定的。 </p><p><strong>插入性能</strong></p><p>  B+树的插入过程与B树类似，性能也基本一致。</p><p><strong>删除性能</strong></p><p>  删除性能与B树也基本一致。</p><p> 面试题：</p><p>hashmap为什么使用红黑树而不用别的树</p><p>​    红黑树是一个比较特殊的树，跟他能产生对比的是平衡二叉树。但是平衡二叉树的严格平衡牺牲了插入、删除操作的性能，来保证了查询的高效。 而红黑树则采用了折中策略，即不牺牲太大的插入删除性能，同时又保证稳定高效的查找效率。（查找性能都是logn）</p><p>为什么MongoDB索引使用B树，而MySQL使用B+树</p><p>​    MongoDB是一个非关系型数据库，对于遍历数据的需求很低，更多的是在做一些单一记录查询。而对于MySQL这种关系型数据库来说，进行遍历关联查询的需求就会很高。</p><p>​    结合B树与B+树的特点来说，B树的查询效率不固定，最好的情况是O（1），所以在做单一数据查询时，B树的平均性能会更好。但如果要对B树进行遍历的话，由于各个节点间没有指针相连，所以性能会很低。</p><p>​    而B+树最大的特点是数据只会出现在叶子节点，因此对于单条数据查询，其一定会进入到叶子节点上，因此平均性能没有B树好。但B+树的叶子节点有指针相连，在进行遍历时，其效率会明显优于B树。</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image040.jpg" class="" title="B 树 和 B + 树 的 区 别 ， 为 什 么 Mysq 用 B + 树  8 树 的 待 点  节 点 排 序  艺 一 个 节 点 了 可 以 存 多 个 元 累 。 多 个 几 索 也 啡 序 了  B + 树 的 点 ：  1. 拥 有 B 树 的 恃 点  艺 叶 了 节 点 之 间 有 指 针  3 ， 菲 叶 了 节 点 上 的 元 哀 在 叶 了 节 白 上 都 冗 厼 了 ， 也 就 是 叶 了 节 点 中 存 了 所 有 的 元 索 ， 并 排 好 顺 序  Mysq 引 使 的 是 “ 树 ， 因 为 索 引 是 用 来 加 快 虫 的 ， 而 8 + 树 通 过 对 庭 进 行 排 所 以 是 可 以 高 虫 词 速 度 ， 然 尸 通 过 一 个 节 中 可 以 存 储 多 个 元 索 ， 从 而 可 以 使 得 8 + 树  的 高 度 不 会 太 高 ， 在 My 蝈 中 一 nn 。 北 页 就 是 一 个 树 节 点 ， —Olnnodb 页 默 认 16kb, 所 以 一 般 兄 下 一 层 的 “ 树 可 以 存 20 閬 万 行 左 右 的 數 ， 然 后 河 过 利 “ 树 叶  子 点 存 储 了 所 有 庭 并 目 讲 行 了 排 序 ， 并 目 叶 子 点 之 间 有 老 针 ， 可 以 很 好 的 支 持 全 轰 闩 描 ， 范 围 找 SQL 句"><h2 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h2><p>堆通常是一个可以被看做一棵树的数组对象。堆的具体实现一般不通过指针域，而是通过构建一个一维数组与二叉树的父子结点进行对应，因此堆总是一颗完全二叉树。</p><p>对于任意一个父节点的序号n来说（这里n从0算），它的子节点的序号一定是2n+1，2n+2，因此可以直接用数组来表示一个堆。</p><p>不仅如此，堆还有一个性质：堆中某个节点的值总是不大于或不小于其父节点的值。将根节点最大的堆叫做最大堆或<strong>大根堆</strong>，根节点最小的堆叫做最小堆或<strong>小根堆</strong>。</p><p>LinkedHashMap </p><p>众所周知 <a href="https://github.com/crossoverJie/Java-Interview/blob/master/MD/HashMap.md">HashMap</a> 是一个无序的 Map，因为每次根据 key 的 hashcode 映射到 Entry 数组上，所以遍历出来的顺序并不是写入的顺序。</p><p>因此 JDK 推出一个基于 HashMap 但具有顺序的 LinkedHashMap 来解决有排序需求的场景。</p><p>它的底层是继承于 HashMap 实现的，由一个双向链表所构成。</p><p>LinkedHashMap 的排序方式有两种：</p><ul><li>根据写入顺序排序。</li><li>根据访问顺序排序。</li></ul><p>其中根据访问顺序排序时，每次 get 都会将访问的值移动到链表末尾，这样重复操作就能的到一个按照访问顺序排序的链表。</p><p><a href="https://crossoverjie.top/2018/02/06/LinkedHashMap/">https://crossoverjie.top/2018/02/06/LinkedHashMap/</a></p><p><a href="https://www.imooc.com/article/23169">https://www.imooc.com/article/23169</a></p><h2 id="Collection集合和Map集合总结"><a href="#Collection集合和Map集合总结" class="headerlink" title="Collection集合和Map集合总结"></a>Collection集合和Map集合总结</h2><p>主要有两大接口，分别是Collection和Map。其中List、Set、Queue实现了Collection接口。</p><p>List</p><p>ArrayList</p><p>LinkedList</p><p>Set</p><p>HashSet</p><p>TreeSet：保持元素的顺序可以用</p><p>Queue</p><p>先进先出</p><p>Map</p><p><strong>1.HashMap</strong>作为Map的主要实现类，线程不安全的，效率高，可以存储null的key和value。</p><p>HashMap底层：数组和链表（jdk7）数组，链表和红黑树（jdk8）</p><p>2.ConcurrentHashMap</p><p>3.LinkedHashMap:是HashMap的子类，保证在遍历map元素时，可以按照添加的顺序实现遍历，对于频繁的遍历操作，它的执行效率高于HashMap. linkedHashMap最大的特点在于有序，但是它的有序主要体现在先进先出FIFIO上。</p><p>​     原因：在原有的HashMap底层结构的基础上，添加了一对指针，指向前一个和后一个元素（双向链表）。</p><p>4.TreeMap:保证按照添加的key-value对进行排序，实现排序遍历，此时考虑key的自然排序或者定制排序。底层使用红黑树，向TreeMap中添加key-value对，要求key必须是由同一个类创建的对象，因为是按照key进行排序的。</p><p>5.Hashtable作为古老的实现类，线程安全，效率低，不可以存储null的key和value。底层都使用哈希表结构，查询速度快。</p><p>6.Properties:是Hashtable的子类，常用来处理配置文件。key和value都是String类型的。</p><p><a href="https://blog.csdn.net/Colton_Null/article/details/80469277">https://blog.csdn.net/Colton_Null/article/details/80469277</a>  集合</p><p><a href="https://blog.csdn.net/qq_30683329/article/details/80455779">https://blog.csdn.net/qq_30683329/article/details/80455779</a> map</p><h2 id="图"><a href="#图" class="headerlink" title="图"></a>图</h2><p>最小生成树：prim，克鲁斯卡尔</p><p>最短路径：迪杰斯特拉，弗洛伊德</p><p>拓扑排序</p><p>prim：加点：从V1出发，到V3最小，为1，将v3加入集合</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image042.jpg" class="" title="%ü.wmv  最 小 代 价 生 成 树  口 普 里 姆 算 法 求 最 小 生 成 树  的  的  步 骤  U  {VI }  { V2 ， V3 ， V4 ， Vs ， V6 }  （ 0 ）  的  的  亡 05 ： 45 以 ！ ） 洳 分 拿  标 记  〔 ℃ ： 02 ： 51 ／ 01 巧 6 ： 17"><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image044.jpg" class="" title="%ü.wmv  1  5  4  2  6  V2 5  6  6  (0)  (1)  (2)  (3)  (4)  {vvvvv)  {VI,V3) {V2 )  iES-X"><p>克鲁斯卡尔：加边：选一条最小的边加入</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image046.jpg" class="" title="%ü.wmv  最 小 代 价 生 成 树 （ 加 边 ）  口 克 鲁 斯 卡 尔 算 法 求 最 小 生 成 树  。 ： 傩 洞 ： 4 0 退 洳 分 拿  标 记  〔 ℃ :31 ： 49 ／ 01 巧 6 ： 17"><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image048.jpg" class="" title="%ü.wmv  最 小 代 价 生 成 树  」 克 鲁 斯 卡 尔 算 法 求 最 小 生 成 树  快 迸 ： 閬 :32 ： 30  。 ： 傩 為 以 ！ ） 洳 分 拿  标 记  〔 ℃ :32 ： 30 ／ 01 巧 6 ： 17"><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image050.jpg" class="" title="%ü.wmv  V2  5 · 1 （ 续 ） 拓 扑 排 序  7 ·  VO  V3  V6  囗 拓 扑 排 序 方 法 ：  1 ） 在 有 向 图 中 选 一 个 无 前 趋 的 顶 点 v ， 输 出 之 ；  2 ） 从 有 向 图 中 删 除 v 及 以 v 为 尾 的 弧 ；  3 ） 重 复 1) 、 2 ） ， 直 接 全 部 输 出 全 部 顶 点 或 有 向 图 中 不 存 在 无 前 趋 的 结 点  时 为 止 。  。 ： 傩 丷 ： 13 以 ！ ） 洳 分 拿  标 记  〔 ℃ ： 44 ． 18 ／ 01 巧 6 ： 17"><p>迪杰斯特阿拉：从V0出发，到各个点的最短路径</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image052.jpg" class="" title="%ü.wmv  迪 杰 斯 特 拉 算 法 （ Dijkstra ）  最 短 路 径 的 求 解 过 程  100  60  30  10  20  10  0 0 佣  ※ 以 为 源 点  。 ： 仇 ： 1 嗎 以 ！ ） 出 分 拿  01 ： 1 1 ： 53 ／ 01 巧 6 ： 17"><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image054.jpg" class="" title="%ü.wmv  ijkstr )  100  30  10  60  10  10  (vo,V2)  30  (vo,V4)  100  (vo,V5)  60  30  (vo,V4)  100  (vo,vÔ  60  (vo, V4,V5)  ô (Y i2täBä"><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image056.jpg" class="" title="Floyd 算 法 求 最 短 路 径  11  4  1 9  11  2  6  7  路 径 长 度  加 入 点 A  腼 入 陲 点 B  AC  AC  AB ABC  BC  CA CAB  伍 ） 路 径  (b) 路 径  伍 ） 路 径"><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image058.jpg" class="" title="弟 七 节 ． wrn  F 丨 oyd 算 法 求 最 短 路 径  4  4  7 00  7 00  路 径 长 度  (a) 路 径 长 度  加 入 顶 点 C  AB ABC  CA CAB  以 0 ， 8 ℃ 0  5 ： 14 &#x2F; 仞 ： ： 1 不">]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> 集合 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java基础</title>
      <link href="/2024/03/24/java%E5%9F%BA%E7%A1%80/"/>
      <url>/2024/03/24/java%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h2 id="接口和抽象类的区别和相同点？"><a href="#接口和抽象类的区别和相同点？" class="headerlink" title="接口和抽象类的区别和相同点？"></a>接口和抽象类的区别和相同点？</h2><p>不同点：</p><p>1.类可以实现很多个接口，但是只能继承一个抽象类</p><p>2.Java接口中声明的变量默认都是final的。抽象类可以包含非final的变量。</p><p>3.接口中所有的方法隐含的都是抽象的。而抽象类则可以同时包含抽象和非抽象的方法。</p><p>4.Java接口中的成员函数默认是public的。抽象类的成员函数可以是private，protected或者是public。</p><p>相同点: </p><p>1.抽象类和接口都不能直接实例化，如果要实例化，抽象类变量必须指向实现所有抽象方法的子类对象，接口变量必须指向实现所有接口方法的类对象。 </p><p>2.抽象类里的抽象方法必须全部被子类所实现（若不是抽象方法则不用全部实现），如果子类不能全部实现父类抽象方法，那么该子类还只能是抽象类。同样，一个类实现接口的时候，如不能全部实现接口方法，那么该类也只能为抽象类。</p><p>扩展：对于一个final变量，如果是基本数据类型的变量，则其数值一旦在初始化之后便不能更改；如果是引用类型的变量，则在对其初始化之后便不能再让其指向另一个对象。</p><p>两种的使用场景：</p><p>abstract class在Java语言中体现的是一种继承关系，父类和派生类之间必须存在“is a”关系，即父类和派生类在概念本质上应该是相同的。对于interface 来说则不然，并不要求interface的实现者和interface定义在概念本质上是一致的，仅仅是实现了interface定义的契约而已。为了使论述便于理解，下面将通过一个简单的实例进行说明。</p><p>考虑这样一个例子，假设在我们的问题领域中有一个关于Door的抽象概念，该Door具有执行两个动作open和close，此时我们可以通过abstract class或者interface来定义一个表示该抽象概念的类型，其他具体的Door类型可以extends使用abstract class方式定义的Door或者implements使用interface方式定义的Door。看起来好像使用abstract class和interface没有大的区别。</p><p>如果现在要求Door还要具有报警的功能。我们该如何设计针对该例子的类结构呢），下面将罗列出可能的解决方案，并从设计理念层面对这些不同的方案进行分析。</p><p>解决方案一：</p><p>简单的在Door的定义中增加一个alarm方法，这种方法违反了面向对象设计中的一个核心原则ISP（Interface Segregation Priciple），在Door的定义中把Door概念本身固有的行为方法和另外一个概念“报警器“的行为方法混在了一起。这样引起的一个问题是那些仅仅依赖于Door这个概念的模块会因为“报警器“这个概念的改变（比如：修改alarm方法的参数）而改变。</p><p>解决方案二：</p><p>既然open、close和alarm属于两个不同的概念，根据ISP原则应该把它们分别定义在代表这两个概念的抽象类中。定义方式有：这两个概念都使用abstract class方式定义；两个概念都使用interface方式定义；一个概念使用abstract class方式定义，另一个概念使用interface方式定义。</p><p>显然，由于Java语言不支持多重继承，所以两个概念都使用abstract class方式定义是不可行的。后面两种方式都是可行的，但是对于它们的选择却反映出对于问题领域中的概念本质的理解、对于设计意图的反映是否正确、合理。</p><p>如果两个概念都使用interface方式来定义，那么就反映出两个问题：1、我们可能没有理解清楚问题领域，AlarmDoor在概念本质上到底是Door还是报警器？2、如果我们对于问题领域的理解没有问题，比如：我们通过对于问题领域的分析发现AlarmDoor在概念本质上和Door是一致的，那么我们在实现时就没有能够正确的揭示我们的设计意图，因为在这两个概念的定义上（均使用interface方式定义）反映不出上述含义。</p><p>如果我们对于问题领域的理解是：AlarmDoor在概念本质上是Door，同时它有具有报警的功能。我们该如何来设计、实现来明确的反映出我们的意思呢？前面已经说过，abstract class在Java语言中表示一种继承关系，而继承关系在本质上是“is a”关系。所以对于Door这个概念，我们应该使用abstarct class方式来定义。另外，AlarmDoor又具有报警功能，说明它又能够完成报警概念中定义的行为，所以报警概念可以通过interface方式定义。</p><p>这种实现方式基本上能够明确的反映出我们对于问题领域的理解，正确的揭示我们的设计意图。其实abstract class表示的是“is a”关系，interface表示的是“like a”关系，大家在选择时可以作为一个依据，当然这是建立在对问题领域的理解上的，比如：如果我们认为AlarmDoor在概念本质上是报警器，同时又具有Door的功能，那么上述的定义方式就要反过来了。</p><p>具体参考： <a href="https://cloud.tencent.com/developer/article/1434229">https://cloud.tencent.com/developer/article/1434229</a></p><h2 id="经典排序算法"><a href="#经典排序算法" class="headerlink" title="经典排序算法"></a>经典排序算法</h2><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image002.jpg" class="" title="img"><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image004.gif" class="" title="img"><p><a href="https://www.runoob.com/w3cnote/ten-sorting-algorithm.html">https://www.runoob.com/w3cnote/ten-sorting-algorithm.html</a></p><h2 id="HashMap-和-Hashtable-的区别"><a href="#HashMap-和-Hashtable-的区别" class="headerlink" title="HashMap 和 Hashtable 的区别"></a>HashMap 和 Hashtable 的区别</h2><ol><li><p>线程是否安全： HashMap 是⾮线程安全的， HashTable 是线程安全的,因为 HashTable 内部的⽅法基本都经过 synchronized 修饰。（如果你要保证线程安全的话就使⽤ConcurrentHashMap 吧！）； </p></li><li><p>效率： 因为线程安全的问题， HashMap 要⽐ HashTable 效率⾼⼀点。另外， HashTable 基本被淘汰，不要在代码中使⽤它； </p></li><li><p>对 <strong>Null key</strong> 和 <strong>Null value</strong> 的⽀持： HashMap 可以存储 null 的 key 和 value，但 null 作为 键只能有⼀个，null 作为值可以有多个；HashTable 不允许有 null 键和 null 值，否则会抛出 NullPointerException 。 </p></li><li><p>初始容量⼤⼩和每次扩充容量⼤⼩的不同 ： ① 创建时如果不指定容量初始值， Hashtable 默认的初始⼤⼩为 11，之后每次扩充，容量变为原来的 2n+1。 HashMap 默认的初始化⼤ ⼩为 16。之后每次扩充，容量变为原来的 2 倍。② 创建时如果给定了容量初始值，那么 Hashtable 会直接使⽤你给定的⼤⼩，⽽ HashMap 会将其扩充为 2 的幂次⽅⼤⼩ （ HashMap 中的 tableSizeFor() ⽅法保证，下⾯给出了源代码）。也就是说 HashMap 总是使⽤ 2 的幂作为哈希表的⼤⼩,后⾯会介绍到为什么是 2 的幂次⽅。 </p></li><li><p>底层数据结构： JDK1.8 以后的 HashMap 在解决哈希冲突时有了重⼤的变化，当链表⻓度⼤于阈值（默认为 8）（将链表转换成红⿊树前会判断，如果当前数组的⻓度⼩于 64，那么 会选择先进⾏数组扩容，⽽不是转换为红⿊树）时，将链表转化为红⿊树，以减少搜索时 间。Hashtable 没有这样的机制</p></li></ol><h2 id="关于JAVA中接口存在的意义"><a href="#关于JAVA中接口存在的意义" class="headerlink" title="关于JAVA中接口存在的意义"></a>关于JAVA中接口存在的意义</h2><p>1、重要性：在Java语言中， abstract class 和interface 是支持抽象类定义的两种机制。正是由于这两种机制的存在，才赋予了Java强大的 面向对象能力。</p><p>2、简单、规范性：如果一个项目比较庞大，那么就需要一个能理清所有业务的架构师来定义一些主要的接口，这些接口不仅告诉开发人员你需要实现那些业务，而且也将命名规范限制住了（防止一些开发人员随便命名导致别的程序员无法看明白）。</p><p>3、维护、拓展性：比如有一个类，实现了某个功能，突然有一天，发现这个类满足不了需求了，然后又要重新设计这个类，更糟糕是你可能要放弃这个类，那么其他地方可能有引用他，这样修改起来很麻烦。</p><p>   如果一开始定义一个接口，把功能放在接口里，然后定义类时实现这个接口，然后只要用这个接口去引用实现它的类就行了，以后要换的话只不过是引用另一个类而已，这样就达到维护、拓展的方便性。比如有个method1的方法，如果用接口，【接口名】 【对象名】&#x3D;new 【实现接口的类】，这样想用哪个类的对象就可以new哪个对象了，new a（）；就是用a的方法，new b（）就是用b的方法，就和USB接口一样，插什么读什么，就是这个原理。</p><p>你要做一个画板程序，其中里面有一个面板类，主要负责绘画功能，然后你就这样定义了这个类。</p><p>4、安全、严密性：接口是实现软件松耦合的重要手段，它描叙了系统对外的所有服务，而不涉及任何具体的实现细节。这样就比较安全、严密一些（一般软件服务商考虑的比较多，jdk中很多方法就是实现了某个接口）。</p><p> <strong>一. 对接口的三个疑问</strong> </p><p>很多初学者都大概清楚interface是1个什么, 我们可以定义1个接口, 然后在里面定义一两个常量(static final) 或抽象方法.然后以后写的类就可以实现这个接口, 重写里面的抽象方法. 很多人说接口通常跟多态性一起存在.接口的用法跟抽象类有点类似.但是为何要这么做呢.</p><p>1.为什么不直接在类里面写对应的方法, 而要多写1个接口(或抽象类)?</p><p>2.既然接口跟抽象类差不多, 什么情况下要用接口而不是抽象类.</p><p>3.为什么interface叫做接口呢? 跟一般范畴的接口例如usb接口, 显卡接口有什么联系呢?</p><p>答案：</p><p>1 需要实现多态</p><p>很明显, 接口其中一个存在意义就是为了实现多态.：农夫喂不同动物水</p><p>而抽象类(继承) 也可以实现多态</p><p>2.要实现的方法(功能)不是当前类族的必要(属性). 根本原因就是抽象类不能多继承</p><p>上面的例子就表明, 捕猎这个方法不是动物这个类必须的,</p><p>在动物的派生类（老虎需要，山羊不需要）中, 有些类需要, 有些不需要. </p><p>如果把捕猎方法写在动物超类里面是不合理的浪费资源.</p><p>所以把捕猎这个方法封装成1个接口, 让派生类自己去选择实现!</p><p>3.要为不同类族的多个类实现同样的方法(功能).</p><p>上面说过了, 其实不是只有Animal类的派生类才可以实现Huntable接口.</p><p>如果Farmer实现了这个接口, 那么农夫自己就可以去捕猎动物了…</p><h2 id="方法覆盖-Overriding-和方法重载-Overload"><a href="#方法覆盖-Overriding-和方法重载-Overload" class="headerlink" title="方法覆盖(Overriding)和方法重载(Overload)"></a>方法覆盖(Overriding)和方法重载(Overload)</h2><p>方法重写的原则：</p><ul><li><ol><li>重写方法的方法名称、参数列表必须与原方法的相同，返回类型可以相同也可以是原类型的子类型(从Java SE5开始支持)。      </li><li>重写方法不能比原方法访问性差（即访问权限不允许缩小）。      </li><li>重写方法不能比原方法抛出更多的异常。      </li><li>被重写的方法不能是final类型，因为final修饰的方法是无法重写的。 </li><li>被重写的方法不能为private，否则在其子类中只是新定义了一个方法，并没有对其进行重写。 </li><li>被重写的方法不能为static。如果父类中的方法为静态的，而子类中的方法不是静态的，但是两个方法除了这一点外其他都满足重写条件，那么会发生编译错误；反之亦然。即使父类和子类中的方法都是静态的，并且满足重写条件，但是仍然不会发生重写，因为静态方法是在编译的时候把静态方法和类的引用类型进行匹配。      </li><li>重写是发生在运行时的，因为编译期编译器不知道并且没办法确定该去调用哪个方法，JVM会在代码运行的时候作出决定。</li></ol></li></ul><p>方法重载的原则：</p><ul><li><ol><li>方法名称必须相同。 </li><li>参数列表必须不同（个数不同、或类型不同、参数类型排列顺序不同等）。      </li><li>方法的返回类型可以相同也可以不相同。      </li><li>仅仅返回类型不同不足以成为方法的重载。      </li><li>重载是发生在编译时的，因为编译器可以根据参数的类型来选择使用哪个方法。</li></ol></li></ul><p>重写和重载的不同：</p><ul><li><ol><li>方法重写要求参数列表必须一致，而方法重载要求参数列表必须不一致。      </li><li>方法重写要求返回类型必须一致(或为其子类型)，方法重载对此没有要求。 </li><li>方法重写只能用于子类重写父类的方法，方法重载用于同一个类中的所有方法。      </li><li>方法重写对方法的访问权限和抛出的异常有特殊的要求，而方法重载在这方面没有任何限制。      </li><li>父类的一个方法只能被子类重写一次，而一个方法可以在所有的类中可以被重载多次。      </li><li>重载是编译时多态，重写是运行时多态。</li></ol></li></ul><h2 id="Java反射高频面试题"><a href="#Java反射高频面试题" class="headerlink" title="Java反射高频面试题"></a>Java反射高频面试题</h2><p>1、除了使用new创建对象之外，还可以用什么方法创建对象？</p><p>使用Java反射可以创建对象!</p><p>2、Java反射创建对象效率高还是通过new创建对象的效率高？</p><p>通过new创建对象的效率比较高。通过反射时，先找查找类资源，使用类加载器创建，过程比较繁琐，所以效率较低</p><p>3、java反射的作用</p><p>反射机制是在运行时，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意个对象，都能够调用它的任意一个方法。在java中，只要给定类的名字，就可以通过反射机制来获得类的所有信息。 这种动态获取的信息以及动态调用对象的方法的功能称为Java语言的反射机制。</p><p>4、哪里会用到反射机制？</p><p>jdbc就是典型的反射</p><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image006.jpg" class="" title="img"><p>这就是反射。如hibernate，struts等框架使用反射实现的。</p><p>5、反射的实现方式：</p><p>第一步：获取Class对象，有4中方法：</p><p>1）Class.forName(“类的路径”)；</p><p>2）类名.class</p><p>3）对象名.getClass()</p><p>4）基本类型的包装类，可以调用包装类的Type属性来获得该包装类的Class对象</p><p>6、实现Java反射的类：</p><p>1）Class：表示正在运行的Java应用程序中的类和接口</p><p>注意： 所有获取对象的信息都需要Class类来实现。</p><p>2）Field：提供有关类和接口的属性信息，以及对它的动态访问权限。</p><p>3）Constructor：提供关于类的单个构造方法的信息以及它的访问权限</p><p>4）Method：提供类或接口中某个方法的信息</p><p>7、反射机制的优缺点：</p><p>优点：</p><p>1）能够运行时动态获取类的实例，提高灵活性；</p><p>2）与动态编译结合</p><p> 缺点：</p><p>1）使用反射性能较低，需要解析字节码，将内存中的对象进行解析。</p><p>解决方案：</p><p>1.通过setAccessible(true)关闭JDK的安全检查来提升反射速度；</p><p>2.多次创建一个类的实例时，有缓存会快很多</p><p>3.ReflflectASM工具类，通过字节码生成的方式加快反射速度</p><p>4.相对不安全，破坏了封装性（因为通过反射可以获得私有方法和属性）</p><p>8、Java 反射 API</p><p>反射 API 用来生成 JVM 中的类、接口或则对象的信息。</p><ol><li>Class 类：反射的核心类，可以获取类的属性，方法等信息。</li><li>Field 类：Java.lang.reflec包中的类，表示类的成员变量，可以用来获取和设置类之中的属性值。</li><li>Method 类： Java.lang.reflec包中的类，表示类的方法，它可以用来获取类中的方法信息或者执行方法。</li><li>Constructor 类： Java.lang.reflec 包中的类，表示类的构造方法。</li></ol><p>9、反射使用步骤（获取 Class 对象、调用对象方法）</p><ol><li>获取想要操作的类的 Class 对象，他是反射的核心，通过 Class 对象我们可以任意调用类的方法。</li><li>调用 Class 类中的方法，既就是反射的使用阶段。</li><li>使用反射 API 来操作这些信息。</li></ol><p>10、获取 Class 对象有几种方法</p><p>调用某个对象的 getClass()方法</p><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image008.jpg" class="" title="Person p.new person() ;  class clazz.p.getclass();"><p>调用某个类的 class 属性来获取该类对应的 Class 对象 </p><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image010.jpg" class="" title="ssel)"><p>使用 Class 类中的 forName()静态方法(最安全&#x2F;性能最好) 当我们获得了想要操作的类的 Class 对象后，可以通过 Class 类中的方法获取并查看该类中的方法和属性。</p><p>11、利用反射动态创建对象实例</p><p>Class 对象的 newInstance()</p><ol><li>使用 Class 对象的 newInstance()方法来创建该 Class 对象对应类的实例，但是这种方法要求该 Class 对象对应的类有默认的空构造器。 调用 Constructor 对象的 newInstance()</li><li>先使用 Class 对象获取指定的 Constructor 对象，再调用 Constructor 对象的 newInstance()方法来创建 Class 对象对应类的实例,通过这种方法可以选定构造方法创建实例。 </li><li><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image014.jpg" class="" title="Person class  c lazz•class . forNæe( reflection. Person&quot;) ; Class .newlnstane Person clazz. newlnstance(); Constructor Person pl.(persm) c. , .20) %}&lt;&#x2F;li&gt;&lt;&#x2F;ol&gt;&lt;h2 id&#x3D;数据类型&quot;&gt;&lt;a href&#x3D;#数据类型 class&#x3D;headerlink title&#x3D;数据类型&gt;&lt;&#x2F;a&gt;数据类型&lt;&#x2F;h2&gt;{% asset_img clip_image016.jpg boolean  char  short  int  long  float  double  void  16-bit  8 bits  16 bits  32 bits  64 bits  32 bits  64 bits  Unicode o  —128  —215  —263  IEEE754  IEEE754  k-kfl  Unicode 216—1  +215—1  +263-1  IEEE754  IEEE754  Boolean  Character  Byte  Short  Integer  Float  Double  Void"><h2 id="i-由几个指令，如何实现原子性"><a href="#i-由几个指令，如何实现原子性" class="headerlink" title="i++由几个指令，如何实现原子性"></a>i++由几个指令，如何实现原子性</h2><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image017.jpg" class="" width="0"><ul><li><ol><li><strong>使用juc中的lock</strong></li><li><strong>使用java关键字synchronized</strong></li><li><strong>使用juc中的AtomicInteger</strong></li><li><strong>volatile****并不能保证原子性操作</strong></li></ol></li></ul><h2 id="泛型"><a href="#泛型" class="headerlink" title="泛型"></a>泛型</h2><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image018.jpg" class="" width="0"><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image020.jpg" class="" width="0"><h2 id="字节码？采用字节码的好处"><a href="#字节码？采用字节码的好处" class="headerlink" title="字节码？采用字节码的好处"></a>字节码？采用字节码的好处</h2><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image021.jpg" class="" width="0"><h2 id="对于线程安全的理解"><a href="#对于线程安全的理解" class="headerlink" title="对于线程安全的理解"></a>对于线程安全的理解</h2><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image022.jpg" class="" width="0"><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image023.jpg" class="" width="0"><h2 id="守护线程的理解"><a href="#守护线程的理解" class="headerlink" title="守护线程的理解"></a>守护线程的理解</h2><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image024.jpg" class="" width="0"><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image025.jpg" class="" width="0"><h2 id="字符串常量池的设计思想"><a href="#字符串常量池的设计思想" class="headerlink" title="字符串常量池的设计思想"></a>字符串常量池的设计思想</h2><ul><li><ol><li>字符串的分配，和其他的对象分配一样，耗费高昂的时间与空间代价，作为最基础的数据类型，大量频繁的创建字符串，极大程度地影响程序的性能</li><li>JVM为了提高性能和减少内存开销，在实例化字符串常量的时候进行了一些优化</li></ol></li><li><ul><li>为字符串开辟一个字符串常量池，类似于缓存区</li><li>创建字符串常量时，首先检查字符串常量池是否存在该字符串</li><li>存在该字符串，返回引用实例，不存在，实例化该字符串并放入池中</li></ul></li></ul><h2 id="对面向对象的理解"><a href="#对面向对象的理解" class="headerlink" title="对面向对象的理解"></a>对面向对象的理解</h2><p>在我理解,面向对象是向现实世界模型的自然延伸，这是一种“万物皆对象”的编程思想。在现实生活中的任何物体都可以归为一类事物，而每一个个体都是一类事物的实例。面向对象的编程是以对象为中心，以消息为驱动，所以程序&#x3D;对象+消息。</p><p>面向对象有三大特性，封装、继承和多态。</p><p>封装就是将一类事物的属性和行为抽象成一个类，使其属性私有化，行为公开化，提高了数据的隐秘性的同时，使代码模块化。这样做使得代码的复用性更高。</p><p>继承则是进一步将一类事物共有的属性和行为抽象成一个父类，而每一个子类是一个特殊的父类–有父类的行为和属性，也有自己特有的行为和属性。这样做扩展了已存在的代码块，进一步提高了代码的复用性。</p><p>如果说封装和继承是为了使代码重用，那么多态则是为了实现接口重用。多态的一大作用就是为了解耦–为了解除父子类继承的耦合度。如果说继承中父子类的关系式IS-A的关系，那么接口和实现类之之间的关系式HAS-A。简单来说，多态就是允许父类引用(或接口)指向子类(或实现类)对象。很多的设计模式都是基于面向对象的多态性设计的。</p><p>总结一下，如果说封装和继承是面向对象的基础，那么多态则是面向对象最精髓的理论。掌握多态必先了解接口，只有充分理解接口才能更好的应用多态。</p><h2 id="java中list与map区别"><a href="#java中list与map区别" class="headerlink" title="java中list与map区别"></a>java中list与map区别</h2><p>java中list与map区别为：性质不同、顺序不同、重复不同。</p><p>一、性质不同</p><p>1、list：list是存储单列数据的集合。</p><p>2、map：map是存储键和值双列数据的集合。</p><p>二、顺序不同</p><p>1、list：list存储的数据是有顺序的。</p><p>2、map：map存储的数据是没有顺序的。</p><p>三、重复不同</p><p>1、list：list存储的数据允许重复。</p><p>2、map：map存储的数据其键是不能重复的，它的值是可以有重复的。</p><h2 id="cookie和session的区别"><a href="#cookie和session的区别" class="headerlink" title="cookie和session的区别"></a>cookie和session的区别</h2><ol><li>session 在服务器端，cookie 在客户端（浏览器）</li><li>cookie不是很安全</li><li>单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。(Session对象没有对存储的数据量的限制，其中可以保存更为复杂的数据类型)</li><li>session 可以放在 文件、数据库、或内存中都可以。</li><li>session 的运行依赖 session id，而     session id 是存在 cookie 中的，也就是说，如果浏览器禁用了 cookie ，同时 session 也会失效（但是可以通过其它方式实现，比如在 url 中传递 session_id） </li><li>用户验证这种场合一般会用 session</li></ol><h2 id="自然排序与定制排序"><a href="#自然排序与定制排序" class="headerlink" title="自然排序与定制排序"></a>自然排序与定制排序</h2><p>自然排序：java.lang.Comparable</p><ul><li><p>Comparable接口强行对实现它的每个类的对象进行整体排序。这种排序被称 为类的自然排序。 </p></li><li><p>实现 Comparable 的类必须实现 compareTo(Object obj) 方法，两个对象即 通过 compareTo(Object obj) 方法的返回值来比较大小。如果当前对象this大 于形参对象obj，则返回正整数，如果当前对象this小于形参对象obj，则返回 负整数，如果当前对象this等于形参对象obj，则返回零。 </p></li><li><p>·实现Comparable接口的对象列表（和数组）可以通过 Collections.sort 或 Arrays.sort进行自动排序。实现此接口的对象可以用作有序映射中的键或有 序集合中的元素，无需指定比较器。</p></li></ul><p>定制排序：java.util.Comparator</p><ul><li><p>当元素的类型没有实现java.lang.Comparable接口而又不方便修改代码， 或者实现了java.lang.Comparable接口的排序规则不适合当前的操作，那 么可以考虑使用 Comparator 的对象来排序，强行对多个对象进行整体排 序的比较</p></li><li><p>重写compare(Object o1,Object     o2)方法，比较o1和o2的大小：如果方法返 回正整数，则表示o1大于o2；如果返回0，表示相等；返回负整数，表示 o1小于o2</p></li><li><p>可以将 Comparator 传递给 sort 方法（如 Collections.sort 或 Arrays.sort）， 从而允许在排序顺序上实现精确控制。</p></li></ul><p><a href="https://www.cnblogs.com/xiao-ran/p/12492783.html">https://www.cnblogs.com/xiao-ran/p/12492783.html</a></p><h2 id="面试题：Comparable-和Comparator的区别"><a href="#面试题：Comparable-和Comparator的区别" class="headerlink" title="面试题：Comparable 和Comparator的区别:"></a>面试题：Comparable 和Comparator的区别:</h2><p>①　Comparable 自然排序 ，实体类实现Comparable接口，可以去重写compareTo()方法,解决实际排序问题。 把元素放到TreeSet里面去，就会自动的调用CompareTo方法; 但是这个Comparable并不是专为TreeSet设计的;只是说TreeSet顺便利用而已; 就像haashCode和equals 也一样，不是说专门为HashSet设计一样;只是你顺便利用而已;</p><p>②　Compartor第三方的比较器接口，也不是专门为TreeSet设计。 用法：设计一个比较器. 创建一个类，实现这个接口，覆写compare()方法,解决不同问题的需求。</p><p><a href="https://www.cnblogs.com/gshao/p/10129139.html">https://www.cnblogs.com/gshao/p/10129139.html</a></p><h2 id="同步和异步"><a href="#同步和异步" class="headerlink" title="同步和异步"></a>同步和异步</h2><p>1.同步与异步<strong>同步和异步关注的是</strong>消息通信机制**(synchronous communication&#x2F; asynchronous communication)所谓同步，就是在发出一个<em>调用</em>时，在没有得到结果之前，该<em>调用</em>就不返回。但是一旦调用返回，就得到返回值了。换句话说，就是由<em>调用者</em>主动等待这个<em>调用</em>的结果。</p><p>而异步则是相反，<em><strong>调用*在发出之后，这个调用就直接返回了，所以没有返回结果</strong>。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。而是在</em>调用<em>发出后，</em>被调用者*通过状态、通知来通知调用者，或通过回调函数处理这个调用。</p><p>典型的异步编程模型比如Node.js</p><p>举个通俗的例子：你打电话问书店老板有没有《分布式系统》这本书，如果是同步通信机制，书店老板会说，你稍等，”我查一下”，然后开始查啊查，等查好了（可能是5秒，也可能是一天）告诉你结果（返回结果）。而异步通信机制，书店老板直接告诉你我查一下啊，查好了打电话给你，然后直接挂电话了（不返回结果）。然后查好了，他会主动打电话给你。在这里老板通过“回电”这种方式来回调。</p><p>2。阻塞与非阻塞阻塞和非阻塞关注的是<strong>程序在等待调用结果（消息，返回值）时的状态.</strong></p><p>阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。</p><p>还是上面的例子，你打电话问书店老板有没有《分布式系统》这本书，你如果是阻塞式调用，你会一直把自己“挂起”，直到得到这本书有没有的结果，如果是非阻塞式调用，你不管老板有没有告诉你，你自己先一边去玩了， 当然你也要偶尔过几分钟check一下老板有没有返回结果。在这里阻塞与非阻塞与是否同步异步无关。跟老板通过什么方式回答你结果无关。</p><h2 id="Java为什么需要默认的无参构造函数"><a href="#Java为什么需要默认的无参构造函数" class="headerlink" title="Java为什么需要默认的无参构造函数"></a>Java为什么需要默认的无参构造函数</h2><p>类本身默认的实例化、初始化：对象的实例化一般都是通过 new 构造器的方式来进行的，如果自定义的类中没有显式提供构造器，则肯定需要一个默认的无参的空构造器用于 new 实例化、初始化(Java编译器插入的)，不然就无法用正常的方式实例化了，例如私有的构造器。换个角度看，默认的无参空构造器使得类可以直接 new 实例化。</p><p>父类的实例化、初始化：子类的实例化必然是伴随着父类的先一步实例化。子类如果没有通过 super 来显式调用父类的构造器，则都会默认调用父类的无参构造器来进行父类的初始化。如果此时父类没有无参构造器，则会出现编译错误。</p><p><a href="https://blog.csdn.net/weixin_35255032/article/details/114548992?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_baidulandingword-1&spm=1001.2101.3001.4242">https://blog.csdn.net/weixin_35255032/article/details/114548992?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_baidulandingword-1&amp;spm=1001.2101.3001.4242</a></p><h2 id="为什么静态方法不能调用非静态方法和变量？"><a href="#为什么静态方法不能调用非静态方法和变量？" class="headerlink" title="为什么静态方法不能调用非静态方法和变量？"></a>为什么静态方法不能调用非静态方法和变量？</h2><p>静态方法是属于类的，在类加载的时候就会分配内存，可以 通过类名直接去访问，非静态成员（变量和方法）属于类的对象，所以只有在对象初始化之后才存在，然后通过类的对象去访问。</p><p><a href="https://blog.csdn.net/weixin_47067712/article/details/106525107">https://blog.csdn.net/weixin_47067712/article/details/106525107</a></p><h2 id="java中的TLAB"><a href="#java中的TLAB" class="headerlink" title="java中的TLAB"></a>java中的TLAB</h2><p>TLAB的全称是Thread Local Allocation Buffer，即线程本地分配缓存区，这是一个线程专用的内存分配区域。</p><p>那为什么需要TLAB呢？</p><p>在日常的业务过程中，Java对象会不断的被新建和不断的被回收，这就涉及到对象的分配了，而新建的对象一般都是分配在堆上，而堆却是线程共享的。所以如果同一时间，有多个线程要在堆上申请空间，这里可以类比多线程访问共享变量的操作，要保证共享变量的线程安全，就得采取线程安全的手段。所以每一次对象分配都要做同步，而越多的线程要在堆上申请空间，竞争就会越激烈，效率就会降低。因此Java虚拟机采用了TLAB这种线程专属的区域来避免出现多线程冲突，提高对象分配的效率。TLAB是默认启动的，在该情况下，JAVA虚拟机会为每一个线程都分配一个TLAB区域。</p><p>如果设置了虚拟机参数 -XX:UseTLAB，在线程初始化时，同时也会申请一块指定大小的内存，只给当前线程使用，这样每个线程都单独拥有一个空间，如果需要分配内存，就在自己的空间上分配，这样就不存在竞争的情况，可以大大提升分配效率。</p><p>TLAB空间的内存非常小，缺省情况下仅占有整个Eden空间的1%，也可以通过选项-XX:TLABWasteTargetPercent设置TLAB空间所占用Eden空间的百分比大小。 </p><p>TLAB的本质其实是三个指针管理的区域：start，top 和 end，每个线程都会从Eden分配一块空间，例如说100KB，作为自己的TLAB，其中 start 和 end 是占位用的，标识出 eden 里被这个 TLAB 所管理的区域，卡住eden里的一块空间不让其它线程来这里分配。</p><p>TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区 更为合理一点 当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。 </p><p>TLAB的缺点 </p><p>事务总不是完美的，TLAB也又自己的缺点。因为TLAB通常很小，所以放不下大对象。 1，TLAB空间大小是固定的，但是这时候一个大对象，我TLAB剩余的空间已经容不下它了。(比如100kb的TLAB，来了个110KB的对象) 2，TLAB空间还剩一点点没有用到，有点舍不得。(比如100kb的TLAB，装了80KB，又来了个30KB的对象) 所以JVM开发人员做了以下处理，设置了最大浪费空间。 当剩余的空间小于最大浪费空间，那该TLAB属于的线程在重新向Eden区申请一个TLAB空间。进行对象创建，还是空间不够，那你这个对象太大了，去Eden区直接创建吧！ 当剩余的空间大于最大浪费空间，那这个大对象请你直接去Eden区创建，我TLAB放不下没有使用完的空间。 </p><p>当然，又回造成新的病垢。 3，Eden空间够的时候，你再次申请TLAB没问题，我不够了，Heap的Eden区要开始GC， 4，TLAB允许浪费空间，导致Eden区空间不连续，积少成多。以后还要人帮忙打理。</p><h2 id="字面量"><a href="#字面量" class="headerlink" title="字面量"></a>字面量</h2><p>字面量就是指这个量本身，比如字面量3。也就是指3. 再比如 string类型的字面量”<a href="https://www.baidu.com/s?wd=ABC&tn=44039180_cpr&fenlei=mv6quAkxTZn0IZRqIHckPjm4nH00T1d9rjn3PW6suh7BuWcYPjm30ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6KdThsqpZwYTjCEQLGCpyw9Uz4Bmy-bIi4WUvYETgN-TLwGUv3EPHnsPjRvn10k">ABC</a>“, 这个”<a href="https://www.baidu.com/s?wd=ABC&tn=44039180_cpr&fenlei=mv6quAkxTZn0IZRqIHckPjm4nH00T1d9rjn3PW6suh7BuWcYPjm30ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6KdThsqpZwYTjCEQLGCpyw9Uz4Bmy-bIi4WUvYETgN-TLwGUv3EPHnsPjRvn10k">ABC</a>“ 通过字来描述。 所以就是字面量，虽然很难下定义。 你就理解成一眼就能知道的量。 对比下 string x; 那么x 是多少呢？ 它是个变量，你不确定它的值。 但是string x&#x3D;”<a href="https://www.baidu.com/s?wd=ABC&tn=44039180_cpr&fenlei=mv6quAkxTZn0IZRqIHckPjm4nH00T1d9rjn3PW6suh7BuWcYPjm30ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6KdThsqpZwYTjCEQLGCpyw9Uz4Bmy-bIi4WUvYETgN-TLwGUv3EPHnsPjRvn10k">ABC</a>“， 你当然知道”ABC” 就是”ABC”了，一眼就能看到值的量（有点像常量）。 string x&#x3D;”ABC” 意思是把字面量”ABC” 赋值给变量X. 再举例 const string y&#x3D;”<a href="https://www.baidu.com/s?wd=cbd&tn=44039180_cpr&fenlei=mv6quAkxTZn0IZRqIHckPjm4nH00T1d9rjn3PW6suh7BuWcYPjm30ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6KdThsqpZwYTjCEQLGCpyw9Uz4Bmy-bIi4WUvYETgN-TLwGUv3EPHnsPjRvn10k">cbd</a>“. 意思是把字面量”<a href="https://www.baidu.com/s?wd=cbd&tn=44039180_cpr&fenlei=mv6quAkxTZn0IZRqIHckPjm4nH00T1d9rjn3PW6suh7BuWcYPjm30ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6KdThsqpZwYTjCEQLGCpyw9Uz4Bmy-bIi4WUvYETgN-TLwGUv3EPHnsPjRvn10k">cbd</a>“ 赋值给了常量y. 明白了吧？ 总之就是描述自己的量。 “ABC” 它描述了自己，你看到了就知道它是”ABC”了。</p><h2 id="句柄"><a href="#句柄" class="headerlink" title="句柄"></a>句柄</h2><p>使用句柄访问对象，会在堆中开辟一块内存作为句柄池，句柄中储存了对象实例数据（属性值结构体）的内存地址，访问对象类型数据的内存地址（类信息，方法类型信息），</p><p>对象实例数据一般也在heap中开辟，类型数据一般储存在方法区中。使用句柄访问的好处是句柄中储存的是稳定的对象地址，当对象被移动时候，只需要更新句柄中的对象实例部分的值即可，句柄本身不用被移动修改。</p><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image026.jpg" class="" width="0"><p> 句柄（Handle）来标示应用程序中不同的对象和同类中不同的实例 注意：句柄有人认为是指针、或者引用</p><p>对象实例数据（堆）:对象中各个实例字段的数据</p><p>对象类型数据（方法区）：对象的类型、父类、实现的接口、方法等</p><p>静态区（也在方法区中）用来存放静态变量，静态块</p><p>详细： <a href="https://blog.csdn.net/lly983909814/article/details/72529773">https://blog.csdn.net/lly983909814/article/details/72529773</a></p><h2 id="节点流与处理流"><a href="#节点流与处理流" class="headerlink" title="节点流与处理流"></a>节点流与处理流</h2><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image028.jpg" class="" width="0"><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image030.jpg" class="" width="0"><p>提供缓冲区的流BufferedWriter，字符编码转换的流InputStreamReader</p><p><a href="https://blog.csdn.net/jingzi123456789/article/details/72123937">https://blog.csdn.net/jingzi123456789/article/details/72123937</a></p><h2 id="java序列化"><a href="#java序列化" class="headerlink" title="java序列化"></a>java序列化</h2><ul><li><ul><li><strong>序列化：将对象写入到<strong><strong>IO</strong></strong>流中</strong></li><li><strong>反序列化：从<strong><strong>IO</strong></strong>流中恢复对象</strong></li><li><strong>意义：序列化机制允许将实现序列化的<strong><strong>Java</strong></strong>对象转换位字节序列，这些字节序列可以保存在磁盘上，或通过网络传输，以达到以后恢复成原来的对象。序列化机制使得对象可以脱离程序的运行而独立存在。</strong></li><li><strong>使用场景：所有可在网络上传输的对象都必须是可序列化的，</strong>比如RMI（remote method invoke,即远程方法调用），传入的参数或返回的对象都是可序列化的，否则会出错；<strong>所有需要保存到磁盘的<strong><strong>java</strong></strong>对象都必须是可序列化的。通常建议：程序创建的每个<strong><strong>JavaBean</strong></strong>类都实现<strong><strong>Serializeable</strong></strong>接口。</strong></li></ul></li></ul><h2 id="引用变量所指向的具体实例对象在运行期才确定"><a href="#引用变量所指向的具体实例对象在运行期才确定" class="headerlink" title="引用变量所指向的具体实例对象在运行期才确定"></a>引用变量所指向的具体实例对象在运行期才确定</h2><p>父类或者接口定义的引用变量可以指向子类或者具体实现类的实例对象，由于程序调用方法是在运行期才动态绑定的，那么引用变量所指向的具体实例对象在运行期才确定。</p><h2 id="值传递和引用传递"><a href="#值传递和引用传递" class="headerlink" title="值传递和引用传递"></a>值传递和引用传递</h2><p>JAVA中只有值传递，没有引用传递 </p><p>值传递（pass by value）是指在调用函数时将实际参数复制一份传递到函数中，这样在函数中如果对参数进行修改，将不会影响到实际参数。</p><p>引用传递（pass by reference）是指在调用函数时将实际参数的地址 直接 传递到函数中，那么在函数中对参数所进行的修改，将影响到实际参数。 </p><p>注意： </p><p>  地址值也是值，传递地址值不一定就是引用传递。 </p><p>  <strong>值传递和引用传递的区别并不是传递的内容。而是实参到底有没有被复制一份给形参。</strong></p><p><strong>详细参考：</strong> <a href="https://www.iteye.com/blog/guhanjie-1683637">https://www.iteye.com/blog/guhanjie-1683637</a></p><p><a href="https://www.jianshu.com/p/2fe41262e498">https://www.jianshu.com/p/2fe41262e498</a></p><h2 id="自动拆装箱"><a href="#自动拆装箱" class="headerlink" title="自动拆装箱"></a>自动拆装箱</h2><p>首先知道String是引用类型不是基本类型，引用类型声明的变量是指该变量在内存中实际存储的是一个引用地址，实体在堆中。引用类型包括类、接口、数组等。String类还是final修饰的。 </p><p><strong>基本数据类型有什么好处</strong></p><p>我们都知道在Java语言中，new一个对象是存储在堆里的，我们通过栈中的引用来使用这些对象；所以，对象本身来说是比较消耗资源的。</p><p>对于经常用到的类型，如int等，如果我们每次使用这种变量的时候都需要new一个Java对象的话，就会比较笨重。</p><p>而包装类就属于引用类型，自动装箱和拆箱就是基本类型和引用类型之间的转换。</p><p><strong>为什么需要包装类</strong></p><p>因为基本类型转换为引用类型后，就可以new对象，从而调用包装类中封装好的方法进行基本类型之间的转换或者toString（当然用类名直接调用也可以，便于一眼看出该方法是静态的），还有就是如果集合中想存放基本类型，泛型的限定类型只能是对应的包装类型。</p><p>详细： <a href="https://www.hollischuang.com/archives/2700">https://www.hollischuang.com/archives/2700</a></p><h2 id="类什么时候被Java虚拟机载入"><a href="#类什么时候被Java虚拟机载入" class="headerlink" title="类什么时候被Java虚拟机载入"></a>类什么时候被Java虚拟机载入</h2><p>1、编译和运行概念要搞清:编译即javac的过程，负责将zhi.java文件compile成.class文件，主要是类型、格式检查与编译成字节码文件，而加载是指java *的过程，将.class文件加载到内存中去解释执行，即运行的时候才会有加载一说。</p><p>2、类的加载时机，肯定是在运行时，但并不是一次性全部加载，而是按需动态，依靠反射来实现动态加载，一般来说一个class只会被加载一次，之后就会从jvm的class实例的缓存中获取，谁用谁取就可以了，不会再去文件系统中加载.class文件了。</p><p>具体细节参考： <a href="https://blog.csdn.net/first_m/article/details/107286563">https://blog.csdn.net/first_m/article/details/107286563</a></p><p><a href="https://www.cnblogs.com/Auge/p/11550213.html">https://www.cnblogs.com/Auge/p/11550213.html</a></p><h2 id="静态绑定和动态绑定"><a href="#静态绑定和动态绑定" class="headerlink" title="静态绑定和动态绑定"></a>静态绑定和动态绑定</h2><p>一：绑定</p><p>​    把一个方法与其所在的类&#x2F;对象 关联起来叫做方法的绑定。绑定分为静态绑定（前期绑定）和动态绑定（后期绑定）。</p><p>  二：静态绑定</p><p>​    静态绑定（前期绑定）是指：在程序运行前就已经知道方法是属于那个类的，在编译的时候就可以连接到类的中，定位到这个方法。</p><p>​    在Java中，final、private、static修饰的方法以及构造函数都是静态绑定的，不需程序运行，不需具体的实例对象就可以知道这个方法的具体内容。</p><p>  三：动态绑定</p><p>​    动态绑定（后期绑定）是指：在程序运行过程中，根据具体的实例对象才能具体确定是哪个方法。</p><p>​    动态绑定是多态性得以实现的重要因素，它通过方法表来实现：每个类被加载到虚拟机时，在方法区保存元数据，其中，包括一个叫做 方法表（method table）的东西，表中记录了这个类定义的方法的指针，每个表项指向一个具体的方法代码。如果这个类重写了父类中的某个方法，则对应表项指向新的代码实现处。从父类继承来的方法位于子类定义的方法的前面。</p><p>​    <strong>动态绑定语句的编译、运行原理</strong>：我们假设 Father ft&#x3D;new Son(); ft.say(); Son继承自Father，重写了say()。</p><p>​    1：编译：我们知道，向上转型时，用父类引用执行子类对象，并可以用父类引用调用子类中重写了的同名方法。但是不能调用子类中新增的方法，为什么呢？</p><p>​           因为<strong>在代码的编译阶段</strong>，编译器通过 <strong>声明对象的类型（即引用本身的类型）</strong> 在方法区中该类型的方法表中查找匹配的方法（最佳匹配法：参数类型最接近的被调用），如果有则编译通过。（这里是根据声明的对象类型来查找的，所以此处是查找 Father类的方法表，而Father类方法表中是没有子类新增的方法的，所以不能调用。）</p><p>​           编译阶段是确保方法的存在性，保证程序能顺利、安全运行。</p><p>​    2：运行：我们又知道，ft.say()调用的是Son中的say()，这不就与上面说的，查找Father类的方法表的匹配方法矛盾了吗？不，这里就是动态绑定机制的真正体现。</p><p>​           上面编译阶段在 声明对象类型 的方法表中查找方法，<strong>只是为了安全地通过编译（也为了检验方法是否是存在的）</strong>。而在实际<strong>运行这条语句</strong>时，在执行 Father ft&#x3D;new Son(); 这一句时创建了一个Son实例对象，然后在 ft.say() 调用方法时，JVM会把刚才的son对象压入操作数栈，用它来进行调用。而用实例对象进行方法调用的过程就是动态绑定：<strong>根据实例对象所属的类型去查找它的方法表，找到匹配的方法进行调用。</strong>我们知道，子类中如果重写了父类的方法，则方法表中同名表项会指向子类的方法代码；若无重写，则按照父类中的方法表顺序保存在子类方法表中。故此：动态绑定根据对象的类型的方法表查找方法是一定会匹配（因为编译时在父类方法表中以及查找并匹配成功了，说明方法是存在的。这也解释了为何向上转型时父类引用不能调用子类新增的方法：<strong>在父类方法表中必须先对这个方法的存在性进行检验，如果在运行时才检验就容易出危险<strong><strong>——</strong></strong>可能子类中也没有这个方法</strong>）。</p><p>  四：区分</p><p>​    程序在JVM运行过程中，会把类的类型信息、static属性和方法、final常量等元数据加载到方法区，<strong>这些在类被加载时就已经知道，不需对象的创建就能访问的，就是静态绑定的内容；需要等对象创建出来，使用时根据堆中的实例对象的类型才进行取用的就是动态绑定的内容。</strong></p><h2 id="Jdk8-9新特性"><a href="#Jdk8-9新特性" class="headerlink" title="Jdk8,9新特性"></a>Jdk8,9新特性</h2><h3 id="Jdk1-8"><a href="#Jdk1-8" class="headerlink" title="Jdk1.8"></a>Jdk1.8</h3><p>1、HashMap</p><p>有人会在问你HashMap的时候会问你JDK1.7和1.8有什么变化;</p><p>主要还是HashMap中链长度大于8时采取红黑树的结构存储。(1.7的时候是链表结构)红黑树，除了添加，效率高于链表结构。</p><p>2、ConcurrentHashMap</p><p>Jdk1.7时隔壁级别CocnurrentLevel（锁分段机制）默认为16。</p><p>JDK1.8采取了CAS算法</p><p>CAS原理主要涉及的有:锁机制、CAS 操作;具体可以参考CAS原理分析</p><p>Jdk1.8没有永久区，取而代之的是MetaSpace元空间，用的是物理内存。</p><p>3、Lambda表达式</p><p>1、Lambda表达式的基础语法：Java8引入了一个新的操作符“-&gt;”，该操作符成为箭头操作符或者Lambda操作符，箭头操作符将Lambda表达式拆分成两部分</p><p>左侧：Lambda表达式的参数列表</p><p>右侧：Lambda表达式中所需执行的功能，即Lambda体。</p><p>4、并行流</p><p>Fork&#x2F;Join框架：</p><p>在必要的情况下，将一个大任务进行必要的拆分Fork成若干个小任务，再将小任务的运算结果进行Join汇总。</p><p>5、Optional类</p><p>Optional 类(java.util.Optional) 是一个容器类，代表一个值存在或不存在，原来用null 表示一个值不存在，现在Optional 可以更好的表达这个概念。并且可以避免空指针异常。</p><h3 id="Jdk9"><a href="#Jdk9" class="headerlink" title="Jdk9"></a>Jdk9</h3><p>1、 Java平台模块化系统</p><p>整个jar都会被JVM加载到内存当中去，模块化可以根据模块的需要加载程序运行需要的class</p><p>2 、新工具JShell</p><p>Java 9首次为Java语言提供了REPL工具，名为JShell。我们可以在命令行或者在IntelliJ IDEA的终端中运行该REPL。java可作为脚本语言。</p><p>3、 多版本兼容Jar</p><p>多版本兼容 JAR 功能能让你创建仅在特定版本的 Java 环境中运行库程序时选择使用的 class 版本</p><p>4、 java.net新内容</p><p>引入了一个新的package:java.net.http，里面提供了对Http访问很好的支持，不仅支持Http1.1而且还支持HTTP2，以及WebSocket</p><p>5、JVM优化</p><p>使用G1垃圾回收器作为默认的垃圾回收器</p><h3 id="Jdk14"><a href="#Jdk14" class="headerlink" title="Jdk14"></a>Jdk14</h3><p>305: instanceof的模式匹配 (预览)</p><p>343: 打包工具 (Incubator)</p><p>345: G1的NUMA内存分配优化</p><p>349: JFR事件流</p><p>352: 非原子性的字节缓冲区映射</p><p>358: 友好的空指针异常</p><p>359: Records (预览)</p><p>361: Switch表达式 (标准)</p><p>362: 弃用Solaris和SPARC端口</p><p>363: 移除CMS（Concurrent Mark Sweep）垃圾收集器</p><p>364: macOS系统上的ZGC</p><p>365: Windows系统上的ZGC</p><p>366: 弃用ParallelScavenge + SerialOld GC组合</p><p>367: 移除Pack200 Tools和API</p><p>368: 文本块 (第二个预览版)</p><p>370: 外部存储器API (Incubator)</p><h2 id="为什么-String-是不可变的？"><a href="#为什么-String-是不可变的？" class="headerlink" title="为什么 String 是不可变的？"></a>为什么 String 是不可变的？</h2><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image032.jpg" class="" title="img"><p>并且是私有的。</p><h2 id="为什么-String-要设计为不可变的？"><a href="#为什么-String-要设计为不可变的？" class="headerlink" title="为什么 String 要设计为不可变的？"></a>为什么 String 要设计为不可变的？</h2><p>原因可以从四个方面说起，缓存、安全性、同步和高性能。</p><p>1）字符串常量池</p><p>字符串恐怕是 Java 中最常用的数据形式了，如果字符串非要谦虚地说自己是老二，就没有人敢说自己是老大。</p><p>因此，把字符串缓存起来，并且重复使用它们会节省大量堆空间（堆内存用来存储 Java 中的对象，无论是成员变量、局部变量，还是类变量，它们指向的对象都存储在堆内存中），因为不同的字符串变量引用的是字符串常量池中的同一个对象。这也正是字符串常量池存在的目的。</p><p>字符串常量池是 Java 虚拟机用来存储字符串的一个特殊的区域，由于字符串是不可变的，因此 Java 虚拟机可以在字符串常量池中只为同一个字符串存储一个字符串副本来节省空间。</p><p>2）安全性</p><p>字符串在 Java 应用程序中的使用范围非常广，几乎无处不在，比如说存储用户名、密码、数据库连接地址等等这些非常敏感的信息，因此，必须要保证 String 类的绝对安全性。</p><p>通常情况下，用户名由客户端传递到服务器端，服务器端接收后要先对用户名进行检查，再进行其他操作，因为客户端传递过来的信息不一定值得信任。</p><p>如果字符串是可变的，那么我们在执行 executeUpdate 更新数据库的时候，就有点不放心，因为即便是安全性检查通过了，字符串仍然有可能被修改。</p><p>3）线程安全</p><p>由于字符串是不可变的，因此可以在多线程之间共享，如果一个线程把字符串的值修改为另外一个，那么就会在字符串常量池中创建另外一个字符串，原有的字符串仍然会保持不变。</p><p>4）哈希码</p><p>字符串广泛应用于 HashMap、HashTable、HashSet 等需要哈希码作为键的数据结构中，在对这些哈希表进行操作的时候，需要频繁调用 hashCode() 方法来获取键的哈希码。</p><p>由于字符串是不可变性，这就保证了键值的哈希值不会发生改变，因此在第一次调用 String 类的 hashCode() 方法时，就对哈希值进行了缓存，此后，就一直返回相同的值。</p><p><a href="https://www.zhihu.com/question/20618891">https://www.zhihu.com/question/20618891</a></p><h2 id="String类型的对象，是保存在堆里还是在栈里呢？"><a href="#String类型的对象，是保存在堆里还是在栈里呢？" class="headerlink" title="String类型的对象，是保存在堆里还是在栈里呢？"></a><a href="https://so.csdn.net/so/search?q=String%E7%B1%BB&spm=1001.2101.3001.7020">String类</a>型的对象，是保存在堆里还是在栈里呢？</h2><p>在Java的实现中，new出来的String对象一般是放在堆中的。</p><p>如果是 String s &#x3D;“xxx”; 这种,那就是放在<a href="https://so.csdn.net/so/search?q=%E5%B8%B8%E9%87%8F%E6%B1%A0&spm=1001.2101.3001.7020">常量池</a>中.</p><h2 id="new创建对象和用字符串常量创建对象的区别"><a href="#new创建对象和用字符串常量创建对象的区别" class="headerlink" title="new创建对象和用字符串常量创建对象的区别"></a>new创建对象和用字符串常量创建对象的区别</h2><p>public class StringDemo2 {</p><p>  public static void main(String[] args) {</p><p>​    String s1 &#x3D; new String(“hello”);</p><p>​    String s2 &#x3D; “hello”;</p><p>​     System.out.println(s1 &#x3D;&#x3D; s2);&#x2F;&#x2F; false</p><p>​    System.out.println(s1.equals(s2));&#x2F;&#x2F; true</p><p>  }</p><p>}</p><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image034.gif" class="" title="在这里插入图片描述"><p>(1)、首先，通过main（）方法进栈。</p><p>(2)、然后再栈中定义一个对象s1,s1由new创建，因此去堆中开辟一个内存空间，将内存空间的引用赋值给s1，“hello”是常量，然后去<a href="https://so.csdn.net/so/search?q=%E5%AD%97%E7%AC%A6%E4%B8%B2&spm=1001.2101.3001.7020">字符串</a>常量池查看是否有hello字符串对象，没有的话分配一个空间存放hello，并且将其空间地址存入堆中new出来的空间中。</p><p>(3)、在栈中定义一个对象s2，s2不是由new创建，因此去字符串常量池中查看是否有”hello”字符串对象，有则直接把“hello”的地址赋值给s2。</p><p>(4)、即s1中存的是堆中分配的空间，堆中分配的空间中存的是字符串常量池中分配空间存放”hello”的空间的地址值。而s2中之中存的是字符串常量池中分配空间存放”hello”的空间的地址值。</p><p>(5)、由于s1与s2中存放的地址不同，所以输出false。因为，类String重写了equals()方法，它比较的是引用类型的 的值是否相等，所以输出true。即结果为false、true。</p><h2 id="final、finally、finalize"><a href="#final、finally、finalize" class="headerlink" title="final、finally、finalize"></a>final、finally、finalize</h2><ul><li><ul><li>final 用于声明属性,方法和类, 分别表示属性不可变, 方法不可覆盖, 类不可继承.</li><li>finally 是异常处理语句结构的一部分，表示总是执行.</li><li>finalize 是Object类的一个方法，在垃圾收集器执行的时候会调用被回收对象的此方法，可以覆盖此方法提供垃圾收集时的其他资源回收，例如关闭文件等. JVM不保证此方法总被调用.</li></ul></li></ul><h2 id="深拷贝和浅拷贝"><a href="#深拷贝和浅拷贝" class="headerlink" title="深拷贝和浅拷贝"></a>深拷贝和浅拷贝</h2><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image036.jpg" class="" title="深 拷 贝 和 浅 拷 贝  深 栳 贝 和 浅 拷 贝 孰 是 指 对 盅 的 拷 贝 ， 一个对象中存在蕊种类型的@性 ， 一 种 是 基 事 数 庭 类 型 ， 一 种 是 实 例 对 象 的 引 庠 ．  1 、 浅 拷 贝 是 挹 ， 只 会 拷 贝 基 本 數 类 型 匾 ， 以 及 实 树 象 引 的 地 址 。 荇 不 会 0 制 一 份 引 0 地 址 所 指 对 象 。 也 就 是 浅 拷 贝 出 来 对 象 。 丙 刁 类 性 尷 向 的 是 同 一 ^  对 象  2 ． 深 店 贝 是 ， 既 会 贝 基 本 数 廡 类 型 的 们 ， 也 会 针 对 买 例 对 的 引 厍 地 址 所 向 的 对 象 行 过 制 ， 深 满 贝 湖 来 的 对 象 ， 内 0 《 性 指 向 的 不 是 同 一 个 对 象"><h2 id="泛型中extends和super的区别"><a href="#泛型中extends和super的区别" class="headerlink" title="泛型中extends和super的区别"></a>泛型中extends和super的区别</h2><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image038.jpg" class="" title="I. ? extends T  2. super">]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> java基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo搭建个人博客</title>
      <link href="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"/>
      <url>/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</url>
      
        <content type="html"><![CDATA[<h1 id="博客搭建过程（采用hexo框架-部署到github）"><a href="#博客搭建过程（采用hexo框架-部署到github）" class="headerlink" title="博客搭建过程（采用hexo框架+部署到github）"></a><strong>博客搭建过程（采用hexo框架+部署到github）</strong></h1><h2 id="1-前期准备"><a href="#1-前期准备" class="headerlink" title="1.前期准备"></a><strong>1.前期准备</strong></h2><h3 id="1-1-注意事项"><a href="#1-1-注意事项" class="headerlink" title="1.1 注意事项"></a><strong>1.1 注意事项</strong></h3><ul><li>很多命令既可以用Windows的cmd来完成，也可以使用git bash来完成，但是部分命令会有一些问题，为避免不必要的问题，建议全部使用git bash来执行</li><li>hexo不同版本差别比较大，网上很多文章的配置信息都是基于2.x的，所以注意不要被误导</li><li>hexo有2种_config.yml文件，一个是根目录下的全局的_config.yml，一个是各个theme下的</li></ul><h3 id="1-2-下载并安装node-js"><a href="#1-2-下载并安装node-js" class="headerlink" title="1.2 下载并安装node.js"></a><strong>1.2 下载并安装node.js</strong></h3><ul><li>官网下载：<a href="https://nodejs.org/en/">https://nodejs.org/en/</a></li><li>安装与使用：见node笔记</li><li>安装后验证：<strong>node -v</strong></li></ul><h3 id="1-3-下载并安装git"><a href="#1-3-下载并安装git" class="headerlink" title="1.3 下载并安装git"></a><strong>1.3 下载并安装git</strong></h3><ul><li>官网下载:  <a href="https://git-scm.com/download/win">https://git-scm.com/download/win</a></li><li>安装与使用：见git笔记</li><li>安装后验证：<strong>git -v</strong></li></ul><h3 id="1-4-命令行安装cnpm"><a href="#1-4-命令行安装cnpm" class="headerlink" title="1.4 命令行安装cnpm"></a><strong>1.4 命令行安装cnpm</strong></h3><ul><li>命令：<strong>npm install -g cnpm –registry&#x3D;&#x3D;<a href="https://registry.npm.taobao.org/">https://registry.npm.taobao.org</a></strong></li><li>安装后验证：<strong>cnpm -v</strong></li></ul><h3 id="1-5-命令行安装hexo"><a href="#1-5-命令行安装hexo" class="headerlink" title="1.5 命令行安装hexo"></a><strong>1.5 命令行安装hexo</strong></h3><ul><li>命令：<strong>cnpm install -g hexo-cli</strong></li><li>安装后验证：<strong>hexo  -v</strong></li></ul><hr><h2 id="2-配置github"><a href="#2-配置github" class="headerlink" title="2.配置github"></a><strong>2.配置github</strong></h2><h3 id="2-1-在github上创建仓库"><a href="#2-1-在github上创建仓库" class="headerlink" title="2.1 在github上创建仓库"></a><strong>2.1 在github上创建仓库</strong></h3><p><strong>创建：</strong></p><ul><li>新建一个名为你的用户名.github.io的仓库</li><li>比如说，如果你的github用户名是test，那么你就新建test.github.io的仓库（必须是你的用户名，其它名称无效），将来你的网站访问地址就是 <a href="http://test.github.io/">http://test.github.io</a> 了，是不是很方便？由此可见，每一个github账户最多只能创建一个这样可以直接使用域名访问的仓库。</li></ul><p><strong>注意：</strong></p><ol><li>注册的邮箱一定要验证，否则不会成功；</li><li>仓库名字必须是：username.github.io，其中username是你的用户名；</li><li>仓库创建成功不会立即生效，需要过一段时间，大概10-30分钟，或者更久；</li><li>创建页面如下：</li></ol><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/1.png" class="" title="img"><p>创建成功后，默认会在你这个仓库里生成一些示例页面，以后你的网站所有代码都是放在这个仓库里啦。</p><h3 id="2-2-绑定域名（这步可省略）"><a href="#2-2-绑定域名（这步可省略）" class="headerlink" title="2.2 绑定域名（这步可省略）"></a><strong>2.2 绑定域名（这步可省略）</strong></h3><p>当然，你不绑定域名肯定也是可以的，就用默认的 xxx.github.io 来访问，如果你想更个性一点，想拥有一个属于自己的域名，那也是OK的。</p><p>首先你要注册一个域名，域名注册以前总是推荐去godaddy，现在觉得其实国内的阿里云也挺不错的，价格也不贵，毕竟是大公司，放心！</p><p>绑定域名分2种情况：带www和不带www的。</p><p>域名配置最常见有2种方式，CNAME和A记录，CNAME填写域名，A记录填写IP，由于不带www方式只能采用A记录，所以必须先ping一下你的用户名.github.io的IP，然后到你的域名DNS设置页，将A记录指向你ping出来的IP，将CNAME指向你的用户名.github.io，这样可以保证无论是否添加www都可以访问，如下：</p><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/2.png" class="" title="img"><p>然后到你的github项目根目录新建一个名为CNAME的文件（无后缀），里面填写你的域名，加不加www看你自己喜好，因为经测试：</p><ul><li>如果你填写的是没有www的，比如 mygit.me，那么无论是访问 <a href="http://www.mygit.me/">http://www.mygit.me</a> 还是 <a href="http://mygit.me/">http://mygit.me</a> ，都会自动跳转到 <a href="http://mygit.me/">http://mygit.me</a></li><li>如果你填写的是带www的，比如 <a href="http://www.mygit.me/">www.mygit.me</a> ，那么无论是访问 <a href="http://www.mygit.me/">http://www.mygit.me</a> 还是 <a href="http://mygit.me/">http://mygit.me</a> ，都会自动跳转到 <a href="http://www.mygit.me/">http://www.mygit.me</a></li><li>如果你填写的是其它子域名，比如 abc.mygit.me，那么访问 <a href="http://abc.mygit.me/">http://abc.mygit.me</a> 没问题，但是访问 <a href="http://mygit.me/">http://mygit.me</a> ，不会自动跳转到 <a href="http://abc.mygit.me/">http://abc.mygit.me</a></li></ul><p>另外说一句，在你绑定了新域名之后，原来的你的用户名.github.io并没有失效，而是会自动跳转到你的新域名。</p><hr><h2 id="3-配置SSH免密登录"><a href="#3-配置SSH免密登录" class="headerlink" title="3. 配置SSH免密登录"></a><strong>3. 配置SSH免密登录</strong></h2><p>为什么要配置这个呢？因为你提交代码肯定要拥有你的github权限才可以，但是直接使用用户名和密码太不安全了，所以我们使用ssh key来解决本地和服务器的连接问题。</p><p><strong>操作步骤：</strong></p><p><strong>第一步：</strong>首先打开电脑文件夹，找到C:\Users\你的用户名.ssh文件夹并删除</p><p><strong>第二步：</strong>在C:\Users\你的用户名 文件夹下右键打开Git Bash Here<strong>输入命令：</strong>ssh-keygen -t rsa -C github邮件地址   生成.ssh秘钥，输入后连敲三次回车，出现下图情况代表成功</p><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/3.png" class="" title="img"><p><strong>第三步：</strong>最终生成了一个新的 C:\Users\你的用户名.ssh文件夹，打开这个文件夹，找到.ssh\id_rsa.pub文件，记事本打开并复制里面的内容</p><p><strong>第四步：</strong>打开你的github主页，进入个人设置 -&gt; SSH and GPG keys -&gt; New SSH key，把复制的内容粘贴进去，title随便填，保存即可，我们的公钥就添加成功了，设置好如下图。</p><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/4.png" class="" title="img"><p><strong>第五步：检测是否设置成功：</strong></p><p>输入命令：  $ ssh -T <a href="mailto:git@github.com">git@github.com</a> # 注意邮箱地址不用改</p><p>如果提示Are you sure you want to continue connecting (yes&#x2F;no)?，输入yes，然后会看到：</p><p>Hi liuxianan! You’ve successfully authenticated, but GitHub does not provide shell access.</p><p>看到这个信息说明SSH已配置成功！</p><p><strong>第六步：此时你还需要配置：</strong></p><p>$ git config –global user.name “liuxianan”&#x2F;&#x2F; 你的github用户名，非昵称 $ git config –global user.email  “<a href="mailto:xxx@qq.com">xxx@qq.com</a>“&#x2F;&#x2F; 填写你的github注册邮箱</p><p>具体这个配置是干嘛的我没仔细深究。</p><hr><h2 id="4-使用-hexo-搭建博客"><a href="#4-使用-hexo-搭建博客" class="headerlink" title="4.使用 hexo 搭建博客"></a><strong>4.使用 hexo 搭建博客</strong></h2><h3 id="4-1-初始化"><a href="#4-1-初始化" class="headerlink" title="4.1 初始化"></a><strong>4.1 初始化</strong></h3><p><strong>第一步：</strong>在电脑的某个地方新建一个名为hexo的文件夹（名字可以随便取），比如我的是E:\xpzsData\hexocode，由于这个文件夹将来就作为你存放代码的地方，所以最好不要随便放</p><p><strong>第二步：</strong>在E:\xpzsData\hexocode文件夹下右键打开 Git Bash Here，输入hexo init 初始化</p><ul><li>hexo会自动下载一些文件到这个目录，包括node_modules，目录结构如下图：</li></ul><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/5.png" class="" title="img"><p><strong>第三步：</strong>执行以下命令之后，hexo就会在public文件夹生成相关html文件，这些文件将来都是要提交到github去的：</p><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/6.png" class="" title="img"><p><strong>第四步：</strong>hexo s 是开启本地预览服务，打开浏览器访问 <a href="http://localhost:4000/">http://localhost:4000</a> 即可看到内容，很多人会碰到浏览器一直在转圈但是就是加载不出来的问题，一般情况下是因为端口占用的缘故，因为4000这个端口太常见了，解决端口冲突问题请参考这篇文章<a href="https://www.runoob.com/w3cnote/windows-finds-port-usage.html">https://www.runoob.com/w3cnote/windows-finds-port-usage.html</a></p><ul><li>到这里初始化就完成了</li></ul><h3 id="4-2-将博客部署到-github-个人主页上"><a href="#4-2-将博客部署到-github-个人主页上" class="headerlink" title="4.2 将博客部署到 github 个人主页上"></a><strong>4.2 将博客部署到 github 个人主页上</strong></h3><p><strong>第一步：</strong>在E:\xpzsData\hexocode目录下安装 hexo-deployer-git 插件</p><ul><li><strong>安装命令：</strong> npm install hexo-deployer-git –save  </li><li>必须安装，否则执行hexo d 的话会报如下错误：</li></ul><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/7.png" class="" title="img"><p><strong>第二步：</strong>编辑E:\xpzsData\hexocode目录下的 _config.yml 文件, 在文件末尾添加如下内容：</p><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/8.png" class="" title="img"><ul><li>注意：其中 repo 中的内容即为 github 个人主页链接地址，具体看下图：</li></ul><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/9.png" class="" title="img"><p><strong>第三步：</strong>在E:\xpzsData\hexocode目录下, <strong>输入命令：hexo d</strong> 将本地 blog 推送到 github仓库, 也可能需要输入 username &amp; pwd。</p><ul><li>推送成功后, 在浏览器中输入对应域名, 即可访问 <a href="https://reclusew.github.io/">https://reclusew.github.io/</a></li></ul><hr><h2 id="5-更换主题"><a href="#5-更换主题" class="headerlink" title="5. 更换主题"></a><strong>5. 更换主题</strong></h2><h3 id="5-1-寻找主题"><a href="#5-1-寻找主题" class="headerlink" title="5.1 寻找主题"></a><strong>5.1 寻找主题</strong></h3><ul><li>既然默认主题很丑，那我们别的不做，首先来替换一个好看点的主题。</li><li>这是hexo官网：<a href="https://hexo.io/themes/%EF%BC%8C%E5%8F%AF%E5%9C%A8%E9%87%8C%E9%9D%A2%E4%B8%8B%E8%BD%BD%E4%B8%BB%E9%A2%98%EF%BC%8C%E7%82%B9%E5%87%BB%E4%B8%BB%E9%A2%98%E5%90%8D%E5%8D%B3%E5%8F%AF%E8%B7%B3%E8%BD%AC%E5%88%B0github%E4%B8%8A%EF%BC%8C%E4%B9%9F%E5%8F%AF%E4%BB%A5%E7%9B%B4%E6%8E%A5%E5%9C%A8github%E4%B8%8A%E6%90%9C%E7%B4%A2%E4%B8%BB%E9%A2%98">https://hexo.io/themes/，可在里面下载主题，点击主题名即可跳转到github上，也可以直接在github上搜索主题</a></li><li>在这里我使用github上一个大佬的主题blinkfox&#x2F;hexo-theme-matery</li></ul><p>​              链接：<a href="https://github.com/blinkfox/hexo-theme-matery">https://github.com/blinkfox/hexo-theme-matery</a>    </p><h3 id="5-2-下载主题"><a href="#5-2-下载主题" class="headerlink" title="5.2 下载主题"></a><strong>5.2 下载主题</strong></h3><p><strong>第一步：</strong>Git Bash Here中先cd到E:\xpzsData\hexocode目录</p><p><strong>第二步：</strong>再输入命令 $ git clone 主题http链接  themes&#x2F;主题名称</p><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/10.png" class="" title="img"><p><strong>注意：</strong></p><ul><li>E:\xpzsData\hexocode目录下的 theme 文件夹下存放的就是博客的主题，主题是否下载成功可到该目录下查看：</li></ul><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/11.png" class="" title="img"><h3 id="5-3-使用主题"><a href="#5-3-使用主题" class="headerlink" title="5.3 使用主题"></a><strong>5.3 使用主题</strong></h3><ul><li>打开E:\xpzsData\hexocode目录下的_config.yml文件，在里面找到theme: landscape改为theme: blinkfox   （blinkfox为我们要使用的主题名）,然后重新执行hexo g来重新生成。</li><li>如果出现一些莫名其妙的问题，可以先执行hexo clean来清理一下public的内容，然后再执行hexo g 和 hexo s 重新生成和发布。</li><li>再次在浏览器中输入对应域名, 即可发现主题已更换</li></ul><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/12.png" class="" title="img"><h3 id="5-4-修改主题内容"><a href="#5-4-修改主题内容" class="headerlink" title="5.4 修改主题内容"></a><strong>5.4 修改主题内容</strong></h3><p>在这里我使用的是blinkfox主题，后期相关修改参考这个主题文档</p><p><strong>文档链接：</strong><a href="https://github.com/blinkfox/hexo-theme-matery/blob/develop/README_CN.md">https://github.com/blinkfox/hexo-theme-matery/blob/develop/README_CN.md</a></p><ul><li>注意：一些非md文件可以把他们放到source文件夹下，这里的所有文件都会原样复制（除了md文件）到public目录的</li><li>大致在下图的文件夹里面修改文件，记得修改后的文件需要关闭后，再在hexocode根目录右键打开Git Bash  Here，输入两个命令：hexo g 重新生成，hexo s 开启本地预览服务,等修改的符合要求了，再输入 hexo d  推送到github仓库即可</li><li>这样就可以输入网址查看更改后的内容了</li></ul><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/13.png" class="" title="img"><p><strong>文档上没有提及的修改：</strong></p><ul><li>返回按钮样式修改：在主题下面的 blinkfox\layout_partial 文件夹中的 back-top.esj 文件中修改</li></ul><p><strong>特别注意：</strong></p><ul><li><strong>修改生成的默认页面信息，要到主题下面的_config.yml文件里面去改，而不是根目录下的_config.yml文件</strong></li></ul><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/14.png" class="" title="img"><ul><li><strong>要把根目录下的_config.yml文件中的这些信息替换成自己的和设置中文</strong></li></ul><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/15.png" class="" title="img"><h3 id="5-5-blinkfox主题的相关配置问题"><a href="#5-5-blinkfox主题的相关配置问题" class="headerlink" title="5.5 blinkfox主题的相关配置问题"></a><strong>5.5 blinkfox主题的相关配置问题</strong></h3><p><strong>配置音乐播放器：</strong>使用网易云音乐id不行，这里用的是QQ音乐</p><p><strong>配置留言功能（利用Valine）：</strong></p><ul><li>我们的评论系统其实是放在Leancloud上的，因此首先需要去注册一个账号</li><li>注册完以后需要创建一个应用，名字可以随便起，然后 进入应用-&gt;设置-&gt;应用key，获取你的appid 和 appkey，复制到主题下面的 _config.yml 文件里面搜索 valine，填入appid 和 appkey</li><li>最后！记得在Leancloud -&gt; 设置 -&gt; 安全中心 -&gt; Web 安全域名 把你的域名加进去就可以了</li><li>主题页面显示的内容在主题下面的 layout 文件夹中的 contact.ejs 文件里面更改</li></ul><hr><h2 id="6-利用Typora软件来写博客"><a href="#6-利用Typora软件来写博客" class="headerlink" title="6.利用Typora软件来写博客"></a><strong>6.利用Typora软件来写博客</strong></h2><h3 id="6-1-Typora介绍"><a href="#6-1-Typora介绍" class="headerlink" title="6.1 Typora介绍"></a><strong>6.1 Typora介绍</strong></h3><ul><li>Typora–一款简单高效的Markdown编辑器，保存后直接为md格式，Markdown中点击导入就可以。</li><li>Markdown是一种可以使用普通文本编辑器编写的标记语言，通过简单的标记语法，它可以使普通文本内容具有一定的格式，其目标是实现易读易写，说人话就是删减版的HTML语言</li><li>Markdown教程：<a href="https://www.runoob.com/markdown/md-tutorial.html">https://www.runoob.com/markdown/md-tutorial.html</a></li></ul><h3 id="6-2-安装Typora"><a href="#6-2-安装Typora" class="headerlink" title="6.2 安装Typora"></a><strong>6.2 安装Typora</strong></h3><p><strong>官网：</strong><a href="https://www.typora.io/#windows">https://www.typora.io/#windows</a></p><h3 id="6-3-写博客的步骤"><a href="#6-3-写博客的步骤" class="headerlink" title="6.3  写博客的步骤"></a><strong>6.3  写博客的步骤</strong></h3><p><strong>第一步：创建.md文件</strong></p><ul><li><strong>方法1：</strong>定位到我们的hexo根目录，Git Bash Here 中执行命令：  hexo new  ‘my-first-blog’                 hexo会帮我们在E:\xpzsData\hexocode\source_posts  下生成相关.md文件，用这个命令的好处是帮我们自动生成了时间，方法1默认生成如下内容：</li></ul><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/16.png" class="" title="img"><ul><li><strong>方法2：</strong>当然你也可以直接自己打开E:\xpzsData\hexocode\source_posts 目录新建.md文件</li></ul><p><strong>第二步：编写并保存</strong></p><p>我们只需要用typora打开这个文件就可以开始写博客了，写完后Ctrl+S 保存关闭即可</p><p><strong>第三步：</strong>清理然后再生成一下，生成后推送到远程仓库即可，hexo根目录下右键Git Bash Here 中依次输入如下命令：</p><ol><li>hexo clean</li><li>hexo g </li><li>hexo d</li></ol><p><strong>补充：</strong>hexo new page ‘postName’命令和hexo new ‘postName’的区别？</p><ul><li>hexo new page ‘My-second-blog’最终部署时生成：hexo\public\my-second-blog\index.html，但是它不会作为文章出现在博文目录。</li></ul><h3 id="6-4-Typora快捷键"><a href="#6-4-Typora快捷键" class="headerlink" title="6.4  Typora快捷键"></a><strong>6.4  Typora快捷键</strong></h3><p>Typora中只要记住一些基本的快捷键就可以了，所有功能软件里面都有对应按钮，这点不用慌。</p><p><strong>快捷键文章：</strong><a href="https://blog.csdn.net/weixin_39533052/article/details/111115263">https://blog.csdn.net/weixin_39533052/article/details/111115263</a></p><h3 id="6-5-注意：所使用的主题的文章-Front-matter-语法"><a href="#6-5-注意：所使用的主题的文章-Front-matter-语法" class="headerlink" title="6.5  注意：所使用的主题的文章 Front-matter 语法"></a><strong>6.5  注意：所使用的主题的文章 Front-matter 语法</strong></h3><p>依据使用的不同主题，一些文章功能所使用的语法可能不一样，例如写博客时给文章添加标签的语法等等，这些都要看所使用的主题的文档，例如我们这里使用的是 <strong>blinkfox</strong> 主题，打开主题文档，往下翻找到<strong>”</strong>  <strong>文章 Front-matter 介绍 “</strong>即可。</p><p><strong>blinkfox主题文档：</strong><a href="https://github.com/blinkfox/hexo-theme-matery/blob/develop/README_CN.md#%E6%96%87%E7%AB%A0-front-matter-%E4%BB%8B%E7%BB%8D">https://github.com/blinkfox/hexo-theme-matery/blob/develop/README_CN.md#%E6%96%87%E7%AB%A0-front-matter-%E4%BB%8B%E7%BB%8D</a></p><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/17.png" class="" title="img"><p><strong>示例：</strong></p><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/18.png" class="" title="img"><h3 id="6-6-YAML语法（了解）"><a href="#6-6-YAML语法（了解）" class="headerlink" title="6.6 YAML语法（了解）"></a><strong>6.6 YAML语法（了解）</strong></h3><p>像在typora中添加tags时，可以直接用数组的写法，也可以使用YAML语法，如下：</p><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/19.png" class="" title="img"><p><strong>YAML教程链接：</strong><a href="https://www.runoob.com/w3cnote/yaml-intro.html">https://www.runoob.com/w3cnote/yaml-intro.html</a></p><hr><h2 id="7-如何向hexo博客中插入图片"><a href="#7-如何向hexo博客中插入图片" class="headerlink" title="7.如何向hexo博客中插入图片"></a><strong>7.如何向hexo博客中插入图片</strong></h2><h3 id="7-1-使用相对路径的方式"><a href="#7-1-使用相对路径的方式" class="headerlink" title="7.1 使用相对路径的方式"></a><strong>7.1 使用相对路径的方式</strong></h3><p>众所周知，在md文件中插入图片的语法为!&#x2F;。</p><p>其中<strong>方括号</strong>是图片描述，<strong>圆括号</strong>是图片路径。</p><p>一般来说有三种图片路径，分别是<strong>相对路径，绝对路径和网络路径</strong>。</p><p>所谓的网络路径就是直接引用网上的图片，直接复制图片地址，放在圆括号中就完事了。</p><p>这种方式十分的方便，但是也存在一定的问题：</p><ul><li>图片失效导致无法加载；</li><li>打开网页后要再请求加载图片；</li><li>原网站限制，如微信公众号的图片会变得不可见等。</li></ul><p>这种方式算是有利有弊。</p><p>绝对路径是图片在计算机中的绝对位置，相对路径是相对于当前文件的路径。</p><p>由于我们的博客是要部署在网站上，部署后会生成新的文件目录，所以我们选择使用相对路径的方式。</p><p>在hexo中使用<strong>文章资源文件夹</strong>需要在config.yaml文件中更改一下配置：</p><p>post_asset_folder: true</p><p>当该配置被应用后，使用hexo new命令创建新文章时，会生成相同名字的文件夹，也就是文章资源文件夹。</p><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/replenish1.jpg" class="" title="img"><p>虽然可以正常引用图片了，但是这种引用图片的方式只有一句话能形容，wtf。</p><h3 id="7-2-hexo-renderer-marked插件的安装与配置"><a href="#7-2-hexo-renderer-marked插件的安装与配置" class="headerlink" title="7.2 hexo-renderer-marked插件的安装与配置"></a><strong>7.2 hexo-renderer-marked插件的安装与配置</strong></h3><p>插件<a href="https://github.com/hexojs/hexo-renderer-marked">hexo-renderer-marked</a>解决了这个问题</p><p><strong>安装：</strong>npm install hexo-image-link –save  ，之后在config.yaml中更改配置如下：</p><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/20.png" class="" title="img"><p>之后就可以愉快的插入图片了</p><h3 id="7-3-hexo-renderer-marked插件与Typora的完美结合"><a href="#7-3-hexo-renderer-marked插件与Typora的完美结合" class="headerlink" title="7.3 hexo-renderer-marked插件与Typora的完美结合"></a><strong>7.3 hexo-renderer-marked插件与Typora的完美结合</strong></h3><p>如果图片数量众多的话，一张一张的放很影响效率。但是不用怕，我们有很方便的解决方法。</p><p><strong>Typora</strong>是我非常喜欢的Markdown文本编辑器，在之前的文章中也介绍过一点。</p><p>Typora对于插入图片的支持做得非常好，在文件-&gt;偏好设置或者直接&lt;C-,&gt;进入设置。</p><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/21.png" class="" title="img"><p><strong>复制网络路径的图片：</strong></p><p>使用该配置后，可以直接复制网页中的图片地址，粘贴到Typora中后，会直接复制该图片到文章资源文件夹，同时自动更改路径。</p><p>如复制网络路径的图片https:&#x2F;&#x2F;…..&#x2F;image.jpg粘贴到Typora中叫文章名的文章后，图片会自动变为(文章名&#x2F;image.jpg)。</p><p>但我们知道部署后，文件路径是不同的，所以当我们插入完所有的图片后，我们还需要删除每个图片路径中的文件名&#x2F;。不慌，也很简单。</p><p>在Typora编辑器中，使用快捷键，将所有的文章名&#x2F;替换为空即可删除。</p><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/22.png" class="" title="img"><p>然后再将博客上传，图片就会随着文章一起打包。在网页中就可以看到正常显示的图片，大功告成</p><hr><h2 id="8-总结"><a href="#8-总结" class="headerlink" title="8.总结"></a>8.总结</h2><p>这是本人搭建博客过程中遇到的一些问题和解决办法，按照我这个步骤基本就能搭建起来一个不错的博客了，文章里面省略了博客的SEO优化，比如让百度和谷歌搜索引擎收录我们的博客网站，这点大家可以去网上搜索，教程很多的，有什么问题欢迎在下方留言！</p><p>参考文献：</p><p>1：<a href="https://github.com/blinkfox/hexo-theme-matery/blob/develop/README_CN.md">https://github.com/blinkfox/hexo-theme-matery/blob/develop/README_CN.md</a></p><p>2：<a href="https://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html">https://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html</a></p><p>3：<a href="https://www.jianshu.com/p/f72aaad7b852">https://www.jianshu.com/p/f72aaad7b852</a></p>]]></content>
      
      
      <categories>
          
          <category> 博客搭建 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 个人博客 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据</title>
      <link href="/2024/03/24/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
      <url>/2024/03/24/%E5%A4%A7%E6%95%B0%E6%8D%AE/</url>
      
        <content type="html"><![CDATA[<h2 id="1-TopK问题"><a href="#1-TopK问题" class="headerlink" title="1.TopK问题"></a>1.TopK问题</h2><h3 id="1-1一类问题"><a href="#1-1一类问题" class="headerlink" title="1.1一类问题"></a>1.1一类问题</h3><ol><li>1亿个浮点数，如果找出最⼤的10000个</li><li>有⼀个<strong>1G</strong>⽂件，内存限制⼤⼩是<strong>1M</strong>。返回频数最⾼<strong>100</strong></li><li>100w个数中找出最⼤的100个数</li><li>海量数据分布在<strong>100</strong>台电脑中，想个办法⾼校统计出这批数据的<strong>TOP10</strong></li><li>海量⽇志数据，提取出某⽇访问百度次数最多的那个<strong>IP</strong></li><li>⼀个亿级⽂本⽂件，找出前<strong>10</strong>个经常出现的词，⽆法⼀次读⼊内存，问最优解</li><li>怎么在海量数据中找出重复次数最多的⼀个</li><li>上千万或上亿数据（有重复），统计其中出现次数最多的前N个数据。</li></ol><p>解法：hash+分治+⼩顶堆+hashmap统计次数+快速排序思想+插入排序思想</p><ol><li><p>hash去重：</p><p>如果这1亿个书⾥⾯有很多重复的数，先通过Hash法，把这1亿个数字去重复，这样如果重复率很⾼的话，会减少很⼤的内存⽤量，从⽽缩⼩运算空间，然后通过分治法或最⼩堆法查找最⼤的10000个数</p></li><li><p>划分文件：</p><p>⽐如模1000，把整个⼤⽂件映射为1000个⼩⽂件，并且相同的数一定在一个文件中</p></li><li><p>分治：</p><p>顺序读⽂件中，对于每个词x，取 ，然后按照该值存到5000个⼩⽂件（记为）中。这样每个⽂件⼤概是200k左右。如果其中的有的⽂件超过了1M⼤⼩，还可以按照类似的⽅法继续往下分，直到分解得到的⼩⽂件的⼤⼩都不超过1M</p></li><li><p>⼩顶堆：</p><p>⾸先读⼊前10000个数来创建⼤⼩为10000的最⼩堆，建堆的时间复杂度为O（mlogm）（m为数组的⼤⼩即为10000），然后遍历后续的数字，并于堆顶（最⼩）数字进⾏⽐较。如果⽐最⼩的数⼩，则继续读取后续数字；如果⽐堆顶数字⼤，则替换堆顶元素并重新调整堆为最⼩堆。整个过程直⾄1亿个数全部遍历完为⽌。然后按照中序遍历的⽅式输出当前堆中的所有10000个数字。该算法的时间复杂度为O（nmlogm），空间复杂度是10000（常数）</p></li><li><p>快速排序思想：</p><p>100万个数据⾥⾯查找最⼤的10000个数据的⽅法如下：⽤快速排序的⽅法，将数据分为2堆，如果⼤的那堆个数N⼤于10000个，继续对⼤堆快速排序⼀次分成2堆，如果⼤的那堆个数N⼤于10000个，继续对⼤堆快速排序⼀次分成2堆，如果⼤堆个数N⼩于10000个，就在⼩的那堆⾥⾯快速排序⼀次，找第10000-n⼤的数字；递归以上过程，就可以找到第1w⼤的数。参考上⾯的找出第1w⼤数字，就可以类似的⽅法找到前10000⼤数字了。此种⽅法需要每次的内存空间为10^6*4&#x3D;4MB，⼀共需要101次这样的⽐较。</p></li><li><p>插入排序思想：</p><p>采⽤局部淘汰法。选取前100个元素，并排序，记为序列L。然后⼀次扫描剩余的元素x，与排好序的100个元素中最⼩的元素⽐，如果⽐这个最⼩的要⼤，那么把这个最⼩的元素删除，并把x利⽤插⼊排序的思想，插⼊到序列L中。依次循环，直到扫描了所有的元素。复杂度为O(100w*100)。 这个⽅法就是插⼊排序。</p></li></ol><h3 id="1-2万级文本文件，每行一个词，统计出其中最频繁出现的前10个词"><a href="#1-2万级文本文件，每行一个词，统计出其中最频繁出现的前10个词" class="headerlink" title="1.2万级文本文件，每行一个词，统计出其中最频繁出现的前10个词"></a>1.2万级文本文件，每行一个词，统计出其中最频繁出现的前10个词</h3><p>这题是考虑时间效率。<u>用trie树统计每个词出现的次数</u>，时间复杂度是O(n<em>le)（le表示单词的平准长度）。然后是找出出现最频繁的前10个词，可以用堆来实现，前面的题中已经讲到了，时间复杂度是O(n</em>lg10)。所以总的时间复杂度，是O(n<em>le)与O(n</em>lg10)中较大的哪一个。</p><h3 id="1-3最热门的10个查询串"><a href="#1-3最热门的10个查询串" class="headerlink" title="1.3最热门的10个查询串"></a>1.3最热门的10个查询串</h3><p>搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。假设目前有一千万个记录，这些查询串的重复读比较高，虽然总数是1千万，但是如果去除重复和，不超过3百万个。一个查询串的重复度越高，说明查询它的用户越多，也就越热门。</p><p>请你统计最热门的10个查询串，要求使用的内存不能超过1G。</p><p>(1) 请描述你解决这个问题的思路；</p><p>(2) 请给出主要的处理流程，算法，以及算法的复杂度。</p><p>方案1：采用trie树，关键字域存该查询串出现的次数，没有出现为0。最后用10个元素的最小推来对出现频率进行排序。</p><p>方案2：可以采用hash分块，然后统计各个块中的最热门的10个查询，然后用堆排序，时间复杂度&#x3D;N+n<em>m +nlog10 +m</em>10log10.此可以用来处理超过内存容量的情况 </p><h3 id="1-4找出出现次数最多的IP"><a href="#1-4找出出现次数最多的IP" class="headerlink" title="1.4找出出现次数最多的IP"></a>1.4找出出现次数最多的IP</h3><p>可以考虑采用“分而治之”的思想，按照IP地址的Hash(IP)%1024值，把海量IP日志分别存储到1024个小文件中。</p><h2 id="2-重复问题"><a href="#2-重复问题" class="headerlink" title="2.重复问题"></a>2.重复问题</h2><h3 id="2-1⽂件包含电话号码，统计不同号码的个数"><a href="#2-1⽂件包含电话号码，统计不同号码的个数" class="headerlink" title="2.1⽂件包含电话号码，统计不同号码的个数"></a>2.1⽂件包含电话号码，统计不同号码的个数</h3><p>对于本题，8 位电话号码可以表示的号码个数为 10^8 个，即 1 亿个。我们每个号码用一个 bit 来表示，则总共需要 1 亿个 bit，内存占用约 100M。</p><p>思路如下：</p><p>申请一个位图数组，长度为 1 亿，初始化为 0。然后遍历所有电话号码，把号码对应的位图中的位置置为 1。遍历完成后，如果 bit 为 1，则表示这个电话号码在文件中存在，否则不存在。bit 值为 1 的数量即为 不同电话号码的个数。</p><h3 id="2-2在2-5亿个整数中找出不重复的整数，内存不⾜以容纳这2-5亿个整数。"><a href="#2-2在2-5亿个整数中找出不重复的整数，内存不⾜以容纳这2-5亿个整数。" class="headerlink" title="2.2在2.5亿个整数中找出不重复的整数，内存不⾜以容纳这2.5亿个整数。"></a>2.2在2.5亿个整数中找出不重复的整数，内存不⾜以容纳这2.5亿个整数。</h3><p>方案1：采用2-Bitmap（每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义）进行，共需内存内存（整数占4B，32位），还可以接受。然后扫描这2.5亿个整数，查看Bitmap中相对应位，如果是00变01，01变10，10保持不变。所描完事后，查看bitmap，把对应位是01的整数输出即可。</p><p>方案2：也可采用上题类似的方法，进行划分小文件的方法。然后在小文件中找出不重复的整数（用hashset和hashmap，trie树对hashmap的优势是，在大量重复的单词中，trie树需要的内存会低一些，hashmap的优势是查找快一些。），并排序。然后再进行归并，注意去除重复的元素。也可像鸽巢原理，整数个数为2^32,也就是，我们可以将这2^32个数，划分为2^8个区域(比如用单个文件代表一个区域)，然后将数据分离到不同的区域，然后不同的区域在利用bitmap就可以直接解决了。也就是说只要有足够的磁盘空间，就可以很方便的解决。</p><h3 id="2-31000万字符串，去重"><a href="#2-31000万字符串，去重" class="headerlink" title="2.31000万字符串，去重"></a>2.31000万字符串，去重</h3><p>这题⽤trie树⽐较合适，hash_map也应该能⾏。</p><h2 id="3-排序问题"><a href="#3-排序问题" class="headerlink" title="3.排序问题"></a>3.排序问题</h2><h3 id="3-1一个文件中有9亿条不重复的9位整数-对这个文件中数字进行排序"><a href="#3-1一个文件中有9亿条不重复的9位整数-对这个文件中数字进行排序" class="headerlink" title="3.1一个文件中有9亿条不重复的9位整数,对这个文件中数字进行排序;"></a>3.1一个文件中有9亿条不重复的9位整数,对这个文件中数字进行排序;</h3><p>解决思路：</p><p>（❌）将所有数据<strong>导入到内存</strong>中,然后使用常规的排序方法,例如插入排序,快速排序,归并排序等各种排序方法对数据进行排序,最后将排序好的数据存入文件.但这些方法在此并不适用,由于数据量巨大,对32位机器而言,很难将这么多数据一次载入到内存,更不用说进行排序了.所以此种方法一般不可行,需要考虑其他方法.     ————————————————</p><ol><li>方法一：数据库排序法.<br>     将文本文件导入到数据库中,让文本文件导入到数据库中,让数据库进行索引排序操作后提取数据到文件.该种方法虽然操作简单,方便,但是运算速度较慢,而且对数据库设备要求比较高.</li><li>方法二：分治法.<br>      通过Hash法将9亿条数据分为20段,每一段大约5000万条,大约需要占用500万*4B &#x3D; 200MB空间,在文件中依次搜索0<del>5000万,50000001</del>1亿  ,,将排序的结果存入文件,该方法要装满9位整数,一共需要20次,所以一共要进行20次排序,需要对文件进行20次读操作.该方法虽然缩小了每次使用的内存空间大小,但是编码复杂,速度也慢.</li><li>方法三：位图法.<br>       考虑到最大的9位整数为999999999,由于9亿条数据是不重复的,可以把这些数据组成一个队列或者数组,让它有0~999999999(一共10亿个数)元素数组下标表示数值,结点中用0表示没有这个数,1表示存在这个数,判断0或1只用一个bit存储就够了,<br>      而声明一个可以包含9位整数的bit数组,一共需要10亿&#x2F;8,大约120MB内存,把内存中的数组全部初始化为0,读取文件中的数据,并将数据放入内存.比如读到一个数据为314332897这个数据,那就先在内存中找到314332897这个bit,并将bit值置为1,遍历整个bit数组,将bit为1的数组下标存入文件,最终得到排序的内容.</li></ol><p>外排序：</p><p>外部排序算法由两个阶段构成：</p><ol><li>按照内存大小，将大文件分成若干长度为     l 的子文件（l     应小于内存的可使用容量），然后将各个子文件依次读入内存，使用适当的内部排序算法对其进行排序（排好序的子文件统称为“归并段”或者“顺段”），将排好序的归并段重新写入外存，为下一个子文件排序腾出内存空间；</li><li>对得到的顺段进行合并，直至得到整个有序的文件为止。</li></ol><p>注意：在实际归并的过程中，由于内存容量的限制不能满足同时将 2 个归并段全部完整的读入内存进行归并，只能不断地取 2 个归并段中的每一小部分进行归并，通过不断地读数据和向外存写数据，直至 2 个归并段完成归并变为 1 个大的有序文件。</p><p><a href="http://data.biancheng.net/view/76.html">http://data.biancheng.net/view/76.html</a></p><h3 id="3-2频度排序"><a href="#3-2频度排序" class="headerlink" title="3.2频度排序"></a>3.2频度排序</h3><p><strong>题目： 有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。要求你按照query的频度排序</strong></p><p>方案1：</p><p> - 顺序读取10个文件，按照hash(query)%10的结果将query写入到另外10个文件中。这样新生成的文件每个的大小大约也1G（假设hash函数是随机的）。</p><p> -找一台内存在2G左右的机器，依次对用hash_map(query, query_count)来统计每个query出现的次数。利用快速&#x2F;堆&#x2F;归并排序按照出现次数进行排序。将排序好的query和对应的query_cout输出到文件中。这样得到了10个排好序的文件。</p><p>  -对这10个文件进行归并排序（内排序与外排序相结合）。</p><p>方案2：</p><p>一般query的总量是有限的，只是重复的次数比较多而已，可能对于所有的query，一次性就可以加入到内存了。这样，我们就可以采用trie树&#x2F;hash_map等直接来统计每个query出现的次数，然后按出现次数做快速&#x2F;堆&#x2F;归并排序就可以了。</p><p>方案3：</p><p>与方案1类似，但在做完hash，分成多个文件后，可以交给多个文件来处理，采用分布式的架构来处理（比如MapReduce），最后再进行合并。（与1相比就是处理构架不同）</p><h2 id="4相等问题"><a href="#4相等问题" class="headerlink" title="4相等问题"></a>4相等问题</h2><h3 id="4-1两文件，如何从-100-亿-URL-中找出相同的-URL？"><a href="#4-1两文件，如何从-100-亿-URL-中找出相同的-URL？" class="headerlink" title="4.1两文件，如何从 100 亿 URL 中找出相同的 URL？"></a>4.1两文件，如何从 100 亿 URL 中找出相同的 URL？</h3><p><strong>Eg： 给定 a、b 两个文件，各存放 50 亿个 URL，每个 URL 各占 64B，内存限制是 4G。请找出 a、b 两个文件共同的 URL。</strong></p><p>每个 URL 占 64B，那么 50 亿个 URL 占用的空间大小约为 320GB。由于内存大小只有 4G，因此，我们不可能一次性把所有 URL 加载到内存中处理。</p><ol><li><p>分治：把一个文件中的 URL 按照某个特征划分为多个小文件，使得每个小文件大小不超过 4G，这样就可以把这个小文件读到内存中进行处理了。</p><p>首先遍历文件 a，对遍历到的 URL 求 hash(URL) % 1000 ，根据计算结果把遍历到的 URL 存储到 a0, a1, a2, …, a999，这样每个大小约为 300MB。使用同样的方法遍历文件 b，把文件 b 中的 URL 分别存储到文件 b0, b1, b2, …, b999 中。这样处理过后，所有可能相同的 URL 都在对应的小文件中，即 a0 对应 b0, …, a999 对应 b999，不对应的小文件不可能有相同的 URL。那么接下来，我们只需要求出这 1000 对小文件中相同的 URL 就好了。</p></li><li><p>hash: 对每个子文件做hashset统计</p><p>接着遍历 ai( i∈[0,999] )，把 URL 存储到一个 HashSet 集合中。然后遍历 bi 中每个 URL，看在 HashSet 集合中是否存在，若存在，说明这就是共同的 URL，可以把这个 URL 保存到一个单独的文件中。</p></li><li><p>Bloom filter</p></li></ol><p>  如果允许有一定的错误率，可以使用Bloom filter，4G内存大概可以表示340亿bit。将其中一个文件中的url使用Bloom filter映射为这340亿bit，然后挨个读取另外一个文件的url，检查是否与Bloom filter，如果是，那么该url应该是共同的url（注意会有一定的错误率）。</p><h2 id="5-中位数问题"><a href="#5-中位数问题" class="headerlink" title="5.中位数问题"></a>5.中位数问题</h2><h3 id="5-1查找中位数"><a href="#5-1查找中位数" class="headerlink" title="5.1查找中位数"></a>5.1查找中位数</h3><p>方法一：</p><p>分治法的思想是把一个大的问题逐渐转换为规模较小的问题来求解。</p><p>对于这道题，顺序读取这 5 亿个数字，对于读取到的数字 num，如果它对应的二进制中最高位为 1，则把这个数字写到 f1 中，否则写入 f0 中。通过这一步，可以把这 5 亿个数划分为两部分，而且 f0 中的数都大于 f1 中的数（最高位是符号位）。</p><p>划分之后，可以非常容易地知道中位数是在 f0 还是 f1 中。假设 f1 中有 1 亿个数，那么中位数一定在 f0 中，且是在 f0 中，从小到大排列的第 1.5 亿个数与它后面的一个数的平均值。</p><p>提示，5 亿数的中位数是第 2.5 亿与右边相邻一个数求平均值。若 f1 有一亿个数，那么中位数就是 f0 中从第 1.5 亿个数开始的两个数求得的平均值。</p><p>对于 f0 可以用次高位的二进制继续将文件一分为二，如此划分下去，直到划分后的文件可以被加载到内存中，把数据加载到内存中以后直接排序，找出中位数。</p><p>注意，当数据总数为偶数，如果划分后两个文件中的数据有相同个数，那么中位数就是数据较小的文件中的最大值与数据较大的文件中的最小值的平均值。</p><p>方法二：</p><p>排序后找。</p><p><a href="https://zhuanlan.zhihu.com/p/75397875%E6%96%B9%E6%B3%95%E6%9B%B4%E5%A4%9A%EF%BC%8C%E6%9B%B4%E8%AF%A6%E7%BB%86">https://zhuanlan.zhihu.com/p/75397875方法更多，更详细</a></p><h3 id="5-2N个机器，如何找到中位数"><a href="#5-2N个机器，如何找到中位数" class="headerlink" title="5.2N个机器，如何找到中位数"></a>5.2N个机器，如何找到中位数</h3><p>题目限制：每个机器上有N个数。每个机器最多存O(N)个数并对它们操作。 </p><p><img src="C:\Users\hasee\Downloads\GetImage.png" alt="GetImage"></p><h2 id="6-随机选择K个数—蓄水池采样"><a href="#6-随机选择K个数—蓄水池采样" class="headerlink" title="6.随机选择K个数—蓄水池采样"></a>6.随机选择K个数—蓄水池采样</h2><p>问题：</p><p>“给出一个数据流，这个数据流的长度很大或者未知。并且对该数据流中数据只能访问一次。请写出一个随机选择算法，使得数据流中所有数据被选中的概率相等。”</p><p>解法：</p><p><strong>蓄水池采样（Reservoir Sampling）算法。</strong></p><p>介绍该算法之前，我们首先从最简单的例子出发（只在数据流中取一个数据）：假设数据流只有一个数据。我们接收数据，发现数据流结束了，直接返回该数据，该数据返回的概率为1。看来很简单，那么我们试试难一点的情况：假设数据流里有两个数据。</p><p>我们读到了第一个数据，这次我们不能直接返回该数据，因为数据流没有结束。我们继续读取第二个数据，发现数据流结束了。因此我们只要保证以相同的概率返回第一个或者第二个数据就可以满足题目要求。因此我们生成一个0到1的随机数R，如果R小于0.5，我们就返回第一个数据，如果R大于0.5，返回第二个数据。</p><p>接着我们继续分析有三个数据的数据流的情况。为了方便，我们按顺序给流中的数据命名为1、2、3。我们陆续收到了数据1、2。和前面的例子一样，我们只能保存一个数据，所以必须淘汰1和2中的一个。应该如何淘汰呢？不妨和上面例子一样，我们按照二分之一的概率淘汰一个，例如我们淘汰了2。继续读取流中的数据3，发现数据流结束了，我们知道在长度为3的数据流中，如果返回数据3的概率为1&#x2F;3，那么才有可能保证选择的正确性。也就是说，目前我们手里有1、3两个数据，我们通过一次随机选择，以1&#x2F;3的概率留下数据3，以2&#x2F;3的概率留下数据1。那么数据1被最终留下的概率是多少呢？</p><p>数据1被留下概率：（1&#x2F;2）* (2&#x2F;3) &#x3D; 1&#x2F;3</p><p>数据2被留下概率：（1&#x2F;2）*(2&#x2F;3) &#x3D; 1&#x2F;3</p><p>数据3被留下概率：1&#x2F;3</p><p>这个方法可以满足题目要求，所有数据被留下返回的概率一样。</p><p><u>因此，循着这个思路，我们可以总结算法的过程</u>：</p><p>假设需要采样的数量为K。</p><p>1、首先构建一个可容纳 K 个元素的数组，将序列的前 K 个元素放入数组中。</p><p>2、对于第 i&gt;&#x3D;k+1，我们以 k&#x2F;i 概率决定是否要把它换入蓄水池，换入时随机的选取一个作为替换项，这样一直做下去，对于任意的样本空间n，对每个数的选取概率都为k&#x2F;n。也就是说对每个数选取概率相等。 当遍历完所有元素之后，数组中剩下的元素即为所需采取的样本。</p><p>代码如下：<img src="/2024/03/24/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E4%BB%A3%E7%A0%81.png" class="" title="GetImage(1)"></p><img src="/2024/03/24/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB.png" class="" title="GetImage(2)">]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> 大数据 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
