<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>linux命令</title>
      <link href="/2024/04/08/linux%E5%91%BD%E4%BB%A4/"/>
      <url>/2024/04/08/linux%E5%91%BD%E4%BB%A4/</url>
      
        <content type="html"><![CDATA[<p>linux命令</p><p>cd （change directory：英文释义是改变目录）切换目录</p><p>pwd （print working directory：显示当前工作目录的绝对路径）</p><p>ls （ls：list的缩写，查看列表）查看当前目录下的所有文件夹（ls 只列出文件名或目录名）</p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={9A26314E-3D14-4B11-9C65-8F3062C200F8}&E3&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">ll （ll：list的缩写，查看列表详情）查看当前目录下的所有详细信息和文件夹（ll 结果是详细,有时间,</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={9A26314E-3D14-4B11-9C65-8F3062C200F8}&E7&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">touch （touch：创建文件）创建文件</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={9A26314E-3D14-4B11-9C65-8F3062C200F8}&E9&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">mkdir （mkdir：创建目录） 创建目录</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={9A26314E-3D14-4B11-9C65-8F3062C200F8}&EB&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">cat （concatenate：显示或把多个文本文件连接起来）查看文件命令（可以快捷查看当前文件的内</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={9A26314E-3D14-4B11-9C65-8F3062C200F8}&F3&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">more （more：更多的意思）分页查看文件命令（不能快速定位到最后一页）</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={DA9CB2AD-BC4C-4FAC-ADB7-772BA8951298}&AE&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">less （lese：较少的意思）分页查看文件命令（可以快速定位到最后一页）</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={DE16D083-F97E-4561-97C0-3A3B300829BC}&A&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">tail（尾巴） 查看文件命令（看最后多少行）</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={DE16D083-F97E-4561-97C0-3A3B300829BC}&16&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">cp（copy单词缩写，复制功能</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={DE16D083-F97E-4561-97C0-3A3B300829BC}&32&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">mv（move单词缩写，移动功能，该文件名称功能）</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={DE16D083-F97E-4561-97C0-3A3B300829BC}&47&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">rm（remove：移除的意思）删除文件，或文件夹</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={DE16D083-F97E-4561-97C0-3A3B300829BC}&A2&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">fifind （fifind：找到的意思）查找指定文件或目录</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={DE16D083-F97E-4561-97C0-3A3B300829BC}&F0&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">vi （VIsual：视觉）文本编辑器 类似win的记事本 （操作类似于地下的vim命令，看底下vim 的操</a><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={DE16D083-F97E-4561-97C0-3A3B300829BC}&F2&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">作）</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={DE16D083-F97E-4561-97C0-3A3B300829BC}&F4&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">vim （VI IMproved：改进版视觉）改进版文本编辑器 （不管是文件查看还是文件编辑 按 Shift + 上或</a><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={DE16D083-F97E-4561-97C0-3A3B300829BC}&F6&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">者下可以上下移动查看视角）</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={DE16D083-F97E-4561-97C0-3A3B300829BC}&FF&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">| 管道命令（把多个命令组合起来使用）</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={8DFFABF0-6FC5-459C-B2E0-2FCCF58C05C2}&19&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">grep （grep ：正则表达式）正则表达式，用于字符串的搜索工作(模糊查询)。不懂可以先过</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={8DFFABF0-6FC5-459C-B2E0-2FCCF58C05C2}&2C&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">yum install -y lrzsz 命令（实现win到Linux文件互相简单上传文件）</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={8DFFABF0-6FC5-459C-B2E0-2FCCF58C05C2}&3E&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">tar （解压 压缩 命令）</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={8DFFABF0-6FC5-459C-B2E0-2FCCF58C05C2}&47&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">ps （process status：进程状态，类似于windows的任务管理器）</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={8DFFABF0-6FC5-459C-B2E0-2FCCF58C05C2}&53&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">clear 清屏命令。</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={8DFFABF0-6FC5-459C-B2E0-2FCCF58C05C2}&5E&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">kill指令</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={8DFFABF0-6FC5-459C-B2E0-2FCCF58C05C2}&66&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">ifconfifig命令</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={8DFFABF0-6FC5-459C-B2E0-2FCCF58C05C2}&72&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">ping （用于检测与目标的连通性）语法：ping ip地址</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={8DFFABF0-6FC5-459C-B2E0-2FCCF58C05C2}&78&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">free 命令 （显示系统内存）</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={8DFFABF0-6FC5-459C-B2E0-2FCCF58C05C2}&81&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">top 命令</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={8DFFABF0-6FC5-459C-B2E0-2FCCF58C05C2}&8D&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">netstat 命令</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={8DFFABF0-6FC5-459C-B2E0-2FCCF58C05C2}&93&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">fifile （可查看文件类型）</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={8DFFABF0-6FC5-459C-B2E0-2FCCF58C05C2}&9D&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">重启linux</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={8DFFABF0-6FC5-459C-B2E0-2FCCF58C05C2}&9F&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">关机linux</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={8DFFABF0-6FC5-459C-B2E0-2FCCF58C05C2}&A1&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">同步时间命令</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={8DFFABF0-6FC5-459C-B2E0-2FCCF58C05C2}&A3&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">更改为北京时间命令</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={8DFFABF0-6FC5-459C-B2E0-2FCCF58C05C2}&A5&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">查看时间命令：</a></p><p><a href="onenote:#linux命令&section-id={44B498D6-A518-443F-8C52-13F8CE0811F2}&page-id={7D79A25B-C637-4B0E-A434-47829260B059}&object-id={01FAA507-E64F-4FC0-833B-507A3B2C60FC}&11&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/linux命令.one">netstat查看服务及监听端口详解</a></p><p>cd （change directory：英文释义是改变目录）切换目录 </p><p>cd ..&#x2F; ;跳到上级目录 </p><p>cd &#x2F;opt ;不管现在到那直接跳到指定的opt文件夹中 </p><p>cd ~ ;切换当前用户的家目录。root用户的家目录就是root目录。 </p><p>pwd （print working directory：显示当前工作目录的绝对路径） </p><p>ls （ls：list的缩写，查看列表）查看当前目录下的所有文件夹（ls 只列出文件名或目录名） </p><p>ls -a ;显示所有文件夹,隐藏文件也显示出来 </p><p>ls -R ;连同子目录一起列出来 </p><p>ll （ll：list的缩写，查看列表详情）查看当前目录下的所有详细信息和文件夹（ll 结果是详细,有时间, </p><p>是否可读写等信息） </p><p>ls -a ;显示所有文件夹,隐藏文件也显示出来 </p><p>ls-R ;连同子目录一 起列出来 </p><p>touch （touch：创建文件）创建文件 </p><p>touch test.txt ;创建test.txt文件 </p><p>touch &#x2F;opt&#x2F;java&#x2F;test.java ;在指定目录创建test.java文件 </p><p>mkdir （mkdir：创建目录） 创建目录 </p><p>mkdir 文件夹名称 ;在此目录创建文件夹 </p><p>mkdir &#x2F;opt&#x2F;java&#x2F;jdk ;在指定目录创建文件夹 </p><p>cat （concatenate：显示或把多个文本文件连接起来）查看文件命令（可以快捷查看当前文件的内 </p><p>容）（不能快速定位到最后一页） </p><p>cat lj.log ;快捷查看文件命令 </p><p>Ctrl + c ;暂停显示文件 </p><p>Ctrl + d ;退出查看文件命令</p><p>more （more：更多的意思）分页查看文件命令（不能快速定位到最后一页） </p><p>回车：向下n行，需要定义，默认为1行。 </p><p>空格键：向下滚动一屏或Ctrl+F </p><p>B：返回上一层或Ctrl+B </p><p>q：退出more </p><p>less （lese：较少的意思）分页查看文件命令（可以快速定位到最后一页） </p><p>less -m 显示类似于more命令的百分比。 </p><p>less -N 显示每行的行号。(大写的N) </p><p>两参数一起使用如：less -mN 文件名，如此可分页并显示行号。 </p><p>空格键：前下一页或page down。 </p><p>回车：向下一行。</p><p>b：后退一页 或 page up。 </p><p>q：退出。 </p><p>d：前进半页。 </p><p>u：后退半页 </p><p>tail（尾巴） 查看文件命令（看最后多少行） </p><p>tail -10 ;文件名 看最后10行</p><p>cp（copy单词缩写，复制功能</p><p>cp &#x2F;opt&#x2F;java&#x2F;java.log &#x2F;opt&#x2F;logs&#x2F; ;把java.log 复制到&#x2F;opt&#x2F;logs&#x2F;下 </p><p>cp &#x2F;opt&#x2F;java&#x2F;java.log &#x2F;opt&#x2F;logs&#x2F;aaa.log ;把java.log 复制到&#x2F;opt&#x2F;logs&#x2F;下并且改名为 aaa.log </p><p>cp -r &#x2F;opt&#x2F;java &#x2F;opt&#x2F;logs ;把文件夹及内容复制到logs文件中 ） </p><p>mv（move单词缩写，移动功能，该文件名称功能）</p><p>mv &#x2F;opt&#x2F;java&#x2F;java.log &#x2F;opt&#x2F;mysql&#x2F; ;移动文件到mysql目录下 </p><p>mv java.log mysql.log ;把java.log改名为mysql.log </p><p>rm（remove：移除的意思）删除文件，或文件夹</p><p>-f或–force 强制删除文件或目录。删除文件不包括文件夹的文件 </p><p>-r或-R或–recursive 递归处理，将指定目录下的所有文件及子目录一并删除。 </p><p>-rf 强制删除文件夹及内容 </p><p>rm 文件名 ;安全删除命令 （yes删除 no取消） </p><p>rm -rf 强制删除文件夹及内容 </p><p>rm -rf * 删除当前目录下的所有内容。 </p><p>rm -rf &#x2F;* 删除Linux系统根目录下所有的内容。系统将完蛋。</p><p>fifind （fifind：找到的意思）查找指定文件或目录</p><p>* 表示0~多个任意字符。 </p><p>find -name 文件名;按照指定名称查找在当前目录下查找文件 </p><p>find &#x2F; -name 文件名按照指定名称全局查找文件 </p><p>find -name ‘*文件名’ ;任意前缀加上文件名在当前目录下查找文件 </p><p>find &#x2F; -name ‘<em>文件名</em>‘ ;全局进行模糊查询带文件名的文件 </p><p>vi （VIsual：视觉）文本编辑器 类似win的记事本 （操作类似于地下的vim命令，看底下vim 的操 </p><p>作） </p><p>vim （VI IMproved：改进版视觉）改进版文本编辑器 （不管是文件查看还是文件编辑 按 Shift + 上或 </p><p>者下可以上下移动查看视角） </p><img src="/2024/04/08/linux%E5%91%BD%E4%BB%A4/clip_image002.jpg" class="" title="iii"><p>| 管道命令（把多个命令组合起来使用） </p><p>管道命令的语法：命令1 | 命令2 | 命令3。 </p><p>grep （grep ：正则表达式）正则表达式，用于字符串的搜索工作(模糊查询)。不懂可以先过</p><img src="/2024/04/08/linux%E5%91%BD%E4%BB%A4/clip_image004.jpg" class="" title="iii"><p>yum install -y lrzsz 命令（实现win到Linux文件互相简单上传文件） </p><img src="/2024/04/08/linux%E5%91%BD%E4%BB%A4/clip_image006.jpg" class="" title="iii"><p>tar （解压 压缩 命令） </p><p><img src="file:///C:/Users/zhiyo/AppData/Local/Temp/msohtmlclip1/01/clip_image008.jpg" alt="iii "></p><p>ps （process status：进程状态，类似于windows的任务管理器）</p><img src="/2024/04/08/linux%E5%91%BD%E4%BB%A4/clip_image010.jpg" class="" title="常 用 组 合 《 ps -ef 标 准 的 格 式 查 看 系 统 进 程  BSD 格 式 查 看 系 统 进 程  PS —aux  ps 一 u grep redi 5 BSD 格 式 查 看 进 程 名 称 带 有 red 、 5 的 系 统 进 程 （ 常 用 披 巧 ）  &#x2F; &#x2F; 显 示 进 程 的 一 些 属 性 ， 需 要 了 解 ()s aux)  USER  PID  XCPIJ  RSS  STAT  START  TIME  &#x2F; &#x2F; 用 户 名  &#x2F; &#x2F; 进 程 ID 号 ， 用 来 杀 死 进 程 的  &#x2F; &#x2F; 进 程 占 用 邮 ℃ PLI 的 百 分 比  &#x2F; &#x2F; 占 用 内 存 的 的 百 分 比  &#x2F; &#x2F; 该 进 程 使 用 的 虚 担 内 存 量 （ KB)  &#x2F; &#x2F; 该 进 程 占 用 的 固 定 内 存 量 (KB)  &#x2F; &#x2F; 进 程 的 状 态  &#x2F; &#x2F; 该 进 程 被 发 启 动 时 间  &#x2F; &#x2F; 该 进 程 实 际 使 用 （ PLI 运 行 的 时 间"><p>clear 清屏命令。</p><p>kill指令</p><img src="/2024/04/08/linux%E5%91%BD%E4%BB%A4/clip_image012.jpg" class="" title="iii"><p>ifconfifig命令</p><img src="/2024/04/08/linux%E5%91%BD%E4%BB%A4/clip_image014.jpg" class="" title="iii"><p>ping （用于检测与目标的连通性）语法：ping ip地址</p><img src="/2024/04/08/linux%E5%91%BD%E4%BB%A4/clip_image016.jpg" class="" title="1 、 在 nd 鳢 5 操 作 系 统 中 囗 cmd 囗 、 pconfig, 查 看 本 机 IP 地 址 《  2 、 再 到 Llnu 又 系 统 中 输 人 ping 讠 0 地 址  （ 公 司 电 蕕 ． 我 就 不 暴 露 Ip 了 ， 没 片 自 己 去 试 ）  *üctrl + （ 可 以 停 止 试 。"><p>free 命令 （显示系统内存） </p><img src="/2024/04/08/linux%E5%91%BD%E4%BB%A4/clip_image018.jpg" class="" title="# 显 示 系 统 内 存 使 用 情 况 ． 包 括 物 理 内 存 、 交 互 区 内 存 （ 5 翮 p ） 和 内 核 缓 冲 区 内 存 ·  -b 以 te 显 示 内 存 使 用 情 况  -k 以 kb 为 单 位 显 示 内 存 使 用 情 况  -m 如 b 为 单 位 显 示 内 存 使 用 情 况  -g 以 gb 为 单 位 显 示 内 存 使 用 情 况  一 5 &lt; 间 隔 杪 数 &gt; 持 续 显 示 内 存  -t 显 示 内 存 使 用 总 合"><p>top 命令</p><img src="/2024/04/08/linux%E5%91%BD%E4%BB%A4/clip_image020.jpg" class="" title="# 显 示 当 前 系 统 止 在 执 行 的 进 程 的 相 关 信 息 ， 包 括 进 程 rm 内 存 占 用 率 、 CPU 占 用 率 等  c 显 示 完 整 的 进 程 命 令  5 保 密 模 式  p &lt; 进 程 号 &gt; 指 定 进 程 显 示  n &lt; 次 数 &gt; 循 环 显 示 次 数"><p>netstat 命令 </p><p><img src="/linux%E5%91%BD%E4%BB%A4/clip_image022.jpg" alt="*Linux  netStat [-acCeFghi IMnNoprstuVvWx] [--ip] "></p><p>fifile （可查看文件类型） </p><p>file 文件名 </p><p>重启linux</p><p>Linux centos 重启命令：reboot </p><p>关机linux</p><p>Linux centos 关机命令：halt </p><p>同步时间命令 </p><p>ntpdate ntp1.aliyun.com </p><p>更改为北京时间命令 </p><p>rm -rf &#x2F;etc&#x2F;localtime </p><p>ln -s &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai &#x2F;etc&#x2F;localtime </p><p>查看时间命令： </p><p>date</p><p>netstat查看服务及监听端口详解</p><img src="/2024/04/08/linux%E5%91%BD%E4%BB%A4/clip_image024.jpg" class="" title="-a ü—all  _A  -c Ü—continuous  -C ü—cache  -e ü—extend  _F ü-fib  -g ü—groups  -h ü—help  -l Ü—listening  -M ü—masquerade  -n ü—numeric  -o ü—timers  -p ü—programs  -r  _t ü—tcp *TCP  -" alt="ä,-verbose  -V ü—version  _wü—raw  -eunix  *FIB.  Routing Table."><p><a href="https://blog.csdn.net/wade3015/article/details/90779669">https://blog.csdn.net/wade3015/article/details/90779669</a></p>]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> linux命令 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式微服务</title>
      <link href="/2024/04/08/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
      <url>/2024/04/08/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<h1 id="分布式系统的设计目标"><a href="#分布式系统的设计目标" class="headerlink" title="分布式系统的设计目标"></a>分布式系统的设计目标</h1><img src="/2024/04/08/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1/clip_image002.jpg" class="" title="img"><p>无状态：比如说session存储在一台机器上，用户访问的时候若是第一台则显示登陆，若是第二台则显示不登录，这样是不行的</p><p>可管理：有一条调用链，A调用B，B调用C，哪一个服务出现了问题应该能快速发现问题所在</p><h1 id="分布式系统中常用的缓存方案"><a href="#分布式系统中常用的缓存方案" class="headerlink" title="分布式系统中常用的缓存方案"></a>分布式系统中常用的缓存方案</h1><img src="/2024/04/08/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1/clip_image004.jpg" class="" title="img"><p>nginx会存一些css，js</p><p>服务器端：本地缓存：map，list</p><p>外部缓存：redis</p><h1 id="CAP理论，BASE理论"><a href="#CAP理论，BASE理论" class="headerlink" title="CAP理论，BASE理论"></a>CAP理论，BASE理论</h1><img src="/2024/04/08/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1/clip_image005.jpg" class="" title="img"><img src="/2024/04/08/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1/clip_image006.jpg" class="" title="img"><h1 id="服务熔断和降级"><a href="#服务熔断和降级" class="headerlink" title="服务熔断和降级"></a>服务熔断和降级</h1><h2 id="服务降级-系统有限的资源的合理协调"><a href="#服务降级-系统有限的资源的合理协调" class="headerlink" title="服务降级:系统有限的资源的合理协调"></a>服务降级:系统有限的资源的合理协调</h2><ul><li>概念：服务降级一般是指在服务器压力剧增的时候，根据实际业务使用情况以及流量，对一些服务和页面有策略的不处理或者用一种简单的方式进行处理，从而释放服务器资源的资源以保证核心业务的正常高效运行。</li><li>原因： 服务器的资源是有限的，而请求是无限的。在用户使用即并发高峰期，会影响整体服务的性能，严重的话会导致宕机，以至于某些重要服务不可用。故高峰期为了保证核心功能服务的可用性，就需要对某些服务降级处理。可以理解为舍小保大</li><li>应用场景： 多用于微服务架构中，一般当整个微服务架构整体的负载超出了预设的上限阈值（和服务器的配置性能有关系），或者即将到来的流量预计会超过预设的阈值时（比如双11、6.18等活动或者秒杀活动）</li><li>服务降级是从整个系统的负荷情况出发和考虑的，对某些负荷会比较高的情况，为了预防某些功能（业务场景）出现负荷过载或者响应慢的情况，在其内部暂时舍弃对一些非核心的接口和数据的请求，而直接返回一个提前准备好的fallback（退路）错误处理信息。这样，虽然提供的是一个有损的服务，但却保证了整个系统的稳定性和可用性。</li><li>需要考虑的问题：</li></ul><p>区分那些服务为核心？那些非核心</p><p>降级策略（处理方式，一般指如何给用户友好的提示或者操作）自动降级还是手动降</p><h2 id="服务熔断："><a href="#服务熔断：" class="headerlink" title="服务熔断："></a>服务熔断：</h2><p>应对雪崩效应的链路自我保护机制。可看作降级的特殊情况</p><ul><li>概念：应对微服务雪崩效应的一种链路保护机制，类似股市、保险丝</li><li>原因： 微服务之间的数据交互是通过远程调用来完成的。服务A调用服务，服务B调用服务c，某一时间链路上对服务C的调用响应时间过长或者服务C不可用，随着时间的增长，对服务C的调用也越来越多，然后服务C崩溃了，但是链路调用还在，对服务B的调用也在持续增多，然后服务B崩溃，随之A也崩溃，导致雪崩效应</li><li>服务熔断是应对雪崩效应的一种微服务链路保护机制。例如在高压电路中，如果某个地方的电压过高，熔断器就会熔断，对电路进行保护。同样，在微服务架构中，熔断机制也是起着类似的作用。当调用链路的某个微服务不可用或者响应时间太长时，会进行服务熔断，不再有该节点微服务的调用，快速返回错误的响应信息。当检测到该节点微服务调用响应正常后，恢复调用链路。</li><li>服务熔断的作用类似于我们家用的保险丝，当某服务出现不可用或响应超时的情况时，为了防止整个系统出现雪崩，暂时停止对该服务的调用。</li><li>在Spring Cloud框架里，熔断机制通过Hystrix实现。Hystrix会监控微服务间调用的状况，当失败的调用到一定阈值，缺省是5秒内20次调用失败，就会启动熔断机制。</li><li>应用场景：微服务架构中，多个微服务相互调用出使用</li><li>需要考虑问题：</li></ul><p>如何所依赖的服务对象不稳定</p><p>失败之后如何快速恢复依赖对象，如何探知依赖对象是否恢复</p><h2 id="服务降级和服务熔断区别"><a href="#服务降级和服务熔断区别" class="headerlink" title="服务降级和服务熔断区别"></a>服务降级和服务熔断区别</h2><ul><li>触发原因不一样，服务熔断由链路上某个服务引起的，服务降级是从整体的负载考虑</li><li>管理目标层次不一样，服务熔断是一个框架层次的处理，服务降级是业务层次的处理</li><li>实现方式不一样，服务熔断一般是自我熔断恢复，服务降级相当于人工控制</li><li>触发原因不同 服务熔断一般是某个服务（下游服务）故障引起，而服务降级一般是从整体负荷考虑；</li></ul><h2 id="一句话："><a href="#一句话：" class="headerlink" title="一句话："></a>一句话：</h2><ul><li>服务熔断是应对系统服务雪崩的一种保险措施，给出的一种特殊降级措施。而服务降级则是更加宽泛的概念，主要是对系统整体资源的合理分配以应对压力。</li><li>服务熔断是服务降级的一种特殊情况，他是防止服务雪崩而采取的措施。系统发生异常或者延迟或者流量太大，都会触发该服务的服务熔断措施，链路熔断，返回兜底方法。这是对局部的一种保险措施。</li><li>服务降级是对系统整体资源的合理分配。区分核心服务和非核心服务。对某个服务的访问延迟时间、异常等情况做出预估并给出兜底方法。这是一种全局性的考量，对系统整体负荷进行管理。</li><li>限流：限制并发的请求访问量，超过阈值则拒绝；</li><li>降级：服务分优先级，牺牲非核心服务（不可用），保证核心服务稳定；从整体负荷考虑；</li><li>熔断：依赖的下游服务故障触发熔断，避免引发本系统崩溃；系统自动执行和恢复</li></ul><p><a href="https://zhuanlan.zhihu.com/p/341939685">https://zhuanlan.zhihu.com/p/341939685</a></p><img src="/2024/04/08/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1/clip_image007.jpg" class="" title="img"><p><a href="https://www.infoq.cn/article/uhixhowebu_tyjewjwcl">https://www.infoq.cn/article/uhixhowebu_tyjewjwcl</a></p><h1 id="限流策略"><a href="#限流策略" class="headerlink" title="限流策略"></a>限流策略</h1><p>「两窗两桶」。两窗就是：固定窗口、滑动窗口，两桶就是：漏桶、令牌桶。</p><p>1.固定窗口</p><p>固定窗口就是定义一个“固定”的统计周期，比如 1 分钟或者 30 秒、10 秒这样。然后在每个周期统计当前周期中被接收到的请求数量，经过计数器累加后如果达到设定的阈值就触发「流量干预」。直到进入下一个周期后，计数器清零，流量接收恢复正常状态。</p><p>2.滑动窗口</p><p>滑动窗口其实就是对固定窗口做了进一步的细分，将原先的粒度切的更细，比如 1 分钟的固定窗口切分为 60 个 1 秒的滑动窗口。然后统计的时间范围随着时间的推移同步后移。</p><p>3.漏桶</p><p>漏桶模式的核心是固定“出口”的速率，不管进来多少量，出去的速率一直是这么多。如果涌入的量多到桶都装不下了，那么就进行「流量干预」。</p><p>4.令牌桶</p><p>令牌桶模式的核心是固定“进口”速率。先拿到令牌，再处理请求，拿不到令牌就被「流量干预」。因此，当大量的流量进入时，只要令牌的生成速度大于等于请求被处理的速度，那么此刻的程序处理能力就是极限。</p><p><a href="https://www.infoq.cn/article/uhixhowebu_tyjewjwcl">https://www.infoq.cn/article/uhixhowebu_tyjewjwcl</a></p><h1 id="Eureka和Zookeeper的区别"><a href="#Eureka和Zookeeper的区别" class="headerlink" title="Eureka和Zookeeper的区别"></a>Eureka和Zookeeper的区别</h1><p>1、Zookeeper当master挂了，会在30-120s进行leader选举，这点类似于redis的哨兵机制，在选举期间Zookeeper是不可用的，这么长时间不能进行服务注册，是无法忍受的，别说30s，5s都不能忍受。这时Zookeeper集群会瘫痪，这也是Zookeeper的CP，保持节点的一致性，牺牲了A&#x2F;高可用。而Eureka不会，即使Eureka有部分挂掉，还有其他节点可以使用的，他们保持平级的关系，只不过信息有可能不一致，这就是AP，牺牲了C&#x2F;一致性。</p><p>2、在之前的文章已经提到过Eureka有自我保护机制（15分钟内超过85%的服务节点没有心跳&#x2F;down），这点我觉得确实要比Zookeeper好，即使服务不可用，也会保留当前失效的微服务，默认90秒，在这90秒Eureka不会注销微服务，在这90秒内仍然可以接受新的服务注册，只是不会同步到其他节点上。当坏掉的服务恢复的时候，会自动加入到节点上，也是高可用的一种。然后退出自我保护机制，这也是应对网络异常的一种机制</p><p>总结：Zookeeper出现网络等故障的时候导致整个服务注册瘫痪太要命了。Eureka能很好的应对网络故障导致失去节点的情况。</p><p>●Eureka：AP架构设计(高可用、分区容错性)，Zookeeper：CP架构设计（一致性、分区容错性）</p><p>那什么是AP、什么是CP，这个就是关于分布式的CAP理论（面试题）:</p><p>C - Consistent-一致性 A - Availability-可用性 P - Partition tolerance -分区容错性</p><p>分布式系统之所以叫分布式，是因为提供服务的各个节点分布在不同机器上，相互之间通过网络交互。那么必然存在网络故障断开的风险，这个网络断开的专业场景成为网络分区。网络分区多个分布式节点无法进行通信，我们对于一个节点无法操作到另外一个节点，数据的一致性没办法满足，因为多节点的数据不再保持一致。如果要保持一致，我们必然要牺牲高可用，也就是需要暂停一部分的服务，不提供对数据的操作(修改、更新等)功能，等到网络恢复的时候再对外服务。当然也可以保证高可用，牺牲数据一致性</p><p>关于CAP理论大概的结论:在网络分区时，不能同时保证高可用和一致性</p><p>目前任何分布式系统都没办法同时满足3个，只能3选其2，分布式系统之所以叫分布式，都是分散在不同的服务器，P是必须要满足的，所以只能选择A或者C了</p><p>在很多的公司以及业务场景，很多会选择保持数据的一致性，在京东&#x2F;双十一这样的情况，只能保证AP，不能保证CP。但也有高可用的.比如某米公司，一次在进行手机抢购的时候，牺牲了数据的一致性，当添加到购物车，然后付款，却发现没有库存了，他保证了服务高可用，但牺牲了数据的一致性 </p><h1 id="一致性Hash"><a href="#一致性Hash" class="headerlink" title="一致性Hash"></a>一致性Hash</h1><p>对2的32次方取模</p><img src="/2024/04/08/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1/clip_image009.jpg" class="" title="img"><p>*<strong>*<em><em><strong><strong>容错性：一台宕机了只用移动部分数据*</strong></strong></em>*</em></strong></p><p>*<strong>*<em><em><strong><strong>可扩展性：增加一台只用移动部分数据*</strong></strong></em>*</em></strong></p><p>*<strong>*<em><em><strong><strong>数据倾斜问题：虚拟节点机制*</strong></strong></em>*</em></strong></p><p>一致性Hash算法引入了虚拟节点机制，即对每一个服务器节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体操作可以为服务器IP或主机名后加入编号来实现。</p><img src="/2024/04/08/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1/clip_image011.jpg" class="" title="img"><img src="/2024/04/08/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1/clip_image013.jpg" class="" title="img"><h1 id="分布式ID"><a href="#分布式ID" class="headerlink" title="分布式ID"></a>分布式ID</h1><h2 id="分布式ID方案总结"><a href="#分布式ID方案总结" class="headerlink" title="分布式ID方案总结"></a><strong>分布式ID方案总结</strong></h2><p>ID是数据的唯一标识，传统的做法是利用UUID和数据库的自增ID，在互联网企业中，大部分公司使用的都是Mysql，并且因为需要事务支持，所以通常会使用Innodb存储引擎，UUID太长以及无序，所以并不适合在Innodb中来作为主键，自增ID比较合适，但是随着公司的业务发展，数据量将越来越大，需要对数据进行分表，而分表后，每个表中的数据都会按自己的节奏进行自增，很有可能出现ID冲突。这时就需要一个单独的机制来负责生成唯一ID，生成出来的ID也可以叫做<strong>分布式ID</strong>，或<strong>全局ID</strong>。下面来分析各个生成分布式ID的机制。</p><img src="/2024/04/08/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1/clip_image015.gif" class="" title="img"><p>这篇文章并不会分析的特别详细，主要是做一些总结，以后再出一些详细某个方案的文章。</p><h3 id="数据库自增ID"><a href="#数据库自增ID" class="headerlink" title="数据库自增ID"></a><strong>数据库自增ID</strong></h3><p>第一种方案仍然还是基于数据库的自增ID，需要单独使用一个数据库实例，在这个实例中新建一个单独的表：</p><p>表结构如下：</p><p>CREATE DATABASE <code>SEQID</code>;</p><p>CREATE TABLE SEQID.SEQUENCE_ID (<br>     id bigint(20) unsigned NOT NULL auto_increment,<br>     stub char(10) NOT NULL default ‘’,<br>     PRIMARY KEY (id),<br>     UNIQUE KEY stub (stub)<br> ) ENGINE&#x3D;MyISAM;</p><p>可以使用下面的语句生成并获取到一个自增ID</p><p>begin;<br> replace into SEQUENCE_ID (stub) VALUES (‘anyword’);<br> select last_insert_id();<br> commit;</p><p>stub字段在这里并没有什么特殊的意义，只是为了方便的去插入数据，只有能插入数据才能产生自增id。而对于插入我们用的是replace，replace会先看是否存在stub指定值一样的数据，如果存在则先delete再insert，如果不存在则直接insert。</p><p>这种生成分布式ID的机制，需要一个单独的Mysql实例，虽然可行，但是基于性能与可靠性来考虑的话都不够，<strong>业务系统每次需要一个ID时，都需要请求数据库获取，性能低，并且如果此数据库实例下线了，那么将影响所有的业务系统。</strong></p><p>为了解决数据库可靠性问题，我们可以使用第二种分布式ID生成方案。</p><h3 id="数据库多主模式"><a href="#数据库多主模式" class="headerlink" title="数据库多主模式"></a><strong>数据库多主模式</strong></h3><p>如果我们两个数据库组成一个<strong>主从模式</strong>集群，正常情况下可以解决数据库可靠性问题，但是如果主库挂掉后，数据没有及时同步到从库，这个时候会出现ID重复的现象。我们可以使用<strong>双主模式</strong>集群，也就是两个Mysql实例都能单独的生产自增ID，这样能够提高效率，但是如果不经过其他改造的话，这两个Mysql实例很可能会生成同样的ID。需要单独给每个Mysql实例配置不同的起始值和自增步长。</p><p>第一台Mysql实例配置：</p><p>set @@auto_increment_offset &#x3D; 1;   – 起始值<br> set @@auto_increment_increment &#x3D; 2; – 步长</p><p>第二台Mysql实例配置：</p><p>set @@auto_increment_offset &#x3D; 2;   – 起始值<br> set @@auto_increment_increment &#x3D; 2; – 步长</p><p>经过上面的配置后，这两个Mysql实例生成的id序列如下：</p><p>mysql1,起始值为1,步长为2,ID生成的序列为：1,3,5,7,9,…</p><p>mysql2,起始值为2,步长为2,ID生成的序列为：2,4,6,8,10,…</p><p>对于这种生成分布式ID的方案，需要单独新增一个生成分布式ID应用，比如DistributIdService，该应用提供一个接口供业务应用获取ID，业务应用需要一个ID时，通过rpc的方式请求DistributIdService，DistributIdService随机去上面的两个Mysql实例中去获取ID。</p><p>实行这种方案后，就算其中某一台Mysql实例下线了，也不会影响DistributIdService，DistributIdService仍然可以利用另外一台Mysql来生成ID。</p><p>但是这种方案的扩展性不太好，如果两台Mysql实例不够用，需要新增Mysql实例来提高性能时，这时就会比较麻烦。</p><p>现在如果要新增一个实例mysql3，要怎么操作呢？</p><p>第一，mysql1、mysql2的步长肯定都要修改为3，而且只能是人工去修改，这是需要时间的。</p><p>第二，因为mysql1和mysql2是不停在自增的，对于mysql3的起始值我们可能要定得大一点，以给充分的时间去修改mysql1，mysql2的步长。</p><p>第三，在修改步长的时候很可能会出现重复ID，要解决这个问题，可能需要停机才行。</p><p>为了解决上面的问题，以及能够进一步提高DistributIdService的性能，如果使用第三种生成分布式ID机制。</p><h3 id="号段模式"><a href="#号段模式" class="headerlink" title="号段模式"></a><strong>号段模式</strong></h3><p>我们可以使用号段的方式来获取自增ID，号段可以理解成批量获取，比如DistributIdService从数据库获取ID时，如果能批量获取多个ID并缓存在本地的话，那样将大大提供业务应用获取ID的效率。</p><p>比如DistributIdService每次从数据库获取ID时，就获取一个号段，比如(1,1000]，这个范围表示了1000个ID，业务应用在请求DistributIdService提供ID时，DistributIdService只需要在本地从1开始自增并返回即可，而不需要每次都请求数据库，一直到本地自增到1000时，也就是当前号段已经被用完时，才去数据库重新获取下一号段。</p><p>所以，我们需要对数据库表进行改动，如下：</p><p>CREATE TABLE id_generator (<br>  id int(10) NOT NULL,<br>  current_max_id bigint(20) NOT NULL COMMENT ‘当前最大id’,<br>  increment_step int(10) NOT NULL COMMENT ‘号段的长度’,<br>  PRIMARY KEY (<code>id</code>)<br> ) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8;</p><p>这个数据库表用来记录自增步长以及当前自增ID的最大值（也就是当前已经被申请的号段的最后一个值），因为自增逻辑被移到DistributIdService中去了，所以数据库不需要这部分逻辑了。</p><p>这种方案不再强依赖数据库，就算数据库不可用，那么DistributIdService也能继续支撑一段时间。但是如果DistributIdService重启，会丢失一段ID，导致ID空洞。</p><p>为了提高DistributIdService的高可用，需要做一个集群，业务在请求DistributIdService集群获取ID时，会随机的选择某一个DistributIdService节点进行获取，对每一个DistributIdService节点来说，数据库连接的是同一个数据库，那么可能会产生多个DistributIdService节点同时请求数据库获取号段，那么这个时候需要利用乐观锁来进行控制，比如在数据库表中增加一个version字段，在获取号段时使用如下SQL：</p><p>update id_generator set current_max_id&#x3D;#{newMaxId}, version&#x3D;version+1 where version &#x3D; #{version}</p><p>因为newMaxId是DistributIdService中根据oldMaxId+步长算出来的，只要上面的update更新成功了就表示号段获取成功了。</p><p>为了提供数据库层的高可用，需要对数据库使用多主模式进行部署，对于每个数据库来说要保证生成的号段不重复，这就需要利用最开始的思路，再在刚刚的数据库表中增加起始值和步长，比如如果现在是两台Mysql，那么</p><p>mysql1将生成号段（1,1001]，自增的时候序列为1，3，4，5，7….</p><p>mysql1将生成号段（2,1002]，自增的时候序列为2，4，6，8，10…</p><p>更详细的可以参考滴滴开源的TinyId： <a href="https://github.com/didi/tinyid/wiki/tinyid%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D">https://github.com/didi/tinyid/wiki/tinyid%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D</a></p><p>在TinyId中还增加了一步来提高效率，在上面的实现中，ID自增的逻辑是在DistributIdService中实现的，而实际上可以把自增的逻辑转移到业务应用本地，这样对于业务应用来说只需要获取号段，每次自增时不再需要请求调用DistributIdService了。</p><h3 id="雪花算法"><a href="#雪花算法" class="headerlink" title="雪花算法"></a><strong>雪花算法</strong></h3><p>上面的三种方法总的来说是基于自增思想的，而接下来就介绍比较著名的雪花算法-snowflake。</p><p>我们可以换个角度来对分布式ID进行思考，只要能让负责生成分布式ID的每台机器在每毫秒内生成不一样的ID就行了。</p><p>snowflake是twitter开源的分布式ID生成算法，是一种算法，所以它和上面的三种生成分布式ID机制不太一样，它不依赖数据库。</p><p>核心思想是：分布式ID固定是一个long型的数字，一个long型占8个字节，也就是64个bit，原始snowflake算法中对于bit的分配如下图：</p><img src="/2024/04/08/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1/clip_image017.gif" class="" title="img"><ul><li><ul><li>第一个bit位是标识部分，在java中由于long的最高位是符号位，正数是0，负数是1，一般生成的ID为正数，所以固定为0。</li><li>时间戳部分占41bit，这个是毫秒级的时间，一般实现上不会存储当前的时间戳，而是时间戳的差值（当前时间-固定的开始时间），这样可以使产生的ID从更小值开始；41位的时间戳可以使用69年，(1L &lt;&lt; 41) &#x2F; (1000L * 60 * 60 * 24 * 365) &#x3D; 69年</li><li>工作机器id占10bit，这里比较灵活，比如，可以使用前5位作为数据中心机房标识，后5位作为单机房机器标识，可以部署1024个节点。</li><li>序列号部分占12bit，支持同一毫秒内同一个节点可以生成4096个ID</li></ul></li></ul><p>根据这个算法的逻辑，只需要将这个算法用Java语言实现出来，封装为一个工具方法，那么各个业务应用可以直接使用该工具方法来获取分布式ID，只需保证每个业务应用有自己的工作机器id即可，而不需要单独去搭建一个获取分布式ID的应用。</p><p>snowflake算法实现起来并不难，提供一个github上用java实现的： <a href="https://github.com/beyondfengyu/SnowFlake">https://github.com/beyondfengyu/SnowFlake</a></p><p>在大厂里，其实并没有直接使用snowflake，而是进行了改造，因为snowflake算法中最难实践的就是工作机器id，原始的snowflake算法需要人工去为每台机器去指定一个机器id，并配置在某个地方从而让snowflake从此处获取机器id。</p><p>但是在大厂里，机器是很多的，人力成本太大且容易出错，所以大厂对snowflake进行了改造。</p><h3 id="百度（uid-generator）"><a href="#百度（uid-generator）" class="headerlink" title="百度（uid-generator）"></a><strong>百度（uid-generator）</strong></h3><p>github地址：<a href="https://github.com/baidu/uid-generator">uid-generator</a></p><p>uid-generator使用的就是snowflake，只是在生产机器id，也叫做workId时有所不同。</p><p>uid-generator中的workId是由uid-generator自动生成的，并且考虑到了应用部署在docker上的情况，在uid-generator中用户可以自己去定义workId的生成策略，默认提供的策略是：应用启动时由数据库分配。说的简单一点就是：应用在启动时会往数据库表(uid-generator需要新增一个WORKER_NODE表)中去插入一条数据，数据插入成功后返回的该数据对应的自增唯一id就是该机器的workId，而数据由host，port组成。</p><p>对于uid-generator中的workId，占用了22个bit位，时间占用了28个bit位，序列化占用了13个bit位，需要注意的是，和原始的snowflake不太一样，时间的单位是秒，而不是毫秒，workId也不一样，同一个应用每重启一次就会消费一个workId。</p><p>具体可参考 <a href="https://github.com/baidu/uid-generator/blob/master/README.zh_cn.md">https://github.com/baidu/uid-generator/blob/master/README.zh_cn.md</a></p><h3 id="美团（Leaf）"><a href="#美团（Leaf）" class="headerlink" title="美团（Leaf）"></a><strong>美团（Leaf）</strong></h3><p>github地址：<a href="https://github.com/Meituan-Dianping/Leaf">Leaf</a></p><p>美团的Leaf也是一个分布式ID生成框架。它非常全面，即支持号段模式，也支持snowflake模式。号段模式这里就不介绍了，和上面的分析类似。</p><p>Leaf中的snowflake模式和原始snowflake算法的不同点，也主要在workId的生成，Leaf中workId是基于ZooKeeper的顺序Id来生成的，每个应用在使用Leaf-snowflake时，在启动时都会都在Zookeeper中生成一个顺序Id，相当于一台机器对应一个顺序节点，也就是一个workId。</p><p><strong>总结</strong></p><p>总得来说，上面两种都是自动生成workId，以让系统更加稳定以及减少人工成功。</p><h3 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a><strong>Redis</strong></h3><p>这里额外再介绍一下使用Redis来生成分布式ID，其实和利用Mysql自增ID类似，可以利用Redis中的incr命令来实现原子性的自增与返回，比如：</p><p>127.0.0.1:6379&gt; set seq_id 1   &#x2F;&#x2F; 初始化自增ID为1<br> OK<br> 127.0.0.1:6379&gt; incr seq_id   &#x2F;&#x2F; 增加1，并返回<br> (integer) 2<br> 127.0.0.1:6379&gt; incr seq_id   &#x2F;&#x2F; 增加1，并返回<br> (integer) 3</p><p>使用redis的效率是非常高的，但是要考虑持久化的问题。Redis支持RDB和AOF两种持久化的方式。</p><p>RDB持久化相当于定时打一个快照进行持久化，如果打完快照后，连续自增了几次，还没来得及做下一次快照持久化，这个时候Redis挂掉了，重启Redis后会出现ID重复。</p><p>AOF持久化相当于对每条写命令进行持久化，如果Redis挂掉了，不会出现ID重复的现象，但是会由于incr命令过得，导致重启恢复数据时间过长。</p><h1 id="分布式选举"><a href="#分布式选举" class="headerlink" title="分布式选举"></a>分布式选举</h1><h2 id="分布式选举-1"><a href="#分布式选举-1" class="headerlink" title="分布式选举"></a><strong>分布式选举</strong></h2><p>主节点在一个分布式集群中负责对其他节点的协调和管理，也就是说其他节点都必须听从主节点的安排。主节点的存在就可以保证其他节点的有序运行，以及数据库集群中的写入数据在每个节点上的一致性。这里的一致性是指，数据在每个集群节点中都是一样的，不存在不同的情况。</p><p>当然，如果主故障了，集群就会天下大乱，就好比一个国家的皇帝驾崩了，国家大乱一样。比如，数据库集群中主节点故障后，可能导致每个节点上的数据会不一致。这，就应了那句话“国不可一日无君”，对应到分布式系统中就是“集群不可一刻无主”。总结来说，选举的作用就是选出一个主节点，由它来协调和管理其他节点，以保证集群有序运行和节点间数据的一致性。</p><p>那么，如何在集群中选出一个合适的主呢？这是一个技术活儿，目前常见的选主方法有基于序号选举的算法（ 比如，Bully 算法）、多数派算法（比如，Raft 算法、ZAB 算法）。</p><h3 id="长者为大：Bully算法"><a href="#长者为大：Bully算法" class="headerlink" title="长者为大：Bully算法"></a><strong>长者为大：</strong>Bully算法</h3><p>Bully 算法是一种霸道的集群选主算法，为什么说是霸道呢？因为它的选举原则是“长者”为大，即在所有活着的节点中，选取 ID 最大的节点作为主节点。在 Bully 算法中，节点的角色有两种：普通节点和主节点。初始化时，所有节点都是平等的，都是普通节点，并且都有成为主的权利。但是，当选主成功后，有且仅有一个节点成为主节点，其他所有节点都是普通节点。当且仅当主节点故障或与其他节点失去联系后，才会重新选主。Bully 算法在选举过程中，需要用到以下 3 种消息：</p><p> Election 消息，用于发起选举；</p><p> Alive 消息，对 Election 消息的应答；</p><p> Victory 消息，竞选成功的主节点向其他节点发送的宣誓主权的消息。</p><p>Bully 算法选举的原则是“长者为大”，意味着它的假设条件是，集群中每个节点均知道其他节点的 ID。在此前提下，其具体的选举过程是：</p><p> 集群中每个节点判断自己的 ID 是否为当前活着的节点中 ID 最大的，如果是，则直接向其他节点发送 Victory 消息，宣誓自己的主权；</p><p> 如果自己不是当前活着的节点中 ID 最大的，则向比自己 ID 大的所有节点发送 Election 消息，并等待其他节点的回复；</p><p> 若在给定的时间范围内，本节点没有收到其他节点回复的 Alive 消息，则认为自己成为主节点，并向其他节点发送 Victory 消息，宣誓自己成为主节点；若接收到来自比自己 ID 大的节点的 Alive 消息，则等待其他节点发送 Victory 消息；</p><p> 若本节点收到比自己 ID 小的节点发送的 Election 消息，则回复一个 Alive 消息，告知其他节点，我比你大，重新选举。</p><img src="/2024/04/08/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1/clip_image061.gif" class="" title="img"><p>目前已经有很多开源软件采用了 Bully 算法进行选主，比如 MongoDB 的副本集故障转移功能。MongoDB 的分布式选举中，采用节点的最后操作时间戳来表示 ID，时间戳最新的节点其 ID 最大，也就是说时间戳最新的、活着的节点是主节点。</p><p>小结一下。Bully 算法的选择特别霸道和简单，谁活着且谁的 ID 最大谁就是主节点，其他节点必须无条件服从。这种算法的优点是，选举速度快、算法复杂度低、简单易实现。但这种算法的缺点在于，需要每个节点有全局的节点信息，因此额外信息存储较多；其次，任意一个比当前主节点 ID 大的新节点或节点故障后恢复加入集群的时候，都可能会触发重新选举，成为新的主节点，如果该节点频繁退出、加入集群，就会导致频繁切主。</p><h3 id="民主投票：Raft-算法"><a href="#民主投票：Raft-算法" class="headerlink" title="民主投票：Raft 算法"></a><strong>民主投票：</strong>Raft <strong>算法</strong></h3><p>Raft 算法是典型的多数派投票选举算法，其选举机制与我们日常生活中的民主投票机制类似，核心思想是“少数服从多数”。也就是说，Raft 算法中，获得投票最多的节点成为主。采用 Raft 算法选举，集群节点的角色有 3 种：</p><p> Leader，即主节点，同一时刻只有一个 Leader，负责协调和管理其他节点；</p><p> Candidate，即候选者，每一个节点都可以成为 Candidate，节点在该角色下才可以被选为新的 Leader；</p><p> Follower，Leader 的跟随者，不可以发起选举。</p><p>Raft 选举的流程，可以分为以下几步：</p><p> 初始化时，所有节点均为 Follower 状态。</p><p> 开始选主时，所有节点的状态由 Follower 转化为 Candidate，并向其他节点发送选举请求。</p><p> 其他节点根据接收到的选举请求的先后顺序，回复是否同意成为主。这里需要注意的是，在每一轮选举中，一个 节点只能投出一张票。</p><p> 若发起选举请求的节点获得超过一半的投票，则成为主节点，其状态转化为 Leader，其他节点的状态则由 Candidate 降为 Follower。Leader 节点与 Follower 节点之间会定期发送心跳包，以检测主节点是否活着。</p><p> 当 Leader 节点的任期到了，即发现其他服务器开始下一轮选主周期时，Leader 节点的状态由 Leader 降级为 Follower，进入新一轮选主。</p><p>节点的状态迁移如下所示（图中的 term 指的是选举周期）：</p><img src="/2024/04/08/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1/clip_image063.gif" class="" title="img"><p>请注意，每一轮选举，每个节点只能投一次票。这种选举就类似人大代表选举，正常情况下每个人大代表都有一定的任期，任期到后会触发重新选举，且投票者只能将自己手里唯一的票投给其中一个候选者。对应到 Raft 算法中，选主是周期进行的，包括选主和任值两个时间段，选主阶段对应投票阶段，任值阶段对应节点成为主之后的任期。但也有例外的时候，如果主节点故障，会立马发起选举，重新选出一个主节点。</p><p>Google 开源的 Kubernetes，擅长容器管理与调度，为了保证可靠性，通常会部署 3 个节点用于数据备份。这 3 个节点中，有一个会被选为主，其他节点作为备。Kubernetes 的选主采用的是开源的 etcd 组件。而，etcd 的集群管理器 etcds，是一个高可用、强一致性的服务发现存储仓库，就是采用了 Raft 算法来实现选主和一致性的。</p><p>小结一下。Raft 算法具有选举速度快、算法复杂度低、易于实现的优点；缺点是，它要求系统内每个节点都可以相互通信，且需要获得过半的投票数才能选主成功，因此通信量大。该算法选举稳定性比 Bully 算法好，这是因为当有新节点加入或节点故障恢复后，会触发选主，但不一定会真正切主，除非新节点或故障后恢复的节点获得投票数过半，才会导致切主。</p><p><strong>具有优先级的民主投票：</strong>ZAB<strong>算法</strong></p><p>ZAB（ZooKeeper Atomic Broadcast）选举算法是为 ZooKeeper 实现分布式协调功能而设计的。相较于 Raft 算法的投票机制，ZAB 算法增加了通过节点 ID 和数据 ID 作为参考进行选主，节点 ID 和数据 ID 越大，表示数据越新，优先成为主。相比较于 Raft 算法，ZAB 算法尽可能保证数据的最新性。所以，ZAB 算法可以说是对 Raft 算法的改进。</p><p>使用 ZAB 算法选举时，集群中每个节点拥有 3 种角色： Leader，主节点； Follower，跟随者节点； Observer，观察者，无投票权。</p><p>选举过程中，集群中的节点拥有 4 个状态：</p><p> Looking 状态，即选举状态。当节点处于该状态时，它会认为当前集群中没有 Leader，因此自己进入选举状态。</p><p> Leading 状态，即领导者状态，表示已经选出主，且当前节点为 Leader。</p><p> Following 状态，即跟随者状态，集群中已经选出主后，其他非主节点状态更新为 Following，表示对 Leader 的追随。</p><p> Observing 状态，即观察者状态，表示当前节点为 Observer，持观望态度，没有投票权和选举权。</p><p>投票过程中，每个节点都有一个唯一的三元组 (server_id, server_zxID, epoch)，其中 server_id 表示本节点的唯一 ID；server_zxID 表示本节点存放的数据 ID，数据 ID 越大表示数据越新，选举权重越大；epoch 表示当前选取轮数，一般用逻辑时钟表示。</p><p>ZAB 选举算法的核心是“少数服从多数，ID 大的节点优先成为主”，因此选举过程中通过 (vote_id, vote_zxID) 来表明投票给哪个节点，其中 vote_id 表示被投票节点的 ID，vote_zxID 表示被投票节点的服务器 zxID。ZAB 算法选主的原则是：server_zxID 最大者成为 Leader；若 server_zxID 相同，则 server_id 最大者成为 Leader。接下来介绍 ZAB 选主的过程。</p><p>第一步：当系统刚启动时，3 个服务器当前投票均为第一轮投票，即 epoch&#x3D;1，且 zxID 均为 0。此时每个服务器都推选自己，并将选票信息 &lt;epoch, vote_id, vote_zxID&gt; 广播出去。</p><img src="/2024/04/08/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1/clip_image065.gif" class="" title="img"><p>第二步：根据判断规则，由于 3 个 Server 的 epoch、zxID 都相同，因此比较 server_id，较大者即为推选对象，因此 Server 1 和 Server 2 将 vote_id 改为 3，更新自己的投票箱并重新广播自己的投票。</p><img src="/2024/04/08/%E5%88%86%E5%B8%83%E5%BC%8F%E5%BE%AE%E6%9C%8D%E5%8A%A1/clip_image067.jpg" class="" title="img"><p><a href="https://blog.csdn.net/yezonggang/article/details/106343806">https://blog.csdn.net/yezonggang/article/details/106343806</a></p><h3 id="分布式评价维度"><a href="#分布式评价维度" class="headerlink" title="分布式评价维度"></a>分布式评价维度</h3><p>分布式的三围：性能（Performance）资源占用（Resource Usage）可用性（Availability）可扩展性（Scalability）</p><p>场景和取舍</p><p>按照业务的架构层次栈，自底向上按照资源、通信、数据与计算的维度，梳理出了 4 个技术层次：分布式资源池化、分布式通信、分布式数据存储与管理、分布式计算。这样的划分符合业务架构设计的一般规律，即“在一定资源上，进行一定通信，通过一定计算，完成一定数据的加工和处理，从而对外提供特定的服务”。另一方面，这样的划分也整合了零散的知识点，具有完备性。分布式技术的地图：</p><p>分布式的三围</p><p>首先，从分布式技术的起源可以看出，分布式系统的出现就是为了用廉价的、普通的机器解决单个计算机处理复杂、大规模数据和任务时存在的性能问题、资源瓶颈问题，以及可用性和可扩展性问题。换句话说，分布式的目的是用更多的机器，处理更多的数据和更复杂的任务。由此可以看出，性能、资源、可用性和可扩展性是分布式系统的重要指标。没错，它们就是分布式系统的“三围”。接下来，我们一起来看看这几个指标吧。</p><p>性能（Performance）</p><p>性能指标，主要用于衡量一个系统处理各种任务的能力。无论是分布式系统还是单机系统，都会对性能有所要求。不同的系统、服务要达成的目的不同，关注的性能自然也不尽相同，甚至是相互矛盾。常见的性能指标，包括吞吐量（Throughput）、响应时间（Response Time）和完成时间（Turnaround Time）。</p><p>吞吐量指的是，系统在一定时间内可以处理的任务数。这个指标可以非常直接地体现一个系统的性能，就好比在客户非常多的情况下，要评判一个银行柜台职员的办事效率，你可以统计一下他在 1 个小时内接待了多少客户。常见的吞吐量指标有 QPS（Queries Per Second）、TPS（Transactions Per Second）和 BPS（Bits Per Second）。</p><p>QPS，即查询数每秒，用于衡量一个系统每秒处理的查询数。这个指标通常用于读操作，越高说明对读操作的支持越好。所以，我们在设计一个分布式系统的时候，如果应用主要是读操作，那么需要重点考虑如何提高 QPS，来支持高频的读操作。</p><p>TPS，即事务数每秒，用于衡量一个系统每秒处理的事务数。这个指标通常对应于写操作，越高说明对写操作的支持越好。我们在设计一个分布式系统的时候，如果应用主要是写操作，那么需要重点考虑如何提高 TPS，来支持高频写操作。</p><p>BPS，即比特数每秒，用于衡量一个系统每秒处理的数据量。对于一些网络系统、数据管理系统，我们不能简单地按照请求数或事务数来衡量其性能。因为请求与请求、事务与事务之间也存在着很大的差异，比方说，有的事务大需要写入更多的数据。那么在这种情况下，BPS 更能客观地反应系统的吞吐量。</p><p>响应时间指的是，系统响应一个请求或输入需要花费的时间。响应时间直接影响到用户体验，对于时延敏感的业务非常重要。比如用户搜索导航，特别是用户边开车边搜索的时候，如果响应时间很长，就会直接导致用户走错路。</p><p>完成时间指的是，系统真正完成一个请求或处理需要花费的时间。任务并行（也叫作任务分布式）模式出现的其中一个目的，就是缩短整个任务的完成时间。特别是需要计算海量数据或处理大规模任务时，用户对完成时间的感受非常明显。</p><p>资源占用（Resource Usage）</p><p>资源占用指的是，一个系统提供正常能力需要占用的硬件资源，比如 CPU、内存、硬盘等。一个系统在没有任何负载时的资源占用，叫做空载资源占用，体现了这个系统自身的资源占用情况。比如，你在手机上安装一个 App，安装的时候通常会提示你有多少 KB，这就是该 App 的空载硬盘资源占用。对于同样的功能，空载资源占用越少，说明系统设计越优秀，越容易被用户接受。</p><p>一个系统满额负载时的资源占用，叫做满载资源占用，体现了这个系统全力运行时占用资源的情况，也体现了系统的处理能力。同样的硬件配置上，运行的业务越多，资源占用越少，说明这个系统设计得越好。</p><p>可用性（Availability）可扩展性（Scalability）</p><p>可用性，通常指的是系统在面对各种异常时可以正确提供服务的能力。可用性是分布式系统的一项重要指标，衡量了系统的鲁棒性，是系统容错能力的体现。系统的可用性可以用系统停止服务的时间与总的时间之比衡量。假设一个网站总的运行时间是 24 小时，在 24 小时内，如果网站故障导致不可用的时间是 4 个小时，那么系统的可用性就是 4&#x2F;24&#x3D;0.167，也就是 0.167 的比例不可用，或者说 0.833 的比例可用。</p><p>除此之外，系统的可用性还可以用某功能的失败次数与总的请求次数之比来衡量，比如对网站请求 1000 次，其中有 10 次请求失败，那么可用性就是 99%。你可能经常在一个系统的宣传语中见到或听到 3 个 9（或 3N，3 Nines）、5 个 9（或 9N，9 Nines）。这些宣传语中所说的 3 个 9、5 个 9，实际上就是系统厂商对可用性的一种标榜，表明该系统可以在 99.9% 或 99.999% 的时间里能对外无故障地提供服务。</p><p>可靠性通常用来表示一个系统完全不出故障的概率，更多地用在硬件领域。而可用性则更多的是指在允许部分组件失效的情况下，一个系统对外仍能正常提供服务的概率。</p><p>杰夫 · 迪恩（Jeff Dean）曾在 Google I&#x2F;O 大会上透露：谷歌一个基于 1000 台通用计算机的集群，一年之内就有 1000+ 硬盘会出现故障。由于现在比较常见的分布式系统基本上都是基于通用计算机的，这就意味着在这些系统中无法实现真正的可靠，所以我们也会在一些场合见到可靠性和可用性交换使用的情况。</p><p>可扩展性，指的是分布式系统通过扩展集群机器规模提高系统性能 (吞吐、响应时间、 完成时间)、存储容量、计算能力的特性，是分布式系统的特有性质。分布式系统的设计初衷，就是利用集群多机的能力处理单机无法解决的问题。然而，完成某一具体任务所需要的机器数目，即集群规模，取决于单个机器的性能和任务的要求。任务的需求随着具体业务不断提高时，除了升级系统的性能做垂直 &#x2F; 纵向扩展外，另一个做法就是通过增加机器的方式去水平 &#x2F; 横向扩展系统规模。这里垂直 &#x2F; 纵向扩展指的是，增加单机的硬件能力，比如 CPU 增强、内存增大等；水平 &#x2F; 横向扩展指的就是，增加计算机数量。好的分布式系统总在追求“线性扩展性”，也就是说系统的某一指标可以随着集群中的机器数量呈线性增长。</p><p>衡量系统可扩展性的常见指标是加速比（Speedup），也就是一个系统进行扩展后相对扩展前的性能提升。如果你的扩展目标是为了提高系统吞吐量，则可以用扩展后和扩展前的系统吞吐量之比进行衡量。如果你的目标是为了缩短完成时间，则可以用扩展前和扩展后的完成时间之比进行衡量。</p><p>场景和取舍</p><p>我们都希望自己的分布式系统是高性能、高可用、高扩展和低资源占用的。但出于硬件成本、开发效率等因素的约束，我们无法在性能、可用性、可靠性和资源占用做到面面俱到。因此，在不同的业务场景中，设计者们需要有所取舍。典型的电商、IoT、电信、HPC（高性能计算）、大数据、云计算、区块链等业务或系统对不同指标的诉求；</p><p>电商系统。对于一个电商系统而言，系统设计者最看重的是吞吐量，为了处理更多的用户访问或订单业务，甚至不惜牺牲一些硬件成本。</p><p>IoT。对于一个 IoT 系统而言，设计者最看重的是资源占用指标，因为在一些功能极简的 IoT 设备上 RAM、ROM 的可用资源通常都是 KB 级的。</p><p>电信业务。对于电信业务而言，最重要的无疑是响应时间、完成时间，以及可用性。因为，你在打电话时不希望你的声音半天才被对方听到，也不希望半天才听到对方的回应，更不希望你的电话无法拨出。</p><p>HPC。HPC 系统最显著的特点是任务执行时间极长，一个天体物理任务的分析和计算通常耗时数周甚至数月。因此，通过水平扩展来提高系统的加速比，是 HPC 系统设计者需要关注的。</p><p>大数据。大数据任务的处理时间可能相对 HPC 系统来讲比较短，但常见的完成时间也达到了小时级，所以扩展性也是大数据系统首先要考虑的。</p><p>云计算。对于一个云计算系统而言，常见任务是虚拟主机或容器的创建、资源调整、销毁等操作，如何减少这些操作的完成时间，从而提升用户体验是设计者们要重点关注的。另外，云计算系统本质上卖的是资源，那么降低系统本身的资源开销，也是系统设计的重中之重。</p><p>区块链。区块链的吞吐量比较低，比特币的 TPS 只有 7 次每秒，单平均一次交易的确认就需要 10 分钟左右，因此吞吐量和完成时间通常是区块链系统设计者的首要目标。</p><p>按照不同维度，分布式系统的指标可以分为性能、资源占用、可用性、可扩展性这四大类。我们自然希望自己的系统，是高性能、高可用、高扩展和低资源占用的，但考虑到硬件成本、开发效率等因素，必须要在设计不同的系统、业务时有所取舍。</p><p>原文链接：<a href="https://blog.csdn.net/yezonggang/article/details/106339450">https://blog.csdn.net/yezonggang/article/details/106339450</a></p>]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> 分布式微服务 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>开放性问题</title>
      <link href="/2024/04/08/%E5%BC%80%E6%94%BE%E6%80%A7%E9%97%AE%E9%A2%98/"/>
      <url>/2024/04/08/%E5%BC%80%E6%94%BE%E6%80%A7%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="项目难题"><a href="#项目难题" class="headerlink" title="项目难题"></a>项目难题</h1><p>price&#x3D;price.replaceAll(“元”,””).replaceAll(“以上”,””); &#x2F;&#x2F;条件搜索时 price.replaceAll(“元”,””) &#x2F;&#x2F;如果不用对象接收，price还是原来的字符串<br>请求头中一个键值可以对应多个value值，请求头中若已经有了AUTHORIZE_TOKEN值，那么在添加就没有了意义</p><img src="/2024/04/08/%E5%BC%80%E6%94%BE%E6%80%A7%E9%97%AE%E9%A2%98/clip_image001.jpg" class="" width="0"><p>(3)测试</p><img src="/2024/04/08/%E5%BC%80%E6%94%BE%E6%80%A7%E9%97%AE%E9%A2%98/clip_image003.jpg" class="" width="0"><p>订单微服务feign调用拦截器：我们发现这块的ServletRequestAttributes始终为空，RequestContextHolder.getRequestAttributes()该方法是从ThreadLocal变量里面取得相应信息的，当hystrix断路器的隔离策略为THREAD时，是无法取得ThreadLocal中的值。 解决方案：hystrix隔离策略换为SEMAPHORE（信号量）</p><h1 id="Hystrix隔离策略"><a href="#Hystrix隔离策略" class="headerlink" title="Hystrix隔离策略"></a>Hystrix隔离策略</h1><p>Hystrix的资源隔离策略分为两种：线程池和信号量。说到资源隔离，我们就要明白为什么需要资源隔离。</p><p>在一个分布式系统中，服务之间都是相互调用的，如下图所示：</p><img src="/2024/04/08/%E5%BC%80%E6%94%BE%E6%80%A7%E9%97%AE%E9%A2%98/clip_image005.jpg" class="" title="img"><p> 例如，我们容器(Tomcat)配置的线程个数为1000，从服务A到服务R，其中服务I的并发量非常的大，需要500个线程来执行，此时，服务I又挂了，那么这500个线程很可能就夯死了，那么剩下的服务，总共可用的线程为500个，随着并发量的增大，剩余服务挂掉的风险就会越来越大，最后导致整个系统的所有服务都不可用，直到系统宕机。这就是服务的雪崩效应。Hystrix就是用来做资源隔离的，比如说，当客户端向服务端发送请求时，给服务I分配了10个线程，只要超过了这个并发量就走降级服务，就算服务I挂了，最多也就导致服务I不可用，容器的10个线程不可用了，但是不会影响系统中的其他服务。下面，我们就来具体说下这两种隔离策略：</p><h2 id="1、线程池"><a href="#1、线程池" class="headerlink" title="1、线程池"></a><strong>1</strong>、线程池</h2><p>线程池隔离的示意图如下：</p><img src="/2024/04/08/%E5%BC%80%E6%94%BE%E6%80%A7%E9%97%AE%E9%A2%98/clip_image007.jpg" class="" title="img"><p> 上图的左边2&#x2F;3是线程池资源隔离示意图，右边的1&#x2F;3是信号量资源隔离示意图，我们先来看左边的示意图。</p><p>当用户请求服务A和服务I的时候，tomcat的线程(图中蓝色箭头标注)会将请求的任务交给服务A和服务I的内部线程池里面的线程(图中橘色箭头标注)来执行，tomcat的线程就可以去干别的事情去了，当服务A和服务I自己线程池里面的线程执行完任务之后，就会将调用的结果返回给tomcat的线程，从而实现资源的隔离，当有大量并发的时候，服务内部的线程池的数量就决定了整个服务的并发度，例如服务A的线程池大小为10个，当同时有12请求时，只会允许10个任务在执行，其他的任务被放在线程池队列中，或者是直接走降级服务，此时，如果服务A挂了，就不会造成大量的tomcat线程被服务A拖死，服务I依然能够提供服务。整个系统不会受太大的影响。</p><h2 id="2、信号量"><a href="#2、信号量" class="headerlink" title="2、信号量"></a><strong>2</strong>、信号量</h2><p>信号量的资源隔离只是起到一个开关的作用，例如，服务X的信号量大小为10，那么同时只允许10个tomcat的线程(此处是tomcat的线程，而不是服务X的独立线程池里面的线程)来访问服务X，其他的请求就会被拒绝，从而达到限流保护的作用。</p><h2 id="3、二者的比较"><a href="#3、二者的比较" class="headerlink" title="3、二者的比较"></a><strong>3</strong>、二者的比较</h2><img src="/2024/04/08/%E5%BC%80%E6%94%BE%E6%80%A7%E9%97%AE%E9%A2%98/clip_image009.gif" class="" title="img"><h2 id="4、总结"><a href="#4、总结" class="headerlink" title="4、总结"></a><strong>4</strong>、总结</h2><p> <strong>当请求的服务网络开销比较大的时候，或者是请求比较耗时的时候，我们最好是使用线程隔离策略，这样的话，可以保证大量的容器(tomcat)线程可用，不会由于服务原因，一直处于阻塞或等待状态，快速失败返回。而当我们请求缓存这些服务的时候，我们可以使用信号量隔离策略，因为这类服务的返回通常会非常的快，不会占用容器线程太长时间，而且也减少了线程切换的一些开销，提高了缓存服务的效率。</strong></p><h1 id="restful接口设计"><a href="#restful接口设计" class="headerlink" title="restful接口设计"></a><strong>restful</strong>接口设计</h1><h2 id="什么是RESTful架构："><a href="#什么是RESTful架构：" class="headerlink" title="什么是RESTful架构："></a>什么是RESTful架构：</h2><p>（1）每一个URI代表一种资源；</p><p>（2）客户端和服务器之间，传递这种资源的某种表现层；</p><p>（3）客户端通过四个HTTP动词，对服务器端资源进行操作，实现”表现层状态转化”。</p><h2 id="1、动作"><a href="#1、动作" class="headerlink" title="1、动作"></a><strong>1</strong>、动作</h2><p>GET （SELECT）：从服务器检索特定资源，或资源列表。</p><p>POST （CREATE）：在服务器上创建一个新的资源。</p><p>PUT （UPDATE）：更新服务器上的资源，提供整个资源。</p><p>PATCH （UPDATE）：更新服务器上的资源，仅提供更改的属性。</p><p>DELETE （DELETE）：从服务器删除资源。</p><h2 id="2、路径（接口命名）"><a href="#2、路径（接口命名）" class="headerlink" title="2、路径（接口命名）"></a><strong>2</strong>、路径（接口命名）</h2><p>路径又称”终点”（endpoint），表示API的具体网址。</p><p>在RESTful架构中，每个网址代表一种资源（resource），所以网址中不能有动词，只能有名词，而且所用的名词往往与数据库的表格名对应。一般来说，数据库中的表都是同种记录的”集合”（collection），所以API中的名词也应该使用复数。</p><p>举例来说，有一个API提供动物园（zoo）的信息，还包括各种动物和雇员的信息，则它的路径应该设计成下面这样。</p><p>接口尽量使用名词，禁止使用动词，下面是一些例子。</p><img src="/2024/04/08/%E5%BC%80%E6%94%BE%E6%80%A7%E9%97%AE%E9%A2%98/clip_image011.jpg" class="" title="img"><h2 id="3、版本（Versioning）"><a href="#3、版本（Versioning）" class="headerlink" title="3、版本（Versioning）"></a><strong>3</strong>、版本（Versioning）</h2><p>应该将API的版本号放入URL。如：<a href="https://api.example.com/v1/">https://api.example.com/v1/</a></p><h2 id="4、过滤信息（Filtering）"><a href="#4、过滤信息（Filtering）" class="headerlink" title="4、过滤信息（Filtering）"></a><strong>4</strong>、过滤信息（Filtering）</h2><p>如果记录数量很多，服务器不可能都将它们返回给用户。API应该提供参数，过滤返回结果。下面是一些常见的参数。</p><img src="/2024/04/08/%E5%BC%80%E6%94%BE%E6%80%A7%E9%97%AE%E9%A2%98/clip_image013.jpg" class="" title="img"><h2 id="5、状态码（Status-Codes）"><a href="#5、状态码（Status-Codes）" class="headerlink" title="5、状态码（Status Codes）"></a><strong>5</strong>、状态码（Status Codes）</h2><p>状态码范围</p><p>1xx 信息，请求收到，继续处理。范围保留用于底层HTTP的东西，你很可能永远也用不到。<br> 2xx 成功，行为被成功地接受、理解和采纳<br> 3xx 重定向，为了完成请求，必须进一步执行的动作<br> 4xx 客户端错误，请求包含语法错误或者请求无法实现。范围保留用于响应客户端做出的错误，例如。他们提供不良数据或要求不存在的东西。这些请求应该是幂等的，而不是更改服务器的状态。<br> 5xx 范围的状态码是保留给服务器端错误用的。这些错误常常是从底层的函数抛出来的，甚至<br> 开发人员也通常没法处理，发送这类状态码的目的以确保客户端获得某种响应。<br> 当收到5xx响应时，客户端不可能知道服务器的状态，所以这类状态码是要尽可能的避免。</p><p>来源：<a href="https://juejin.cn/post/6844903902375051278">https://juejin.cn/post/6844903902375051278</a></p><h1 id="session存不下怎么办"><a href="#session存不下怎么办" class="headerlink" title="session存不下怎么办"></a>session存不下怎么办</h1><p>session存不下怎么办？ 势必会有多服务器的共享Session问题，这时候Session信息就应该保存在redis中，所有的服务器写入或获取Session都从redis中进行。</p><h1 id="HTTP和RPC的区别"><a href="#HTTP和RPC的区别" class="headerlink" title="HTTP和RPC的区别"></a>HTTP和RPC的区别</h1><p> HTTP的本质是什么？</p><p>就是客户端和服务端约定好的一种通信格式。</p><p>HTTP 就规定了请求头，请求行，请求体</p><p>获取哪些资源，时间，内容，格式，长度</p><p>RPC 则是远程调用，各个微服务之间相互调用，必然需要网络通信，用的协议可以使http也可是tcp</p><p><a href="https://zhuanlan.zhihu.com/p/110424162">https://zhuanlan.zhihu.com/p/110424162</a></p><h1 id="压测中为什么TPS上不去的原因"><a href="#压测中为什么TPS上不去的原因" class="headerlink" title="压测中为什么TPS上不去的原因"></a>压测中为什么TPS上不去的原因</h1><p>下面就说说压测中为什么TPS上不去的原因：</p><p><strong>1</strong>、网络带宽</p><p>在压力测试中，有时候要模拟大量的用户请求，如果单位时间内传递的数据包过大，超过了带宽的传输能力，那么就会造成网络资源竞争，间接导致服务端接收到的请求数达不到服务端的处理能力上限。</p><p><strong>2</strong>、连接池</p><p>可用的连接数太少，造成请求等待。连接池一般分为服务器连接池（比如Tomcat）和数据库连接池（或者理解为最大允许连接数也行）。</p><p>（关于连接池的具体内容，可参考之前的博客：<a href="http://www.cnblogs.com/imyalost/p/7189455.html">性能测试：连接池和线程</a>）</p><p><strong>3</strong>、垃圾回收机制</p><p>从常见的应用服务器来说，比如Tomcat，因为java的的堆栈内存是动态分配，具体的回收机制是基于算法，如果新生代的Eden和Survivor区频繁的进行Minor GC，老年代的full GC也回收较频繁，那么对TPS也是有一定影响的，因为垃圾回收其本身就会占用一定的资源。</p><p><strong>4</strong>、数据库配置</p><p>高并发情况下，如果请求数据需要写入数据库，且需要写入多个表的时候，如果数据库的最大连接数不够，或者写入数据的SQL没有索引没有绑定变量，抑或没有主从分离、读写分离等，</p><p>就会导致数据库事务处理过慢，影响到TPS。</p><p><strong>5</strong>、通信连接机制</p><p>串行、并行、长连接、管道连接等，不同的连接情况，也间接的会对TPS造成影响。</p><p>（关于协议的连接，可参考之前的博客：<a href="http://www.cnblogs.com/imyalost/p/7887667.html">HTTP协议进阶：连接管理</a>）</p><p><strong>6</strong>、硬件资源</p><p>包括CPU（配置、使用率等）、内存（占用率等）、磁盘（I&#x2F;O、页交换等）。</p><p><strong>7</strong>、压力机</p><p>比如jmeter，单机负载能力有限，如果需要模拟的用户请求数超过其负载极限，也会间接影响TPS（这个时候就需要进行分布式压测来解决其单机负载的问题）。</p><p><strong>8</strong>、压测脚本</p><p>还是以jemter举个例子，之前工作中同事遇到的，进行阶梯式加压测试，最大的模拟请求数超过了设置的线程数，导致线程不足。</p><p>提到这个原因，想表达意思是：有时候测试脚本参数配置等原因，也会影响测试结果。</p><p><strong>9</strong>、业务逻辑</p><p>业务解耦度较低，较为复杂，整个事务处理线被拉长导致的问题。</p><p><strong>10</strong>、系统架构</p><p>比如是否有缓存服务，缓存服务器配置，缓存命中率、缓存穿透以及缓存过期等，都会影响到测试结果。</p><h1 id="网络较慢的排查"><a href="#网络较慢的排查" class="headerlink" title="网络较慢的排查"></a>网络较慢的排查</h1><ol><li>traceroute</li></ol><p>前面提到的traceroute不仅可以查看路由的正确性，还可以查看网络中每一跳的延时，从而定位延时最高的网络区段。</p><ol start="2"><li>iftop</li></ol><p>iftop命令类似于top命令，查看哪些网络连接占用的带宽较多</p><ol start="3"><li>tcpdump</li></ol><p>当一切排查手段都无济于事时仍然不能找到网络速度慢、丢包严重等原因时，往往祭出杀手锏——抓包。抓包的最佳手段是在通信的双方同时抓取，这样可以同时检验发出的数据包和收到的数据包，tcpdump是常用的抓包工具。</p><h1 id="系统运行过程中出现fullGC，怎么排查，什么情况出现fullGC"><a href="#系统运行过程中出现fullGC，怎么排查，什么情况出现fullGC" class="headerlink" title="系统运行过程中出现fullGC，怎么排查，什么情况出现fullGC"></a>系统运行过程中出现fullGC，怎么排查，什么情况出现fullGC</h1><p>top – jstate – map工具</p><img src="/2024/04/08/%E5%BC%80%E6%94%BE%E6%80%A7%E9%97%AE%E9%A2%98/clip_image015.gif" class="" title="1  2  3  4  5  top - 08:31:10 up 30 min,  KiB mem:  2046460  KiB swap: 1048572  total ,  total ,  load average: 0.73, 0.58, 0.34  ø users,  1923864 used,  1225% free,  14388 buffers  ø used, 1048572 free. 1192352 cached Mem  SHR S %CPU  VIRT  RES  TIME*  PID USER  9 root  PR  20  2557160 288976 15812 s 98.0 14.1 ø:a2.6ø java"><img src="/2024/04/08/%E5%BC%80%E6%94%BE%E6%80%A7%E9%97%AE%E9%A2%98/clip_image017.gif" class="" title="iii"><img src="/2024/04/08/%E5%BC%80%E6%94%BE%E6%80%A7%E9%97%AE%E9%A2%98/clip_image019.gif" class="" title="iii"><p>![经 过 mat 工 具 分 析 之 后 ， 我 们 基 本 上 就 能 确 定 内 存 中 主 要 是 哪 个 对 象 比 较 氵 肖 耗 内 存 ， 然 后 找 到 该 对 象 的 创 建 位 置 ， 进 行 处 理 即 可 。  这 里 的 主 要 是 PrintStreamn 多 ， 但 是 我 们 也 可 以 看 到 ， 其 内 存 氵 肖 耗 量 只 有 12 ． 2 ％ 。 也 就 是 说 ， 其 还 不 足 以 导 致 大 量 的 F 創 GC, 此 时 我 们  需 要 考 虑 另 外 一 种 情 况 ， 就 是 代 码 或 者 第 三 方 依 赖 的 包 中 有 显 示 的 System ． gc() 调 用 。  这 种 情 况 我 们 查 看 dump 内 存 得 到 的 文 件 即 可 判 断 ， 因 为 其 会 打 E 卩 GC 原 因 ：  1  2  [Full GC (System.gc()) [Tenured: 262546K 一 &gt; 262546K （ 349568K ） ， 9 ． 9914879 secs] 262546K 一 &gt; 262546K （ 596816K ） 丿  [GC (Allocation Failure) [DefNew: 2795K 一 &gt; OK （ 157248K ） ， 9 ． 9991594 secs]<a href="%E5%BC%80%E6%94%BE%E6%80%A7%E9%97%AE%E9%A2%98/clip_image021.gif">Tenured: 262546K 一 &gt; 492K （ 349568K ） 丿  [Metaspace: 31  9 ． 9912949 secs]  比 如 这 里 第 一 次 GC 是 由 于 System ． gc() 的 显 示 调 用 导 致 的 ， 而 第 二 次 GC 则 是 JVM 主 动 发 起 的 。 总 结 来 说 ， 对 于 Full GC 次 数 过 多 ， 主 要 有  以 下 两 种 原 因 ：  · 代 码 中 一 冫 欠 获 取 了 大 量 的 对 象 ， 导 致 内 存 溢 出 ， 此 时 可 以 通 过 eclipse 的 mat 工 具 查 看 内 存 中 有 哪 些 对 象 比 较 多 ；  · 内 存 占 用 不 高 ， 但 是 F GC 次 数 还 是 比 较 多 ， 此 时 可 能 是 显 示 的 System. gc() 调 用 导 致 GC 次 数 过 多 ， 这 可 以 通 过 添 加 一  XX:+Disab1eExp1icitGC 来 禁 用 JVMX 寸 显 刁、GC的响 应 。 </a></p><p><a href="https://blog.csdn.net/xiaoxiaole0313/article/details/104285018/">https://blog.csdn.net/xiaoxiaole0313/article/details/104285018/</a></p><h1 id="当用户反馈网站反应慢，怎么处理"><a href="#当用户反馈网站反应慢，怎么处理" class="headerlink" title="当用户反馈网站反应慢，怎么处理"></a>当用户反馈网站反应慢，怎么处理</h1><img src="/2024/04/08/%E5%BC%80%E6%94%BE%E6%80%A7%E9%97%AE%E9%A2%98/clip_image022.jpg" class="" title="img"><img src="/2024/04/08/%E5%BC%80%E6%94%BE%E6%80%A7%E9%97%AE%E9%A2%98/clip_image023.jpg" class="" title="img"><h1 id="高内聚和低耦合"><a href="#高内聚和低耦合" class="headerlink" title="高内聚和低耦合"></a>高内聚和低耦合</h1><p>是判断软件设计好坏的标准，主要用于程序的</p><p><a href="https://baike.baidu.com/item/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/2262089?fromModule=lemma_inlink">面向对象</a>的设计，主要看类的内聚性是否高，</p><p><a href="https://baike.baidu.com/item/%E8%80%A6%E5%90%88%E5%BA%A6/2603938?fromModule=lemma_inlink">耦合度</a>是否低。目的是使程序模块的可重用性、移植性大大增强。通常程序结构中各模块的内聚程度越高，模块间的耦合程度就越低。内聚是从功能角度来度量模块内的联系，一个好的内聚模块应当恰好做一件事，它描述的是模块内的功能联系；耦合是软件结构中各模块之间相互连接的一种</p><p><a href="https://baike.baidu.com/item/%E5%BA%A6%E9%87%8F/34036?fromModule=lemma_inlink">度量</a>，耦合强弱取决于模块间接口的复杂程度、进入或访问一个模块的点以及通过接口的数据</p><p>划分模块的一个准则是高内聚低耦合。从模块粒度来看，高内聚：尽可能类的每个成员方法只完成一件事（最大限度的聚合）； 低耦合：减少类内部，一个成员方法调用另一个成员方法。从类角度来看， 高内聚低耦合：减少类内部，对其他类的调用；从功能块来看 高内聚低耦合：减少模块之间的交互复杂度（接口数量，参数数据）即横向：类与类之间、模块与模块之间；纵向：层次之间；尽可能，内容内聚，数据耦合。</p><p><strong>降低耦合度的方法</strong></p><p>1、少使用类的继承，多用接口隐藏实现的细节。 Java面向对象编程引入接口除了支持多态外， 隐藏实现细节也是其中一个目的。</p><p>2、模块的功能化分尽可能的单一，道理也很简单，功能单一的模块供其它模块调用的机会就少。（其实这是高内聚的一种说法，高内聚低耦合一般同时出现）。</p><p>3、遵循一个定义只在一个地方出现。</p><p>4、少使用全局变量。</p><p>5、类属性和方法的声明少用public，多用private关键字。</p><p>6、多用设计模式，比如采用MVC的设计模式就可以降低界面与业务逻辑的耦合度。</p><p>7、尽量不用“硬编码”的方式写程序，同时也尽量避免直接用SQL语句操作数据库。</p><p>8、最后当然就是避免直接操作或调用其它模块或类（内容耦合）；如果模块间必须存在耦合，原则上尽量使用数据耦合，少用控制耦合，限制公共耦合的范围，避免使用内容耦合。</p><p><strong>增强内聚度方法</strong></p><p>1、模块只对外暴露最小限度的接口，形成最低的依赖关系。</p><p>2、只要对外接口不变，模块内部的修改，就不得影响其他模块。</p><p>3、删除一个模块，应当只影响有依赖关系的其他模块，而不应该影响其他无关部分。</p><h1 id="数字证书"><a href="#数字证书" class="headerlink" title="数字证书"></a>数字证书</h1><p>数字证书是一个经证书授权中心</p><p><a href="https://baike.so.com/doc/2871106-3029793.html">数字签名</a>的包含</p><p><a href="https://baike.so.com/doc/296087-313468.html">公开密钥</a>拥有者信息以及公开密钥的文件。最简单的证书包含一个公开密钥、名称以及证书授权中心的数字签名。数字证书还有一个重要的特征就是只在特定的时间段内有效</p><p>它以数字证书为核心的</p><p><a href="https://baike.so.com/doc/6539431-6753170.html">加密技术</a>(加密传输、数字签名、数字信封等安全技术)可以对网络上传输的信息进行加密和解密、数字签名和签名验证，确保网上传递信息的机密性、完整性及交易的不可抵赖性。使用了数字证书，即使您发送的信息在网上被他人截获，甚至您丢失了个人的账户、密码等信息，仍可以保证您的账户、资金安全。</p><p> 数字证书绑定了<a href="https://baike.so.com/doc/6626282-6840081.html">公钥</a>及其持有者的真实身份，它类似于现实生活中的居民身份证，所不同的是数字证书不再是纸质的证照，而是一段含有证书持有者身份信息并经过</p><p><a href="https://baike.so.com/doc/6254560-6467973.html">认证中心</a>审核签发的电子数据，可以更加方便灵活地运用在电子商务和电子政务中。</p>]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> 开放性问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>企业权限管理系统</title>
      <link href="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/"/>
      <url>/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h1 id="SSMAOP日志"><a href="#SSMAOP日志" class="headerlink" title="SSMAOP日志"></a>SSMAOP日志</h1><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image001.jpg" class="" title="img"><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image002.jpg" class="" title="img"><h1 id="基于AOP日志处理-："><a href="#基于AOP日志处理-：" class="headerlink" title="基于AOP日志处理 ："></a>基于AOP日志处理 ：</h1><p>访问之前：主要获取访问时间、访问的类、访问的方法（(JoinPoint jp：通过连接点的方法）</p><p>访问之后：主要获取日志中其它信息，时长、name、ip、url</p><p>name：SecurityContextHolder获取（上下文信息）</p><p>url：是类上的@RequestMapping的value+方法上的 @RequestMapping的value</p><p>ip：通过request.getRemoteAddr()方法获取到</p><p>封装进对象中存入数据库，点击访问日志就会显示日志信息（将日志信息查出来显示）</p><h1 id="Spring-Security"><a href="#Spring-Security" class="headerlink" title="Spring Security"></a>Spring Security</h1><p>安全包括两个主要操作。</p><p>“认证”，是为用户建立一个他所声明的主体。主体一般是指用户，设备或可以在你系 统中执行动作的其他系 统。 </p><p>“授权”指的是一个用户能否在你的应用中执行某个操作，在到达授权判断之前，身份的主题已经由 身份验证 过程建立了。 </p><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image003.jpg" class="" title="img"><p> 1.配置不过滤的资源（静态资源及登录相关）</p><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image004.jpg" class="" title="img"><p> 2.配置连接，表示任意路径都需要ROLE_USER权限</p><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image005.jpg" class="" title="img"><p>3.自定义登陆页面，login-page 自定义登陆页面 authentication-failure-url 用户权限校验失败之 后才会跳转到这个页面，如果数据库中没有这个用户则不会跳转到这个页面。 default-target-url 登陆成功后跳转的页面。 </p><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image006.jpg" class="" title="img"><p>4.登出， invalidate-session 是否删除session logout-url：登出处理链接 logout-successurl：登出成功页面     注：登出操作 只需要链接到 logout即可登出当前用户</p><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image007.jpg" class="" title="img"><h2 id="Spring-Security使用数据库认证"><a href="#Spring-Security使用数据库认证" class="headerlink" title="Spring Security使用数据库认证"></a>Spring Security使用数据库认证</h2><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image008.jpg" class="" title="img"><p>在Spring Security中如果想要使用数据进行认证操作，有很多种操作方式，这里我们介绍使用UserDetails、 UserDetailsService来完成操作。</p><p>UserDetails是一个接口，我们可以认为UserDetails作用是于封装当前进行认证的用户信息，但由于其是一个 接口，所以我们可以对其进行实现，也可以使用Spring Security提供的一个UserDetails的实现类User来完成 操作 </p><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image009.jpg" class="" title="img"><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image010.jpg" class="" title="img"><p>UserDetailsService</p><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image011.jpg" class="" title="img"><h2 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h2><p>Service：</p><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image012.jpg" class="" title="img"><p>去查数据库，能查到就返回用户信息登录成功</p><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image013.jpg" class="" title="img"><h2 id="用户登出："><a href="#用户登出：" class="headerlink" title="用户登出："></a>用户登出：</h2><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image014.jpg" class="" title="img"><h2 id="用户，角色，权限"><a href="#用户，角色，权限" class="headerlink" title="用户，角色，权限"></a>用户，角色，权限</h2><p>数据库关系</p><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image015.jpg" class="" title="img"><p>用户操作</p><p>查询所有用户</p><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image016.jpg" class="" title="img"><p>添加用户</p><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image017.jpg" class="" title="img"><p>查询用户详情</p><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image018.jpg" class="" title="img"><p>2.角色操作</p><p>查询所有角色</p><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image019.jpg" class="" title="img"><p>插入角色</p><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image020.jpg" class="" title="img"><p>3.资源权限管理</p><p>查询所有</p><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image021.jpg" class="" title="img"><p>添加</p><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image022.jpg" class="" title="img"><p>4.用户与角色绑定：用户与角色之间是多对多关系，我们要建立它们之间的关系，只需要在中间表user_role插入数据即可。 </p><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image023.jpg" class="" title="img"><p>（1）查找要操作的用户及可以添加的角色</p><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image024.jpg" class="" title="img"><p>调用IUserService的findById方法获取要操作的User </p><p>调用IRoleService的findOtherRole方法用于获取可以添加的角色信息</p><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image025.jpg" class="" title="img"><p>（2）添加关联</p><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image026.jpg" class="" title="img"><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image027.jpg" class="" title="img"><p>5.角色权限关联 ：角色与权限之间是多对多关系，我们要建立它们之间的关系，只需要在中间表role_permission插入数据即可。 </p><p>（1）查找要操作的角色及可以添加的权限，参数是要操作的角色id</p><p>调用IRoleService的findById方法获取要操作的Role </p><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image028.jpg" class="" title="img"><p>调用IPermissionService的findOtherPermission方法用于获取可以添加的权限信息 </p><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image029.jpg" class="" title="img"><p>（2）添加关联</p><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image030.jpg" class="" title="img"><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image031.jpg" class="" title="img"><h2 id="服务器端方法级权限控制"><a href="#服务器端方法级权限控制" class="headerlink" title="服务器端方法级权限控制"></a>服务器端方法级权限控制</h2><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image032.jpg" class="" title="img"><img src="/2024/04/08/%E4%BC%81%E4%B8%9A%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/clip_image033.jpg" class="" title="img">]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> 企业权限管理系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ElasticSearch</title>
      <link href="/2024/04/07/ElasticSearch/"/>
      <url>/2024/04/07/ElasticSearch/</url>
      
        <content type="html"><![CDATA[<h1 id="elasticsearch"><a href="#elasticsearch" class="headerlink" title="elasticsearch"></a>elasticsearch</h1><h2 id="项目流程"><a href="#项目流程" class="headerlink" title="项目流程"></a>项目流程</h2><h3 id="数据导入"><a href="#数据导入" class="headerlink" title="数据导入"></a>数据导入</h3><p>现在需要将数据从数据库中查询出来，然后将数据导入到ES中。</p><img src="/2024/04/07/ElasticSearch/clip_image002.gif" class="" title="O  searchkß%  Fei gn  Ä-ifiSku  goodskß-%  Eureka  Elasticsearch"><p>1.创建一个JavaBean，在JavaBean（SkuInfo）中添加索引库映射配置（一些注解）</p><p>FieldType.Text:Text类型，Text支持分词</p><p>index&#x3D;true；添加数据时，是否分词</p><p>analyzer&#x3D;“ik_smart”:创建索引的分词器</p><p>store&#x3D;false;是否存储</p><p>searchAnalyzer&#x3D;”ik_smart”:搜索时使用的分词器</p><p>2.创建Feign，实现查询所有Sku集合</p><p>3.在搜索微服务中调用Feign,查询所有Sku集合，并将Sku集合转化为SkuInfo的集合</p><p>4.Controller-Service-调用Dao（继承ElasticsearchRepository）实现数据导入到Elasticsearch</p><h3 id="文档映射Bean创建"><a href="#文档映射Bean创建" class="headerlink" title="文档映射Bean创建"></a>文档映射Bean创建</h3><p>搜索商品的时候，会根据如下属性搜索数据,并且不是所有的属性都需要分词搜索，我们创建JavaBean，将JavaBean数据存入到ES中要以搜索条件和搜索展示</p><p>结果为依据，部分关键搜索条件分析如下：</p><p>1.可能会根据商品名称搜索，而且可以搜索商品名称中的任意一个词语，所以</p><p>需要分词</p><p>2.可能会根据商品分类搜索，商品分类不需要分词</p><p>3.可能会根据商品品牌搜索，商品品牌不需要分词</p><p>4.可能会根据商品商家搜索，商品商家不需要分词</p><p>5.可能根据规格进行搜索，规格时一个键值对结构，用Map</p><h3 id="关键字搜索"><a href="#关键字搜索" class="headerlink" title="关键字搜索"></a>关键字搜索</h3><img src="/2024/04/07/ElasticSearch/clip_image004.gif" class="" title="畅 购  到 0 CHANG GOU  全 品 分 类  关 键 字 索  服 装 城  华 为 ×  美 妆 馆  青 橙 超 市  全 球 购  Q  Stiger 、  闪 购  联 湮 4G  团 购  有 趣  秒 杀  全 部 结 果 &#x2F; 智 能 手 机  手 机 、 数 码 、 配 亻 牛  品 牌  网 络 制 式  显 示 屏 尺 寸  像 头 像 寮  价  更 多 筛 选 项  锥 晕 新 品  iPhone ×  条 亻 牛 索  萦 尼 0  GSM （ 移 动 &#x2F; 联 湮 2G ）  OPPO ×  电 信 2G  多 选  更 多  长 (C 能 ．  Stig 亿 0  电 信 3G  联 湮 3G  电 信 3G  移 动 3G  (C) 匚 H  联 湮 3G  EX 匚 囗  联 湮 4G  nMSUN  生 0 一 生 9 英 ，  12 開 万 以 上  生 0 一 生 9 英 寸  800-1199 万  500 一 1000 兀  0 一 5D0 兀  恃 点  1200 一 1599 万  100D 一 1500 兀  卡 双 卡  移 动 3G  16 開 万 以 上  15D0 一 2D00 兀  其 他  200D 一 3000 兀  3000 元 以 上  系 统  手 机 内 存  评 价"><p>我们先使用SpringDataElasticsearch实现一个简单的搜索功能，先实现根据关键字搜索，从上面搜索图片可以看得到，每次搜索的时候，除了关键字外，还有可能有品</p><p>牌、分类、规格等，后台接收搜索条件使用Map接收比较合适。</p><p>查询关键字为诺基亚的商品，key为keywords，value为诺基亚</p><h3 id="分类统计"><a href="#分类统计" class="headerlink" title="分类统计"></a>分类统计</h3><p>看下面的SQL语句，我们在执行搜索的时候，第1条SQL语句是执行搜，第2条语句是根据分类名字分组查看有多少分类，大概执行了2个步骤就可以获取数据结果以及分类统计，我</p><p>们可以发现他们的搜索条件完全一样。</p><p>`&#96;&#96;sql</p><p>– 查询所有</p><p>SELECT * FROM tb_sku WHERE name LIKE ‘%手机%’;</p><p>– 根据分类名字分组查询</p><p>SELECT category_name FROM tb_sku WHERE name LIKE ‘%手机%’ GROUP BY category_name;</p><p>`&#96;&#96;</p><img src="/2024/04/07/ElasticSearch/clip_image006.gif" class="" title="手 机 、 数 码 、  长 (C “ 伊 H “  配 亻  品 牌  网 络 制 式  显 示 屏 尺 寸  像 头 像 寮  价  更 多 筛 选 项  0  分 类 显 示  多 选  更 多  萦 尼 0  GSM （ 移 动 &#x2F; 联 湮 2G ）  电 信 2G  Stig 亿 r 、  电 信 3G  Stig 亿 0  联 湮 3G  HO 匚 H  联 湮 3G  EX 匚 囗  联 湮 4G  AMSUN  移 动 3G  联 湮 4G  电 信 3G  3000 元 以 上  移 动 3G  生 0 一 生 9 英 ，  12 開 万 以 上  生 0 一 生 9 英 寸  800-1199 万  500 一 1000 兀  1200 一 1599 万  100D 一 1500 兀  卡 双 卡  16 開 万 以 上  15D0 一 2D00 兀  其 他  无 f 象 头  200D 一 3000 兀  0 一 5D0 兀  恃 点  系 统  手 机 内 存  新 品  评 价"><p>我们每次执行搜索的时候，需要显示商品分类名称，这里要显示的分类名称其实就是符合搜素条件的所有商品的分类集合，我们可以按照上面的实现思路，使用ES根据分组名称做</p><p>一次分组查询即可实现。</p><h3 id="品牌统计"><a href="#品牌统计" class="headerlink" title="品牌统计"></a>品牌统计</h3><img src="/2024/04/07/ElasticSearch/clip_image008.jpg" class="" title="img"><p>– 查询所有</p><p>SELECT * FROM tb_sku WHERE name LIKE ‘%手机%’;</p><p>– 根据品牌名字分组查询</p><p>SELECT brand_name FROM tb_sku WHERE name LIKE ‘%手机%’ GROUP BY brand_name;</p><h3 id="规格统计"><a href="#规格统计" class="headerlink" title="规格统计"></a>规格统计</h3><img src="/2024/04/07/ElasticSearch/clip_image010.jpg" class="" title="既 35  5 ． 5 寸  土 。 尺 寸  和 0 的 0  色  咩 26  5 寸  16G  移 动  3 的 万 寺  红  0  0 万  藎  景  0  s11"><p>– 查询所有</p><p>SELECT * FROM tb_sku WHERE name LIKE ‘%手机%’;</p><p>– 根据规格名字分组查询</p><p>SELECT spec FROM tb_sku WHERE name LIKE ‘%手机%’ GROUP BY spec;</p><p>上述SQL语句执行后的结果如下图：</p><img src="/2024/04/07/ElasticSearch/clip_image012.gif" class="" title="Map---&gt;Put---&gt;Map&lt;String,Set&gt;  ENG,  a a p &lt; Strin g"><p>获取到的规格数据我们发现有重复，不过也可以解决，解决思路如下：</p><p>1.获取所有规格数据</p><p>2.将所有规格数据转换成Map</p><p>3.定义一个Map&lt;String,Set&gt;,key是规格名字，防止重复所以用Map，valu是规格值，规格值</p><p>有多个，所以用集合，为了防止规格重复，用Set去除重复</p><p>4.循环规格的Map，将数据填充到定义的Map&lt;String,Set&gt;中</p><h3 id="条件筛选"><a href="#条件筛选" class="headerlink" title="条件筛选"></a>条件筛选</h3><img src="/2024/04/07/ElasticSearch/clip_image014.gif" class="" title="分 委  品 牌  网 制 式  示 屏 尺 寸  生 0-4.9 英 を  像 羡 像 素  1200 万 以 上  价 格  0-500 兀  更 多 篩 造  特 点  量 新 品  手 机 、 数 、 配 件  蓋 尼 ( SO ル り  GSM ( 移 &#x2F; 朕 通 2G )  TCL  圭 信 2G  信 3G  移 劯 3G  5 む 8 化 「 、  朕 通 3G  通 4G  日 ロ CH  通 3G  EXC ロ  通 4G  多 更 多  @分莞叟索  SUN ( 2 槲 叟 索 4.0-4.9 英 寸 800-1199 万 500-1000 兀 手 机 内 存 价 格 1500 万 以 上 1500-2000 兀 其 他 信 3G 3000 元 以 上 1200-1599 万 1000-1500 兀 十 双 十 ④ 排 序 无 像 美 2000-3000 兀 移 3G ① 价 槲 叟 索 %}&lt;p&gt;分类、品牌筛选&lt;&#x2F;p&gt;&lt;p&gt;页面每次向后台传入对应的分类和品牌，后台据分类和品牌进行条件过滤可。&lt;&#x2F;p&gt;&lt;p&gt;规格过滤&lt;&#x2F;p&gt;&lt;p&gt;规格这一块，需要向后台发送规格名字以及规格值，我们可以按照一定要求来发送数据，例如规格名字以特殊前缀提交到后台：spec_网络制式：电信4G、spec_显示屏尺寸：4.0-4.9英寸&lt;&#x2F;p&gt;&lt;p&gt;后台接到数据后，可以根据前缀spec_来区分是否是规格，如果以spec_xxx开始的数据则为规格数据，需要根据指定规格找信息。&lt;&#x2F;p&gt;{% asset_img clip_image016.gif&quot; num&quot;: { type: long •specMap&quot;: { propefties : { type: text, fields: { keyword: { ignore_above • 256, type: keywo;d type: text, fields: { keyword. { ignore_above : 256, type: keyword type : text , fields: { keyword: { ignore_above : 256, type: keyword type: text, fields: { keyword: { specMapnißE*.kemord %}&lt;p&gt;上图是规格的索引存储格式，真实数据在spechMap.规格名字.keyword中，所以找数据也是按照如下格式去找：spechMap.规格名字.keyword&lt;&#x2F;p&gt;&lt;p&gt;价格区间查询&lt;&#x2F;p&gt;&lt;p&gt;价格区间查询，每次需要将价格传入到后台，前端传入后台的价格大概是&lt;code&gt;price&#x3D;0-500&lt;&#x2F;code&gt;或者&lt;code&gt;price&#x3D;500-1000&lt;&#x2F;code&gt;依次类推，最后一个是&lt;code&gt;price&#x3D;3000&lt;&#x2F;code&gt;,后台可以根据-分割，如果分割得到的结果最多有2个，第1个表示&lt;code&gt;x&lt;price&lt;&#x2F;code&gt;，第2个表示&lt;code&gt;price&lt;&#x3D;y&lt;&#x2F;code&gt;。&lt;&#x2F;p&gt;&lt;h3 id&#x3D;搜索排序&quot;&gt;&lt;a href&#x3D;#搜索排序 class&#x3D;headerlink title&#x3D;搜索排序&gt;&lt;&#x2F;a&gt;搜索排序&lt;&#x2F;h3&gt;&lt;p&gt;排序这里总共有根据价格排序、根据评价排序、根据新品排序、根据销量排序，排序要想实现非常简单，只需要告知排序的域以及排序方式即可实现。&lt;&#x2F;p&gt; &lt;p&gt;价格排序：只需要根据价格高低排序即可，降序价格高-&gt;低，升序价格低-&gt;高&lt;&#x2F;p&gt; &lt;p&gt;评价排序：评价分为好评、中评、差评，可以在数据库中设计3个列，用来记录好评、中评、差评的量，每次排序的时候，好评的比例来排序，当然还要有条数限制，评价条数需要超过N条。&lt;&#x2F;p&gt; &lt;p&gt;新品排序：直接根据商品的发布时间或者更新时间排序。&lt;&#x2F;p&gt; &lt;p&gt;销量排序：销量排序除了销售数量外，还应该要有时间段限制。&lt;&#x2F;p&gt; &lt;p&gt;这里我们不单独针对某个功能实现排序，我们只需要在后台接收2个参数，分别是排&lt;&#x2F;p&gt; &lt;p&gt;序域名字和排序方式（升序，降序）&lt;&#x2F;p&gt; &lt;h3 id&#x3D;高亮显示&gt;&lt;a href&#x3D;#高亮显示 class&#x3D;headerlink title&#x3D;高亮显示&gt;&lt;&#x2F;a&gt;高亮显示&lt;&#x2F;h3&gt;&lt;p&gt;高亮搜索实现步骤解析：&lt;&#x2F;p&gt; &lt;p&gt;将之前的搜索换掉，换成高亮搜索，我们需要做3个步骤：&lt;&#x2F;p&gt; &lt;p&gt;1.指定高亮域，也就是设置哪个域需要高亮显示设置高亮域的时候，需要指定前缀和后缀，也就是关键词用什么html标签包裹，再给该标签样式&lt;&#x2F;p&gt; &lt;p&gt;2.高亮搜索实现&lt;&#x2F;p&gt; &lt;p&gt;3.将非高亮数据替换成高亮数据&lt;&#x2F;p&gt; &lt;p&gt;第1点，例如在百度中搜索数据的时候，会有2个地方高亮显示，分别是标题和描述，商城搜索的时候，只是商品名称高亮显示了。而高亮显示其实就是添加了样式，例如&lt;span style&#x3D;color:red;&gt;笔记本&lt;&#x2F;span&gt;,而其中span开始标签可以称为前缀，span结束标签可以称为后缀。&lt;&#x2F;p&gt; &lt;p&gt;第2点，高亮搜索使用ElasticsearchTemplate实现。&lt;&#x2F;p&gt; &lt;p&gt;第3点，高亮搜索后，会搜出非高亮数据和高亮数据，高亮数据会加上第1点中的高亮样式，此时我们需要将非高亮数据换成高亮数据即可。例如非高亮:华为笔记本性能超强悍 高亮数据：华为&lt;span style&#x3D;”color:red;”笔记本&lt;&#x2F;span&gt;性能超强悍,将非高亮的换成高亮的，到页面就能显示样式了。&lt;&#x2F;p&gt; &lt;h2 id&#x3D;倒排索引&gt;&lt;a href&#x3D;#倒排索引 class&#x3D;headerlink title&#x3D;倒排索引&gt;&lt;&#x2F;a&gt;倒排索引&lt;&#x2F;h2&gt;{% asset_img clip_image017.jpg img"><p>term dictionary相当于给term作了一个排序</p><p>term index 维护了term的前缀以及偏移量（位置）</p><img src="/2024/04/07/ElasticSearch/clip_image018.jpg" class="" title="img"><p>posting List中存放了后面的那些</p><p>这些词在文章中的偏移量</p><p>权重：TFIDF 词频逆文档频率</p><p>那如果反过来我想查询 name 中包含了 li 的数据有哪些?这样如何高效查询呢?</p><p>仅仅通过上文提到的正排索引显然起不到什么作用，只能依次将所有数据遍历后判断名称中是否包含 li ;这样效率十分低下。</p><p>但如果我们重新构建一个索引结构：</p><img src="/2024/04/07/ElasticSearch/clip_image020.gif" class="" title="img"><p>当要查询 name 中包含 li 的数据时，只需要通过这个索引结构查询到 Posting List 中所包含的数据，再通过映射的方式查询到最终的数据。</p><p>这个索引结构其实就是倒排索引。</p><h3 id="Term-Dictionary"><a href="#Term-Dictionary" class="headerlink" title="Term Dictionary"></a>Term Dictionary</h3><p>但如何高效的在这个索引结构中查询到 li 呢，结合我们之前的经验，只要我们将 Term 有序排列，便可以使用二叉树搜索树的数据结构在 o(logn) 下查询到数据。</p><p>将一个文本拆分成一个一个独立Term 的过程其实就是我们常说的分词。</p><p>而将所有 Term 合并在一起就是一个 Term Dictionary，也可以叫做单词词典。</p><p>英文的分词相对简单，只需要通过空格、标点符号将文本分隔便能拆词，中文则相对复杂，但也有许多开源工具做支持(由于不是本文重点，对分词感兴趣的可以自行搜索)。</p><p>当我们的文本量巨大时，分词后的 Term 也会很多，这样一个倒排索引的数据结构如果存放于内存那肯定是不够存的，但如果像 MySQL 那样存放于磁盘，效率也没那么高。</p><h3 id="Term-Index"><a href="#Term-Index" class="headerlink" title="Term Index"></a>Term Index</h3><p>所以我们可以选择一个折中的方法，既然无法将整个 Term Dictionary 放入内存中，那我们可以为 Term Dictionary 创建一个索引然后放入内存中。</p><p>这样便可以高效的查询 Term Dictionary ，最后再通过 Term Dictionary 查询到 Posting List。</p><p>相对于 MySQL 中的 B+树来说也会减少了几次磁盘 IO。</p><img src="/2024/04/07/ElasticSearch/clip_image022.gif" class="" title="img"><p>这个 Term Index 我们可以使用这样的 Trie 树，也就是我们常说的字典树来存放。</p><img src="/2024/04/07/ElasticSearch/clip_image024.gif" class="" title="img"><p>如果我们是以 j 开头的 Term 进行搜索，首先第一步就是通过在内存中的 Term Index 查询出以 j 打头的 Term 在 Term Dictionary 字典文件中的哪个位置(这个位置可以是一个文件指针，可能是一个区间范围)。</p><p>紧接着在将这个位置区间中的所有 Term 取出，由于已经排好序，便可通过二分查找快速定位到具体位置;这样便可查询出 Posting List。</p><p>最终通过 Posting List 中的位置信息便可在原始文件中将目标数据检索出来。</p><h2 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h2><h3 id="分词器的组成"><a href="#分词器的组成" class="headerlink" title="分词器的组成"></a>分词器的组成</h3><p>分词器是专门处理分词的组件，分词器由以下三部分组成：</p><p>Character Filters</p><p>：针对原始文本处理，比如去除 html 标签</p><p>Tokenizer</p><p>：按照规则切分为单词，比如按照空格切分</p><p>Token Filters</p><p>：将切分的单词进行加工，比如大写转小写，删除 stopwords，增加同义语</p><img src="/2024/04/07/ElasticSearch/clip_image026.gif" class="" title="img"><p>同时 Analyzer 三个部分也是有顺序的，从图中可以看出，从上到下依次经过 Character Filters，Tokenizer 以及 Token Filters，这个顺序比较好理解，一个文本进来肯定要先对文本数据进行处理，再去分词，最后对分词的结果进行过滤。</p><h3 id="ES-分词器"><a href="#ES-分词器" class="headerlink" title="ES 分词器"></a><strong>ES</strong> <strong>分词器</strong></h3><p>首先来介绍下 Stamdard Analyzer 分词器：</p><p><strong>Stamdard Analyzer</strong></p><img src="/2024/04/07/ElasticSearch/clip_image028.gif" class="" title="img"><p>它是 ES <strong>默认的分词器</strong>，它会对输入的文本<strong>按词的方式进行切分</strong>，切分好以后会进行<strong>转小写</strong>处理，<strong>默认的</strong> <strong>stopwords</strong> <strong>是关闭的</strong>。</p><p>可以看出是按照空格、非字母的方式对输入的文本进行了转换，比如对 Java 做了转小写，对一些停用词也没有去掉，比如 in。</p><p>其中 token 为分词结果；start_offset 为起始偏移；end_offset 为结束偏移；position 为分词位置。</p><p>IK提供了两个分词算法ik_smart 和 ik_max_word ，其中 ik_smart 为最少切分，ik_max_word为最细粒度划分 </p><p><a href="https://zhuanlan.zhihu.com/p/111775508">https://zhuanlan.zhihu.com/p/111775508</a></p><h2 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h2><img src="/2024/04/07/ElasticSearch/clip_image029.jpg" class="" title="img"><p>Mapping：描述一个文档：有多少key，怎么分词的</p><p>安全状态：绿色：安全  黄色：有分片没有备份    红色：有数据丢失</p><p>架构：其实就是说分片和副本是怎样分布的</p><p>使用场景：还有日志，大数据量机器学习等，百度搜索，B站搜索</p><p>Elasticsearch是面向文档(document oriented)的，这意味着它可以存储整个对象或文档(document)。然而它不仅 </p><p>仅是存储，还会索引(index)每个文档的内容使之可以被搜索。在Elasticsearch中，你可以对文档（而非成行成列的 </p><p>数据）进行索引、搜索、排序、过滤。Elasticsearch比传统关系型数据库如下： </p><p>Relational DB ‐&gt; Databases ‐&gt; Tables ‐&gt; Rows ‐&gt; Columns </p><p>Elasticsearch ‐&gt; Indices  ‐&gt; Types ‐&gt; Documents ‐&gt; Fields</p><h2 id="Elasticsearch核心概念"><a href="#Elasticsearch核心概念" class="headerlink" title="Elasticsearch核心概念"></a>Elasticsearch核心概念</h2><h3 id="索引-index"><a href="#索引-index" class="headerlink" title="索引 index"></a>索引 index</h3><p>一个索引就是一个拥有几分相似特征的文档的集合。比如说，你可以有一个客户数据的索引，另一个产品目录的索 引，还有一个订单数据的索引。一个索引由一个名字来标识（必须全部是小写字母的），并且当我们要对对应于这 个索引中的文档进行索引、搜索、更新和删除的时候，都要使用到这个名字。在一个集群中，可以定义任意多的索 引。 </p><h3 id="类型-type"><a href="#类型-type" class="headerlink" title="类型 type"></a>类型 type</h3><p>在一个索引中，你可以定义一种或多种类型。一个类型是你的索引的一个逻辑上的分类&#x2F;分区，其语义完全由你来 定。通常，会为具有一组共同字段的文档定义一个类型。比如说，我们假设你运营一个博客平台并且将你所有的数 据存储到一个索引中。在这个索引中，你可以为用户数据定义一个类型，为博客数据定义另一个类型，当然，也可以为评论数据定义另一个类型。 </p><h3 id="字段Field"><a href="#字段Field" class="headerlink" title="字段Field"></a>字段Field</h3><p>相当于是数据表的字段，对文档数据根据不同属性进行的分类标识 </p><h3 id="映射-mapping"><a href="#映射-mapping" class="headerlink" title="映射 mapping"></a>映射 mapping</h3><p>mapping是处理数据的方式和规则方面做一些限制，如某个字段的数据类型、默认值、分析器、是否被索引等等， 这些都是映射里面可以设置的，其它就是处理es里面数据的一些使用规则设置也叫做映射，按着最优规则处理数据 对性能提高很大，因此才需要建立映射，并且需要思考如何建立映射才能对性能更好。 </p><h3 id="文档-document"><a href="#文档-document" class="headerlink" title="文档 document"></a>文档 document</h3><p>一个文档是一个可被索引的基础信息单元。比如，你可以拥有某一个客户的文档，某一个产品的一个文档，当然， 也可以拥有某个订单的一个文档。文档以JSON（Javascript Object Notation）格式来表示，而JSON是一个到处存 在的互联网数据交互格式。 </p><p>在一个index&#x2F;type里面，你可以存储任意多的文档。注意，尽管一个文档，物理上存在于一个索引之中，文档必须 被索引&#x2F;赋予一个索引的type。 </p><h3 id="接近实时-NRT"><a href="#接近实时-NRT" class="headerlink" title="接近实时 NRT"></a>接近实时 NRT</h3><p>Elasticsearch是一个接近实时的搜索平台。这意味着，从索引一个文档直到这个文档能够被搜索到有一个轻微的延迟（通常是1秒以内） </p><h3 id="集群-cluster"><a href="#集群-cluster" class="headerlink" title="集群 cluster"></a>集群 cluster</h3><p>一个集群就是由一个或多个节点组织在一起，它们共同持有整个的数据，并一起提供索引和搜索功能。一个集群由 </p><p>一个唯一的名字标识，这个名字默认就是“elasticsearch”。这个名字是重要的，因为一个节点只能通过指定某个集 群的名字，来加入这个集群 </p><h3 id="节点-node"><a href="#节点-node" class="headerlink" title="节点 node"></a>节点 node</h3><p>一个节点是集群中的一个服务器，作为集群的一部分，它存储数据，参与集群的索引和搜索功能。和集群类似，一 个节点也是由一个名字来标识的，默认情况下，这个名字是一个随机的漫威漫画角色的名字，这个名字会在启动的 时候赋予节点。这个名字对于管理工作来说挺重要的，因为在这个管理过程中，你会去确定网络中的哪些服务器对应于Elasticsearch集群中的哪些节点。 </p><p>一个节点可以通过配置集群名称的方式来加入一个指定的集群。默认情况下，每个节点都会被安排加入到一个叫 做“elasticsearch”的集群中，这意味着，如果你在你的网络中启动了若干个节点，并假定它们能够相互发现彼此， 它们将会自动地形成并加入到一个叫做“elasticsearch”的集群中。 在一个集群里，只要你想，可以拥有任意多个节点。而且，如果当前你的网络中没有运行任何Elasticsearch节点， 这时启动一个节点，会默认创建并加入一个叫做“elasticsearch”的集群。 </p><h3 id="分片和复制-shards-replicas"><a href="#分片和复制-shards-replicas" class="headerlink" title="分片和复制 shards&amp;replicas"></a>分片和复制 shards&amp;replicas</h3><p>一个索引可以存储超出单个结点硬件限制的大量数据。比如，一个具有10亿文档的索引占据1TB的磁盘空间，而任 一节点都没有这样大的磁盘空间；或者单个节点处理搜索请求，响应太慢。为了解决这个问题，Elasticsearch提供 了将索引划分成多份的能力，这些份就叫做分片。当你创建一个索引的时候，你可以指定你想要的分片的数量。每 个分片本身也是一个功能完善并且独立的“索引”，这个“索引”可以被放置到集群中的任何节点上。分片很重要，主要有两方面的原因： 1）允许你水平分割&#x2F;扩展你的内容容量。 2）允许你在分片（潜在地，位于多个节点上）之上 进行分布式的、并行的操作，进而提高性能&#x2F;吞吐量。 至于一个分片怎样分布，它的文档怎样聚合回搜索请求，是完全由Elasticsearch管理的，对于作为用户的你来说， 这些都是透明的。 </p><p>在一个网络&#x2F;云的环境里，失败随时都可能发生，在某个分片&#x2F;节点不知怎么的就处于离线状态，或者由于任何原因 消失了，这种情况下，有一个故障转移机制是非常有用并且是强烈推荐的。为此目的，Elasticsearch允许你创建分 片的一份或多份拷贝，这些拷贝叫做复制分片，或者直接叫复制。 复制之所以重要，有两个主要原因： 在分片&#x2F;节点失败的情况下，提供了高可用性。因为这个原因，注意到复制分片从不与原&#x2F;主要（original&#x2F;primary）分片置于同一节点上是非常重要的。扩展你的搜索量&#x2F;吞吐量，因为搜索可以 在所有的复制上并行运行。总之，每个索引可以被分成多个分片。一个索引也可以被复制0次（意思是没有复制） 或多次。一旦复制了，每个索引就有了主分片（作为复制源的原来的分片）和复制分片（主分片的拷贝）之别。分 片和复制的数量可以在索引创建的时候指定。在索引创建之后，你可以在任何时候动态地改变复制的数量，但是你 </p><p>事后不能改变分片的数量。 </p><p>默认情况下，Elasticsearch中的每个索引被分片5个主分片和1个复制，这意味着，如果你的集群中至少有两个节 点，你的索引将会有5个主分片和另外5个复制分片（1个完全拷贝），这样的话每个索引总共就有10个分片。</p><h2 id="写入数据的工作原理"><a href="#写入数据的工作原理" class="headerlink" title="写入数据的工作原理"></a>写入数据的工作原理</h2><img src="/2024/04/07/ElasticSearch/clip_image030.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image031.jpg" class="" title="img"><h2 id="查询数据的原理"><a href="#查询数据的原理" class="headerlink" title="查询数据的原理"></a>查询数据的原理</h2><img src="/2024/04/07/ElasticSearch/clip_image033.jpg" class="" title="img"><h2 id="ES部署如何优化"><a href="#ES部署如何优化" class="headerlink" title="ES部署如何优化"></a>ES部署如何优化</h2><img src="/2024/04/07/ElasticSearch/clip_image035.jpg" class="" title="img"><h2 id="腾讯课堂"><a href="#腾讯课堂" class="headerlink" title="腾讯课堂"></a>腾讯课堂</h2><h3 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h3><img src="/2024/04/07/ElasticSearch/clip_image036.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image037.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image038.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image039.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image040.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image041.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image042.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image043.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image044.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image045.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image046.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image047.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image048.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image049.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image050.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image051.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image052.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image053.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image054.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image055.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image056.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image057.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image058.jpg" class="" title="img"><h3 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h3><img src="/2024/04/07/ElasticSearch/clip_image059.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image060.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image061.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image062.jpg" class="" title="img"><p>数据可变性问题：当更新数据的时候会触发分段的合并</p><img src="/2024/04/07/ElasticSearch/clip_image063.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image064.jpg" class="" title="img"><p>es文档的格式相当于作了一层json封装，Json形式更好操作，lucene文件相当于只有下面这种键值对的形式</p><img src="/2024/04/07/ElasticSearch/clip_image065.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image066.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image067.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image068.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image069.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image070.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image071.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image072.jpg" class="" title="img"><p>也会找到doc的id，再去倒排索引去查数据</p><img src="/2024/04/07/ElasticSearch/clip_image073.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image074.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image075.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image076.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image077.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image078.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image079.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image080.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image081.jpg" class="" title="img"><h3 id="数据更新"><a href="#数据更新" class="headerlink" title="数据更新"></a>数据更新</h3><img src="/2024/04/07/ElasticSearch/clip_image082.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image083.jpg" class="" title="img"><p>先写到主分片，副本分片是同步过来的</p><img src="/2024/04/07/ElasticSearch/clip_image084.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image085.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image086.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image087.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image088.jpg" class="" title="img"><p>删除的时候只标记，等到合并的时候不合并标记的数据就是删除了</p><img src="/2024/04/07/ElasticSearch/clip_image089.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image090.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image091.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image092.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image093.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image094.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image095.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image096.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image097.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image098.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image099.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image100.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image101.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image102.jpg" class="" title="img"><p>弱一致性：不能保证主副的数据每一时刻都是最新的</p><img src="/2024/04/07/ElasticSearch/clip_image103.jpg" class="" title="img"><p>本地检查点：两个segment合并到哪一步了</p><p>全局检查点：复制到哪一步了</p><img src="/2024/04/07/ElasticSearch/clip_image104.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image105.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image106.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image107.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image108.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image109.jpg" class="" title="img"><h3 id="查询数据"><a href="#查询数据" class="headerlink" title="查询数据"></a>查询数据</h3><img src="/2024/04/07/ElasticSearch/clip_image110.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image111.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image112.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image113.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image114.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image115.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image116.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image117.jpg" class="" title="img"><p>为什么比传统数据库快：（1）因为字典树相当于是第一层索引，放在内存中，词典相当于是第二层索引，放在磁盘中，（2）各种算法的优化，不同情况进行选择</p><p>例如查询ABC模糊查询：先到字典树中查到数据在哪些块，在到词典中根据倒排索引查到编号（链表形式），结果合并是链表生成了跳表，跳表非常合适去做合并</p><p>若不是模糊匹配而是精确匹配，用位图的话合并的速度会更快</p><img src="/2024/04/07/ElasticSearch/clip_image118.jpg" class="" title="img"><p>索引结构是一个多维的，比如说100个字段（都是数字的），那么就会建立100维的索引，这样就会比传统数据库快</p><img src="/2024/04/07/ElasticSearch/clip_image119.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image120.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image121.jpg" class="" title="img"><p>倒排索引还要排序，根据term和文档的关联度打分并排序</p><img src="/2024/04/07/ElasticSearch/clip_image122.jpg" class="" title="img"><p>filter精确查询会更快，比模糊匹配更快，因为这个bitmap算法，并且会做缓存</p><img src="/2024/04/07/ElasticSearch/clip_image123.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image124.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image125.jpg" class="" title="img"><p>参照点：查第二页的时候把第一页的最后一条数据的id给我</p><img src="/2024/04/07/ElasticSearch/clip_image126.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image127.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image128.jpg" class="" title="img"><p>局部：先分片内排序，在整体汇总排序</p><p>全局：把词的信息做一个汇总，再排序，排完序在提出来</p><img src="/2024/04/07/ElasticSearch/clip_image129.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image130.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image131.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image132.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image133.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image134.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image135.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image136.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image137.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image138.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image139.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image140.jpg" class="" title="img"><img src="/2024/04/07/ElasticSearch/clip_image141.jpg" class="" title="img">]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> ElasticSearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RabbitMQ</title>
      <link href="/2024/04/07/RabbitMQ/"/>
      <url>/2024/04/07/RabbitMQ/</url>
      
        <content type="html"><![CDATA[<h1 id="rabbitmq"><a href="#rabbitmq" class="headerlink" title="rabbitmq"></a>rabbitmq</h1><h2 id="为什么使用消息队列？"><a href="#为什么使用消息队列？" class="headerlink" title="为什么使用消息队列？"></a>为什么使用消息队列？</h2><p>（1）解耦：系统A在代码中直接调用系统B和系统C的代码，如果将来D系统接入，系统A还需要修改代码，过于麻烦！</p><p>（2）异步：非必要的业务逻辑（邮件短信）以异步的方式运行，加快响应速度</p><p>（3）削峰：并发量大的时候，所有的请求直接怼到数据库，造成数据库连接异常,系统A慢慢的按照数据库能处理的并发量，从消息队列中慢慢拉取消息。</p><h2 id="有什么缺点"><a href="#有什么缺点" class="headerlink" title="有什么缺点?"></a>有什么缺点?</h2><p>（1）系统可用性降低：消息队列挂了系统可用性降低</p><p>（2）系统复杂性增加：一致性问题、如何保证消息不被重复消费，如何保证保证消息可靠传输</p><p>（3）消息传递路径更长，延时会增加</p><p>（4）上游无法知道下游的执行结果，这一点是很致命的</p><h2 id="选型"><a href="#选型" class="headerlink" title="选型?"></a>选型?</h2><p>（1）选RabbitMQ：一方面，erlang语言天生具备高并发的特性，而且他的管理界面用起来十分方便。RabbitMQ的社区十分活跃，可以解决开发过程中遇到的bug。基于AMQP协议来实现。AMQP的主要特征是面向消息、队列、路由（包括点对点和发布&#x2F;订阅）、可靠性、安全。AMQP协议更多用在企业系统内对数据一致性、稳定性和可靠性要求很高的场景。</p><p>（2）排除其他的：数据量没那么大，选消息中间件，应首选功能比较完备的，所以kafka排除，不支持事务，对消息的重复、丢失、错误没有严格要求。不考虑rocketmq的原因是，rocketmq是阿里出品，如果阿里放弃维护rocketmq，中小型公司一般抽不出人来进行rocketmq的定制化开发，因此不推荐。</p><img src="/2024/04/07/RabbitMQ/clip_image001-1712496107528.jpg" class="" title="img"><img src="/2024/04/07/RabbitMQ/clip_image003-1712496107528.jpg" class="" title="Kafka  优 点 ： 吞 吐 量 非 常 大 ， 性 能 非 常 好 ， 集 群 高 可 用 ·  缺 点 ： 会 丢 数 ， 功 能 比 较 单 一  使 用 场 景 ： 日 志 分 析 ． 大 数 据 采 集  RabbitMO  优 点 ： 消 息 可 壶 性 高 ， 功 能 全 面 ·  点 ： 吞 吐 量 比 较 低 ， 消 息 积 累 会 严 甭 影 响 性 能 ． g 刂 g 言 不 好 定 制 ．  使 用 场 景 ： 小 规 模 场 景 。  RocketMQ  优 点 ： 高 吞 吐 、 高 性 能 、 高 可 用 。 功 能 菲 常 全 面 ·  点 ： 分 源 版 功 能 不 如 云 上 商 业 版 · 官 方 文 档 和 周 边 生 态 还 不 够 成 熟 ． 客 户 端 只 攴 持 iava ·  使 用 场 景 ： 是 全 场 景 ·"><h2 id="集群，如何保证消息队列是高可用的？"><a href="#集群，如何保证消息队列是高可用的？" class="headerlink" title="集群，如何保证消息队列是高可用的？"></a>集群，如何保证消息队列是高可用的？</h2><p>集群：</p><p>（1）<strong>普通模式：消息实体在其中一个节点上，消费时同步</strong></p><p>增加更多节点时，能线性的增加性能（CPU、内存）和容量（内存和磁盘）。</p><p><strong>（<strong><strong>2</strong></strong>）镜像模式：消息实体会同步到所有节点上：</strong>把需要的队列做成镜像队列，存在与多个节点属于RabbitMQ的HA（高可用）方案。</p><p>该模式带来的副作用也很明显，除了降低系统性能外，如果镜像队列数量过多，加之大量的消息进入，集群内部的网络带宽将会被这种同步通讯大大消耗掉。</p><p><a href="https://www.cnblogs.com/gaopengpy/p/13476371.html%E8%BE%83%E6%80%BB%E7%BB%93">https://www.cnblogs.com/gaopengpy/p/13476371.html较总结</a></p><p><a href="https://blog.csdn.net/fgf00/article/details/79558498%E8%BE%83%E7%BB%86%E8%8A%82">https://blog.csdn.net/fgf00/article/details/79558498较细节</a></p><img src="/2024/04/07/RabbitMQ/clip_image004-1712496107528.jpg" class="" title="img"><img src="/2024/04/07/RabbitMQ/clip_image005-1712496107528.jpg" class="" title="img"><img src="/2024/04/07/RabbitMQ/clip_image006-1712496107528.jpg" class="" title="img"><p>master的GM收到消息后表明走了一圈又回来了</p><p>GM不直接操作阻塞队列，通过mirror_queue_&#x2F;操作</p><p>Queue是负责操作的，真正存数据时阻塞队列</p><h2 id="消息不被重复消费（消息队列的幂等性）"><a href="#消息不被重复消费（消息队列的幂等性）" class="headerlink" title="消息不被重复消费（消息队列的幂等性）?"></a>消息不被重复消费（消息队列的幂等性）?</h2><p>正常情况下，消费者在消费消息时候，消费完毕后，会发送一个确认信息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除。只是不同的消息队列发送的确认信息形式不同,例如RabbitMQ是发送一个ACK确认消息。因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将该消息分发给其他的消费者。</p><p>（1)若拿到这个消息做数据库的insert操作。那就容易了，给这个消息做一个唯一主键，</p><p>（2）若拿到这个消息做redis的set的操作，不用解决，set操作本来就算幂等操作。</p><p>（3）准备一个第三方介质,来做消费记录。以redis为例，给消息分配一个全局id，只要消费过该消息，将&lt;id,message&gt;以K-V形式写入redis。那消费者开始消费前，先去redis中查询有没消费记录即可。</p><h2 id="消息可靠性传输"><a href="#消息可靠性传输" class="headerlink" title="消息可靠性传输?"></a>消息可靠性传输?</h2><p>(1)生产者丢数据：</p><p>RabbitMQ提供transaction和confirm模式来确保生产者不丢消息：</p><p>a.transaction机制就是说，发送消息前，开启事物(channel.txSelect())，然后发送消息，如果发送过程中出现什么异常，事物就会回滚(channel.txRollback())，如果发送成功则提交事物(channel.txCommit())。然而缺点就是吞吐量下降了。</p><p>b.生产上用confirm模式的居多。一旦channel进入confirm模式，所有在该信道上面发布的消息都将会被指派一个唯一的ID(从1开始)，一旦消息被投递到所有匹配的队列之后，rabbitMQ就会发送一个Ack给生产者(包含消息的唯一ID)，这就使得生产者知道消息已经正确到达目的队列了.如果rabiitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。</p><p>(2)消息队列丢数据</p><p>持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。</p><p>(3)消费者丢数据消费者丢数据一般是因为采用了自动确认消息模式。采用手动确认消息即可。完成操作了在回复确认。</p><h2 id="消息的顺序性？"><a href="#消息的顺序性？" class="headerlink" title="消息的顺序性？"></a>消息的顺序性？</h2><p>局部有序：多个qq窗口，只要保证一个窗口内的消息有序就行了，多个订单，一个订单有很多处理步骤，只要保证一个订单的处理步骤不乱就行了</p><p>全局有序（mq不保证）：所有窗口的消息之间都要有序</p><p>rabbitMq中就是queue，然后只用一个消费者去消费该队列。观点是保证入队有序就行，出队以后的顺序交给消费者自己去保证，没有固定套路。</p><p><a href="https://www.cnblogs.com/williamjie/p/9481780.html">https://www.cnblogs.com/williamjie/p/9481780.html</a></p><img src="/2024/04/07/RabbitMQ/clip_image008.jpg" class="" title="ii"><h2 id="高效读写-零拷贝"><a href="#高效读写-零拷贝" class="headerlink" title="高效读写_零拷贝"></a>高效读写_零拷贝</h2><img src="/2024/04/07/RabbitMQ/clip_image009-1712496107528.jpg" class="" title="img"><img src="/2024/04/07/RabbitMQ/clip_image010-1712496107529.jpg" class="" title="img"><img src="/2024/04/07/RabbitMQ/clip_image011-1712496107529.jpg" class="" title="img"><p>用户空间只拿映射：内存地址，长度，要写的大小</p><p><strong>DMA</strong>(Direct Memory Access，直接存储器访问</p><img src="/2024/04/07/RabbitMQ/clip_image012-1712496107529.jpg" class="" title="img"><p>使用MQ如何保证分布式事务的最终一致性</p><img src="/2024/04/07/RabbitMQ/clip_image013-1712496107529.jpg" class="" title="img"><p>也可用分布式事务</p><p>最终一致性：不能保证支付完了，同一时刻下单物流完成，只能保证支付完了，下单物流在一定时间内完成</p><img src="/2024/04/07/RabbitMQ/clip_image014-1712496107529.jpg" class="" title="img"><h2 id="分布式MQ的三种语义"><a href="#分布式MQ的三种语义" class="headerlink" title="分布式MQ的三种语义"></a>分布式MQ的三种语义</h2><img src="/2024/04/07/RabbitMQ/clip_image015-1712496107529.jpg" class="" title="img"><p>at least once: 发送者至少发送一次，没有成功则继续发，消费者也是至少接受一次，失败了则再次接受</p><p>at most once: 只发一次，不管成功没</p><p>exactly once: 刚刚好一次就成功</p><h2 id="让你设计一个MQ，如何设计"><a href="#让你设计一个MQ，如何设计" class="headerlink" title="让你设计一个MQ，如何设计"></a>让你设计一个MQ，如何设计</h2><img src="/2024/04/07/RabbitMQ/clip_image016-1712496107529.jpg" class="" title="img"><p>实现一个先进先出的队列，要有消息（进行封装，要有什么字段），可扩展（消息多了队列就增长，少了就缩短）</p><h2 id="RabbitMQ架构设计"><a href="#RabbitMQ架构设计" class="headerlink" title="RabbitMQ架构设计"></a>RabbitMQ架构设计</h2><img src="/2024/04/07/RabbitMQ/clip_image017-1712496107529.jpg" class="" title="img"><p>pull和push模式反了</p><img src="/2024/04/07/RabbitMQ/clip_image018-1712496107529.jpg" class="" title="img"><h2 id="交换机类型"><a href="#交换机类型" class="headerlink" title="交换机类型"></a>交换机类型</h2><img src="/2024/04/07/RabbitMQ/clip_image020-1712496107529.jpg" class="" title="img"><h2 id="可以直连队列吗"><a href="#可以直连队列吗" class="headerlink" title="可以直连队列吗"></a>可以直连队列吗</h2><img src="/2024/04/07/RabbitMQ/clip_image021-1712496107529.jpg" class="" title="img"><img src="/2024/04/07/RabbitMQ/clip_image022-1712496107529.jpg" class="" title="img"><img src="/2024/04/07/RabbitMQ/clip_image023-1712496107529.jpg" class="" title="img"><h2 id="持久化机制"><a href="#持久化机制" class="headerlink" title="持久化机制"></a>持久化机制</h2><img src="/2024/04/07/RabbitMQ/clip_image024-1712496107529.jpg" class="" title="img"><p>删除时：整理左—-中复制到左—–删除中—-整理左—–右到复制左—删除右</p><img src="/2024/04/07/RabbitMQ/clip_image025-1712496107529.jpg" class="" title="img"><h2 id="事务机制"><a href="#事务机制" class="headerlink" title="事务机制"></a>事务机制</h2><p>客户端发送给服务器Tx.Select(开启事务模式)</p><p>服务器端返回Tx.Select-Ok（开启事务模式ok）</p><p>推送消息</p><p>客户端发送给事务提交Tx.Commit</p><p>服务器端返回Tx.Commit-Ok</p><p>生产者开启事务，发送消息到Q2，若发生异常则将Q2中消息删除，若commit了，则将Q2中消息发送到Q1供消费者消费</p><p>消费者方要使用事务应把ack机制置为false，消费方控制队列中的消息是否删除，若异常则不删除，若commit就可删除消息</p><img src="/2024/04/07/RabbitMQ/clip_image026-1712496107529.jpg" class="" title="img"><h2 id="死信队列，延迟队列原理"><a href="#死信队列，延迟队列原理" class="headerlink" title="死信队列，延迟队列原理"></a>死信队列，延迟队列原理</h2><img src="/2024/04/07/RabbitMQ/clip_image028-1712496107529.jpg" class="" title="img"><h2 id="消息队列中的数据怎么删除"><a href="#消息队列中的数据怎么删除" class="headerlink" title="消息队列中的数据怎么删除"></a>消息队列中的数据怎么删除</h2><ul><li><ol><li>清除队列并添加回其他9条消息</li><li>在用户端检查一条消息并拒绝&#x2F;忽略该消息</li><li>将所有消息转发到另一个队列,但1条消息除外</li></ol></li></ul>]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> RabbitMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Oauth2.0</title>
      <link href="/2024/04/07/Oauth2-0/"/>
      <url>/2024/04/07/Oauth2-0/</url>
      
        <content type="html"><![CDATA[<h1 id="Oauth2-0"><a href="#Oauth2-0" class="headerlink" title="Oauth2.0"></a>Oauth2.0</h1><h2 id="认证流程"><a href="#认证流程" class="headerlink" title="认证流程"></a>认证流程</h2><p>(1)传统授权流程</p><img src="/2024/04/07/Oauth2-0/clip_image002.gif" class="" title="客 户  令 牌 台 法 ， 返 回 资 源  申 清 令 牌  权 务  生 成 令 牌  返 回 令 牌  校 令 牌 的 台 法 性  返 回 校 结 果 及 用 户 信  令 牌 访 问 资 源  资 源 务 器"><p>资源服务器授权流程如上图，客户端先去授权服务器申请令牌，申请令牌后，携带令牌访问资源服务器，资源服务器访问授权服务校验令牌的合法性，授权服务会返回校验结果，如果校验成功会返回用户信息给资源服务器，资源服务器如果接收到的校验结果通过了，则返回资源给客户端。</p><p>传统授权方法的问题是用户每次请求资源服务，资源服务都需要携带令牌访问认证服务去</p><p>校验令牌的合法性，并根 据令牌获取用户的相关信息，性能低下。 </p><p>(2)公钥私钥授权流程</p><img src="/2024/04/07/Oauth2-0/clip_image004.gif" class="" title="申 情 令 牌  客 户  私 钥  生 成 令 牌  返 回 令 牌  携 諾 令 牌 访 向 源  资 源 服 务 器  公 钥  校 令 牌 的 台 法 性  令 台 进 ， 逛 回 资 源"><p>传统的授权模式性能低下，每次都需要请求授权服务校验令牌合法性，我们可以利用公钥私钥完成对令牌的加密，如果加密解密成功，则表示令牌合法，如果加密解密失败，则表示令牌无效不合法，合法则允许访问资源服务器的资源，解密失败，则不允许访问资源服务器资源。</p><h2 id="项目开发的认证流程："><a href="#项目开发的认证流程：" class="headerlink" title="项目开发的认证流程："></a>项目开发的认证流程：</h2><img src="/2024/04/07/Oauth2-0/clip_image006.gif" class="" title="O  登 录 页 面  0  资 源 页 面  O  退 出 页 面  令 牌 仕 鼓 巴 n 〕 添 加 到 c 囗 鼓 中  C 囗 囗 巴 ： t 囗 en  校 令 牌 ， 不 台 法 则 拒 绝 访 问  de 1 巴 ： C 囗 囗 巴 ： t 囗 en  认 务  务 网 关  认 务"><p>1、用户登录，请求认证服务 </p><p>2、认证服务认证通过，生成jwt令牌，将jwt令牌及相关信息写入cookie </p><p>3、用户访问资源页面，带着cookie到网关 </p><p>4、网关从cookie获取token，如果存在token，则校验token合法性，如果不合法则拒绝访问，否则放行 </p><p>5、用户退出，请求认证服务，删除cookie中的token</p><p>认证服务需要实现的功能如下： </p><p>1、登录接口 </p><p>前端post提交账号、密码等，用户身份校验通过，生成令牌，并将令牌写入cookie。 </p><p>2、退出接口 校验当前用户的身份为合法并且为已登录状态。 将令牌从cookie中删除。</p><img src="/2024/04/07/Oauth2-0/clip_image008.gif" class="" title="O  &#x2F;user&#x2F;login  changgou-user-oauth  Spr ingSecuri ty  &#x2F;user&#x2F;login-&gt;hft" alt="fi  @NLILL %LIserDetai Is  LIserDetai 1sServiceImp1  NULL  LIserDetai Is"><p>业务层</p><img src="/2024/04/07/Oauth2-0/clip_image010.gif" class="" title="0  登 录 页 面  0 &amp; 此 h2  Controller  将 令 牌 。 0 ） 添 加 到 0 “ k “ 中  令 牌 息  Service"><p>如上图，我们现在实现一个认证流程，用户从页面输入账号密码，到认证服务的Controller层，Controller层调用Service层，Service层调用OAuth2.0的认证地址，进行密码授权认证操作，如果账号密码正确了，就返回令牌信息给Service层，Service将令牌信息给Controller层，Controller层将数据存入到Cookie中，再响应用户。</p><h2 id="单点登录与OAuth的关系"><a href="#单点登录与OAuth的关系" class="headerlink" title="单点登录与OAuth的关系"></a>单点登录与OAuth的关系</h2><p>用户访问的项目中，至少有3个微服务需要识别用户身份，如果用户访问每个微服务都登录一次就太麻烦了，需要实现让用户在一个系统中登录，其他任意受信任的系统都可以访问，这个功能就叫单点登录。</p><p>单点登录（Single Sign On），简称为 SSO。</p><img src="/2024/04/07/Oauth2-0/clip_image012.jpg" class="" title="ffZNSSO? ,  SSO Single Sign On —nn, BEN. Spring Security %}&lt;h2 id&#x3D;什么是认证和授权&quot;&gt;&lt;a href&#x3D;#什么是认证和授权 class&#x3D;headerlink title&#x3D;什么是认证和授权&gt;&lt;&#x2F;a&gt;什么是认证和授权&lt;&#x2F;h2&gt;{% asset_img clip_image014.jpg ． 什 么 是 认 证 和 授 权 ？ 如 何 设 计 一 个 权 限 认 证 框 架 ？  认 证 ； 就 是 对 系 骁 访 回 占 的 身 佾 讲 巧 确 认 ． 用 户 名 醪 0 录 ． 二 鲢 醪 丰 机 矧 信 0 ． 坟 ． 刷 ． ·  授 权 ， 就 是 对 系 晚 访 问 占 的 行 为 行 制 · 授 板 0 斓 是 在 认 过 之 后 ， 系 内 的 用 户 河 私 数 的 行 护 · 后 台 接 冂 访 问 仅 、  前 台 怿 的 砺 。  RBACE" alt="主 体 一 } 角 色 一 》 源 ． 》 访 回 系 统 蝓 巧 为 ·  认 证 和 覆 也 是 对 一 个 艱 认 梅 架 行 扩 層 的 两 主 要 的 方 面 到"><h2 id="定义和几种模式"><a href="#定义和几种模式" class="headerlink" title="定义和几种模式"></a>定义和几种模式</h2><p>授权码模式，简化模式，密码模式，客户端认证模式</p><img src="/2024/04/07/Oauth2-0/clip_image016.jpg" class="" title="img"><img src="/2024/04/07/Oauth2-0/clip_image017.jpg" class="" title="img"><p>认证服务需要实现的功能如下：</p><p>1、登录接口 </p><p>前端post提交账号、密码等，用户身份校验通过，生成令牌，并将令牌写入cookie。 </p><p>2、退出接口 校验当前用户的身份为合法并且为已登录状态。 将令牌从cookie中删除。 </p><img src="/2024/04/07/Oauth2-0/clip_image018.jpg" class="" title="img"><p>三方都不互信的情况：百度是看不到用户授权的，用户是看不到令牌的</p><img src="/2024/04/07/Oauth2-0/clip_image019.jpg" class="" title="img"><p>剩余两方对用户的信任增加了，让用户知道令牌了</p><img src="/2024/04/07/Oauth2-0/clip_image020.jpg" class="" title="img"><p>用户和百度完全互信，直接告诉百度用户名密码去申请令牌</p><img src="/2024/04/07/Oauth2-0/clip_image021.jpg" class="" title="img"><p>三方完全互信，直接用客户端id和秘钥去申请令牌</p><p><a href="https://www.bilibili.com/video/BV1Kt4y1i7nk?from=search&seid=10964394913623719590">https://www.bilibili.com/video/BV1Kt4y1i7nk?from=search&amp;seid=10964394913623719590</a></p><h2 id="设计一个Oauth2-0协议"><a href="#设计一个Oauth2-0协议" class="headerlink" title="设计一个Oauth2.0协议"></a>设计一个Oauth2.0协议</h2><p>使用授权码模式完成OAuth2.0授权的过程需要以下三个步骤：</p><p>client请求授权服务端，获取Authorization Code；</p><p>client通过Authorization Code再次请求授权服务端，获取Access Token；</p><p>client通过服务端返回的Access Token获取用户的基本信息</p><p>因此，OAuth2.0授权服务端的设计也就主要围绕这几个接口展开，其主要流程是这样的：</p><img src="/2024/04/07/Oauth2-0/clip_image022.jpg" class="" title="img"><p><a href="https://www.zifangsky.cn/1313.html">https://www.zifangsky.cn/1313.html</a></p><h2 id="如何设计开放授权平台"><a href="#如何设计开放授权平台" class="headerlink" title="如何设计开放授权平台"></a>如何设计开放授权平台</h2><img src="/2024/04/07/Oauth2-0/clip_image024.jpg" class="" title="img"><h2 id="JWT令牌，和普通令牌有什么区别"><a href="#JWT令牌，和普通令牌有什么区别" class="headerlink" title="JWT令牌，和普通令牌有什么区别"></a>JWT令牌，和普通令牌有什么区别</h2><img src="/2024/04/07/Oauth2-0/clip_image026.jpg" class="" title="lb9f2eaa1-8715.gp.B6c7-06bf757a5f7c  ImFk W. liwi N  TizzmEtN 2 IhZGJlL NTIm C161mMKlno.tJ5d7R8KP8d6w78260 2 Dt ZXV"><h3 id="JWT的构成"><a href="#JWT的构成" class="headerlink" title="JWT的构成"></a>JWT的构成</h3><p>一个JWT实际上就是一个字符串，它由三部分组成，头部、载荷与签名。</p><h3 id="头部（Header）"><a href="#头部（Header）" class="headerlink" title="头部（Header）"></a>头部（Header）</h3><p>头部用于描述关于该JWT的最基本的信息，例如其类型以及签名所用的算法</p><p>等。这也可以被表示成一个JSON对象。</p><p>{“typ”:”JWT”,”alg”:”HS256”}</p><p>在头部指明了签名算法是HS256算法。 </p><h3 id="载荷（playload）"><a href="#载荷（playload）" class="headerlink" title="载荷（playload）"></a>载荷（playload）</h3><p>载荷就是存放有效信息的地方。这个名字像是特指飞机上承载的货品，这些有效信息包含三个部分</p><p>（1）标准中注册的声明（建议但不强制使用）</p><p>iss: jwt签发者</p><p>sub: jwt所面向的用户</p><p>aud: 接收jwt的一方</p><p>exp: jwt的过期时间，这个过期时间必须要大于签发时间</p><p>nbf: 定义在什么时间之前，该jwt都是不可用的.</p><p>iat: jwt的签发时间</p><p>jti: jwt的唯一身份标识，主要用来作为一次性token,从而回避重放攻击。</p><p>（2）公共的声明</p><p>公共的声明可以添加任何的信息，一般添加用户的相关信息或其他业务需要的必要信息.但不建议添加敏感信息，因为该部分在客户端可解密.  </p><p>（3）私有的声明</p><p>私有声明是提供者和消费者所共同定义的声明，一般不建议存放敏感信息，因为base64是对称解密的，意味着该部分信息可以归类为明文信息。</p><p>这个指的就是自定义的claim。比如下面面结构举例中的admin和name都属于自定的claim。这些claim跟JWT标准规定的claim区别在于：JWT规定的claim，JWT的接收方在拿到JWT之后，都知道怎么对这些标准的claim进行验证(还不知道是否能够验证)；而private claims不会验证，除非明确告诉接收方要对这些claim进行验证以及规则才行。</p><p>定义一个payload:</p><p>{“sub”:”1234567890”,”name”:”John Doe”,”admin”:true}</p><h3 id="签证（signature）"><a href="#签证（signature）" class="headerlink" title="签证（signature）"></a>签证（signature）</h3><p>jwt的第三部分是一个签证信息，这个签证信息由三部分组成：</p><p> header (base64后的)</p><p> payload (base64后的)</p><p>secret</p><p>这个部分需要base64加密后的header和base64加密后的payload使用.连接组成的字符串，然后通过header中声明的加密方式进行加盐secret组合加密（第一部分+第二部分，再用secret+加盐加密），然后就构成了jwt的第三部分。加盐加密：就是人为的通过一组随机字符与用户原密码的组合形成一个新的字符。</p><p>TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ</p><p>将这三部分用.连接成一个完整的字符串,构成了最终的jwt:</p><p>eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ</p><p><strong>注意</strong>：secret是保存在服务器端的，jwt的签发生成也是在服务器端的，secret就是用来进行jwt的签发和jwt的验证，所以，它就是你服务端的私钥，在任何场景都不应该流露出去。一旦客户端得知这个secret, 那就意味着客户端是可以自我签发jwt了。根据以下公式生</p><p>成签名：HMACSHA256(base64UrlEncode(header) + “.” + base64UrlEncode(payload),secret)</p><h2 id="什么是CSRF攻击？如何防止"><a href="#什么是CSRF攻击？如何防止" class="headerlink" title="什么是CSRF攻击？如何防止"></a>什么是CSRF攻击？如何防止</h2><img src="/2024/04/07/Oauth2-0/clip_image028.jpg" class="" title="img"><p>如果某一个Cookie 选项被设置成 HttpOnly &#x3D; true 的话，那此Cookie 只能通过服务器端修改，Js 是操作不了的，对于 document.cookie 来说是透明的。</p><img src="/2024/04/07/Oauth2-0/clip_image030.jpg" class="" title="img"><h3 id="sso和OAuth2-0的关系"><a href="#sso和OAuth2-0的关系" class="headerlink" title="sso和OAuth2.0的关系"></a>sso和OAuth2.0的关系</h3><h2 id="Cookie和Session区别"><a href="#Cookie和Session区别" class="headerlink" title="Cookie和Session区别"></a>Cookie和Session区别</h2><img src="/2024/04/07/Oauth2-0/clip_image032.jpg" class="" title="img">]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> Oauth2.0 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式事务</title>
      <link href="/2024/04/07/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
      <url>/2024/04/07/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<h1 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h1><h2 id="1-两阶段提交"><a href="#1-两阶段提交" class="headerlink" title="1.两阶段提交"></a>1.两阶段提交</h2><img src="/2024/04/07/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/clip_image050.jpg" class="" title="img"><img src="/2024/04/07/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/clip_image052.jpg" class="" title="img"><img src="/2024/04/07/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/clip_image054.jpg" class="" title="img"><img src="/2024/04/07/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/clip_image056.jpg" class="" title="img"><p>两阶段的问题：</p><p>两阶段提交协议的问题在于数据库在提交请求阶段应答后对很多资源处于锁定状态，要等到事务管理器收集齐所有数据库的应答后，才能发commit或者rollback消息结束这种锁定。锁定时间的长度是由最慢的一个数据库制约，如果数据库一直没有应答，所有其他库也需要无休止的锁并等待。并且，如果事务管理器出现故障，被锁定的资源将长时间处于锁定状态。无论是任一数据库或者事务管理器故障，其他数据库都需要永久锁定或者至少长时间锁定。并且，分布式系统中节点越多，存在缓慢网络或者故障节点的概率也就越大，资源被长时间锁定的概率指数上升。</p><p>两阶段提交协议的另一个问题是只要有任意一个数据库不可用都会导致事务失败，这导致事务更倾向于失败。对于多个副本的备份系统，很多时候我们希望部分副本点失效时系统仍然可用，使用该协议则不能实现。并且，分布式系统中节点越多，存在故障节点的概率也就越大，系统的可用性指数下降。</p><p>另外，如果数据库在第一阶段应答后到第二阶段正式提交前的某个阶段网络故障或者节点故障，该协议无法提交或回滚，数据不一致不能绝对避免。</p><h2 id="2-TCC"><a href="#2-TCC" class="headerlink" title="2.TCC"></a>2.TCC</h2><p>先是服务调用链路依次执行 Try 逻辑。</p><p>如果都正常的话，TCC 分布式事务框架推进执行 Confirm 逻辑，完成整个事务。</p><p>如果某个服务的 Try 逻辑有问题，TCC 分布式事务框架感知到之后就会推进执行各个服务的 Cancel 逻辑，撤销之前执行的各种操作。</p><p><a href="https://www.cnblogs.com/jajian/p/10014145.html">https://www.cnblogs.com/jajian/p/10014145.html</a></p><img src="/2024/04/07/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/clip_image058.jpg" class="" title="img"><h2 id="3-本地消息表："><a href="#3-本地消息表：" class="headerlink" title="3.本地消息表："></a>3.本地消息表：</h2><p>其基本的设计思想是将远程分布式事务拆分成一系列的本地事务。</p><p>举个经典的跨行转账的例子来描述：</p><p>第一步伪代码如下，扣款 1W，通过本地事务保证了凭证消息插入到消息表中。</p><p>第二步，通知对方银行账户上加 1W 了。那问题来了，如何通知到对方呢？</p><p>通常采用两种方式：</p><p>采用时效性高的 MQ，由对方订阅消息并监听，有消息时自动触发事件</p><p>采用定时轮询扫描的方式，去检查消息表的数据。</p><p>两种方式其实各有利弊，仅仅依靠 MQ，可能会出现通知失败的问题。而过于频繁的定时轮询，效率也不是最佳的（90% 是无用功）。所以，我们一般会把两种方式结合起来使用。</p><p>万一这消息有重复被消费，往用户帐号上多加了钱，那岂不是后果很严重？在消息消费方，也通过一个“消费状态表”来记录消费状态。在执行“加款”操作之前，检测下该消息（提供标识）是否已经消费过，消费完成后，通过本地事务控制来更新这个“消费状态表”。这样子就避免重复消费的问题。</p><p><a href="https://www.infoq.cn/article/solution-of-distributed-system-transaction-consistency/">https://www.infoq.cn/article/solution-of-distributed-system-transaction-consistency/</a></p>]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> 分布式事务 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分布式锁</title>
      <link href="/2024/04/07/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
      <url>/2024/04/07/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</url>
      
        <content type="html"><![CDATA[<h1 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h1><h2 id="分布式锁应用场景"><a href="#分布式锁应用场景" class="headerlink" title="分布式锁应用场景"></a><strong>分布式锁</strong>应用场景</h2><p>将服务器从单机部署升级为多机部署后，则会发现Java提供的原生锁机制在多机部署下失效了。这是因为Java本身提供的锁，他们只对属于自己JVM里面的线程有效，对于其他JVM的线程是无效的。</p><h2 id="场景示例"><a href="#场景示例" class="headerlink" title="场景示例"></a>场景示例</h2><p>​    现在有一个电商系统，此时只通过一台机器进行部署，当用户下单时，首先会检查库存是否足够，只有当库存足够时，才会允许进行下单。</p><p>​    为了提高系统的并发性能，因此会首先将商品库存信息预热到redis中，当用户下单时，会更新redis中的库存信息。</p><img src="/2024/04/07/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/clip_image060.gif" class="" title="Redis  MySQL"><p>​    此时在单线程下执行是没有任何问题的，但是假设现在某一商品库存数量为1，且同时有两个线程同时对该商品执行下单操作，线程A和线程B查询库存结果都为1，此时线程A先执行第三步更新mysql将库存数量由1变为0。但是当线程B再来执行第三步更新mysql</p><p>时，库存数量会变为-1，此时库存超卖出现。</p><img src="/2024/04/07/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/clip_image062.gif" class="" title="stock-I  update table set stock—stock-#{number}  stock&#x3D;0  stock&#x3D;l  update table set stock-stock-#{number}  stock"><p>​    此时要想解决超卖问题，则可以进行加锁，将2，3，4步利用synchronized或者</p><p>ReentrantLock进行加锁，从而让线程排队，避免超卖问题的出现。</p><img src="/2024/04/07/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/clip_image064.gif" class="" title="ı.F3  ock  zül*  4.sredis  3  Redis  MySQL"><p>​    但是当随着并发量的增大，此时单机部署已经无法承受这么大的并发量了，则会将</p><p>系统由单机变为多机部署。</p><img src="/2024/04/07/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/clip_image066.gif" class="" title="1 ． 下 单  秒 杀 系 统  unl  2 查 库 存  4． 更 %edis  1 ． 下 单  lock  秒 杀 系 统  2 ． 检 0 库 存  4.Eredis  3 ． 锁 定 更 新 库 存  Redis  商 品 库 存 信 息  MySQL  3 ． 锁 定 抖 更 新 库 存"><p>​    此时假设同时有两个用户进行下单，请求分别进入两台机器中，那么这两个请求是可以同时执行的，则仍然会出现超卖问题。</p><p>​    因为不管synchronized或者ReentrantLock都是只作用于自己机器的JVM中，对其他机</p><p>器的JVM无效。相当于两台不同的机器使用的是不同的两把锁，导致锁失效。</p><p>​    解决该问题的思路则需要保证不同的机器使用的是相同的一把锁，则此时需要使用分布式锁。对于分布式锁的实现，可以基于Mysql、redis、zookeeper、consule等进行实</p><p>现。</p><h2 id="分布式锁具备的条件"><a href="#分布式锁具备的条件" class="headerlink" title="分布式锁具备的条件"></a>分布式锁具备的条件</h2><p>- <strong>互斥性</strong>：同一时刻只能有一个服务(或应用)访问资源。</p><p>- <strong>原子性</strong>：一致性要求保证加锁和解锁的行为是原子性的。</p><p>- <strong>安全性</strong>：锁只能被持有该锁的服务(或应用)释放。</p><p>- <strong>容错性</strong>：在持有锁的服务崩溃时，锁仍能得到释放，避免死锁。</p><p>- <strong>高可用</strong>：获取锁和释放锁 要高可用。</p><p>- <strong>高性能</strong>：获取锁和释放锁的性能要好。</p><p>- <strong>持久性</strong>：锁按业务需要自动续约&#x2F;自动延期。</p><h2 id="分布式锁的实现"><a href="#分布式锁的实现" class="headerlink" title="分布式锁的实现"></a>分布式锁的实现</h2><h3 id="基于数据库表实现"><a href="#基于数据库表实现" class="headerlink" title="基于数据库表实现"></a><a href="onenote:#分布式锁的实现&section-id={3685743C-702A-48F2-B3FF-3D01808AF522}&page-id={F5CE60B2-981A-40F8-9AAF-B0CF1C91DF08}&object-id={A529F93C-5E1F-40E0-9895-5A708E9FC8B9}&14&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/畅购.one">基于数据库表实现</a></h3><h3 id="zookeeper实现"><a href="#zookeeper实现" class="headerlink" title="zookeeper实现"></a><a href="onenote:#分布式锁的实现&section-id={3685743C-702A-48F2-B3FF-3D01808AF522}&page-id={F5CE60B2-981A-40F8-9AAF-B0CF1C91DF08}&object-id={4DB8704F-D766-4F09-92A9-0C6CB7D62396}&13&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/畅购.one">zookeeper实现</a></h3><h3 id="redis实现"><a href="#redis实现" class="headerlink" title="redis实现"></a>r<a href="onenote:#分布式锁的实现&section-id={3685743C-702A-48F2-B3FF-3D01808AF522}&page-id={F5CE60B2-981A-40F8-9AAF-B0CF1C91DF08}&object-id={4DB8704F-D766-4F09-92A9-0C6CB7D62396}&11&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/畅购.one">edis实现</a></h3><h3 id="基于数据库表实现-1"><a href="#基于数据库表实现-1" class="headerlink" title="基于数据库表实现"></a>基于数据库表实现</h3><p>准备工作：创建tb_program表，用于记录当前哪个程序正在使用数据</p><img src="/2024/04/07/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/clip_image068.jpg" class="" title="CREATE TABLE  program no  NOT NULL,  tb_program• (  varchar(188) CHARACTER SET utf8 COLLATE  PRIMARY KEY USING BTREE  ) ENGINE  InnoDB CHARACTER SET &#x3D; utf8 COLLATE -  utf8_genera1_ci  ROW  SET  FORMAT &#x3D; Dynamic;  FOREIGN KEY CHECKS"><p>实现步骤：</p><ol><li><p>程序访问数据时，将程序的编号（insert）存入tb_program表。</p></li><li><p>当insert成功，代表该程序获得了锁，即可执行逻辑。</p></li><li><p>当program_no相同的其他程序进行insert时，由于主键冲突会导致insert失败，则代表获取锁失败。</p></li><li><p>获取锁成功的程序在逻辑执行完以后，删除该数据,代表释放锁。</p></li></ol><h3 id="基于条件"><a href="#基于条件" class="headerlink" title="基于条件"></a>基于条件</h3><p>​    对于分布式锁的实现，比较常见的一种就是基于MySQL乐观锁方式来完成，这种方式的思想就是利用MySQL的InnoDB引擎的<strong>行锁</strong>机制来完成。</p><p>​    对于乐观锁的实现，又分为两种，分别为<strong>根据条件</strong>和<strong>根据版本号</strong>。</p><img src="/2024/04/07/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/clip_image070.jpg" class="" title="public interface Bookmapper extends {  @Update(update tb book set where id {id} and stock-#{sa1eNum}&gt;&#x3D;e&quot;) void updateNoLock(@Param(id) int id, int saleNum); %}&lt;p&gt;通过Jemeter进行并发测试，可以发现其已经可以保证库存不会被扣减超卖。&lt;&#x2F;p&gt;&lt;h3 id&#x3D;基于version版本号&quot;&gt;&lt;a href&#x3D;#基于version版本号 class&#x3D;headerlink title&#x3D;基于version版本号&gt;&lt;&#x2F;a&gt;基于version版本号&lt;&#x2F;h3&gt;&lt;p&gt;​ 有时我们并没有一些特定的条件让我们去进行判断。此时就会在数据表中新增一个字段版本字段version来进行数据并发控制。&lt;&#x2F;p&gt; {% asset_img clip_image072.gif null  varchar  stock  version"><img src="/2024/04/07/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/clip_image074.jpg" class="" title="@lJpdate(update tb book set version-version+l where {id} and version&#x3D;#{version})  int updateByVersion(@Param(id&quot;)int version); %}&lt;h3 id&#x3D;zookeeer实现&quot;&gt;&lt;a href&#x3D;#zookeeer实现 class&#x3D;headerlink title&#x3D;zookeeer实现&gt;&lt;&#x2F;a&gt;zookeeer实现&lt;&#x2F;h3&gt;&lt;p&gt;对于分布式锁的实现，zookeeper天然携带的一些特性能够很完美的实现分布式锁。其内部主要是利用znode节点特性和watch机制完成。&lt;&#x2F;p&gt; &lt;p&gt;znode节点&lt;&#x2F;p&gt; &lt;p&gt;在zookeeper中节点会分为四类，分别是：&lt;&#x2F;p&gt; &lt;p&gt;- &lt;strong&gt;持久节点：&lt;&#x2F;strong&gt;一旦创建，则永久存在于zookeeper中，除非手动删除。&lt;&#x2F;p&gt; &lt;p&gt;- &lt;strong&gt;持久有序节点：&lt;&#x2F;strong&gt;一旦创建，则永久存在于zookeeper中，除非手动删除。同时每个节点都会默认存在节点序号，每个节点的序号都是有序递增的。如demo000001、demo000002…..demo00000N。&lt;&#x2F;p&gt; &lt;p&gt;- &lt;strong&gt;临时节点：&lt;&#x2F;strong&gt;当节点创建后，一旦服务器重启或宕机，则被自动删除。&lt;&#x2F;p&gt; &lt;p&gt;- &lt;strong&gt;临时有序节点：&lt;&#x2F;strong&gt;当节点创建后，一旦服务器重启或宕机，则被自动删除。同时每个节点都会默认存在节点序号，每个节点的序号都是有序递增的。如&lt;&#x2F;p&gt; &lt;p&gt;demo000001、demo000002…..demo00000N。&lt;&#x2F;p&gt; &lt;p&gt;watch监听机制&lt;&#x2F;p&gt; &lt;p&gt;​ watch监听机制主要用于&lt;strong&gt;监听节点状态变更&lt;&#x2F;strong&gt;，用于后续事件触发，假设当B节点监听A节点时，一旦A节点发生修改、删除、子节点列表发生变更等事件，B节点则会收到A节点改变的通知，接着完成其他额外事情。&lt;&#x2F;p&gt; {% asset_img clip_image076.gif 2)  znodeA  znodeB"><p>实现原理</p><p>其实现思想是当某个线程要对方法加锁时，首先会在zookeeper中创建一个与当前方法对应的父节点，接着每个要获取当前方法的锁的线程，都会在父节点下创建一个<strong>临时有序节点</strong>（临时：避免死锁，持久节点会一直占着锁，有序：获取锁的效率高），因为节点序号是递增的，所以后续要获取锁的线程在zookeeper中的序号也是逐次递增的。根据这个特性，当前序号最小的节点一定是首先要获取锁的线程，因此可以规定<strong>序号最小的节点获得锁</strong>。所以，每个线程再要获取锁时，可以判断自己的节点序号是否是最小的，如果是则获取到锁。当释放锁时，只需将自己的临时有序节点删除即可。</p><img src="/2024/04/07/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/clip_image078.gif" class="" title="methodA  ThreadA000001  ThreadC000003  zookeeper server  methodB  ThreadA000001  ThreadC000003  methodC  ThreadA000001  ThreadC000003"><p>根据上图，在并发下，每个线程都会在对应方法节点下创建属于自己的临时节点，且每个节点都是临时且有序的。那么zookeeper又是如何有序的将锁分配给不同线程呢？ 这里就应用到了watch监听机制。每当添加一个新的临时节点时，其都会基于watcher机制监听着它本身的前一个节点等待前一个节点的通知，当前一个节点删除时，就轮到它来持有锁了。然后依次类推。判断是否获取锁，只要判断放弃那节点序号是否是最小的。</p><img src="/2024/04/07/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/clip_image080.gif" class="" title="methodA  ThreadA000001  watch  ThreadB000002  watch  ThreadC000003  watch  zookeeper server  methodB  ThreadA000001  watch  ThreadB000002  watch  ThreadC000003  watch  methodC  ThreadA000001  watch  ThreadB000002  watch  ThreadC000003  watch"><p>低效锁思想&amp;实现</p><img src="/2024/04/07/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/clip_image082.gif" class="" title="开 始 事 务  一 当 删 除 一  锁 节 点 已 存 在  不 成 功  监 听 锁 节 点 删 除  获 取 锁  创 建 锁 节 点  类 型 ： 临 时 节 点  如 ： &#x2F;lock  否 创 建 成 功  获 得 锁  放 锁  删 除 锁 节 点"><p>此种实现方式，只会存在一个锁节点。当创建锁节点时，如果锁节点不存在，则创建成功，代表当前线程获取到锁，如果创建锁节点失败，代表已经有其他线程获取到锁，则该</p><p>线程会监听锁节点的释放。当锁节点释放后，则继续尝试创建锁节点加锁。</p><p>测试运行可以发现：当一个线程获取到锁之后，其他线程则一起监听同一个节点，当线程将锁释放后，其他线程再来继续竞争这把锁。</p><p>这种方案的低效点就在于，只有一个锁节点，其他线程都会监听同一个锁节点，一旦锁节点释放后，其他线程都会收到通知，然后竞争获取锁节点。这种大量的通知操作会严重降低zookeeper性能，对于这种由于一个被watch的znode节点的变化，而造成大量的通知操作，叫做羊群效应。</p><p>高效锁思想&amp;实现 </p><p>为了避免羊群效应的出现，业界内普遍的解决方案就是，让获取锁的线程产生排队，后一个监听前一个，依次排序。推荐使用这种方式实现分布式锁。</p><img src="/2024/04/07/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/clip_image084.gif" class="" title="开 始 务  获 取 锁 功  获 取 锁  刂 断 父 节 三  不 存 在  创 建 临 时 有 序 节 点  创 建 父 节 点  0 燙 韙 00- 。  获 取 锁  判 断 身 是 台 为 序 号  最 小 节  不 是 最 小 节  序 号 一 1 的 节  阝 且 蔗 等 彳 寺 前 置  节 中 删 除 通 知  收 前 置 节 点 剂 令 兰 知  0 过"><p>1）定义HighLock类</p><p>1.判断父节点是否存在，父节点不存在，创建持久节点</p><p>2.如果当前节点不存在，则在父节点下创建第一个临时有序节点</p><p>3.如果当前节点存在，则获取父节点下的子节点列表</p><p>4.对子节点列表进行排序</p><p>5.判断当前节点是否为父节点下序号最小的节点</p><p>6.是序号最小的节点，则加锁成功</p><p>7.如果不是序号最小的节点，则对前置节点进行赋值</p><p>锁失效问题</p><p><img src="/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/clip_image086.jpg" alt="@Override  @Transactiona1  public void updatestock(int id, int saleNum) {  String methodName  [8] . getMethodName() ;  AbstractLock lock  lock. getLock();  Thread . current Thread ( ) . getStackTrace ( )  new High Lock(&quot; /&quot;+methodName);  Book book = bookmapper.se1ectById(id);  if (book.  bookmapper. updateNoLock(id , saleNum) ;  System. out. println( &quot; &quot; ) ;  }else {  System. out. println( &quot; ) ;  lock. releaseLock(); "></p><p>此时通过Jemeter测试，发现仍然出现了超卖。那么问题出现在哪里了呢？ 当前不管使用</p><p>分布式锁还是JVM提供的锁都是控制不住超卖的(sync、redis、zookeeper)。</p><p>当把事务去掉，再通过jemeter进行测试，可以发现已经可以控制住超卖问题了。</p><p>其实原因就出现在@Transactional事务上。在业务层上，首先会开启事务，然后加锁、进行业务操作、释放锁，最后才会进行事务提交。 此时因为锁是先释放，那么其他线程就可以获取到锁再来执行该方法，但之前的事务还并未提交，那么后进来的事务当查询时，库存数量仍然满足条件。 因此最终出现超卖问题。这就业锁失效的问题。</p><p>对于该问题的解决，第一种方式：将自动事务更改为手动控制事务，在service改代码。 第二种：将锁操作上移到表现层。 开发中，常见的是使用第二种方式进行解决。</p><h3 id="Redis实现"><a href="#Redis实现" class="headerlink" title="Redis实现"></a>Redis实现</h3><p>单节点Redis实现分布式锁</p><p>原理实现</p><p>分布式锁的一个很重要的特性就是互斥性，同一时间内多个调用方加锁竞争，只能有一个调用方加锁成功。而redis是基于单线程模型的，可以利用这个特性让调用方的请求排队，</p><p>对于并发请求，只会有一个请求能获取到锁。</p><p>-redis实现分布式锁也很简单，基于客户端的几个API就可以完成，主要涉及三个核心API：</p><p>- setNx()：向redis中存key-value，只有当key不存在时才会设置成功，否则返回0。用于体现</p><p>互斥性。</p><p>- expire()：设置key的过期时间，用于避免死锁出现。</p><p> - delete()：删除key，用于释放锁。</p><p>如果加锁失败，则自旋不断尝试获取锁，同时在一定时间内如果仍没有获取到锁，则退出</p><p>自旋，不再尝试获取锁。</p><p>解锁时，要避免当前线程将别人的锁释放掉。假设线程A加锁成功，当过了一段时间线程A来解锁，但线程A的锁已经过期了，在这个时间节点，线程B也来加锁，因为线程A的锁已经过期，所以线程B时可以加锁成功的。此时，就会出现问题，线程A将线程B的锁给释放了。</p><p>对于这个问题，就需要使用到加锁时的requestId。当解锁时要判断当前锁键的value与传入的value是否相同，相同的话，则代表是同一个人，可以解锁。否则不能解锁。</p><p>但是对于这个操作，有非常多的人，会先查询做对比，接着相同则删除。虽然思路是对的，但是忽略了一个问题，<strong>原子性</strong>。判断与删除分成两步执行，则无法保证原子性，一样会出现问题。所以解锁时不仅要保证加锁和解锁是同一个人还要保证解锁的原子性。因此结合lua脚本完成查询&amp;删除操作。</p><p>多线程会竞争同一把锁，且没有获取获取到锁的线程会自旋不断尝试去获取锁。每当一个线程将锁释放后，则会有另外一个线程持有锁。依次类推。</p><p>单节点问题</p><p>锁续期</p><p>当对业务进行加锁时，锁的过期时间，绝对不能想当然的设置一个值。假设线程A在执行某个业务时加锁成功并设置锁过期时间。但该业务执行时间过长，业务的执行时间超过了锁过期时间，那么在业务还没执行完时，锁就自动释放了。接着后续线程就可以获取到锁，又来执行该业务。就会造成线程A还没执行完，后续线程又来执行，导致同一个业务逻辑被重复执行。因此对于锁的超</p><p>时时间，需要结合着业务执行时间来判断，让锁的过期时间大于业务执行时间。</p><p>上面的方案是一个基础解决方案，但是仍然是有问题的。</p><p>业务执行时间的影响因素太多了，无法确定一个准确值，只能是一个估值。无法百分百保证业务执行期间，锁只能被一个线程占有。</p><p>如想保证的话，可以在创建锁的同时创建一个守护线程，同时定义一个定时任务每隔一段时间去为未释放的锁增加过期时间。当业务执行完，释放锁后，再</p><p>关闭守护线程。 这种实现思想可以用来解决锁续期。</p><img src="/2024/04/07/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/clip_image088.gif" class="" title="业 务 节 中  1 〕 执 行 能  锁 ， 并 设 过  雖 时 河  一 锁 洹 一  疯 行 业 务  4 〕 放 锁  关 0 守 护 线  守 护 线 程  到 创 守 护 线 程  到 定 时 延 长 锁 洹 时 河"><p>服务单点&amp;集群问题</p><p>在单点redis虽然可以完成锁操作，可一旦redis服务节点挂掉了，则无法提供锁操作。</p><p>在生产环境下，为了保证redis高可用，会采用<strong>异步复制</strong>方法进行主从部署。当主节点写入数据成功，会异步的将数据复制给从节点，并且当主节点宕机，从节点会被提升为主节点继续工作。假设主节点写入数据成功，在没有将数据复制给从节点时，主节点宕机。则会造成提升为主节点的从节点中是没有锁信息的，其他线程则又可以继续加锁，导致互斥失效。</p><img src="/2024/04/07/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/clip_image090.gif" class="" title="client  redis master  redis slave  data"><h1 id=""><a href="#" class="headerlink" title=""></a></h1><h3 id="Redisson实现分布式锁"><a href="#Redisson实现分布式锁" class="headerlink" title="Redisson实现分布式锁"></a>Redisson实现分布式锁</h3><p>redisson是redis官网推荐实现分布式锁的一个第三方类库。其内部完成的功能非常强大，对各种锁都有实现，同时对于使用者来说非常简单，让使用者能够将更多的关</p><p>注点放在业务逻辑上。此处重点利用Redisson解决单机Redis锁产生的两个问题。</p><p>单机Redisson实现分布式锁</p><p>基于redisson实现分布式锁很简单，直接基于lock()&amp;unlock()方法操作即可。</p><p>多线程并发获取所时，当一个线程获取到锁，其他线程则获取不到，并且其内部会不断尝试获取锁，当持有锁的线程将锁释放后，其他线程则会继续去竞争锁。</p><p> 看门狗</p><p>lock()方法虽然可以设置过期时间，当到期后，锁就会自动释放，因此在业务执行中，通过lock()加锁会存在隐患。Redisson也考虑到了这点，所以提供了看门狗机制。</p><p>改造锁示例代码，让锁超时时间为1秒，但是业务执行时，需要耗时3秒，此时执行可以发现，多线程间在上一个锁没有释放的情况下，后续线程又获取到了锁。但是解锁的时候，出现异常，因为加锁时的唯一标识与解锁时的唯一标识发生了改变，造成死锁。</p><p>因为业务执行多久无法确定一个准确值，所以在看门狗的实现中，不需要对锁key设置过期时间，当过期时间为-1时，这时会启动一个定时任务，在业务释放锁之前，会一直不停的增加这个锁的有效时间，从而保证在业务执行完毕前，这把锁不会被提前释放掉。</p><p>要开启看门狗机制也很简单，只需要将加锁时使用**lock()<strong>改为</strong>tryLock()**即可。</p><p>红锁</p><p>当在单点redis中实现redis锁时，一旦redis服务器宕机，则无法进行锁操作。因此会考虑将redis配置为主从结构，但在主从结构中，数据复制是异步实现的。假设在主从结构中，master会异步将数据复制到slave中，一旦某个线程持有了锁，在还没有将数据复制到slave时，master宕机。则slave会被提升为master，但被提升为slave的master中并没有之前线程的锁信息，那么其他线程则又可以重新加锁。</p><p>redlock是一种<strong>基于多节点redis实现分布式锁</strong>的算法，可以有效解决redis单点故</p><p>障的问题。官方建议搭建<strong>五台redis</strong>服务器对redlock算法进行实现。</p><p>整个实现过程分为五步：</p><p>1）记录获取锁前的当前时间</p><p>2）使用相同的key，value获取所有redis实例中的锁，并且设置获取锁的时间要远远小于锁自动释放的时间。假设锁自动释放时间是10秒，则获取时间应在5-50毫秒之间。通过这种方式避免客户端长时间等待一个已经关闭的实例，如果一个实例不可用了，则尝试获取下一个实例。</p><p>3）客户端通过获取所有实例的锁后的时间减去第一步的时间，得到的差值要小于锁自动释放时间，避免拿到一个已经过期的锁。并且要有超过半数的redis实例成功获取到锁，才算最终获取锁成功。如果不是超过半数，有可能出现多个客户端重复获取到锁，导致锁失效。</p><p>4）当已经获取到锁，那么它的真正失效时间应该为：过期时间-第三步的差值。</p><p>5）如果客户端获取锁失败，则在所有redis实例中释放掉锁。为了保证更高效的获取锁，还可以设置重试策略，在一定时间后重新尝试获取锁，但不能是无休止的，要</p><p>设置重试次数。</p><p>​    虽然通过redlock能够更加有效的防止redis单点问题，但是仍然是存在隐患的。假设redis没有开启持久化，clientA获取锁后，所有redis故障重启，则会导致clientA锁记录消失，clientB仍然能够获取到锁。这种情况虽然发生几率极低，但并不</p><p>能保证肯定不会发生。</p><p>​    保证的方案就是开始AOF持久化，但是要注意同步的策略，使用每秒同步，</p><p>如果在一秒内重启，仍然数据丢失。使用always又会造成性能急剧下降。</p><p>​    官方推荐使用默认的AOF策略即每秒同步，且在redis停掉后，要在ttl时间后</p><p>再重启。 缺点就是ttl时间内redis无法对外提供服务。</p><h3 id="Redis与zookeeper分布式锁对比"><a href="#Redis与zookeeper分布式锁对比" class="headerlink" title="Redis与zookeeper分布式锁对比"></a>Redis与zookeeper分布式锁对比</h3><p>redis实现分布式锁优点在于其性能很高，能够支撑高并发的加锁与解锁操作。而其</p><p>缺点也很明显，主要如下：</p><p>采用抢占式方式进行锁的获取，需要不断的在用户态进行CAS尝试获取锁，对CPU占</p><p>用率高。</p><p> redis本身并不是CP模型，即便采用了redlock算法，但仍然无法保证百分百不会出现</p><p>问题，如持久化问题。</p><p>对于redis分布式锁的使用，在企业中是非常常见的，绝大多数情况不会出现极端情</p><p>况。</p><p>zookeeper实现分布式的优点在于其是强一致性的，采用排队监听的方式获取锁，不会像redis那样不断进行轮询尝试，对性能消耗较小。其缺点则是如果频繁的加锁和</p><p>解锁，对zk服务器压力较大。</p><p>当进行技术选型时，应该对其优缺点结合公司当前情况进行考虑。 如果公司有条件使用zk集群，更推荐使用zk的分布式锁，因为redis实现分布式锁有可能出现数据不正</p><p>确的情况，但如果公司没有zk集群，使用redis集群完成分布式锁也无可厚非。</p>]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> 分布式锁 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>秒杀系统</title>
      <link href="/2024/04/07/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/"/>
      <url>/2024/04/07/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h1 id="项目架构"><a href="#项目架构" class="headerlink" title="项目架构"></a>项目架构</h1><img src="/2024/04/07/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/clip_image002.gif" class="" title="Eureka  gi t hub  ConfigSezveE  ConfigServer  ConfigSecver  Keep alived  N ginx Master  N ginx Backup  Keep alived  Hystrix Dashboard  iJ 3;  MySQL  Eureka  oauth2.  Hyst ix &#x2F;  ff!j  MYSQL  My3QL  Redis  Eureka  Redis  SpringCIoud Bus  Redis"><p>SPU与SKU</p><p>SPU与SKU概念</p><h3 id="SPU-Standard-Product-Unit-（标准产品单位）"><a href="#SPU-Standard-Product-Unit-（标准产品单位）" class="headerlink" title="SPU &#x3D; Standard Product Unit  （标准产品单位）"></a>SPU &#x3D; Standard Product Unit  （标准产品单位）</h3><p>概念 : SPU 是商品信息聚合的最小单位，是一组可复用、易检索的标准化信息</p><p>的集合，该集合描述了一个产品的特性。</p><p>通俗点讲，属性值、特性相同的货品就可以称为一个 SPU</p><p>&#x3D;&#x3D;同款商品的公共属性抽取&#x3D;&#x3D;</p><p>例如：<strong>华为P30 就是一个 SPU</strong></p><h3 id="SKU-stock-keeping-unit-库存量单位"><a href="#SKU-stock-keeping-unit-库存量单位" class="headerlink" title="SKU&#x3D;stock keeping unit( 库存量单位)"></a>SKU&#x3D;stock keeping unit( 库存量单位)</h3><p>SKU 即库存进出计量的单位， 可以是以件、盒、托盘等为单位。</p><p>SKU 是物理上不可分割的最小存货单元。在使用时要根据不同业态，不同管理模式来处理。</p><p>在服装、鞋类商品中使用最多最普遍。</p><p>例如：<strong>华为P30 红色 64G 就是一个 SKU</strong></p><p>&#x3D;&#x3D;某个库存单位的商品独有属性(某个商品的独有属性)&#x3D;&#x3D;</p><img src="/2024/04/07/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/clip_image004.jpg" class="" title="tb_spu *  id  name  caption  brand id  (SPU*)  SPUE  category 1 _id  category2_id  category3_id  template_id  freight_id  mage  mages  sale service  introduction  spec_items  para_items  sale num  comment num  is marketable  is_enable_spec  is delete  status  BIGINT  VARCHAR  VARCHAR  VARCHAR  INT  INT  INT  INT  INT  INT  VARCHAR  VARCHAR  VARCHAR  TEXT  VARCHAR  VARCHAR  INT  INT  CHAR  CHAR  CHARBf2,ä Windows  Windows,  CHAR"><img src="/2024/04/07/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/clip_image006.jpg" class="" title="tb_sku  id  name  pnce  num  alert num  mage  mages  weight  create time  update time  spu_id  category_id  category_name  brand name  spec  sale num  comment num  status  fits (h)  SPUD  I-IEÆ,  BIGINT  VARCHAR  VARCHAR  INT  INT  INT  VARCHAR  VARCHAR  INT  DATETIME  DATETIME  BIGINT  INT  VARCHAR  VARCHAR  VARCHAR  INT  INT  CHAR  Windows"><h2 id="秒杀："><a href="#秒杀：" class="headerlink" title="秒杀："></a>秒杀：</h2><h3 id="防止超卖："><a href="#防止超卖：" class="headerlink" title="防止超卖："></a>防止超卖：</h3><ul><li>下单时：为每个商品个数创建队列，里面存商品id（某商品有100个，存100个次此商品id），每次下单从里面取一个，如果有说明有商品，相反则删除排队信息。在我们对Redis进行操作的时候，很多时候，都是先将数据查询出来，在内存中修改，然后存入到Redis，在并发场景，会出现数据错乱问题，为了控制数量准确，我们单独将商品数量整一个自增键，自增键是线程安全的，所以不担心并发场景的问题。</li><li>支付成功后修改库存：将商品查出来减少库存在放入数据库中，多线程购买的时候会引起超卖现象，利用数据库的行级锁可防止此情况。</li></ul><h3 id="防止用户重复排队："><a href="#防止用户重复排队：" class="headerlink" title="防止用户重复排队："></a>防止用户重复排队：</h3><ul><li>用户每次抢单的时候，一旦排队，我们设置一个自增值，让该值的初始值为1，每次进入抢单的时候，对它进行递增，如果值&gt;1，则表明已经排队,不允许重复排队,如果重复排队，则对外抛出异常，并抛出异常信息100表示已经正在排队。</li></ul><h3 id="并发削峰："><a href="#并发削峰：" class="headerlink" title="并发削峰："></a>并发削峰：</h3><ul><li>抢购商品时，使用redis排队抢单，并多线程抢单，排队抢单：队列中记录订单的状态SeckillStatus ：用户ID和商品ID（商品ID，商品抢购时间段，用户登录名）</li><li>削峰还可以提一下nginx和分布式微服务中的<a href="onenote:分布式微服务.one#限流策略&section-id={6BA1F89F-1441-4B70-9972-A327827F7CF9}&page-id={CC2EC0F0-E52F-44AC-8A3D-82130A4EBFEC}&object-id={A4CB52A9-9549-438C-807D-8A55F9A57771}&10&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java">限流策略</a></li></ul><h3 id="超时订单回滚："><a href="#超时订单回滚：" class="headerlink" title="超时订单回滚："></a>超时订单回滚：</h3><ul><li>通过rabbitmq延时队列实现</li></ul><h3 id="多个用户请求的时候怎样保证redis中的数据是准确的："><a href="#多个用户请求的时候怎样保证redis中的数据是准确的：" class="headerlink" title="多个用户请求的时候怎样保证redis中的数据是准确的："></a>多个用户请求的时候怎样保证redis中的数据是准确的：</h3><p>对于一些可能产生并发问题的操作进行加锁操作</p><p>获取队列判断有无商品的时候</p><h3 id="分布式锁红锁5个机器键和值是一样的吗："><a href="#分布式锁红锁5个机器键和值是一样的吗：" class="headerlink" title="分布式锁红锁5个机器键和值是一样的吗："></a>分布式锁红锁5个机器键和值是一样的吗：</h3><p>是一样的</p><h3 id="redis中获取队列有线程安全的问题吗："><a href="#redis中获取队列有线程安全的问题吗：" class="headerlink" title="redis中获取队列有线程安全的问题吗："></a>redis中获取队列有线程安全的问题吗：</h3><p>redis本身一个键值同一时刻只能一个进程操作，但是操作不能保证原子性，所以也会造成问题</p><p>我们正常理解的线程安全问题是指单进程多线程模型内部多个线程操作进程内共享内存导致的数据资源充突。而 Redis 的线程安全问题的产生，并不是来自于 Redis 服务器内部。</p><p>Redis 作为数据服务器，就相当于多个客户端的共享内存，多个客户端就相当于同一进程下的多个线程，如果多个客户端之间没有良好的数据同步策略，就会产生类似线程安全的问题。</p><p>典型场景是：</p><p>Redis 内存储了一个用户的状态： user5277&#x3D;idle；</p><p>客户端连接 A 读取了用户状态，获取到用户的空闲状态 status &#x3D; get(“user5277”)；</p><p>客户端连接 B 也同样读取了用户状态；</p><p>客户端连接 A 给用户安排了一个任务，并将 Redis 内用户状态置为忙碌 set(“user5277”, “busy”)；</p><p>客户端连接 B 同样设置用户为忙碌状态。</p><p>可是此时用户却被同时分配了两个任务。</p><p>导致这个问题的原因就是虽然 Redis 是单线程的，能保证命令的序列化，但由于其执行效率很高，多个客户端的命令之间不做好请求同步，同样会造成命令的顺序错乱。</p><p>当然这个问题也很好解决，给用户状态加锁就行了，使同一时间内只能有一个客户端操作用户状态。不过加锁我们就需要考虑锁粒度、死锁等问题了，无疑添加了程序的复杂性，不利于维护。</p><p>效率问题：获取两次键值就是两次请求，慢，导致这种问题的原因就是 Redis 的普通命令没有服务端计算的能力，无法在服务器进行复合命令操作，虽然有 Redis 也提供了 pipeline 的特性，但它需要多个命令的请求和响应之间没有依赖关系。想简化多个相互依赖的命令就只能将数据拉回客户端，由客户端处理后再请求 Redis。</p><p>Lua脚本的执行。</p><p><a href="https://segmentfault.com/a/1190000040160105">https://segmentfault.com/a/1190000040160105</a></p><h3 id="多个用户请求的时候怎样保证redis中的数据是准确的"><a href="#多个用户请求的时候怎样保证redis中的数据是准确的" class="headerlink" title="多个用户请求的时候怎样保证redis中的数据是准确的"></a>多个用户请求的时候怎样保证redis中的数据是准确的</h3><img src="/2024/04/07/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/clip_image008.gif" class="" title="img"><h3 id="并发量大加锁的话用户来了并发就会很慢怎么解决："><a href="#并发量大加锁的话用户来了并发就会很慢怎么解决：" class="headerlink" title="并发量大加锁的话用户来了并发就会很慢怎么解决："></a>并发量大加锁的话用户来了并发就会很慢怎么解决：</h3><p>预估机器资源，每个机器最大访问量多少，保证请求响应时间短，不要加特定的锁，成功就成功，失败就失败，多线程下单</p><p>购物车提交订单时要做价格校验，一定以数据库为准</p><p>支付系统：用户通过网关路由到订单系统进行下单，下单之后订单系统会将订单号发送给支付系统，支付系统会访问微信服务器。</p><p>多线程抢单之后，更新排队信息，这时可以查询订单状态，若已抢单，则进入支付，若未抢单，则隔几秒查询一次</p><p>加盐加密：就是人为的通过一组随机字符与用户原密码的组合形成一个新的字符</p><p>服务器端怎样认证令牌正确性：服务端拿到令牌后，使用base64之后的头部的信息和载荷的信息与使用自身的秘钥（私钥）做加盐，在用头部声明的算法加密，与令牌的签名部分做对比，若相同，则说明认证成功</p><p>这一步是直接让队列中的元素出来，并发是没有问题的，因为redis是单线程，不需要用分布式锁来互斥的获取</p><img src="/2024/04/07/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/clip_image010.jpg" class="" title="img"><img src="/2024/04/07/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/clip_image012.jpg" class="" title="img"><p>没有库存的话直接同步到redis中</p><p>redis中数据和mysql的数据怎么保持一致，redis中没有数据了，但是mysql中有，到底以哪为准，最终的信息以数据库中为准吗</p><p>不能保证强一致性，只能是最终一致性，要保证一致性可以使用延时双删或者是先删数据库在删redis，为了确保能删掉，可以将消息发送到mq(<a href="onenote:redis.one#如何保证Redis和数据库的数据一致&section-id={D84E434C-802C-4920-94C4-EEBB2F80F9EC}&page-id={AE05E194-ADFA-4690-81F5-8E9AE85A4DFF}&object-id={864C5691-4462-44C1-8FF5-7971AD421BC8}&3B&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java">如何保证Redis和数据库的数据一致</a>)。最终数据以mysql中为准</p><p>可以说最终的信息由mysql决定，那redis做了哪些操作呢</p><p>主要是缓存的作用，把大量的并发放到redis中解决，后台可以慢慢放到数据库中，可以说下<a href="onenote:redis.one#Redis为什么性能非常高&section-id={D84E434C-802C-4920-94C4-EEBB2F80F9EC}&page-id={7883F82C-D021-464E-B062-B14525EB644D}&object-id={109DE118-1D4A-4432-BAEA-7068718A759B}&46&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java">Redis为什么性能非常高</a></p><h3 id="rabbitmq的作用"><a href="#rabbitmq的作用" class="headerlink" title="rabbitmq的作用"></a>rabbitmq的作用</h3><p>死信队列</p><p>用户支付失败了，消息队列中的数据怎么删除</p><p>没有办法消除</p><p>怎么实现秒杀功能，比如说多并发去抢商品，怎样保证商品还有：</p><p>我说的是创建队列去把同等数量的id放到redis队列中，但是多个线程去都去先get队列，还是会遇到问题（其实是不会遇到问题的，因为redis是单线程，获取队列后，直接将元素取出来，这个元素就不在队列了，其他线程在取其实就没用了），这时就要用到分布式锁 ，减到负的怎么办，就清空redis中该商品的数据，减到负的就不减了</p><p>在一个事务中，锁超时了怎么办，还要去获取锁，续命策略有哪些</p><p>看门狗机制：加锁的时间是30秒.如果加锁的业务没有执行完,那么到 30-10 &#x3D; 20秒的时候,就会进行一次续期,把锁重置成30秒.那这个时候可能又有同学问了,那业务的机器万一宕机了呢?宕机了定时任务跑不了,就续不了期,那自然30秒之后锁就解开了呗.</p><p>分布式锁出现死锁怎么办：设置过期时间，或者就是看门狗设置特定的过期时间</p><p>怎样解锁 </p><p>删除键值</p><p>A调用B，A中失败了，但是消息已经发出去了，B如果已经消费了消息怎么办：</p><p>分布式事务-两阶段提交 </p><p>线程池如何使用?为什么这样设置：</p><p><a href="onenote:并发.one#线程池调优&section-id={C7CC559D-F80F-49BD-AAAC-881F89FBE30F}&page-id={9D1939F5-3D95-4700-BE4B-501272561604}&end&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java">线程池调优</a></p><p>如果秒杀开始后，商家想改库存，但是redis已经减了， 如何保证库存-致性</p><p>canal可以用来监控数据库数据的变化，从而获得新增数据，或者修改的数据。</p><p>Canal工作原理</p><ol><li>canal模拟mysql slave的交互协议，伪装自己为mysql slave，向mysql master发</li></ol><p>送dump协议</p><ol start="2"><li><p>mysql master收到dump请求，开始推送binary log给slave(也就是canal)</p></li><li><p>canal解析binary log对象(原始为byte流)</p></li></ol><p>7.如果并发量增大了，你会如何改进你的架构?</p><p>8.限制单体并发量提高的瓶颈是什么?</p><p>9.缓存该如何使用?除了使用Redis 之外，还有什么解决方案吗?</p><ol start="10"><li><p>Redis 的ZSet是怎么实现的?</p></li><li><p>热点数据如何缓存，你提到了本地缓存,你项目的进程使用什么方式与本地缓存的进程进行通信?</p></li></ol><p>12.如果秒杀开始后，商家想改库存，但是redis已经减了， 如何保证库存-致性</p><p>13.分布式锁能解决什么问题，几种实现</p><ol start="14"><li>spring拦截 器限流如何实现</li></ol><p>15.验证码从0到1</p><h2 id="表结构说明"><a href="#表结构说明" class="headerlink" title="表结构说明"></a>表结构说明</h2><h3 id="秒杀商品信息表"><a href="#秒杀商品信息表" class="headerlink" title="秒杀商品信息表"></a>秒杀商品信息表</h3><img src="/2024/04/07/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/clip_image014.jpg" class="" title="CREATE  sup  sku  TABLE (  bigint(2e) NOT NULL AUTO INCREMENT,  id" alt="bigint(28) DEFAULT NULL COWENT  id"><h3 id="秒杀订单表"><a href="#秒杀订单表" class="headerlink" title="秒杀订单表"></a>秒杀订单表</h3><img src="/2024/04/07/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/clip_image016.jpg" class="" title="CREATE TABLE (  • id" alt="bigint(2e) NOT NULL COMMENT  seckill bigint(28) DEFAULT NULL COMMENT ,  -money"><h2 id="秒杀流程"><a href="#秒杀流程" class="headerlink" title="秒杀流程"></a>秒杀流程</h2><p>秒杀技术实现核心思想是运用缓存减少数据库瞬间的访问压力！读取商品详细信息时运用缓存，当用户点击抢购时减少缓存中的库存数量，当库存数为0时或活动期结束时，同步到数据库。 产生的秒杀预订单也不会立刻写到数据库中，而是先写到缓存，当用户付款成功后再写入数据库。</p><img src="/2024/04/07/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/clip_image018.gif" class="" title="img"><h3 id="秒杀商品压入缓存实现"><a href="#秒杀商品压入缓存实现" class="headerlink" title="秒杀商品压入缓存实现"></a>秒杀商品压入缓存实现</h3><p>秒杀商品列表和秒杀商品详情都是从Redis中取出来的，所以我们首先要将符合参与秒杀的商品定时查询出来，并将数据存入到Redis缓存中。</p><p>数据存储类型我们可以选择Hash类型。</p><p>秒杀分页列表这里可以通过获取redisTemplate.boundHashOps(key).values()获取结果数据。</p><p>秒杀商品详情，可以通过redisTemplate.boundHashOps(key).get(key)获取详情。</p><p>&#x2F;&#x2F; namespace &#x3D; SeckillGoods_20195712</p><p>redisTemplate.boundHashOps(“SeckillGoods_”+extName).put(seckillGood.getId(),seckillGood);</p><p>Redis数据如下：</p><img src="/2024/04/07/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/clip_image020.gif" class="" title=". oods 2019052422  xAC xED x00 x05t x00 x17Secki11Goods 2019052422  Size:  30 TTL:  Rename  row  2  3  4  5  6  7  8  10  11  12  13  14  15  16  17  18  19  key  value  changgou.  changgou.  changgou.  changgou.  changgou.  changgou.  changgou.  changgou.  changgou.  changgou.  changgou.  changgou.  changgou.  changgou.  changgou.  changgou.  changgou.  changgou.  changgou.  seckill.  seckill.  seckill.  seckill.  seckill.  seckill.  seckill.  seckill.  seckill.  seckill.  seckill.  seckill.  seckill.  seckill.  seckill.  seckill.  seckill.  seckill.  seckill.  • Secki 1 x02  POJ0.  • Secki 1 x02  POJ0.  • Secki 1 x02  POJ0.  • Secki 1 x02  POJ0.  • Secki 1 x02  POJ0.  • Secki 1 x02  POJ0.  • Secki 1 x02  POJ0.  • Secki 1 x02  POJ0.  • Secki 1 x02  POJ0.  • Secki 1 x02  POJ0.  • Secki 1 x02  POJ0.  • Secki 1 x02  POJ0.  • Secki 1 x02  POJ0.  • Secki 1 x02  POJ0.  • Secki 1 x02  POJ0.  • Secki 1 x02  POJ0.  • Secki 1 x02  POJ0.  • Secki 1 x02  POJ0.  • Secki 1 x02  POJ0."><p>SeckillGoodsCount—在我们对Redis进行操作的时候，很多时候，都是先将数据查询出来，在内存中修改，然后存入到Redis，在并发场景，会出现数据错乱问题，为了控制数量准确，我们单独将商品数量整一个自增键，自增键是线程安全的，所以不担心并发场景的问题。</p><p>SeckillGoodsCountList—防止超卖放id的</p><img src="/2024/04/07/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/clip_image022.jpg" class="" title="for (Secki llGoods seckillGocn:i : seckillGoods) (  redi gTempIate. boundHashOps( key: . put (gecki I IGood. getld() , secki IIGood)  Longo ids &#x3D; pushlds (seckillGood. getStockCount secki llGood. getld())  redisTemplate. boundListOps( key: getld()) . leftPushAll(ids) ,  redisTempIatc. boundHashOps( key: SeckillGoodsCount-) . increment (seckil IGood. getld , secki IlGood. getStockCount . %}&lt;p&gt;将秒杀商品从数据库中查询出来，并存入到Redis缓存&lt;&#x2F;p&gt;&lt;p&gt;查询活动没结束的所有秒杀商品&lt;&#x2F;p&gt;&lt;p&gt;1)计算秒杀时间段&lt;&#x2F;p&gt;&lt;p&gt;2)状态必须为审核通过 status&#x3D;1&lt;&#x2F;p&gt;&lt;p&gt;3)商品库存个数&gt;0&lt;&#x2F;p&gt;&lt;p&gt;4)活动没有结束 endTime&gt;&#x3D;now()&lt;&#x2F;p&gt;&lt;p&gt;5)在Redis中没有该商品的缓存&lt;&#x2F;p&gt;&lt;p&gt;6)执行查询获取对应的结果集&lt;&#x2F;p&gt;&lt;p&gt;将活动没有结束的秒杀商品入库&lt;&#x2F;p&gt;{% asset_img clip_image024.jpg&quot; 定 时 任 务 方 法  3 &#x2F; ． 就 就 ？ ： 从 每 分 钟 的 第 3 秒 开 始 执 行 ， 每 过 秒 执 行 一  @Schedu1ed(cron"><h3 id="秒杀详情页"><a href="#秒杀详情页" class="headerlink" title="秒杀详情页"></a>秒杀详情页</h3><p>秒杀详情页需要根据商品ID查询商品详情，我们可以在频道页点击秒杀抢</p><p>购的时候将时间和ID一起传到后台，然后根据ID去Redis中查询详情信息。</p><h3 id="用户排队下单"><a href="#用户排队下单" class="headerlink" title="用户排队下单"></a>用户排队下单</h3><p>首先要判断用户是否重复排队：</p><p>用户每次抢单的时候，一旦排队，我们设置一个自增值，让该值的初始值为1，每次进入抢单的时候，对它进行递增，如果值&gt;1，则表明已经排队,不允许重复排队,如果重复排队，则对外抛出异常，并抛出</p><p>异常信息100表示已经正在排队。</p><p>![COverride  public Boolean add (Long id, String time, String username) <a href="file:///C:/Users/zhiyo/AppData/Local/Temp/msohtmlclip1/01/clip_image026.jpg">  Long userQueueCount ¯ redisTemp1ate. boundHashOps( key: “UserQueueCount”) . increment (username,  if (userQueueCount&gt;1) {  h’100:  throw new RuntimeException(String_ valueOf(StatusCode. REPERROR’) </a></p><p>若没有则进行排队，我们可以采用Redis的队列实现。 排队信息中需要有用户抢单的商品信息，主要包含商品ID，商品抢购时间段，用户登录名。</p><img src="/2024/04/07/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/clip_image028.jpg" class="" title="Secki11Status secki11Status -  id, time);  new Seckillstatus(username,  new Date(),l,  &#x2F; Redis* , , Listtgæ  redisTemp1ate. boundLis tops ( Seckill OrderQueue ) . leftPush(secki11Status);  multi Thread ingCreateOrder. createorder();"><h3 id="多线程下单操作"><a href="#多线程下单操作" class="headerlink" title="多线程下单操作"></a>多线程下单操作</h3><img src="/2024/04/07/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/clip_image030.gif" class="" title="存 储 商 品 完 整 信 息  R e d i s  引 ： k count:2  itle ． 华 为 笔 记 本  定 时 任 务  压 入 队 列 队 列  123  123  创 建 订 单  Reds 中 商 品 个 数 递 臧  队 列 中 0 i 123  good 引 123 商 品  秒 杀 下 单  存 雀  队 列 是  否 存 亡  不 存 亡"><h3 id="防止超卖"><a href="#防止超卖" class="headerlink" title="防止超卖"></a>防止超卖</h3><p>可以利用Redis队列实现，给每件商品创建一个独立的商品个数队列</p><p>每次给用户下单的时候，先从队列中取数据，如果能取到数据，则表明有库存，如果取不到，则表明没有库存。</p><img src="/2024/04/07/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/clip_image032.gif" class="" title="CAsync  public void createOrder ( ) {  Secki11Status secki11Status  try {  (Secki11Status) redisTemp1ate. boundListOps( key:  Secki11GoodsCountList Seckil 10rderQueue) . rightPop ( ) + secki11Status. getGoodsId ( ) ) . rightPop ( ) Object sgood &#x3D; redisTemp1ate. boundList0ps( key: if (sgood null) { cl earQueue (secki 11 Status) return ; &#x2F;&#x2F;i&#x2F;iiJ&#x2F;X&#x2F;iiJ secki11Status. getTime ( ) String time String username&#x3D;secki IIStatus. getUsername ( ) Long id secki 11 Status. getGoodsId ( ) (Secki11Goods) redisTemp1ate. boundHashOps( key: Secki 1 IGoods goods iT1)t new Secki110rder ( ) Secki 110rder secki 1 IOrder secki 110rder. setld (idWorker. nextld ( ) ) secki 110rder. setSecki111d (id) setMoney (goods. getCostPrice ( ) ) secki 1 IOrder. secki 1 IOrder. setUserId (username) secki110rder. setCreateTime (new Date ( ) ) secki110rder. setStatus (0) Secki 1 IGoods + time). get(id) f&#x2F;JRedi s 1&#x2F;1 redisTemp1ate. boundHash0ps ( key: Secki110rder) . put (username, secki 110rder) Long surplusCount &#x3D; redisTemp1ate. boundHash0ps( key: Secki11GoodsCount) . increment (id, Dj,h} goods. setStockCount (surplusCount. intVa1ue ( ) ) DiJDjÆ} if (surplusCount&lt;&#x3D;0) { 9&#x2F;41 2&#x2F;74!&#x2F;rdUbf&#x2F;JMySQL 1&#x2F;1 secki 1 IGoodsMapper. updateByPr imaryKeySe1 ect i ve (goods) i%V&#x2F;c- if s $4&#x2F;&#x2F;-1&#x2F;1 redisTemp1ate. boundHashOps ( key: Secki11Goods  } else {  QWiffChf&#x2F;JRei ds 1&#x2F;1  redisTemp1ate. boundHash0ps ( key: Secki11Goods secki IIStatus. setStatus (2) secki IIStatus. setOrderId (secki 110rder. getld ( ) ) + time). delete(id)  + time) . put (id, goods)  secki IIStatus. setMoney (secki 110rder. getMoney ( ) . floatVa1ue ( ) )  redisTemp1ate. boundHash0ps ( key: UserQueueStatus&quot;) . put (username, secki IIStatus) catch (Exception e) { e. printStackTrace ( ) * gparam seckil 1Sta tus public void clearQueue (Secki11Status secki11Status) { redisTemp1ate. boundHashOps ( key: redisTemp1ate. boundHashOps ( key: UserQueueCount) . delete (secki 11Status. getUsername ( ) ) UserQueueStatus) . delete (secki 11Status. getUsername ( ) ) %}&lt;h3 id&#x3D;goods-setStockCount-surplusCount-intValue-只是为了下面将数据重置到redis&quot;&gt;&lt;a href&#x3D;#goods-setStockCount-surplusCount-intValue-只是为了下面将数据重置到redis class&#x3D;headerlink title&#x3D;goods.setStockCount(surplusCount.intValue()) 只是为了下面将数据重置到redis&gt;&lt;&#x2F;a&gt;goods.setStockCount(surplusCount.intValue()) 只是为了下面将数据重置到redis&lt;&#x2F;h3&gt;&lt;p&gt;清理用户排队信息：UserQueueCount是为了防止用户重复抢单建立的&lt;&#x2F;p&gt; &lt;p&gt; UserQueueStatus是为了查询用户订单状态建立的&lt;&#x2F;p&gt; &lt;h3 id&#x3D;下单状态查询&gt;&lt;a href&#x3D;#下单状态查询 class&#x3D;headerlink title&#x3D;下单状态查询&gt;&lt;&#x2F;a&gt;下单状态查询&lt;&#x2F;h3&gt;&lt;p&gt;虽然可以实现用户下单异步操作，但是并不能确定下单是否成功，所以我们需要做一个页面判断，每过1秒钟查询一次下单状态,多线程下单的时&lt;&#x2F;p&gt; &lt;p&gt;候，需要修改抢单状态，支付的时候，清理抢单状态。&lt;&#x2F;p&gt; &lt;p&gt;排队信息不仅放到list集合中供抢单使用，也会放到一个hash中，供查询状态&lt;&#x2F;p&gt; {% asset_img clip_image034.jpg new SeckillStatus (username, new Date Status: l, id, time) .  SeckillStatus secki IIStatus -  ( key: I ;  rcdisTompIato. boundHashOps ( key: UserQucucStatus¯) . put (username. seckiIIStatus) %}&lt;p&gt;多线程抢单后更新状态：&lt;&#x2F;p&gt;&lt;p&gt;0是排队，2是等待支付&lt;&#x2F;p&gt;{% asset_img clip_image036.jpg&quot; seekiIIStatus. setStatus (2)  setOrderld(seckillOrder. getld())  secki IStatus  setb%ney L " alt="Order. getoney floatValue ; redisTeapIate. boundHashOps( key: •UserOueueStatus•). put (usernatne. seckiIIStatus) %}&lt;h3 id&#x3D;后台可根据用户名查询抢单状态&quot;&gt;&lt;a href&#x3D;#后台可根据用户名查询抢单状态 class&#x3D;headerlink title&#x3D;后台可根据用户名查询抢单状态&gt;&lt;&#x2F;a&gt;后台可根据用户名查询抢单状态&lt;&#x2F;h3&gt;{% asset_img clip_image038.jpg public Secki11Status queryStatus(String username) {  return (Secki11Status) redisTemp1ate.boundHashOps(lJserQueueStatus&quot;) .get(username); %}&lt;h3 id&#x3D;订单支付&quot;&gt;&lt;a href&#x3D;#订单支付 class&#x3D;headerlink title&#x3D;订单支付&gt;&lt;&#x2F;a&gt;订单支付&lt;&#x2F;h3&gt;&lt;p&gt;创建支付二维码&lt;&#x2F;p&gt; &lt;p&gt;下单成功后，会跳转到支付选择页面，在支付选择页面要显示订单编号和订单金额，所以我们需要在下单的时候，将订单金额以及订单编号信息存储到用户查询对象中。&lt;&#x2F;p&gt; &lt;p&gt;选择微信支付后，会跳转到微信支付页面，微信支付页面会根据用户名查看用户秒杀订单，并根据用户秒杀订单的ID和钱数创建预支付信息并获取二维码信息，展示给用户看,此时页面每3秒查询一次支付状态，如果支付成功，需要修改订单状态信息。&lt;&#x2F;p&gt; &lt;p&gt;支付流程&lt;&#x2F;p&gt; {% asset_img clip_image040.gif @支 付 状 态 一 〉 n 。 ti 巧 -1  微 信 支 付  @二 维  O  网 关  1 下 单  Order—Hash  支 付 系 统  MySQL  订 单 入  Redi s—MySQL  秒 杀 系 统  4 s end  清 理 排 队  Redis  存 回 滚  清 理 排 队  成 功  L1st ner  昷 听 回 讠 周 支 、  send  delay  LIStener  delay  订 单 支 付 超 时  Redis  R dis 存 在 订 单  清 理 排 队 信 息  回 滚 存  10 S  微 信 支 付"><p>1.用户抢单，经过秒杀系统实现抢单，下单后会将向MQ发送一个延时队列消</p><p>息，包含抢单信息，延时半小时后才能监听到</p><p>2.秒杀系统同时启用延时消息监听，一旦监听到订单抢单信息，判断Redis缓存</p><p>中是否存在订单信息，如果存在（就说明用户没有支付），则回滚</p><p>3.秒杀系统还启动支付回调信息监听，如果支付完成，则将订单吃句话到</p><p>MySQL，如果没完成，清理排队信息回滚库存</p><p>4.每次秒杀下单后调用支付系统，创建二维码，如果用户支付成功了，微信系</p><p>统会将支付信息发送给支付系统指定的回调地址，支付系统收到信息后，将信</p><p>息发送给MQ，第3个步骤就可以监听到消息了。</p><p>支付回调队列指定</p><p>1.创建支付二维码需要指定队列</p><p>2.回调地址回调的时候，获取支付二维码指定的队列，将支付信息发送到</p><p>指定队列中</p><p>支付微服务的参数携带</p><img src="/2024/04/07/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/clip_image042.jpg" class="" title="Map paran new HashMap()  param. put ( •appid•, appid);  param. put ( •mch_id•, partner);  param. put (  •nonce_str•, FXPayUti l.  param. put (  • body • , ;  param. put ( •  out _ , get  param. put (  param. put (  •gpbi  • , •127.0.  param. put ( •notify_url•, notifyurl) ;  param. put ( • trade_type• .  •NATIVE) ; param. put ( •attach&quot;, JSON_ toJSQVString(parameter)) %}&lt;p&gt;支付状态监听&lt;&#x2F;p&gt;&lt;p&gt;支付状态通过回调地址发送给MQ之后，我们需要在秒杀系统中监听支付信息（支付成功的状态码，success还是fail）&lt;&#x2F;p&gt;&lt;p&gt;如果用户支付成功，则修改订单信息（为了将订单信息放入mysql，先将”SeckillOrder”从redis中查出来，修改成已支付：1），并将订单入库，删除用户排队信息（”UserQueueCount”），清空redis中缓存（”SeckillOrder”），删除抢购状态信息(“UserQueueStatus”)&lt;&#x2F;p&gt;{% asset_img clip_image044.jpg&quot; @param out trade _ no  @param transaction_id  @param username  @Override  public void updatePayStatus(String out_trade_no,  Secki110rder secki110rder  (Seckillorder)  String username) {  redisTemp1ate. boundHashOps ( Seckillorder ) . get(username ) ;  secki110rder. setSta  secki110rder. setPayTime(new Date()) ;  secki110rderMapper. insertselective(seckillorder) ;  redisTemp1ate. boundHashOps ( Seckillorder&quot; ) . delete(username) ; redisTemp1ate. boundHashOps ( UserQueueCount ) . del ete ( username) ; redisTemp1ate. boundHashOps ( UserQueueStatus ) . delete( username) ; %}&lt;p&gt;如果用户支付失败，则关闭订单，删除订单信息，回滚库存，删除用户排队信息。&lt;&#x2F;p&gt;{% asset_img clip_image046.jpg&quot; @param username  @Override  public void closeOrder(String username) {  Secki11Status secki11Status &#x3D;  (Secki11Status)  redisTemp1ate. boundHashOps ( UserQueueStatus . get(username) ; Secki110rder secki110rder (Seckillorder) redisTemp1ate. boundHashOps ( Seckillorder ) . get(username ) ; if(secki11Status!&#x3D;nu11 &amp;&amp; secki110rder redis Templ ate. boundHashOps( Secki110rder ) . delete( username) ; Secki11Goods secki11Goods &#x3D; (Secki11Goods) redisTemp1ate. boundHashOps ( Secki11Goods_+secki11Status. getT ime() ) . get(secki11Status . getGoodsId ( ) ) ; e Secki11GoodsCount Secki11GoodsCountList&quot; if(secki11Goods&#x3D;&#x3D;nu11){ secki11Goods - secki11GoodsMapper. selectByPrimaryKey (secki11Status . getGoodsId ( ) ) ; Long surplusCount redisTemp1ate. boundHashOps ( Secki 11Good scount ) . increment( secki IIStatus. getGoodsId() , secki11Goods. setStockCount(surp1 usCount. intVa1ue()) ; redisTemp1ate. bound ListOps(Secki11GoodsCountList secki11Status . getGoodsId ( ) ) . leftPush(secki11Status . getGoodsId ) ; Windows Windowsc %}{% asset_img clip_image048.jpg&quot; img"><h3 id="用户超时半小时未支付关闭订单回滚库存"><a href="#用户超时半小时未支付关闭订单回滚库存" class="headerlink" title="用户超时半小时未支付关闭订单回滚库存"></a>用户超时半小时未支付关闭订单回滚库存</h3><p>1.创建一个过期队列 Queue1</p><p>2.接收消息的队列  Queue2</p><p>3.中转交换机</p><p>4.监听Queue2</p><p>1)SeckillStatus-&gt;检查Redis中是否有订单信息</p><p>2)如果有订单信息，调用删除订单回滚库存-&gt;[需要先关闭微信支付]</p><p>3)如果关闭订单时，用户已支付，修改订单状态即可</p><p>4)如果关闭订单时，发生了别的错误，记录日志，人工处理</p><h2 id="秒杀系统的设计思考"><a href="#秒杀系统的设计思考" class="headerlink" title="秒杀系统的设计思考"></a>秒杀系统的设计思考</h2><img src="/2024/04/07/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/clip_image092.gif" class="" title="img"><h2 id="高性能"><a href="#高性能" class="headerlink" title="高性能"></a>高性能</h2><h3 id="1-动静分离"><a href="#1-动静分离" class="headerlink" title="1 动静分离"></a>1 动静分离</h3><p>数据拆分</p><ol><li>用户。用户身份信息包括登录状态以及登录画像等；与之相关的广平推荐，如用户偏好、地域偏好等，同样可以通过异步方式进行加载</li><li>时间。秒杀时间是由服务端统一管控的，可以通过动态请求进行获取</li></ol><p>静态缓存</p><p>三种方式：1、浏览器；2、服务端 ；3、CDN</p><p>1.浏览器当然是第一选择，但用户的浏览器是不可控的，主要体现在如果用户不主动刷新，系统很难主动地把消息推送给用户，如此可能会导致用户端在很长一段时间内看到的信息都是错误的。对于秒杀系统，保证缓存可以在秒级时间内失效是不可或缺的。</p><p>2.服务端主要进行动态逻辑计算及加载，本身并不擅长处理大量连接，每个连接消耗内存较多，同时 Servlet 容器解析 HTTP 较慢，容易侵占逻辑计算资源；另外，静态数据下沉至此也会拉长请求路径。</p><p>3.CDN本身更擅长处理大并发的静态文件请求，既可以做到主动失效，又离用户尽可能近。</p><p>失效问题。任何一个缓存都应该是有时效的</p><p>命中率问题。高命中是缓存系统最为核心的性能要求</p><p>选择若干 CDN 节点进行静态化改造，节点的选取通常需要满足以下几个条件：</p><ol><li>临近访问量集中的地区</li><li>距离主站较远的地区</li><li>节点与主站间网络质量良好的地区</li></ol><p>数据整合</p><p>分离出动静态数据之后，前端如何组织数据页就是一个新的问题，主要在于动态数据的加载处理，通常有两种方案：ESI（Edge Side Includes）方案和 CSI（Client Side Include）方案。</p><ol><li>ESI 方案：Web 代理服务器上请求动态数据，并将动态数据插入到静态页面中，用户看到页面时已经是一个完整的页面。这种方式对服务端性能要求高，但用户体验较好</li><li>CSI 方案：Web 代理服务器上只返回静态页面，前端单独发起一个异步 JS 请求动态数据。这种方式对服务端性能友好，但用户体验稍差</li></ol><h3 id="2-热点优化"><a href="#2-热点优化" class="headerlink" title="2 热点优化"></a>2 热点优化</h3><p>热点操作</p><p>零点刷新、零点下单、零点添加购物车等都属于热点操作。热点操作是用户的行为，不好改变，但可以做一些限制保护，比如用户频繁刷新页面时进行提示阻断。</p><p>热点数据</p><p><em>热点识别</em></p><ol><li>静态热点：能够提前预测的热点数据。大促前夕，可以根据大促的行业特点、活动商家等纬度信息分析出热点商品，或者通过卖家报名的方式提前筛选；另外，还可以通过技术手段提前预测，例如对买家每天访问的商品进行大数据计算，然后统计出 TOP N 的商品，即可视为热点商品</li><li>动态热点：无法提前预测的热点数据。冷热数据往往是随实际业务场景发生交替变化的，尤其是如今直播卖货模式的兴起——带货商临时做一个广告，就有可能导致一件商品在短时间内被大量购买。由于此类商品日常访问较少，即使在缓存系统中一段时间后也会被逐出或过期掉，甚至在db中也是冷数据。瞬时流量的涌入，往往导致缓存被击穿，请求直接到达DB，引发DB压力过大</li></ol><p>秒杀系统需要实现热点数据的动态发现能力，一个常见的实现思路是：</p><ol><li>异步采集交易链路各个环节的热点 Key 信息，如 Nginx采集访问URL或 Agent 采集热点日志（一些中间件本身已具备热点发现能力），提前识别潜在的热点数据</li><li>聚合分析热点数据，达到一定规则的热点数据，通过订阅分发推送到链路系统，各系统根据自身需求决定如何处理热点数据，或限流或缓存，从而实现热点保护</li></ol><h3 id="热点隔离"><a href="#热点隔离" class="headerlink" title="热点隔离"></a>热点隔离</h3><p>将热点数据隔离出来，不要让 1% 影响到另外的 99%。</p><ol><li>业务隔离。秒杀作为一种营销活动，卖家需要单独报名，从技术上来说，系统可以提前对已知热点做缓存预热</li><li>系统隔离。系统隔离是运行时隔离，通过分组部署和另外 99% 进行分离，另外秒杀也可以申请单独的域名，入口层就让请求落到不同的集群中</li><li>数据隔离。秒杀数据作为热点数据，可以启用单独的缓存集群或者DB服务组，从而更好的实现横向或纵向能力扩展</li></ol><p>热点优化</p><ol><li>缓存：热点缓存是最为有效的办法。如果热点数据做了动静分离，那么可以长期缓存静态数据</li><li>限流：流量限制更多是一种保护机制。需要注意的是，各服务要时刻关注请求是否触发限流并及时进行review</li></ol><h3 id="3-系统优化"><a href="#3-系统优化" class="headerlink" title="3 系统优化"></a>3 系统优化</h3><p>如提升硬件水平、调优JVM 性能</p><ol><li>减少序列化：减少 Java 中的序列化操作可以很好的提升系统性能。序列化大部分是在 RPC 阶段发生，因此应该尽量减少 RPC 调用，一种可行的方案是将多个关联性较强的应用进行 “合并部署”，从而减少不同应用之间的 RPC 调用（微服务设计规范）</li><li>直接输出流数据：只要涉及字符串的I&#x2F;O操作，无论是磁盘 I&#x2F;O 还是网络 I&#x2F;O，都比较耗费 CPU 资源，因为字符需要转换成字节，而这个转换又必须查表编码。所以对于常用数据，比如静态字符串，推荐提前编码成字节并缓存，具体到代码层面就是通过 OutputStream() 类函数从而减少数据的编码转换；另外，热点方法toString()不要直接调用ReflectionToString实现，推荐直接硬编码，并且只打印DO的基础要素和核心要素</li><li>裁剪日志异常堆栈：无论是外部系统异常还是应用本身异常，都会有堆栈打出，超大流量下，频繁的输出完整堆栈，只会加剧系统当前负载。可以通过日志配置文件控制异常堆栈输出的深度</li><li>去组件框架：极致优化要求下，可以去掉一些组件框架，比如去掉传统的 MVC 框架，直接使用 Servlet 处理请求。这样可以绕过一大堆复杂且用处不大的处理逻辑，节省毫秒级的时间，当然，需要合理评估你对框架的依赖程度</li></ol><h2 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h2><h3 id="1-减库存的方式"><a href="#1-减库存的方式" class="headerlink" title="1 减库存的方式"></a>1 减库存的方式</h3><ol><li>下单减库存。买家下单后，扣减商品库存。下单减库存是最简单的减库存方式，也是控制最为精确的一种</li><li>付款减库存。买家下单后，并不立即扣减库存，而是等到付款后才真正扣减库存。但因为付款时才减库存，如果并发比较高，可能出现买家下单后付不了款的情况，因为商品已经被其他人买走了</li><li>预扣库存。这种方式相对复杂一些，买家下单后，库存为其保留一定的时间（如 15 分钟），超过这段时间，库存自动释放，释放后其他买家可以购买</li></ol><h3 id="2-减库存的问题"><a href="#2-减库存的问题" class="headerlink" title="2 减库存的问题"></a>2 减库存的问题</h3><p>下单减库存:</p><ul><li>优势：用户体验最好。下单减库存是最简单的减库存方式，也是控制最精确的一种。下单时可以直接通过数据库事务机制控制商品库存，所以一定不会出现已下单却付不了款的情况。</li><li>劣势：可能卖不出去。正常情况下，买家下单后付款概率很高，所以不会有太大问题。但有一种场景例外，就是当卖家参加某个促销活动时，竞争对手通过恶意下单的方式将该商品全部下单，导致库存清零，那么这就不能正常售卖了——要知道，恶意下单的人是不会真正付款的，这正是 “下单减库存” 的不足之处。</li></ul><p>付款减库存</p><ul><li>优势：一定实际售卖。“下单减库存” 可能导致恶意下单，从而影响卖家的商品销售， “付款减库存” 由于需要付出真金白银，可以有效避免。</li><li>劣势：用户体验较差。用户下单后，不一定会实际付款，假设有 100 件商品，就可能出现 200 人下单成功的情况，因为下单时不会减库存，所以也就可能出现下单成功数远远超过真正库存数的情况，这尤其会发生在大促的热门商品上。如此一来就会导致很多买家下单成功后却付不了款，购物体验自然是比较差的。</li></ul><p>预扣库存</p><ul><li>优势：缓解了以上两种方式的问题。预扣库存实际就是“下单减库存”和 “付款减库存”两种方式的结合，将两次操作进行了前后关联，下单时预扣库存，付款时释放库存。</li><li>劣势：并没有彻底解决以上问题。比如针对恶意下单的场景，虽然可以把有效付款时间设置为 10 分钟，但恶意买家完全可以在 10 分钟之后再次下单。</li></ul><h3 id="3-实际如何减库存"><a href="#3-实际如何减库存" class="headerlink" title="3 实际如何减库存"></a>3 实际如何减库存</h3><p>业界最为常见的是预扣库存。无论是外卖点餐还是电商购物，下单后一般都有个 “有效付款时间”，超过该时间订单自动释放，这就是典型的预扣库存方案。但如上所述，预扣库存还需要解决恶意下单的问题，保证商品卖的出去；另一方面，如何避免超卖，也是一个痛点。</p><ol><li>卖的出去：恶意下单的解决方案主要还是结合安全和反作弊措施来制止。比如，识别频繁下单不付款的买家并进行打标，这样可以在打标买家下单时不减库存；再比如为大促商品设置单人最大购买件数，一人最多只能买 N 件商品；又或者对重复下单不付款的行为进行次数限制阻断等</li><li>避免超卖：库存超卖的情况实际分为两种。对于普通商品，秒杀只是一种大促手段，即使库存超卖，商家也可以通过补货来解决；而对于一些商品，秒杀作为一种营销手段，完全不允许库存为负，也就是在数据一致性上，需要保证大并发请求时数据库中的库存字段值不能为负，一般有多种方案：一是在通过事务来判断，即保证减后库存不能为负，否则就回滚；二是直接设置数据库字段类型为无符号整数，这样一旦库存为负就会在执行 SQL 时报错；三是使用 CASE WHEN 判断语句——</li></ol><p>UPDATE item SET inventory &#x3D; CASE WHEN inventory &gt;&#x3D; xxx THEN inventory-xxx ELSE inventory END</p><p>业务手段保证商品卖的出去，技术手段保证商品不会超卖，库存问题从来就不是简单的技术难题，解决问题的视角是多种多样的。</p><h3 id="4-一致性性能的优化"><a href="#4-一致性性能的优化" class="headerlink" title="4 一致性性能的优化"></a>4 一致性性能的优化</h3><p>4.1 高并发读</p><p>秒杀场景解决高并发读问题，关键词是“分层校验”。即在读链路时，只进行不影响性能的检查操作，如用户是否具有秒杀资格、商品状态是否正常、用户答题是否正确、秒杀是否已经结束、是否非法请求等，而不做一致性校验等容易引发瓶颈的检查操作；直到写链路时，才对库存做一致性检查，在数据层保证最终准确性。</p><p>因此，在分层校验设定下，系统可以采用分布式缓存甚至LocalCache来抵抗高并发读。即允许读场景下一定的脏数据，这样只会导致少量原本无库存的下单请求被误认为是有库存的，等到真正写数据时再保证最终一致性，由此做到高可用和一致性之间的平衡。</p><p>实际上，分层校验的核心思想是：不同层次尽可能过滤掉无效请求，只在“漏斗” 最末端进行有效处理，从而缩短系统瓶颈的影响路径。</p><p>4.2 高并发写</p><p><em>更换<strong>DB</strong>选型</em></p><p>秒杀商品和普通商品的减库存是有差异的，核心区别在数据量级小、交易时间短，把秒杀减库存直接放到缓存系统中实现，也就是直接在一个带有持久化功能的缓存中进行减库存操作，比如 Redis.</p><p>如果减库存逻辑非常单一的话，比如没有复杂的 SKU 库存和总库存这种联动关系的话，是完全可以的。但如果有比较复杂的减库存逻辑，或者需要使用到事务，那就必须在数据库中完成减库存操作。</p><p><em>优化<strong>DB</strong>性能</em></p><p>库存数据落地到数据库实现其实是一行存储（MySQL），因此会有大量线程来竞争 InnoDB 行锁。但并发越高，等待线程就会越多，TPS 下降，RT 上升，吞吐量会受到严重影响</p><ol><li>应用层排队。通过缓存加入集群分布式锁，从而控制集群对数据库同一行记录进行操作的并发度，同时也能控制单个商品占用数据库连接的数量，防止热点商品占用过多的数据库连接</li><li>数据层排队。应用层排队是有损性能的，数据层排队是最为理想的。业界中，阿里的数据库团队开发了针对InnoDB 层上的补丁程序（patch），可以基于DB层对单行记录做并发排队，从而实现秒杀场景下的定制优化——注意，排队和锁竞争是有区别的，如果熟悉 MySQL 的话，就会知道 InnoDB 内部的死锁检测，以及 MySQL Server 和 InnoDB 的切换都是比较消耗性能的。</li></ol><h3 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h3><p>秒杀请求高度集中于某一特定的时间点。造成一个特别高的零点峰值，而对资源的消耗也几乎是瞬时的。所以秒杀系统的可用性保护是不可或缺的。</p><p>1 流量削峰</p><p>能够抢到商品的人数是固定的，无论 100 人和 10000 人参加结果都是一样的，即有效请求额度是有限的。并发度越高，无效请求也就越多。但秒杀作为一种商业营销手段，活动开始之前是希望有更多的人来刷页面，只是真正开始后，秒杀请求不是越多越好。因此系统可以设计一些规则，人为的延缓秒杀请求，甚至可以过滤掉一些无效请求。</p><p>1.1 答题</p><ol><li>防止作弊。早期秒杀器比较猖獗，存在恶意买家或竞争对手使用秒杀器扫货的情况，商家没有达到营销的目的，所以增加答题来进行限制</li><li>延缓请求。零点流量的起效时间是毫秒级的，答题可以人为拉长峰值下单的时长，由之前的 &lt;1s 延长到 &lt;10s。这个时间对于服务端非常重要，会大大减轻高峰期并发压力；另外，由于请求具有先后顺序，答题后置的请求到来时可能已经没有库存了，因此根本无法下单，此阶段落到数据层真正的写也就非常有限了</li></ol><p>答题除了做正确性验证，还需要对提交时间做验证，比如&lt;1s 人为操作的可能性就很小，可以进一步防止机器答题的情况。</p><p>1.2 排队</p><p>最为常见的削峰方案是使用消息队列，通过把同步的直接调用转换成异步的间接推送缓冲瞬时流量。除了消息队列，类似的排队方案还有很多，例如：</p><ol><li>线程池加锁等待</li><li>本地内存蓄洪等待</li><li>本地文件序列化写，再顺序读</li></ol><p>排队方式的弊端也是显而易见的，主要有两点：</p><ol><li>请求积压。流量高峰如果长时间持续，达到了队列的水位上限，队列同样会被压垮，这样虽然保护了下游系统，但是和请求直接丢弃也没多大区别</li><li>用户体验。异步推送的实时性和有序性自然是比不上同步调用的，由此可能出现请求先发后至的情况，影响部分敏感用户的购物体验</li></ol><p>排队本质是在业务层将一步操作转变成两步操作，从而起到缓冲的作用，但鉴于此种方式的弊端，最终还是要基于业务量级和秒杀场景做出妥协和平衡。</p><p>1.3 过滤</p><p>过滤的核心结构在于分层，通过在不同层次过滤掉无效请求，达到数据读写的精准触发。常见的过滤主要有以下几层：</p><p>1、读限流：对读请求做限流保护，将超出系统承载能力的请求过滤掉</p><p>2、读缓存：对读请求做数据缓存，将重复的请求过滤掉</p><p>3、写限流：对写请求做限流保护，将超出系统承载能力的请求过滤掉</p><p>4、写校验：对写请求做一致性校验，只保留最终的有效数据</p><h3 id="2-Plan-B"><a href="#2-Plan-B" class="headerlink" title="2 Plan B"></a>2 Plan B</h3><p>在秒杀这一场景下，为了保证系统的高可用，必须设计一个 Plan B 方案来进行兜底。</p><p>高可用建设，其实是一个系统工程，贯穿在系统建设的整个生命周期。</p><img src="/2024/04/07/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/clip_image094.gif" class="" title="img"><p>具体来说，系统的高可用建设涉及架构阶段、编码阶段、测试阶段、发布阶段、运行阶段，以及故障发生时，逐一进行分析：</p><ol><li>架构阶段：考虑系统的可扩展性和容错性，避免出现单点问题。例如多地单元化部署，即使某个IDC甚至地市出现故障，仍不会影响系统运转</li><li>编码阶段：保证代码的健壮性，例如RPC调用时，设置合理的超时退出机制，防止被其他系统拖垮，同时也要对无法预料的返回错误进行默认的处理</li><li>测试阶段：保证CI的覆盖度以及Sonar的容错率，对基础质量进行二次校验，并定期产出整体质量的趋势报告</li><li>发布阶段：系统部署最容易暴露错误，因此要有前置的checklist模版、中置的上下游周知机制以及后置的回滚机制</li><li>运行阶段：系统多数时间处于运行态，最重要的是运行时的实时监控，及时发现问题、准确报警并能提供详细数据，以便排查问题</li><li>故障发生：首要目标是及时止损，防止影响面扩大，然后定位原因、解决问题，最后恢复服务</li></ol><p>日常运维而言</p><ol><li>预防：建立常态压测体系，定期对服务进行单点压测以及全链路压测，摸排水位</li><li>管控：做好线上运行的降级、限流和熔断保护。需要注意的是，无论是限流、降级还是熔断，对业务都是有损的，所以在进行操作前，一定要和上下游业务确认好再进行。就拿限流来说，哪些业务可以限、什么情况下限、限流时间多长、什么情况下进行恢复，都要和业务方反复确认</li><li>监控：建立性能基线，记录性能的变化趋势；建立报警体系，发现问题及时预警</li><li>恢复：遇到故障能够及时止损，并提供快速的数据订正工具，不一定要好，但一定要有</li></ol>]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> 秒杀系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>操作系统</title>
      <link href="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
      <url>/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<h1 id="用户态和内核态"><a href="#用户态和内核态" class="headerlink" title="用户态和内核态"></a>用户态和内核态</h1><p>在CPU的所有指令中，有一些指令是非常危险的，如果错用，将导致整个系统崩溃。比如：清内存、设置时钟等。如果所有的程序都能使用这些指令，那么你的系统一天死机n回就不足为奇了。所以，CPU将指令分为特权指令和非特权指令，对于那些危险的指令，只允许操作系统及其相关模块使用。</p><p>从用户空间到内核空间有两种触发手段：</p><p>1.用户空间的应用程序，通过系统调用，进入内核空间。这个时候用户空间的进程要传递很多变量、参数的值给内核，内核态运行的时候也要保存用户进程的一些寄存器值、变量等。所谓的“进程上下文”，可以看作是用户进程传递给内核的这些参数以及内核要保存的那一整套的变量和寄存器值和当时的环境等。</p><p>2.硬件通过触发信号，导致内核调用中断处理程序，进入内核空间。这个过程中，硬件的一些变量和参数也要传递给内核，内核通过这些参数进行中断处理。所谓的“中断上下文”，其实也可以看作就是硬件传递过来的这些参数和内核需要保存的一些其他环境（主要是当前被打断执行的进程环境）。</p><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image001.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image002.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image003.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image004.jpg" class="" title="img"><h1 id="进程和线程"><a href="#进程和线程" class="headerlink" title="进程和线程"></a>进程和线程</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><ul><li>什么是进程</li></ul><p>进程可以理解为就是应用程序的启动实例。如微信、Idea、Navicat等，当打开它们后，就相当于开启了一个进程。每个进程都会在操作系统中拥有独立的内存空间、地址、文件资源、数据资源等。<strong>进程是资源分配和管理的最小单位</strong></p><p>线程从属于进程，是程序的实际执行者，一个进程中可以包含若干个线程，并且也可以把线程称为轻量级进程。每个线程都会拥有自己的计数器、堆栈、局部变量等属性，并且能够访问共享的内存变量。**线程是操作系统（CPU）调度和执行的最小单位。CPU会在这些线程上来回切换，让使用者感觉线程是在同时执行的。</p><p><strong>线程使用带来的问题</strong></p><p>​    有很多人都会存在一个误区，在代码中使用多线程，一定会为系统带来性能提升，这个观点是错误的。并发编程的目的是为了让程序运行的更快，但是，绝对不是说启动的线程越多，性能提升的就越大，其会受到很多因素的影响，如锁问题、线程状态切换问题、线程上下文切换问题，还会受到硬件资源的影响，如CPU核数。</p><p>什么叫做线程上下文切换</p><p>​    不管是在多核甚至单核处理器中，都是能够以多线程形式执行代码的，CPU通过给每个线程分配CPU时间片来实现线程执行间的快速切换。 所谓的时间片就是CPU分配给每个线程的执行时间，当某个线程获取到CPU时间片后，就会在一定时间内执行，当时间片到期，则该线程会进入到挂起等待状态。时间片一般为几十毫秒，通过在CPU的高速切换，让使用者感觉是在同时执行。</p><p>​    同时还要保证线程在切换的过程中，要记录线程被挂起时，已经执行了哪些指令、变量值是多少，那这点则是通过每个线程内部的程序计数器来保证。</p><p>​    简单来说：线程从挂起到再加载的过程，就是一次上下文切换。其是比较耗费资源的。</p><p>引起上下文切换的几种情况：</p><ul><li>时间片用完，CPU正常调度下一个任务。</li><li>被其他优先级更高的任务抢占。</li><li>执行任务碰到IO阻塞，调度器挂起当前任务，切换执行下一个任务。</li><li>用户代码主动挂起当前任务让出CPU时间。</li><li>多任务抢占资源，由于没有抢到被挂起。</li><li>硬件中断。</li></ul><p><strong>CPU时间片轮转机制&amp;优化</strong></p><p>​    之前已经提到了线程的执行，是依赖于CPU给每个线程分配的时间来进行。在CPU时间片轮转机制中，如果一个线程的时间片到期，则CPU会挂起该线程并给另一个线程分配一定的时间分片。如果进程在时间片结束前阻塞或结束，则 CPU 会立即进行切换。</p><p>​     时间片太短会导致频繁的进程切换，降低了 CPU 效率: 而太长又可能引起对短的交互请求的响应变差。时间片为 <strong>100ms</strong> 通常是一个比较合理的折衷。</p><p>并行与并发的理解</p><p>并发即让多个任务能够<strong>交替</strong>执行，一般都会附带一个时间单位，也就是所谓的在单</p><p>位时间内的并发量有多少。</p><p>并行即让多个任务能够同时执行。比如说：你可以一遍上厕所，一遍吃饭。</p><p>线程的实现方式有两种：继承Thread类、实现Runnable接口。但是有一些书籍或者文章会说有三种方式，即实现Callable接口。但通过该接口定义线程并不是Java标准的定义方式，而是基于</p><p>Future思想来完成。</p><p>Thread是对一个线程的抽象，而Runnable是对业务逻辑的抽象，并且Thread 可以接受任意一个 Runnable 的实例并执行。</p><p>优化：启动线程前，最好为这个线程设置特定的线程名称，这样在出现问题时，给开发人员一些提示，快速定位到问题线程。</p><p>线程中止</p><p>线程在正常下当run执行完，或出现异常都会让该线程中止。</p><p>理解suspend()、resume()、stop()</p><p>这三个方法对应的是暂停、恢复和中止。</p><p>但是三个已经在Java源码中被标注为过期方法。</p><p>当调用suspend()时，线程不会将当前持有的资源释放(如锁)，而是占有者资源进入到暂停状</p><p>态，这样的话，容易造成死锁问题的出现。</p><p>当调用stop()时，会<strong>立即停止run()中剩余的操作</strong>。因此可能会导致一些的工作得不到完成，如文件流，数据库等关闭。并且<strong>会立即释放该线程所持有的所有的锁</strong>，导致数据得</p><p>不到同步的处理，出现数据不一致的问题。</p><p>线程中止的安全且优雅姿势</p><p>​    Java对于线程安全中止设计了一个<strong>中断属性</strong>，其可以理解是线程的一个标识位属性。它用于表示一个运行中的线程是否被其他线程进行了中断操作。好比其他线程对这个线程打了一个招呼，告诉它你该中断了。通过**interrupt()**实现。</p><p>添加该方法后，会出现一个异常，但是可以发现并不会线程的继续执行。</p><p>​    线程通过检查自身是否被中断来进行响应，可以通过**isInterrupted()**进行判断，如果返回值为true，代表添加了中断标识，返回false，代表没有添加中断标识。通过它可以对线程进行中断操作。</p><p>对线程中断属性的判断，可以利用其进行线程执行的中断操作。线程也可以通过静态方法**Thread.interrupted()**查询线程是否被中断，并对中断标识进行复位，如果该线程已经被添加了中断标识，当使用了该方法后，会将线程的中断标识由true改为false。</p><p>同时要注意：<strong>处于死锁下的线程，无法被中断</strong></p><h2 id="进程和线程的区别"><a href="#进程和线程的区别" class="headerlink" title="进程和线程的区别"></a>进程和线程的区别</h2><p>进程是执行着的应用程序，而线程是进程内部的一个执行序列。一个进程可以有多个线程。线程又叫做轻量级进程。</p><p>**a.**<strong>地址空间和其它资源</strong>：进程间拥有独立内存，进程是资源分配的基本单位；线程隶属于某一进程，且同一进程的各线程间共享内存（资源），线程是cpu调度的基本单位。 进程间相互独立，同一进程的各线程间共享。某进程内的线程在其它进程不可见。</p><p>**b.**<strong>通信：</strong>进程间相互独立，通信困难，常用的方法有：管道，信号，套接字，共享内存，消息队列等；线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性。 </p><p>**c.**<strong>调度和切换</strong>：线程上下文切换比进程上下文切换要快。进程间切换要保存上下文，加载另一个进程；而线程则共享了进程的上下文环境，切换更快。</p><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image005.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image006.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image008.jpg" class="" title="线 程 的 优 点 ：  。 一 个 进 程 中 可 以 同 时 存 在 个 线 程 ；  。 各 个 线 程 之 间 可 以 并 发 执 行 ；  。 各 个 线 程 之 间 可 以 共 享 地 址 空 间 和 文 件 等 资 源 ；  线 程 的 缺 点 ：  能 当 进 程 中 的 一 个 线 程 崩 溃 时 ， 会 导 致 其 所 属 进 程 的 所 有 线 程 崩 溃 。"><h2 id="线程间通信方式"><a href="#线程间通信方式" class="headerlink" title="线程间通信方式"></a>线程间通信方式</h2><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image009.jpg" class="" title="img"><p>共享存储：基于数据结构：eg.在共享空间放数组</p><p>基于存储区：在内存区中画出一片共享存储区，数据的形式和存放位置由进程决定</p><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image010.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image011.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image012.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image013.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image014.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image015.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image016.jpg" class="" title="img"><h2 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h2><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image017.jpg" class="" title="img"><p>死锁的定义</p><p>一组进程中，<strong>每个进程都无限等待被该组进程中另一进程所占有的资源</strong>，因而永远无法得到的资源，这种现象称为进程死锁，这一组进程就称为死锁进程。</p><p>产生死锁的必要条件</p><p>(1)互斥使用(资源独占)：一个资源每次只能给一个进程使用</p><p>(2)占有且等待(请求和保持，部分分配)：进程在申请新的资源的同时保持对原有资源的占有</p><p>(3)不可剥夺：资源申请者不能强行的从资源占有者手中夺取资源，资源只能由占有者自愿释放</p><p>(4)循环等待：存在一个进程等待队列 {P1 , P2 , … , Pn}，其中P1等待P2占有的资源，P2等待P3占有的资源，…，Pn等待P1占有的资源，形成一个进程等待环路。</p><p>以哲学家进餐问题为例，我占着筷子，你们不能抢我的，我还想要另一只筷子，形成一个圈。            (互斥)   (不可剥夺)   (请求和保持)    (循环等待)</p><p> 什么情况会发生死锁</p><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image018.jpg" class="" title="img"><p>死锁预防</p><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image019.jpg" class="" title="img"><p> 死锁避免</p><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image021.jpg" class="" title="img"><p> 死锁检测与消除</p><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image022.jpg" class="" title="img"><p><a href="https://www.huaweicloud.com/articles/9fa2f8ad06587f13ca7f11ec4d9a5077.html">https://www.huaweicloud.com/articles/9fa2f8ad06587f13ca7f11ec4d9a5077.html</a></p><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image023.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image024.jpg" class="" title="img"><p><a href="https://blog.csdn.net/qq_46527915/category_10424299.html">https://blog.csdn.net/qq_46527915/category_10424299.html</a></p><p>线程之间同步的方式</p><p>1、 临界区（CCriticalSection）</p><p>当多个线程访问一个独占性共享资源时，可以使用临界区对象（有正在访问临界区资源标志）。拥有临界区的线程可以访问被保护起来的资源或代码段，其他线程若想访问，则被挂起，直到拥有临界区的线程放弃临界区为止。</p><p>2、互斥对象：互斥对象和临界区很像，采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以能保证公共资源不会同时被多个线程同时访问。当前拥有互斥对象的线程处理完任务后必须将线程交出，以便其他线程访问该资源</p><p>3、信号量：信号量也是内核对象。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目</p><p>在用CreateSemaphore()创建信号量时即要同时指出允许的最大资源计数和当前可用资源计数。一般是将当前可用资源计数设置为最大资源计数，每增加一个线程对共享资源的访问，当前可用资源计数就会减1 ，只要当前可用资源计数是大于0 的，就可以发出信号量信号。但是当前可用计数减小到0时则说明当前占用资源的线程数已经达到了所允许的最大数目，不能在允许其他线程的进入，此时的信号量信号将无法发出。线程在处理完共享资源后，应在离开的同时通过ReleaseSemaphore （）函数将当前可用资源计数加1 。在任何时候当前可用资源计数决不可能大于最大资源计数。</p><p>4、 事件（CEvent）</p><p>事件机制，则允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。比如在某些网络应用程序中，一个线程如A负责侦听通信端口，另外一个线程B负责更新用户数据，利用事件机制，则线程A可以通知线程B何时更新用户数据。</p><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image025.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image026.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image027.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image028.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image029.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image030.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image031.jpg" class="" title="img"><h2 id="进程调度"><a href="#进程调度" class="headerlink" title="进程调度"></a>进程调度</h2><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image032.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image033.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image034.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image035.jpg" class="" title="img"><h2 id="线程优先级"><a href="#线程优先级" class="headerlink" title="线程优先级"></a>线程优先级</h2><p>线程优先级的<strong>范围是****1~10</strong>。一个线程的<strong>默认优先级是****5</strong>，可以在构建线程时，通过**setPriority()**修改该线程的优先级。优先级高的线程分配时间片的数量会高于优先级低的线程。</p><p>​    一般来说对于频繁阻塞的线程需要设置优先级高点，而偏重计算的线程优先级会设置低些，确保处理器不会被独占。</p><p>​    但<strong>注意，线程优先级不能作为线程执行正确性的依赖，因为不同的操作系统可能会忽略优先级的设置。</strong></p><h2 id="守护线程"><a href="#守护线程" class="headerlink" title="守护线程"></a>守护线程</h2><p>守护线程是一种支持型的线程，我们之前创建的线程都可以称之为用户线程。通过守护线程可以完成一些支持性的工作，如GC、分布式锁续期。守护线程会伴随着用户线程的结束而结束。</p><p>对于守护线程的创建，可以通过setDaemon()设置。</p><p>当线程实例没有被设置为守护线程时，该线程并不会随着主线程的结束而结束。但是当被设置为守护线程后，当主线程结束，该线程也会伴随着结束。同时守护线程不一定会执行finally代码块。所以当线程被设定为守护线程后，无法确保清理资源等操作一定会被执行。</p><h2 id="线程状态"><a href="#线程状态" class="headerlink" title="线程状态"></a>线程状态</h2><p><img src="/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image037.jpg" alt="Object.wait()  Objectjoin()  LockSupportprk()  《 实 例 化  初 始  (NEW)  T “ d 对 酾 0  (RUNNABLE)  运 行 中  (RUNNING)  等 待  (WAITING)  Objectnotify()  Object.notifyAllO  L&#39;EkSupm»rt.unvx•rk(Thread)  系 统 调 度  yield()  系 统 调 度  就 *(READY)  执 行 完 成  终 上  (TERMINATED)  Obiect.waiulong)  Thread.join(long)  LockSupport.parkNanos()  LockSupport.parktJntil()  超 时 等 待  (TIMED WAITING)  （ j “ 上 n 《 下 0  （ 讣 卞 0 ． n fyAll()  L&#39;RkSupport.unpark(Thread)  超 进 时 间 到  等 待 进 入 、 yn 山 ronized 方 法  获 取 到 锁 等 待 进 入 “ niz 块  阻 塞  (BLOCKED)  由 上 图 可 以 看 出 ： 线 程 创 建 之 后 它 将 处 于 NEW （ 新 建 ） 状 态 ， 调 用 start() 方 法 后 开 始 运 行 ，  线 程 这 时 候 处 于 READY （ 可 运 行 ） 状 态 。 可 运 行 状 态 的 线 程 获 得 了 CPU 时 间 片 (timeslice)  后 就 处 于 RUNNING （ 运 行 ） 状 态 。 "><img src="/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image039.jpg" alt="状 态 名 称  NEW  RUNNABLE  BLOCKED  WAITING  TIME WAITING  TERMINATED  初 始 状 态 ， 线 程 被 构 建 ， 但 是 还 没 有 调 用 start() 方 法  运 行 状 态  ， Java 线 程 将 作 系 统 中 的 就 绪 和 运 行 两 种 状 态 花 统 地 你 作 “ 运 行 中 &quot;  阻 不 状 态 ．  表 示 线 程 阻 寒 于 锁  等 待 状 态 ， 表 示 线 程 进 人 等 待 状 态 ， 进 人 该 状 态 表 示 当 前 线 程 需 要 等 待 其 他 线 程  做 出 一 些 特 定 动 作 （ 通 知 或 中 断 ）  超 时 等 侍 状 态 ， 该 状 态 不 同 于 WA 仃 ING ， 它 是 可 以 在 指 定 的 时 间 自 行 返 回 的  这 Il ． 态 ， 表 示 当 前 线 已 经 执 行 完 毕 "></p><h2 id="线程安全活跃态问题以及竞态条件"><a href="#线程安全活跃态问题以及竞态条件" class="headerlink" title="线程安全活跃态问题以及竞态条件"></a>线程安全活跃态问题以及竞态条件</h2><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image041.jpg" class="" title="1 ． 线 程 安 全 的 活 跃 性 问 题 可 以 分 为 死 锁 、 活 锁 、 饥 饿  1 ． 活 锁 就 是 有 时 线 程 虽 然 没 有 发 生 阻 塞 ， 但 是 仍 然 会 存 在 执 行 不 下 去 的 情 况 ， 活 锁 不 会 阻 塞 线 程 ， 线 程 会 一  直 重 复 执 行 某 个 相 同 的 操 作 ， 并 且 一 直 失 败 重 试  1 ． 我 们 开 发 中 使 用 的 异 步 消 息 队 列 就 有 可 能 造 成 活 锁 的 问 题 ， 在 消 息 队 列 的 消 费 端 如 果 没 有 正 确 的 旦  消 息 ， 并 目 执 行 过 程 中 报 错 了 ， 就 会 冉 次 放 回 消 息 头 ， 然 后 冉 拿 出 来 执 行 ， 一 直 循 环 往 复 的 失 败 。 这  个 问 题 除 了 正 确 的 匹 之 外 ， 往 往 是 通 i 寻 失 败 的 息 放 入 到 延 时 队 列 中 ， 等 到 一 定 的 延 时 冉 进 行 重  试 来 解 决 。  2 ．  几 的 时 间 就 可 以 ， 会 按 时 间  去 重 试"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image043.jpg" class="" title="2 ． 饥 饿 就 是 线 程 因 无 法 访 问 所 需 资 氵 原 而 无 氵 去 执 行 下 去 的 情 况  1 ， 饥 饿 分 为 两 种 情 况 ：  1 ． 一 种 是 具 他 的 线 程 在 临 界 区 做 了 无 限 循 环 競 无 限 制 等 待 资 源 的 操 作 ， 让 其 他 的 线 程 一 直 不 能 拿 到  锁 进 入 临 界 区 ， 对 其 他 线 程 来 说 ， 就 进 入 了 饥 饿 状 态  2 ． 另 一 种 是 因 为 线 程 优 先 级 不 合 理 的 分 配 ， 导 致 部 分 线 程 始 终 无 法 获 取 到 CPU 资 源 而 一 直 无 法 执 行  2 ． 解 决 饥 饿 的 问 题 有 几 种 方 案 ．  1 ． 保 证 资 源 充 足 ， 很 多 场 景 下 ， 资 源 的 稀 缺 性 无 法 解 决  2 ． 公 平 分 配 资 源 ， 在 并 发 编 程 里 使 用 公 平 锁 ， 例 如 FIFO 策 略 ， 线 程 等 待 是 有 顺 序 的 ， 排 在 等 待 队 列  前 面 的 线 程 会 优 先 获 得 资 源  3 ， 免 持 有 锁 的 线 程 长 时 间 执 行 ， 很 多 场 景 下 ， 持 有 锁 的 线 程 的 执 行 时 间 也 很 难 缩 短  3 ． 死 锁 线 程 在 对 同 一 把 锁 进 行 竟 争 的 时 候 ， 未 抢 占 到 锁 的 纟 呈 会 等 待 持 有 锁 的 线 程 释 放 锁 后 继 纟 仓 占 ， 如  果 两 个 或 两 个 以 上 的 纟 呈 互 相 持 有 对 方 将 要 抢 占 的 锁 ， 互 相 等 待 对 方 先 行 释 放 锁 就 会 进 入 到 一 个 循 环 等 待  的 过 程 ， 这 个 过 程 就 叫 做 死 锁"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image045.jpg" class="" title="2 、 线 程 安 全 的 竟 态 条 件 问 题  1 ． 同 一 个 程 序 多 线 程 访 问 同 一 个 资 源 ， 如 果 对 资 源 的 访 问 顺 序 敏 感 ， 就 称 存 在 竞 态 条 件 ， 代 码 区 成 为 临 界  区 。 大 多 数 并 发 错 误 一 样 ， 竟 态 条 件 不 总 是 会 产 生 问 题 ， 还 需 要 不 恰 当 的 执 行 时 序  2 ， 最 常 见 的 竟 态 条 件 为  1 ． 先 检 测 后 执 行 执 行 依 赖 于 检 测 的 结 果 ， 而 检 测 结 果 依 赖 于 多 个 线 程 的 执 行 时 序 ， 而 多 个 线 程 的 执 行 时  序 通 帛 情 况 下 是 不 固 定 不 可 判 断 的 ， 从 而 导 致 执 行 结 果 出 现 各 种 问 题 ， 见 一 种 可 能 的 解 决 办 法 就 是 ．  在 一 个 纟 呈 修 改 访 问 一 个 状 态 时 ， 要 防 止 其 他 线 程 访 问 修 改 ， 也 就 是 加 锁 机 制 ， 保 证 原 子 性  2 ． 延 迟 初 始 化 （ 典 型 为 单 例 ）"><h2 id="多级反馈队列调度算法"><a href="#多级反馈队列调度算法" class="headerlink" title="多级反馈队列调度算法"></a>多级反馈队列调度算法</h2><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image046.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image047.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image049.gif" class="" title="img"><h2 id="孤儿进程，僵尸进程"><a href="#孤儿进程，僵尸进程" class="headerlink" title="孤儿进程，僵尸进程"></a>孤儿进程，僵尸进程</h2><p><strong>孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。</strong></p><p><strong>僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。</strong></p><p><a href="https://www.cnblogs.com/Anker/p/3271773.html">https://www.cnblogs.com/Anker/p/3271773.html</a></p><h1 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h1><h2 id="逻辑地址和物理地址"><a href="#逻辑地址和物理地址" class="headerlink" title="逻辑地址和物理地址"></a>逻辑地址和物理地址</h2><ul><li><ul><li>逻辑地址</li><li>指由程序产生的段内偏移。有时候直接把逻辑地址当做虚拟地址。</li></ul></li><li><ul><li>物理地址</li><li>指CPU外部地址总线上寻址物理内存的地址信号，是地址变换的最终结果。</li></ul></li><li><ul><li>虚拟地址</li><li>指由程序产生的由段选择符和段内偏移地址组成的地址。</li></ul></li><li><ul><li>线性地址</li><li>指虚拟地址到物理地址变换的中间层，是处理器可寻址的内存空间中的地址。程序代码会产生逻辑地址，也就是段中的偏移地址，加上相应的段基址就成了线性地址。如果开启了分页机制，那么线性地址需要再经过变换，转为为物理地址。如果无分页机制，那么线性地址就是物理地址。</li></ul></li></ul><h2 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h2><p><a href="onenote:#内存管理&section-id={7168EEEF-275B-413A-9384-A420806C9C4F}&page-id={9B7BA1DC-0CC3-41C0-A8E0-09388B487078}&object-id={2FB06EC1-4084-4E60-9B5D-D762ABB54D5D}&2B&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/操作系统.one">内存分段</a></p><p><a href="onenote:#内存管理&section-id={7168EEEF-275B-413A-9384-A420806C9C4F}&page-id={9B7BA1DC-0CC3-41C0-A8E0-09388B487078}&object-id={2FB06EC1-4084-4E60-9B5D-D762ABB54D5D}&82&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/操作系统.one">内存分页</a></p><p><a href="onenote:#内存管理&section-id={7168EEEF-275B-413A-9384-A420806C9C4F}&page-id={9B7BA1DC-0CC3-41C0-A8E0-09388B487078}&object-id={2FB06EC1-4084-4E60-9B5D-D762ABB54D5D}&89&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/操作系统.one">多级页表</a></p><p><a href="onenote:#内存管理&section-id={7168EEEF-275B-413A-9384-A420806C9C4F}&page-id={9B7BA1DC-0CC3-41C0-A8E0-09388B487078}&object-id={2FB06EC1-4084-4E60-9B5D-D762ABB54D5D}&C4&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/操作系统.one">段页式内存管理</a></p><p><a href="onenote:#内存管理&section-id={7168EEEF-275B-413A-9384-A420806C9C4F}&page-id={9B7BA1DC-0CC3-41C0-A8E0-09388B487078}&object-id={2FB06EC1-4084-4E60-9B5D-D762ABB54D5D}&DD&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/操作系统.one">总结</a></p><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image050.jpg" class="" title="img"><p> 内存分段</p><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image051.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image052.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image053.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image054.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image056.jpg" class="" title="再 来 看 看 ， 分 段 为 什 么 会 寻 致 内 存 交 换 效 率 低 的 问 ？  对 于 弓 进 程 的 系 统 来 说 ， 用 分 段 的 方 式 ， 内 存 碎 片 是 很 容 易 产 生 的 ， 产 生 了 内 存 碎 片 ， 那 不  得 不 申 新 Swap 内 存 区 域 ， 这 个 过 程 会 产 生 性 能 瓶 颈 。  因 为 硬 盘 的 访 闷 速 度 要 比 内 存 慢 太 了 ， 每 一 次 内 存 交 换 ， 我 们 都 需 要 把 一 大 段 连 续 的 内 存  数 踞 写 到 硬 盘 上 。  所 以 ， 如 果 内 存 交 挨 的 时 候 ， 交 挨 的 是 一 个 占 内 存 空 间 很 大 的 程 序 ， 这 样 整 个 机 器 都 会 显 得  为 了 解 决 内 存 分 殿 的 内 存 碎 片 和 内 存 交 涣 效 率 低 的 闷 ， 就 出 现 了 内 存 分 页 。"><p>内存分页</p><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image057.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image058.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image059.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image060.jpg" class="" title="img"><p>多级页表</p><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image061.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image062.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image063.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image064.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image065.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image066.jpg" class="" title="img"><p> 段页式内存管理</p><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image067.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image068.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image069.jpg" class="" title="img"><p>总结</p><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image070.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image071.jpg" class="" title="img"><h2 id="快表和多级页表"><a href="#快表和多级页表" class="headerlink" title="快表和多级页表"></a>快表和多级页表</h2><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image072.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image073.jpg" class="" title="img"><h2 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h2><p>局部性原理</p><p>在CPU访问寄存器时，无论是存取数据抑或存取指令，都趋于聚集在一片连续的区域中，这就被称为局部性原理。 </p><p>时间局部性（temporal locality）  </p><p>时间局部性指的是：被引用过一次的存储器位置在未来会被多次引用（通常在循环中）。 </p><p>空间局部性（spatial locality）  </p><p>如果一个存储器的位置被引用，那么将来他附近的位置也会被引用。</p><p>基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其余部分留在外存，就可以启动程序执行。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存,然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换出到外存上，从而腾出空间存放将要调入内存的信息。这样，系统好像为用户提供了一个比实际内存大得多的存储器，称为虚拟存储器。</p><p>之所以将其称为虚拟存储器，是因为这种存储器实际上并不存在，只是由于（对用户完全透明），给用户的感觉是好像存在一个比实际物理内存大得多的存储器。虚拟存储器的大小由计算机的地址结构决定，并非是内存和外存的简单相加。 </p><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image074.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image075.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image076.jpg" class="" title="img"><p><a href="https://blog.csdn.net/lvyibin890/article/details/82217193">https://blog.csdn.net/lvyibin890/article/details/82217193</a></p><h2 id="页错误"><a href="#页错误" class="headerlink" title="页错误"></a>页错误</h2><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image077.jpg" class="" title="img"><p><a href="https://blog.csdn.net/lqy971966/article/details/106910442">https://blog.csdn.net/lqy971966/article/details/106910442</a></p><h2 id="时钟置换算法"><a href="#时钟置换算法" class="headerlink" title="时钟置换算法"></a>时钟置换算法</h2><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image078.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image079.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image080.jpg" class="" title="img"><h2 id="LRU算法"><a href="#LRU算法" class="headerlink" title="LRU算法"></a>LRU算法</h2><p>LRU 存储是基于双向链表实现的，下面的图演示了它的原理。其中 h 代表双向链表的表头，t 代表尾部。首先预先设置 LRU 的容量，如果存储满了，可以通过 O(1) 的时间淘汰掉双向链表的尾部，每次新增和访问数据，都可以通过 O(1)的效率把新的节点增加到对头，或者把已经存在的节点移动到队头。</p><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image081.jpg" class="" title="img"><p>1.save(key, value)，首先在 HashMap 找到 Key 对应的节点，如果节点存在，更新节点的值，并把这个节点移动队头。如果不存在，需要构造新的节点，并且尝试把节点塞到队头，如果LRU空间不足，则通过 tail 淘汰掉队尾的节点，同时在 HashMap 中移除 Key。</p><p>2.get(key)，通过 HashMap 找到 LRU 链表节点，把节点插入到队头，返回缓存的值。 </p><h1 id="IO模型"><a href="#IO模型" class="headerlink" title="IO模型"></a>IO模型</h1><p>阻塞IO，非阻塞IO，IO多路复用，事件响应IO，异步IO</p><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image082.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image083.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image084.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image085.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image086.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image087.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image088.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image089.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image090.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image091.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image092.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image093.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image094.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image095.jpg" class="" title="img"><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image096.jpg" class="" title="img"><p><a href="https://zhuanlan.zhihu.com/p/115912936">https://zhuanlan.zhihu.com/p/115912936</a></p><h1 id="中断"><a href="#中断" class="headerlink" title="中断"></a>中断</h1><img src="/2024/04/07/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/clip_image098.jpg" class="" title="臊 作 系 统 收 到 了 中 断 求 ， 会 打 断 其 他 进 程 的 运 行 ， 所 以 中 断 谴 求 的 应 程 序 ， 也 就 是 中 断  处 理 程 序 ， 要 尽 可 能 快 的 执 行 完 ， 这 样 可 以 少 对 正 常 进 程 运 行 调 度 地 影 。">]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> 操作系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机网络</title>
      <link href="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
      <url>/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="7层模型"><a href="#7层模型" class="headerlink" title="7层模型"></a>7层模型</h1><p>应⽤层 </p><p>应⽤层(application-layer）的任务是通过应⽤进程间的交互来完成特定⽹络应⽤。应⽤层协议定义的是应⽤进程（进程：主机中正在运⾏的程序）间的通信和交互的规则。对于不同的⽹络应⽤需要不同的应⽤层协议。在互联⽹中应⽤层协议很多，如域名系统DNS，⽀持万维⽹应⽤的<strong>HTTP协议，⽀持电⼦邮件的</strong> <strong>SMTP协议等等。我们把应⽤层交互的据单元称为报⽂。</strong> </p><p>运输层 </p><p>运输层**(transport layer)**的主要任务就是负责向两台主机进程之间的通信提供通⽤的数据传输服务。应⽤进程利⽤该服务传送应⽤层报⽂。“通⽤的”是指并不针对某⼀个特定的⽹络应⽤，⽽是 多种应⽤可以使⽤同⼀个运输层服务。由于⼀台主机可同时运⾏多个线程，因此运输层有复⽤和 分⽤的功能。所谓复⽤就是指多个应⽤层进程可同时使⽤下⾯运输层的服务，分⽤和复⽤相反， 是运输层把收到的信息分别交付上⾯应⽤层中的相应进程。 </p><p>运输层主要使⽤以下两种协议**:**</p><ol><li><p>传输控制协议 <strong>TCP</strong>（Transmission Control Protocol）–提供⾯向连接的，可靠的数据传输 服务。 </p></li><li><p>⽤户数据协议 <strong>UDP</strong>（User Datagram Protocol）–提供⽆连接的，尽最⼤努⼒的数据传输服 务（不保证数据传输的可靠性）</p></li></ol><p>⽹络层 </p><p>在计算机⽹络中进⾏通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信⼦⽹。⽹络层的任务就是选择合适的⽹间路由和交换结点， 确保数据及时传送。在发送数据时，⽹络层把运输层产⽣的报⽂段或⽤户数据报封装成分组和包进⾏传送。</p><p>数据链路层 </p><p>数据链路层**(data link layer)**通常简称为链路层。两台主机之间的数据传输，总是在⼀段</p><p>⼀段的链 路上传送的，这就需要使⽤专⻔的链路层的协议。 在两个相邻节点之间传送数据时，数据链路层 将⽹络层交下来的 <strong>IP</strong> 数据报组装成帧，在两个相邻节点间的链路上传送帧。每⼀帧包括数据和必要的控制信息（如同步信息，地址信息，差错控制等）。</p><p>⽹络并不是⼀个整体，⼀旦数据需要跨⽹络传输，就需要有⼀个设备同时在两个⽹络当中，这个设备⼀般是路由器，路由器可以通过路由 表计算出下⼀个要去的 IP 地址。 </p><p>那问题来了，路由器怎么知道这个 IP 地址是哪个设备的呢？ </p><p>于是，就需要有⼀个专⻔的层来标识⽹络中的设备，让数据在⼀个链路中传输，这就是数据链路层（<em>Data Link Layer</em>），它主要为⽹络层提供链路级别传的服务。</p><p>物理层 </p><p>在物理层上所传送的数据单位是⽐特。 </p><p>物理层**(physical layer)**的作⽤是实现相邻计算机节点之间⽐特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异。</p><h1 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h1><h2 id="HTTP-是什么？描述⼀下"><a href="#HTTP-是什么？描述⼀下" class="headerlink" title="HTTP 是什么？描述⼀下"></a>HTTP 是什么？描述⼀下</h2><p>HTTP 是超⽂本传输协议，也就是Hyper TextTransfer Protocol。</p><p>HTTP的名字「超⽂本协议传输」，它可以拆成三个部分：超⽂本传输，协议</p><p>​超⽂本：现在「⽂本」的涵义已经可以扩展为图⽚、视频、压缩包等，在 HTTP 眼⾥这些都算作「⽂本」。最关键有超链接，能从⼀个超⽂本跳转到另外⼀个超⽂本。HTML 就是最常⻅的超⽂本了，它本身只是纯⽂字⽂件，但内部⽤很多标签定义了图⽚、视频等的链接，再经过浏览器的解释，呈现给我们的就是⼀个⽂字、有画⾯的⽹⻚了。</p><p>​    传输：计算机世界⾥专⻔⽤来在两点之间传输数据的约定和规范，我们在上⽹冲浪时，浏览器是请求⽅ A ，百度⽹站就是应答⽅ B。双⽅约定⽤ HTTP 协议来通信，于是浏览器把请求数据发送给⽹站，⽹站再把⼀些数据返回给浏览器，最后由浏览器渲染在屏幕，就可以看到图⽚、视频了。</p><p>​    协议：计算机之间交流通信的规范（两个以上的参与者），以及相关的各种控制和错误处理⽅式（⾏为约定和规范）。数据虽然是在 A 和 B 之间传输，但允许中间有中转或接⼒。HTTP ⾥，需要中间⼈遵从 HTTP 协议，只要不打扰基本的数据传输，就可以添加任意额外的东⻄。</p><h2 id="HTTP-是⽤于从互联⽹服务器传输超⽂本到本地浏览器的协议-，这种说法正确吗？"><a href="#HTTP-是⽤于从互联⽹服务器传输超⽂本到本地浏览器的协议-，这种说法正确吗？" class="headerlink" title="HTTP 是⽤于从互联⽹服务器传输超⽂本到本地浏览器的协议 ，这种说法正确吗？"></a>HTTP 是⽤于从互联⽹服务器传输超⽂本到本地浏览器的协议 ，这种说法正确吗？</h2><p>不正确的。因为也可以是「服务器&lt; –&gt;服务器」，所以采⽤两点之间的描述会更准确</p><h2 id="HTTP-常⻅的状态码"><a href="#HTTP-常⻅的状态码" class="headerlink" title="HTTP 常⻅的状态码"></a>HTTP 常⻅的状态码</h2><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image002.gif" class="" title="img"><p><em>1xx</em></p><p>​    属于提示信息，是协议处理中的⼀种中间状态，实际⽤到的⽐较少。</p><p><em>2xx</em></p><p>​    表示服务器成功处理了客户端的请求</p><p>​    「<strong>200 OK</strong>」是最常⻅的成功状态码，表示⼀切正常。如果是⾮ HEAD 请求，服务器返回的响应头都会有 body 数据。（HEAD：HEAD和GET本质是一样的，区别在于HEAD不含有呈现数据，而仅仅是HTTP头信息。有的人可能觉得这个方法没什么用，其实不是这样的。想象一个业务情景：欲判断某个资源是否存在，我们通常使用GET，但这里用HEAD则意义更加明确。）</p><p>​    「<strong>204 No Content</strong>」也是常⻅的成功状态码，与 200 OK 基本相同，但响应头没</p><p>有 body 数据。</p><p>​    「<strong>206 Partial Content</strong>」是应⽤于 HTTP 分块下载或断点续传，表示响应返回的</p><p> body 数据并不是资源的全部，⽽是其中的⼀部分，也是服务器处理成功的状态。</p><p><em>3xx</em></p><p>​    表示客户端请求的资源发送了变动，需要客户端⽤新的 URL 重新发送请求获取资源，也就是重定向。</p><p>​    「<strong>301 Moved Permanently</strong>」表示永久重定向，说明请求的资源已经不存在了，</p><p>需改⽤新的 URL 再次访问。</p><p>​    「<strong>302 Found</strong>」表示临时重定向，说明请求的资源还在，但暂时需要⽤另⼀个 URL 来访问。301 和 302 都会在响应头⾥使⽤字段 Location ，指明后续要跳转的 URL，浏览</p><p>器会⾃动重定向新的 URL。</p><p>​    「<strong>304 Not Modified</strong>」不具有跳转的含义，表示资源未修改，重定向已存在的</p><p>缓冲⽂件，也称缓存重定向，⽤于缓存控制。</p><p><em>4xx</em></p><p>​    表示客户端发送的报⽂有误，服务器⽆法处理，也就是错误码的含义。</p><p>​    「<strong>400 Bad Request</strong>」表示客户端请求的报⽂有错误，但只是个笼统的错误。</p><p>​    「<strong>403 Forbidden</strong>」表示服务器禁⽌访问资源，并不是客户端的请求出错。</p><p>​    「<strong>404 Not Found</strong>」表示请求的资源在服务器上不存在或未找到，所以⽆法提</p><p>供给客户端。</p><p><em>5xx</em></p><p>​    表示客户端请求报⽂正确，但是服务器处理时内部发⽣了错误，属于服务器端的错</p><p>误码。</p><p>​    「<strong>500 Internal Server Error</strong>」与 400 类型，是个笼统通⽤的错误码，服务器发⽣</p><p>了什么错误，我们并不知道。</p><p>「<strong>501 Not Implemented</strong>」表示客户端请求的功能还不⽀持，类似“即将开业，敬请期待”的意思。</p><p>「<strong>502 Bad Gateway</strong>」通常是服务器作为⽹关或代理时返回的错误码，表示服务器⾃身⼯作正常，访问后端服务器发⽣了错误。</p><p>「<strong>503 Service Unavailable</strong>」表示服务器当前很忙，暂时⽆法响应服务器，类似“⽹络服务正忙，请稍后重试”的意思。</p><h2 id="http-常⻅字段有哪些"><a href="#http-常⻅字段有哪些" class="headerlink" title="http 常⻅字段有哪些"></a>http 常⻅字段有哪些</h2><ol><li><em>Host</em> 字段：客户端发送请求时，⽤来指定服务器的域名。</li></ol><p>​          Host: <a href="http://www.a.com/">www.A.com</a>    可以将请求发往「同⼀台」服务器上的不同⽹站。</p><ol start="2"><li><em>Content</em>-<em>Length</em> 字段：服务器在返回数据时，会有 Content-Length 字段，表明本次回应的数据⻓度。</li></ol><p>​      Content-Length: 1000    是告诉浏览器，本次服务器回应的数据⻓度是 1000 个字节，后⾯的字节就属于下⼀个回应了。</p><ol start="3"><li><em>Connection</em> 字段：常⽤于客户端要求服务器使⽤ TCP 持久连接，以便其他请求复⽤。</li></ol><p>​       Connection: keep-alive    持久连接，但为了兼容⽼版本的 HTTP，需要指定 Connection ⾸部字段的值为Keep-Alive 。</p><ol start="4"><li><em>Content</em>-<em>Type</em> 字段：于服务器回应时，告诉客户端，本次数据是什么格式。</li></ol><p>​       Content-Type: text&#x2F;html; charset&#x3D;utf-8上⾯的类型表明，发送的是⽹⻚，⽽且编码是UTF-8。</p><p>​          客户端请求的时候，可以使⽤ Accept 字段声明⾃⼰可以接受哪些数据格式。</p><p>​          Accept: **&#x2F;**上⾯代码中，客户端声明⾃⼰可以接受任何格式的数据。</p><ol start="5"><li><em>Content</em>-<em>Encoding</em> 字段：说明数据的压缩⽅法。表示服务器返回的数据使⽤了什么压缩格式</li></ol><p>​        Content-Encoding: gzip    服务器返回的数据采⽤了 gzip ⽅式压缩，告知客户端需要⽤此⽅式解压。</p><p>​        Accept-Encoding: gzip, deflate：说明⾃⼰可以接受哪些压缩⽅法。</p><p>​6. User Agent也简称UA。 它是一个特殊字符串头，是一种向访问网站提供你所使用的浏览器类型及版本、操作系统及版本、浏览器内核、等信息的标识。</p><h2 id="说⼀下-GET-和-POST-的区别"><a href="#说⼀下-GET-和-POST-的区别" class="headerlink" title="说⼀下 GET 和 POST 的区别"></a>说⼀下 GET 和 POST 的区别</h2><p>Get ⽅法的含义是请求从服务器获取资源，这个资源可以是静态的⽂本、⻚⾯、图⽚视频等。</p><p>POST ⽅法则是相反操作，它向 URI 指定的资源提交数据，数据就放在报⽂的 body ⾥。</p><p>功能区别：get获取数据，post提交数据</p><p>url：get携带数据，post不携带，在请求体中</p><p>url长度限制</p><p>get数据包一个，post两个</p><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image003.jpg" class="" width="0"><h2 id="GET-和-POST-⽅法都是安全和幂等的吗"><a href="#GET-和-POST-⽅法都是安全和幂等的吗" class="headerlink" title="GET 和 POST ⽅法都是安全和幂等的吗"></a>GET 和 POST ⽅法都是安全和幂等的吗</h2><p>「安全」是指请求⽅法不会「破坏」服务器上的资源。</p><p>「幂等」，意思是多次执⾏相同的操作，结果都是「相同」的。</p><p>​        <strong>GET</strong> ⽅法就是安全且幂等的，因为它是「只读」操作，⽆论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。</p><p>​        <strong>POST</strong> 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创建多个资源，所以不是幂等的。</p><h2 id="HTTP-的优点有哪些"><a href="#HTTP-的优点有哪些" class="headerlink" title="HTTP 的优点有哪些"></a>HTTP 的优点有哪些</h2><p>HTTP 最凸出的优点是「简单、灵活和易于扩展、应⽤⼴泛和跨平台」。</p><p>* 1.* 简单：HTTP 基本的报⽂格式就是 header + body ，头部信息也是 key-value 简单⽂本的形式。</p><p> <em>2.</em> 灵活和易于扩展：HTTP协议⾥的各类请求⽅法、URI&#x2F;URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发⼈员⾃定义和扩充。同时 HTTP 由于是⼯作在应⽤层（ OSI 第七层），则它下层可以随意变化。HTTPS 也就是在 HTTP 与 TCP 层之间增加了 SSL&#x2F;TLS 安全传输层，HTTP&#x2F;3 甚⾄把 TCP 层换成了基于 UDP 的QUIC。</p><p> <em>3.</em> 应⽤⼴泛和跨平台：从台式机的浏览器到⼿机上的各种 APP，同时天然具有跨平台的优越性。</p><h2 id="HTTP-的缺点有哪些"><a href="#HTTP-的缺点有哪些" class="headerlink" title="HTTP 的缺点有哪些"></a><strong>HTTP</strong> <strong>的缺点有哪些</strong></h2><p>「⽆状态、明⽂传输」「不安全」</p><p>​    <em>1.</em> ⽆状态双刃剑</p><p>​    ⽆状态的好处，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存⽤来对外提供服务。</p><p>​    ⽆状态的坏处，既然服务器没有记忆能⼒，它在完成有关联性的操作时会⾮常麻烦。例如登录-添加购物⻋-下单-结算-⽀付，这系列操作都要知道⽤户的身份才⾏。但服务器不知道这些请求是有关联的，每次都要问⼀遍身份信息。</p><p>​    解法⽅案：Cookie 通过在请求和响应报⽂中写⼊ Cookie 信息来控制客户端的状态。</p><p>​    2. 明⽂传输双刃剑</p><p>​    ⽅便阅读的，通过浏览器的 F12 控制台或 Wireshark 抓包都可以直接⾁眼查看，为调试⼯作带了极⼤的便利性。</p><p>​    信息的内容都毫⽆隐私可⾔，很容易就能被窃取，如果⾥⾯有你的账号密码信息，那你号没了。</p><p>​    3.不安全</p><p>​    通信使⽤明⽂（不加密），内容可能会被窃听。⽐如，账号信息容易泄漏，那你号没了。</p><p>​    不验证通信⽅的身份，因此有可能遭遇伪装。⽐如，访问假的淘宝、拼多多，那你钱没了。</p><p>​    ⽆法证明报⽂的完整性，所以有可能已遭篡改。⽐如，⽹⻚上植⼊垃圾⼴告，视觉污染，眼没了。</p><p>​    HTTP 的安全问题，可以⽤ HTTPS 的⽅式解决，通过引⼊ SSL&#x2F;TLS 层。</p><h2 id="HTTP-1-1-的性能如何？"><a href="#HTTP-1-1-的性能如何？" class="headerlink" title="HTTP&#x2F;1.1 的性能如何？"></a>HTTP&#x2F;1.1 的性能如何？</h2><p>HTTP 协议是基于 <strong>TCP&#x2F;IP</strong>，并且使⽤了「请求 -应答」的通信模式，所以性能的关键就在这两点⾥。</p><p>​    <em>1.</em> ⻓连接</p><p>​    早期 HTTP&#x2F;1.0 性能上的⼀个很⼤的问题，那就是每发起⼀个请求，都要新建⼀次 TCP 连接（三次握⼿），⽽且是串⾏请求，做了⽆谓的 TCP 连接建⽴和断开，增加了通信开销。</p><p>​    HTTP&#x2F;1.1 提出了⻓连接的通信⽅式，持久连接的特点是，只要任意⼀端没有明确提出断开连接，则保持 TCP 连接状态。</p><p>​    <em>2.</em> 管道⽹络传输</p><p>​    即可在同⼀个 TCP 连接⾥⾯，客户端可以发起多个请求，只要第⼀个请求发出去了，不必等其回来，就可以发第⼆个请求出去，可以减少整体的响应时间。举例来说，客户端需要请求两个资源。以前的做法是，在同⼀个TCP连接⾥⾯，先发送 A 请求，然后等待服务器做出回应，收到后再发出 B 请求。管道机制则是允许浏览器同时发出 A 请求和 B 请求。</p><p>​    3.队头阻塞        </p><p>​    但是服务器还是按照顺序，先回应 A 请求，完成后再回应 B 请求。要是前⾯的回应特别慢，后⾯就会有许多请求排队等着。这称为「队头堵塞」。</p><h1 id="HTTPS"><a href="#HTTPS" class="headerlink" title="HTTPS"></a><strong>HTTPS</strong></h1><h2 id="HTTP-与-HTTPS-有哪些区别？"><a href="#HTTP-与-HTTPS-有哪些区别？" class="headerlink" title="HTTP 与 HTTPS 有哪些区别？"></a>HTTP 与 HTTPS 有哪些区别？</h2><ol><li><p>HTTP 是超⽂本传输协议，信息是明⽂传输，存在安全⻛险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP ⽹络层之间加⼊了 SSL&#x2F;TLS 安全协议，使得报⽂能够加密传输。</p></li><li><p>HTTP 连接建⽴相对简单， TCP 三次握⼿之后便可进⾏ HTTP 的报⽂传输。⽽ HTTPS 在 TCP 三次握⼿之 后，还需进⾏ SSL&#x2F;TLS 的握⼿过程，才可进⼊加密报⽂传输。 </p></li><li><p>HTTP 的端⼝号是 80，HTTPS 的端⼝号是 443。 </p></li><li><p>HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。</p></li></ol><h2 id="HTTP和HTTPS请求的整个过程详解"><a href="#HTTP和HTTPS请求的整个过程详解" class="headerlink" title="HTTP和HTTPS请求的整个过程详解"></a>HTTP和HTTPS请求的整个过程详解</h2><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image005.jpg" class="" title="img"><p>HTTP请求的过程**</p><p>1.浏览器根据域名解析IP地址</p><p>2.浏览器与WEB服务器建立一个TCP连接</p><p>TCP的3次握手过程。</p><p>3.浏览器给WEB服务器发送一个HTTP请求</p><p>4.服务器端响应HTTP请求，浏览器得到HTML代码</p><p>5.浏览器解析HTML代码，并请求HTML代码中的资源</p><p><a href="https://blog.fundebug.com/2019/02/28/what-happens-from-url-to-webpage/">https://blog.fundebug.com/2019/02/28/what-happens-from-url-to-webpage/</a></p><p><strong>HTTPS请求的过程</strong></p><ul><li><ul><li>1.客户端向服务器发起HTTPS的请求，连接到服务器的443端口；</li><li>2.服务器将非对称加密的公钥传递给客户端，以证书的形式回传到客户端；</li><li>3.客户端接受到该公钥进行验证，如果有问题，则HTTPS请求无法继续；如果没有问题，客户端这个时  候随机生成一个私钥，称为client key,用于对称加密数据的。使用前面的公钥对client      key进行非对称加密；客户端发起二次HTTP请求，将加密之后的client key传递给服务器；</li><li>4.服务器使用私钥进行解密，得到client key,使用client key对数据进行对称加密；</li><li>5.将对称加密的数据传递给客户端，客户端使用对称解密，得到服务器发送的数据，完成第二次HTTP请求。</li></ul></li></ul><p><a href="https://blog.csdn.net/GavinBC/article/details/107001255">https://blog.csdn.net/GavinBC/article/details/107001255</a></p><h2 id="HTTPS-解决了-HTTP-的哪些问题？"><a href="#HTTPS-解决了-HTTP-的哪些问题？" class="headerlink" title="HTTPS 解决了 HTTP 的哪些问题？"></a>HTTPS 解决了 HTTP 的哪些问题？</h2><p>HTTP 由于是明⽂传输，所以安全上存在以下三个⻛险： </p><p>窃听⻛险，⽐如通信链路上可以获取通信内容，⽤户号容易没。 </p><p>篡改⻛险，⽐如强制植⼊垃圾⼴告，视觉污染，⽤户眼容易瞎。 </p><p>冒充⻛险，⽐如冒充淘宝⽹站，⽤钱容易没。</p><p>HTTP<strong>S</strong> 在 HTTP 与 TCP 层之间加⼊了 SSL&#x2F;TLS 协议，可以很好的解决了上述的⻛险： </p><p>信息加密：交互信息⽆法被窃取，但你的号会因为「⾃身忘记」账号⽽没。 </p><p>校验机制：⽆法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾⼴告。 </p><p>身份证书：证明淘宝是真的淘宝⽹，但你的钱还是会因为「剁⼿」没。</p><p>HTTPS 是如何解决上⾯的三个⻛险的？ </p><p>混合加密的⽅式实现信息的机密性，解决了窃听的⻛险。</p><p>摘要算法的⽅式来实现完整性，它能够为数据⽣成独⼀⽆⼆的「指纹」，指纹⽤于校验数据的完整性，解决了 篡改的⻛险。</p><p>将服务器公钥放⼊到数字证书中，解决了冒的⻛险。</p><p><em>1.</em> 混合加密</p><p>在通信建⽴前采⽤⾮对称加密的⽅式交换「会话秘钥」，后续就不再使⽤⾮对称加密。</p><p>在通信过程中全部使⽤对称加密的「会话秘钥」的⽅式加密明⽂数据。</p><p>采⽤「混合加密」的⽅式的原因： </p><p>对称加密只使⽤⼀个密钥，运算速度快，密钥必须保密，⽆法做到安全的密钥交换。 </p><p>⾮对称加密使⽤两个密钥：公钥和私钥，公钥可以任意分发⽽私钥保密，解决了密钥交换问题但速度。</p><p><em>2.</em> 摘要算法 </p><p>摘要算法⽤来实现完整性，能够为数据⽣成独⼀⽆⼆的「指纹」，⽤于校验数据的完整性，解决了篡改的⻛险</p><p>客户端在发送明⽂之前会通过摘要算法算出明⽂的「指纹」，发送的时候把「指纹 + 明⽂」⼀同加密成密⽂后，发送给服务器，服务器解密后，⽤相同的摘要算法算出发送过来的明⽂，通过⽐较客户端携带的「指纹」和当前算出的「指纹」做⽐较，若「指纹」相同，说明数据是完整的。</p><p><em>3.</em> 数字证书 </p><p>客户端先向服务器端索要公钥，然后⽤公钥加密信息，服务器收到密⽂后，⽤⾃⼰的私钥解密。 </p><p>这就存在些问题，如何保证公钥不被篡改和信任度？ </p><p>所以这⾥就需要借助第三⽅权威机构 CA （数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。</p><h2 id="HTTPS-是如何建⽴连接的？"><a href="#HTTPS-是如何建⽴连接的？" class="headerlink" title="HTTPS 是如何建⽴连接的？"></a>HTTPS 是如何建⽴连接的？</h2><p>SSL&#x2F;TLS 协议基本流程： </p><p>客户端向服务器索要并验证服务器的公钥。 </p><p>双⽅协商⽣产「会话秘钥」。</p><p>双⽅采⽤「会话秘钥」进⾏加密通信。</p><p>SSL&#x2F;TLS 协议建⽴的详细流程： </p><p><em>1. ClientHello</em> </p><p>⾸先，由客户端向服务器发起加密通信请求，也就是 ClientHello 请求。 在这⼀步，客户端主要向服务器发送以下信息：</p><p>（1）客户端⽀持的 SSL&#x2F;TLS 协议版本，如 TLS 1.2 版本。 </p><p>（2）客户端⽣产的随机数（ Client Random ），后⾯⽤于⽣产「会话秘钥」。 </p><p>（3）客户端⽀持的密码套件列表，如 RSA 加密算法。 </p><p><em>2. SeverHello</em> </p><p>服务器收到客户端请求后，向客户端发出响应，也就是 SeverHello 。服务器回应的内容有如下内容： </p><p>（1）确认 SSL&#x2F; TLS 协议版本，如果浏览器不⽀持，则关闭加密通信。 </p><p>（2）服务器⽣产的随机数（ Server Random ），后⾯⽤于⽣产「会话秘钥」。 </p><p>（3）确认的密码套件列表，如 RSA 加密算法。 </p><p>（4）服务器的数字证书。 </p><p>*3.*客户端回应 </p><p>客户端收到服务器的回应之后，⾸先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。</p><p>如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使⽤它加密报⽂，向服务器发送如下信息： </p><p>（1）⼀个随机数（ pre-master key ）。该随机数会被服务器公钥加密。 </p><p>（2）加密通信算法改变通知，表示随后的信息都将⽤「会话秘钥」加密通信。 </p><p>（3）客户端握⼿结束通知，表示客户端的握⼿阶段已经结束。这⼀项同时把之前所有内容的发⽣的数据做个摘 要，⽤来供服务端校验。上⾯第⼀项的随机数是整个握⼿阶段的第三个随机数，这样服务器和客户端就同时有三个随机数，接着就⽤双⽅协 商的加密算法，各⾃⽣成本次通信的「会话秘钥」。</p><p><em>4.</em> 服务器的最后回应 </p><p>服务器收到客户端的第三个随机数（ pre-master key ）之后，通过协商的加密算法，计算出本次通信的「会话秘 钥」。然后，向客户端发⽣最后的信息： </p><p>（1）加密通信算法改变通知，表示随后的信息都将⽤「会话秘钥」加密通信。 </p><p>（2）服务器握⼿结束通知，表示服务器的握⼿阶段已经结束。这⼀项同时把之前所有内容的发⽣的数据做个摘 要，⽤来供客户端校验。 </p><p>⾄此，整个 SSL&#x2F;TLS 的握⼿阶段全部结束。接下来，客户端与服务器进⼊加密通信，就完全是使⽤普通的 HTTP </p><h1 id="HTTP-1-1、HTTP-2、HTTP-3-演变"><a href="#HTTP-1-1、HTTP-2、HTTP-3-演变" class="headerlink" title="HTTP&#x2F;1.1、HTTP&#x2F;2、HTTP&#x2F;3 演变"></a><strong>HTTP&#x2F;1.1</strong>、<strong>HTTP&#x2F;2</strong>、<strong>HTTP&#x2F;3</strong> 演变</h1><h2 id="HTTP-1-1-相⽐-HTTP-1-0-提⾼了什么性能？"><a href="#HTTP-1-1-相⽐-HTTP-1-0-提⾼了什么性能？" class="headerlink" title="HTTP&#x2F;1.1 相⽐ HTTP&#x2F;1.0 提⾼了什么性能？"></a>HTTP&#x2F;1.1 相⽐ HTTP&#x2F;1.0 提⾼了什么性能？</h2><p>HTTP&#x2F;1.1 相⽐ HTTP&#x2F;1.0 性能上的改进： </p><p>使⽤ TCP ⻓连接的⽅式改善了 HTTP&#x2F;1.0 短连接造成的性能开销。 </p><p>⽀持管道（pipeline）⽹络传输，只要第⼀个请求发出去了，不必等其回来，就可以发第⼆个请求出去，可以 减少整体的响应时间。</p><p>但 HTTP&#x2F;1.1 还是有性能瓶颈： </p><p>请求 &#x2F; 响应头部（Header）未经压缩就发送，⾸部信息越多延迟越⼤。只能压缩 Body 的部分； </p><p>发送冗⻓的⾸部。每次互相发送相同的⾸部造成的浪费较多； </p><p>服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端⼀直请求不到数据，也就是队头阻塞； </p><p>没有请求优先级控制；</p><p>请求只能从客户端开始，服务器只被动响应。</p><h2 id="HTTP-2"><a href="#HTTP-2" class="headerlink" title="HTTP&#x2F;2"></a>HTTP&#x2F;2</h2><p><em>1.</em> 头部压缩HTTP&#x2F;2 会压缩头（Header）如果你同时发出多个请求，他们的头是⼀</p><p>样的或是相似的，那么，协议会帮你消除重 复的部分。 这就是所谓的 HPACK 算法：在客户端和服务器同时维护⼀张头信息表，所有字段都会存⼊这个表，⽣成⼀个索引号，以后就不发送同样字段了，只发送索引号，这样就提⾼速度了。 </p><p><em>2.</em> ⼆进制格式 </p><p>HTTP&#x2F;2 不再像 HTTP&#x2F;1.1 ⾥的纯⽂本形式的报⽂，⽽是全⾯采⽤了⼆进制格式，头信息和数据体都是⼆进制，并 且统称为帧（frame）：头信息帧和数据帧。但是对计算机⾮常友好，因为计算机只懂⼆进制，那么收到报⽂后，⽆需再将明⽂的报⽂转成⼆进制，⽽是直接解析⼆进制报⽂，这增加了数据传输效率。</p><p><em>3.</em> 数据流 </p><p>HTTP&#x2F;2 的数据包不是按顺序发送的，同⼀个连接⾥⾯连续的数据包，可能属于不同的回应。因此，必须要对数据 包做标记，指出它属于哪个回应。</p><p>每个请求或回应的所有数据包，称为⼀个数据流（ Stream ）。每个数据流都标记着⼀个独⼀⽆⼆的编号，其中规 定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数，</p><p>客户端还可以指定数据流的优先级。优先级⾼的请求，服务器就先响应该请求。</p><p><em>4.</em> 多路复⽤ </p><p>HTTP&#x2F;2 是可以在⼀个连接中并发多个请求或回应，⽽不⽤按照顺序⼀⼀对应。 </p><p>移除了 HTTP&#x2F;1.1 中的串⾏请求，不需要排队等待，也就不会再出现「队头阻塞」问题，降低了延迟，⼤幅度提⾼ 了连接的利⽤率。 </p><p>举例来说，在⼀个 TCP 连接⾥，服务器收到了客户端 A 和 B 的两个请求，如果发现 A 处理过程⾮常耗时，于是就 回应 A 请求已经处理好的部分，接着回应 B 请求，完成后，再回应 A 请求剩的部分。</p><p><em>5.</em> 服务器推送 </p><p>HTTP&#x2F;2 还在⼀定程度上改善了传统的「请求 - 应答」⼯作模式，服务不再是被动地响应，也可以主动向客户端发 送消息。 </p><p>举例来说，在浏览器刚请求 HTML 的时候，就提前把可能会⽤到的 JS、CSS ⽂件等静态资源主动发给客户端，减 少延时的等待，也就是服务器推送（Server Push，也叫 Cache Push）。 </p><h2 id="HTTP-3"><a href="#HTTP-3" class="headerlink" title="HTTP&#x2F;3"></a>HTTP&#x2F;3</h2><p>HTTP&#x2F;2 主要的问题在于，多个 HTTP 请求在复⽤⼀个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求 的。所以⼀旦发⽣了丢包现象，就会触发 TCP 的᯿传机制，这样在⼀个 TCP 连接中的所有的 <strong>HTTP</strong> 请求都必须等 待这个丢了的包被重传回来。 </p><p>HTTP&#x2F;1.1 中的管道（ pipeline）传输中如果有⼀个请求阻塞了，那么队列后请求也统统被阻塞住了 HTTP&#x2F;2 多个请求复⽤⼀个TCP连接，⼀旦发⽣丢包，就会阻塞住所有的 HTTP 请求。 </p><p>这都是基于 TCP 传输层的问题，所以 <strong>HTTP&#x2F;3</strong> 把 <strong>HTTP</strong> 下层的 <strong>TCP</strong> 协议改成了 <strong>UDP</strong>！</p><p>UDP 发⽣是不管顺序，也不管丢包的，所以不会出现 HTTP&#x2F;1.1 的队头阻塞 和 HTTP&#x2F;2 的</p><p>⼀个丢包全部重传问题。</p><p> UDP 是不可靠传输的，但基于 UDP 的 <strong>QUIC</strong> 协议 可以实现类似 TCP 的可靠性传输。 </p><p>QUIC 有⾃⼰的⼀套机制可以保证传输的可靠性的。当某个流发⽣丢包时，只会阻塞这个流，其他流不会受到 影响。 </p><p>TLS3 升级成了最新的 1.3 版本，头部压缩算法也升级成了 QPack 。 </p><p>HTTPS 要建⽴⼀个连接，要花费 6 次交互，先是建⽴三次握⼿，然后是 TLS&#x2F;1.3 的三次握⼿。QUIC 直接把 以往的 TCP 和 TLS&#x2F;1.3 的 6 次交互合并成了 <strong>3</strong> 次，减少了交互次数。</p><p>QUIC 是⼀个在 UDP 之上的伪 TCP + TLS + HTTP&#x2F;2 的多路复⽤的协议。 </p><p>QUIC 是新协议，对于很多⽹络设备，根本不知道什么是 QUIC，只会当做 UDP，这样会出现新的问题。所以HTTP&#x2F;3 现在普及的进度⾮常的缓慢，不知道未来 UDP 是否能够逆袭 TCP。</p><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image006.jpg" class="" width="0"><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image007.jpg" class="" width="0"><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image008.jpg" class="" width="0"><h1 id="TCP与UDP"><a href="#TCP与UDP" class="headerlink" title="TCP与UDP"></a>TCP与UDP</h1><h2 id="基本认识"><a href="#基本认识" class="headerlink" title="基本认识"></a>基本认识</h2><h3 id="TCP-头格式"><a href="#TCP-头格式" class="headerlink" title="TCP 头格式"></a>TCP 头格式</h3><ul><li><ol><li>序列号：在建⽴连接时由计算机⽣成的随机数作为其初始值，通过      SYN 包传给接收端主机，每发送⼀次数据，就「累加」⼀次该「数据字节数」的⼤⼩。⽤来解决⽹络包乱序问题。</li><li>确认应答号：指下⼀次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。⽤来解决不丢包的问题。</li><li>控制位：</li></ol></li><li><ul><li><em>ACK</em>：该位为      1 时，「确认应答」的字段变为有效，TCP 规定除了最初建⽴连接时的 SYN 包之外该位必须设置为 1 。</li><li><em>RST</em>：该位为      1 时，表示 TCP 连接中出现异常必须强制断开连接。</li><li><em>SYN</em>：该位为      1 时，表示希望建⽴连接，并在其「序列号」的字段进⾏序列号初始值的设定。</li><li><em>FIN</em>：该位为      1 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双⽅的主机之间就可以相互交换 FIN 位为 1 的 TCP 段。</li></ul></li></ul><h3 id="为什么需要-TCP-协议？-TCP-⼯作在哪⼀层？"><a href="#为什么需要-TCP-协议？-TCP-⼯作在哪⼀层？" class="headerlink" title="为什么需要 TCP 协议？ TCP ⼯作在哪⼀层？"></a><strong>为什么需要</strong> <strong>TCP</strong> <strong>协议？</strong> <strong>TCP</strong> <strong>⼯作在哪⼀层？</strong></h3><p>IP 层是「不可靠」的，它不保证⽹络包的交付、不保证⽹络包的按序交付、也不保证⽹络包中的数据的完整性。</p><p>如果需要保障⽹络数据包的可靠性，那么就需要由上层（传输层）的 TCP 协议来负责。</p><p>因为 TCP 是⼀个⼯作在<strong>传输层</strong>的可靠数据传输的服务，它能确保接收端接收的⽹络包是⽆损坏、⽆间隔、⾮冗余和按序的。</p><h3 id="什么是-TCP-？"><a href="#什么是-TCP-？" class="headerlink" title="什么是 TCP ？"></a><strong>什么是</strong> <strong>TCP</strong> <strong>？</strong></h3><p>TCP 是⾯向连接的、可靠的、基于字节流的传输层通信协议。</p><p>⾯向连接：⼀定是「⼀对⼀」才能连接，不能像 UDP 协议可以⼀个主机同时向多个主机发送消息，也就是⼀对多是⽆法做到的；</p><p>可靠的：⽆论的⽹络链路中出现了怎样的链路变化，TCP 都可以保证⼀个报⽂⼀定能够到达接收端；</p><p>字节流：消息是「没有边界」的，所以⽆论我们消息有多⼤都可以进⾏传输。并且消息是「有序的」，当「前⼀个」消息没有收到的时候，即使它先收到了后⾯的字节，那么也不能扔给应⽤层去处理，同时对「重复」的报⽂会⾃动丢弃。</p><h3 id="什么是-TCP-连接？"><a href="#什么是-TCP-连接？" class="headerlink" title="什么是 TCP 连接？"></a><strong>什么是</strong> <strong>TCP</strong> <strong>连接？</strong></h3><p>⽤于保证可靠性和流量控制维护的某些状态信息，这些信息的组合，包括<strong>Socket</strong>、序列号和窗⼝⼤⼩称为连接。</p><p>建⽴⼀个 TCP 连接是需要客户端与服务器端达成上述三个信息的共识。</p><p>- Socket：由 IP 地址和端⼝号组成</p><p>- 序列号：⽤来解决乱序问题等</p><p>- 窗⼝⼤⼩：⽤来做流量控制</p><h3 id="如何唯⼀确定⼀个-TCP-连接呢？"><a href="#如何唯⼀确定⼀个-TCP-连接呢？" class="headerlink" title="如何唯⼀确定⼀个 TCP 连接呢？"></a>如何唯⼀确定⼀个 TCP 连接呢？</h3><p>TCP 四元组可以唯⼀的确定⼀个连接，四元组包括如下：</p><p>- 源地址</p><p>- 源端⼝</p><p>- ⽬的地址</p><p>- ⽬的端⼝</p><p> 源地址和⽬的地址的字段（32位）是在 IP 头部中，作⽤是通过 IP 协议发送报⽂给对⽅主机。</p><p> 源端⼝和⽬的端⼝的字段（16位）是在 TCP 头部中，作⽤是告诉 TCP 协议应该把报⽂发给哪个进程。</p><h3 id="有⼀个-IP-的服务器监听了⼀个端⼝，它的-TCP-的最⼤连接数是多少？"><a href="#有⼀个-IP-的服务器监听了⼀个端⼝，它的-TCP-的最⼤连接数是多少？" class="headerlink" title="有⼀个 IP 的服务器监听了⼀个端⼝，它的 TCP 的最⼤连接数是多少？"></a>有⼀个 IP 的服务器监听了⼀个端⼝，它的 TCP 的最⼤连接数是多少？</h3><p>服务器通常固定在某个本地端⼝上监听，等待客户端的连接请求。</p><p>因此，客户端 IP 和 端⼝是可变的，其理论值计算公式如下: </p><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image010.gif" class="" title="img"><p>对 IPv4，客户端的 IP 数最多为 2 的 32 次⽅，客户端的端⼝数最多为 2 的 16 次⽅，也就是服务端单机最⼤TCP 连接数，约为 2 的 48 次⽅。</p><p>当然，服务端最⼤并发 TCP 连接数远不能达到理论上限。</p><p>- ⾸先主要是⽂件描述符限制，Socket 都是⽂件，所以⾸先要通过 ulimit 配置⽂件描述符的数⽬；</p><p>- 另⼀个是内存限制，每个 TCP 连接都要占⽤⼀定内存，操作系统的内存是有限的。</p><h3 id="UDP-和-TCP-有什么区别呢？"><a href="#UDP-和-TCP-有什么区别呢？" class="headerlink" title="UDP 和 TCP 有什么区别呢？"></a><strong>UDP</strong> <strong>和</strong> <strong>TCP</strong> <strong>有什么区别呢？</strong></h3><p>UDP概念</p><p>UDP 不提供复杂的控制机制，利⽤ IP 提供⾯向「⽆连接」的通信服务。</p><p>UDP 协议真的⾮常简单，头部只有 8 个字节（ 64 位），UDP 的头部格式如下：</p><p>- ⽬标和源端⼝：主要是告诉 UDP 协议应该把报⽂发给哪个进程。</p><p>- 包⻓度：该字段保存了 UDP ⾸部的⻓度跟数据的⻓度之和。</p><p>- 校验和：校验和是为了提供可靠的 UDP ⾸部和数据⽽设计。</p><p>TCP和 UDP 区别：</p><p><em>1.</em> 连接</p><p>TCP 是⾯向连接的传输层协议，传输数据前先要建⽴连接。</p><p>UDP 是不需要连接，即刻传输数据。</p><p><em>2.</em> 服务对象</p><p>TCP 是⼀对⼀的两点服务，即⼀条连接只有两个端点。</p><p>UDP ⽀持⼀对⼀、⼀对多、多对多的交互通信</p><p><em>3.</em> 可靠性</p><p>TCP 是可靠交付数据的，数据可以⽆差错、不丢失、不重复、按需到达。</p><p>UDP 是尽最⼤努⼒交付，不保证可靠交付数据。</p><p><em>4.</em> 拥塞控制、流量控制</p><p>TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。</p><p>UDP 则没有，即使⽹络⾮常拥堵了，也不会影响 UDP 的发送速率。</p><p><em>5.</em> ⾸部开销</p><p>TCP ⾸部⻓度较⻓，会有⼀定的开销，⾸部在没有使⽤「选项」字段时是 20 个字节，如果使⽤了「选项」字段则会变⻓的。</p><p>UDP ⾸部只有 8 个字节，并且是固定不变的，开销较⼩。</p><p><em>6.</em> 传输⽅式</p><p>TCP 是流式传输，没有边界，但保证顺序和可靠。</p><p>UDP 是⼀个包⼀个包的发送，是有边界的，但可能会丢包和乱序。</p><p><em>7.</em> 分⽚不同</p><p>TCP 的数据⼤⼩如果⼤于 MSS ⼤⼩，则会在传输层进⾏分⽚，⽬标主机收到后，也同样在传输层组装 TCP数据包，如果中途丢失了⼀个分⽚，只需要传输丢失的这个分⽚。</p><p>UDP 的数据⼤⼩如果⼤于 MTU ⼤⼩，则会在 IP 层进⾏分⽚，⽬标主机收到后，在 IP 层组装完数据，接着再传给传输层，但是如果中途丢了⼀个分⽚，在实现可靠传输的 UDP 时则</p><p>就需要重传所有的数据包，这样传输效率⾮常差，所以通常 UDP 的报⽂应该⼩于 MTU。</p><h3 id="TCP-和-UDP-应⽤场景："><a href="#TCP-和-UDP-应⽤场景：" class="headerlink" title="TCP 和 UDP 应⽤场景："></a>TCP 和 UDP 应⽤场景：</h3><p>由于 TCP 是⾯向连接，能保证数据的可靠性交付，因此经常⽤于：</p><p>- FTP ⽂件传输</p><p>- HTTP &#x2F; HTTPS</p><p>由于 UDP ⾯向⽆连接，它可以随时发送数据，再加上UDP本身的处理既简单⼜⾼效，因此经常⽤于：</p><p>- 包总量较少的通信，如 DNS 、 SNMP 等</p><p>- 视频、⾳频等多媒体通信</p><p>- ⼴播通信</p><h3 id="为什么-UDP-头部没有「⾸部⻓度」字段，⽽-TCP-头部有「⾸部⻓度」字段呢"><a href="#为什么-UDP-头部没有「⾸部⻓度」字段，⽽-TCP-头部有「⾸部⻓度」字段呢" class="headerlink" title="为什么 UDP 头部没有「⾸部⻓度」字段，⽽ TCP 头部有「⾸部⻓度」字段呢?"></a>为什么 UDP 头部没有「⾸部⻓度」字段，⽽ TCP 头部有「⾸部⻓度」字段呢?</h3><p> TCP 有可变⻓的「选项」字段，⽽ UDP 头部⻓度则是不会变化的，⽆需多⼀个字段去记录</p><p> UDP 的⾸部⻓度。</p><h3 id="为什么-UDP-头部有「包⻓度」字段，⽽-TCP-头部则没有「包⻓度」字段呢？"><a href="#为什么-UDP-头部有「包⻓度」字段，⽽-TCP-头部则没有「包⻓度」字段呢？" class="headerlink" title="为什么 UDP 头部有「包⻓度」字段，⽽ TCP 头部则没有「包⻓度」字段呢？"></a>为什么 UDP 头部有「包⻓度」字段，⽽ TCP 头部则没有「包⻓度」字段呢？</h3><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image012.gif" class="" title="img"><p>其中 IP 总⻓度 和 IP ⾸部⻓度，在 IP ⾸部格式是已知的。TCP ⾸部⻓度，则是在 TCP ⾸部格式已知的，所以就可以求得 TCP 数据的⻓度。</p><p> UDP 也是基于 IP 层的呀，那 UDP 的数据⻓度也可以通过这个公式计算呀，为何还要有</p><p>「包⻓度」呢？”这么⼀问，确实感觉 UDP 「包⻓度」是冗余的。</p><p>因为为了⽹络设备硬件设计和处理⽅便，⾸部⻓度需要是 44 字节的整数倍。</p><p>如果去掉 UDP 「包⻓度」字段，那 UDP ⾸部⻓度就不是 4 字节的整数倍了，所以⼩林觉得这可能是为了补全</p><p>UDP ⾸部⻓度是 4 字节的整数倍，才补充了「包⻓度」字段。</p><h2 id="TCP-连接建⽴"><a href="#TCP-连接建⽴" class="headerlink" title="TCP 连接建⽴"></a>TCP 连接建⽴</h2><h3 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h3><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image014.gif" class="" title="img"><p>- ⼀开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端⼝，处于 LISTEN 状态</p><p>- 客户端会随机初始化序号（ client_isn ），将此序号置于 TCP ⾸部的「序号」字段中，同时把 SYN 标志位置为 1 ，表示 SYN 报⽂。接着把第⼀个 SYN 报⽂发送给服务端，表示向服务端发起连接，该报⽂不包含应⽤层数据，之后客户端处于 SYN-SENT 状态。</p><p>- 服务端收到客户端的 SYN 报⽂后，⾸先服务端也随机初始化⾃⼰的序号（ server_isn ），将此序号填⼊TCP ⾸部的「序号」字段中，其次把 TCP ⾸部的「确认应答号」字段填⼊ client_isn + 1 , 接着把 SYN 和ACK 标志位置为 1 。最后把该报⽂发给客户端，该报⽂也不包含应⽤层数据，之后服务端处于 SYN-RCVD状态。</p><p>- 客户端收到服务端报⽂后，还要向服务端回应最后⼀个应答报⽂，⾸先该应答报⽂ TCP ⾸部 ACK 标志位置为1 ，其次「确认应答号」字段填⼊ server_isn + 1 ，最后把报⽂发送给服务端，这次报⽂可以携带客户到服务器的数据，之后客户端处于 ESTABLISHED 状态。</p><p>- 服务器收到客户端的应答报⽂后，也进⼊ ESTABLISHED 状态。</p><p>第三次握⼿是可以携带数据的，前两次握⼿是不可以携带数据的，这也是⾯试常问的题</p><p><a href="https://zhuanlan.zhihu.com/p/53374516">https://zhuanlan.zhihu.com/p/53374516</a></p><h3 id="为什么是三次握⼿？不是两次、四次？"><a href="#为什么是三次握⼿？不是两次、四次？" class="headerlink" title="为什么是三次握⼿？不是两次、四次？"></a>为什么是三次握⼿？不是两次、四次？</h3><p>- 三次握⼿才可以阻⽌重复历史连接的初始化（主要原因）</p><p>- 三次握⼿才可以同步双⽅的初始序列号</p><p>- 三次握⼿才可以避免资源浪费</p><ol><li>阻⽌重复历史连接</li></ol><p>客户端连续发送多次 SYN 建⽴连接的报⽂，在⽹络拥堵情况下：⼀个「旧 SYN 报⽂」⽐「最新的 SYN 」 报⽂早到达了服务端；那么此时服务端就会回⼀个 SYN + ACK 报⽂给客户端；客户端收到后可以根据⾃身的上下⽂，判断这是⼀个历史连接（序列号过期或超时），那么客户端就会发送RST 报⽂给服务端，表示中⽌这⼀次连接。</p><p>如果是两次握⼿连接，就不能判断当前连接是否是历史连接，三次握⼿则可以在客户端（发送⽅）准备发送第三次报⽂时，客户端因有⾜够的上下⽂来判断当前连接是否是历史连接：</p><p>如果是历史连接（序列号过期或超时），则第三次握⼿发送的报⽂是 RST 报⽂，以此中⽌历史连接；如果不是历史连接，则第三次发送的报⽂是 ACK 报⽂，通信双⽅就会成功建⽴连接；</p><ol start="2"><li>同步双⽅的初始序列号</li></ol><p>TCP 协议的通信双⽅， 都必须维护⼀个「序列号」， 序列号是可靠传输的⼀个关键因素，它的作⽤：</p><p>- 接收⽅可以去除重复的数据；</p><p>- 接收⽅可以根据数据包的序列号按序接收；</p><p>- 可以标识发送出去的数据包中， 哪些是已经被对⽅收到的；</p><p>四次握⼿其实也能够可靠的同步双⽅的初始化序号，但由于第⼆步和第三步可以优化成⼀</p><p>步，所以就成了「三次握⼿」。⽽两次握⼿只保证了⼀⽅的初始序列号能被对⽅成功接收，没办法保证双⽅的初始序列号都能被确认接收。</p><ol start="3"><li>三次握⼿才可以避免资源浪费</li></ol><p>如果客户端的 SYN 阻塞了，重复发送多次 SYN 报⽂，那么服务器在收到请求后就会建⽴多个冗余的⽆效链接，造成不必要的资源浪费。</p><h3 id="3次握手序列号的作用"><a href="#3次握手序列号的作用" class="headerlink" title="3次握手序列号的作用"></a>3次握手序列号的作用</h3><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image015.jpg" class="" width="0"><h2 id="TCP-连接断开"><a href="#TCP-连接断开" class="headerlink" title="TCP 连接断开"></a><strong>TCP</strong> <strong>连接断开</strong></h2><h3 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h3><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image017.gif" class="" title="img"><p>- 客户端打算关闭连接，此时会发送⼀个 TCP ⾸部 FIN 标志位被置为 1 的报⽂，也即 FIN 报⽂，之后客户端进⼊ FIN_WAIT_1 状态。</p><p>- 服务端收到该报⽂后，就向客户端发送 ACK 应答报⽂，接着服务端进⼊ CLOSED_WAIT 状态。</p><p>- 客户端收到服务端的 ACK 应答报⽂后，之后进⼊ FIN_WAIT_2 状态。</p><p>- 等待服务端处理完数据后，也向客户端发送 FIN 报⽂，之后服务端进⼊ LAST_ACK 状态。</p><p>- 客户端收到服务端的 FIN 报⽂后，回⼀个 ACK 应答报⽂，之后进⼊ TIME_WAIT 状态</p><p>- 服务器收到了 ACK 应答报⽂后，就进⼊了 CLOSED 状态，⾄此服务端已经完成连接的关闭。</p><p>- 客户端在经过 2MSL ⼀段时间后，⾃动进⼊ CLOSED 状态，⾄此客户端也完成连接的关闭。</p><p>主动关闭连接的，才有 <strong>TIME_WAIT</strong> 状态。</p><h3 id="为什么挥⼿需要四次？"><a href="#为什么挥⼿需要四次？" class="headerlink" title="为什么挥⼿需要四次？"></a>为什么挥⼿需要四次？</h3><p>- 关闭连接时，客户端向服务端发送 FIN 时，仅仅表示客户端不再发送数据了但是还能接收数据。</p><p>- 服务器收到客户端的 FIN 报⽂时，先回⼀个 ACK 应答报⽂，⽽服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报⽂给客户端来表示同意现在关闭连接。</p><p>服务端通常需要等待完成数据的发送和处理，所以服务端的 ACK 和 FIN ⼀般都会分开发送，从⽽⽐三次握⼿导致多了⼀次。</p><h3 id="为什么-TIME-WAIT-等待的时间是-2MSL？"><a href="#为什么-TIME-WAIT-等待的时间是-2MSL？" class="headerlink" title="为什么 TIME_WAIT 等待的时间是 2MSL？"></a><strong>为什么</strong> <strong>TIME_WAIT</strong> <strong>等待的时间是</strong> <strong>2MSL？</strong></h3><p>MSL 是 Maximum Segment Lifetime，报⽂最⼤⽣存时间，它是任何报⽂在⽹络上存在的最⻓时间，超过这个时间报⽂将被丢弃。</p><p>TIME_WAIT 等待 2 倍的 MSL，⽐较合理的解释是： ⽹络中可能存在来⾃发送⽅的数据包，当这些发送⽅的数据包，被接收⽅处理后⼜会向对⽅发送响应，所以⼀来⼀回需要等待 <strong>2</strong> 倍的时间。</p><p>如果被动关闭⽅没有收到断开连接的最后的 ACK 报⽂，就会触发超时重发 Fin 报⽂，另⼀⽅接收到 FIN 后，会重发 ACK 给被动关闭⽅， ⼀来⼀去正好 2 个 MSL。</p><p>2MSL 的时间是从客户端接收到 <strong>FIN</strong> 后发送 <strong>ACK</strong> 开始计时的。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端⼜接收到了服务端重发的 FIN 报⽂，那么 <strong>2MSL</strong> 时间将重新计时。</p><h3 id="为什么需要-TIME-WAIT-状态？"><a href="#为什么需要-TIME-WAIT-状态？" class="headerlink" title="为什么需要 TIME_WAIT 状态？"></a><strong>为什么需要</strong> <strong>TIME_WAIT</strong> <strong>状态？</strong></h3><p>- 防⽌具有相同「四元组」的「旧」数据包被收到；</p><p>- 保证「被动关闭连接」的⼀⽅能被正确的关闭，即保证最后的 ACK 能让被动关闭⽅接收，从⽽帮助其正常关闭；</p><p> 防止旧数据包引起错乱：</p><p> 假设 TIME_WAIT 没有等待时间或时间过短,服务端在关闭连接之前发送的 SEQ &#x3D; 301 报⽂，被⽹络延迟了。这时有相同端⼝的 TCP 连接被复⽤后，被延迟的 SEQ &#x3D; 301 抵达了客户端，那么客户端是有可能正常接收这个过期的报⽂，这就会产⽣数据错乱等严乱的问题。</p><p> TCP 就设计出了这么⼀个机制，经过 2MSL 这个时间，⾜以让两个⽅向上的数据包都被丢弃，使得原来连接的数据包在⽹络中都⾃然消失，再出现的数据包⼀定都是新建⽴连接所产⽣的。</p><p> 保证连接正确关闭：</p><p> TIME-WAIT 作⽤是等待⾜够的时间以确保最后的 <strong>ACK</strong> 能让被动关闭⽅接收，从⽽帮助其正常关闭。</p><p> 客户端四次挥⼿的最后⼀个 ACK 报⽂如果在⽹络中被丢失了，此时如果客户端 TIME-</p><p> WAIT过短或没有，则就直接进⼊了 CLOSED 状态了，那么服务端则会⼀直处在 LASE_ACK 状态。当客户端发起建⽴连接的 SYN 请求报⽂后，服务端会发送 RST 报⽂给客户端，连接建⽴的过程就会被终⽌。</p><h2 id="TCP-如何保证可靠性传输"><a href="#TCP-如何保证可靠性传输" class="headerlink" title="TCP 如何保证可靠性传输"></a><strong>TCP</strong> <strong>如何保证可靠性传输</strong></h2><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image019.jpg" class="" title="iii"><h2 id="发送窗口的作用"><a href="#发送窗口的作用" class="headerlink" title="发送窗口的作用"></a>发送窗口的作用</h2><p>可靠传输，流量控制</p><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image020.jpg" class="" title="img"><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image021.jpg" class="" title="img"><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image022.jpg" class="" title="img"><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image023.jpg" class="" title="img"><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image024.jpg" class="" title="img"><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image025.jpg" class="" title="img"><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image026.jpg" class="" title="img"><p><a href="https://www.cnblogs.com/lisuyun/articles/5803583.html">https://www.cnblogs.com/lisuyun/articles/5803583.html</a></p><h2 id="TCP的流量控制"><a href="#TCP的流量控制" class="headerlink" title="TCP的流量控制"></a><strong>TCP的流量控制</strong></h2><p>所谓流量控制就是让发送方的发送速率不要太快，让接收方来得及接收。因为如果发送方把数据发送得过快，接收方可能会来不及接收，这就会造成数据的丢失。TCP的流量控制是通过大小可变的滑动窗口来实现的。接收端将自己可以接收的缓冲区大小放入TCP首部中的“窗口大小”字段，通过ACK报文来通知发送端，滑动窗口是接收端用来控制发送端发送数据的大小，从而达到流量控制。</p><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image028.jpg" class="" title="iii"><p>设A向B发送数据。在连接建立时，B告诉了A：“我的接收窗口是 rwnd &#x3D; 400 ”(这里的 rwnd 表示 receiver window) 。因此，发送方的发送窗口不能超过接收方给出的接收窗口的数值。假设每一个报文段为100字节长，而数据报文段序号的初始值设为1。</p><p><img src="file:///C:/Users/zhiyo/AppData/Local/Temp/msohtmlclip1/01/clip_image030.jpg" alt="iii "></p><p>从图中可以看出，B进行了三次流量控制。第一次把窗口减少到 rwnd &#x3D; 300 ，第二次又减到了 rwnd &#x3D; 100 ，最后减到 rwnd &#x3D; 0 ，即不允许发送方再发送数据了。这种使发送方暂停发送的状态将持续到主机B重新发出一个新的窗口值为止。B向A发送的三个报文段都设置了 ACK &#x3D; 1 ，只有在 ACK&#x3D;1 时确认号字段才有意义。</p><h2 id="TCP的拥塞控制"><a href="#TCP的拥塞控制" class="headerlink" title="TCP的拥塞控制"></a><strong>TCP的拥塞控制</strong></h2><p><strong>TCP的拥塞控制：</strong></p><p>拥塞控制就是防止过多的数据注入网络中，使网络中的路由器或链路不致过载。发送方维持一个拥塞窗口cwnd 的状态变量。拥塞窗口的大小动态变化，取决于网络的拥塞程度，发送方让自己的发送窗口等于拥塞窗口。只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。 拥塞控制的方法主要有以下几种：慢启动、拥塞避免、快重传和快恢复。</p><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image032.jpg" class="" title="ii"><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image034.jpg" class="" title="iii"><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image036.jpg" class="" title="iii"><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image038.jpg" class="" title="iii"><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image040.jpg" class="" title="发 送 万  发 送 M 》  发 送 M2  发 送 M)  发 送 M" alt="发 送 Ms  收 到 三 个 连 续 的 发 送 M6  对 M2 的 重 复 确 认 送 Ml  立 即 重 传 Ms  t  接 收 方  确 认 Ml  确 认 M:  重 复 确 认 M2  重 复 确 认 Ma  重 复 确 认 M2  立 即 重 传 M  t"><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image042.jpg" class="" title="接 收 方 收 到 了 Ml 和 M2 后 都 分 别 发 出 了 确 认 。 现 在 假 定 接 收 方 没 有 收 到 M3 但 接 看 收 到 了 M4 。 显 然 ， 接 收 方 不 能 确 认 M4 ， 因 为 M4 是  收 到 的 失 序 报 文 段 。 根 据 可 靠 传 输 原 理 ， 接 收 方 可 以 什 么 都 不 做 ， 也 可 以 在 适 当 时 机 发 送 一 次 对 M2 的 确 认 。 但 按 照 快 重 传 篡 法 的 规  定 ， 接 收 方 应 及 时 发 送 对 M2 的 重 复 确 认 ， 汶 样 做 可 以 让 发 送 方 及 早 知 道 报 文 段 M3 没 有 到 达 接 收 方 。 发 送 方 接 看 发 送 了 M5 和 M6 。  接 收 方 收 到 汶 两 个 报 文 后 ， 也 还 要 再 次 发 出 对 M2 的 重 复 确 认 。 汶 样 ， 发 送 方 共 收 到 了 接 收 方 的 雪 个 对 M2 的 确 认 ， 其 中 后 三 个 都 是  重 复 确 认 。"><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image044.jpg" class="" title="（ 4 ） 快 恢 复 ： 与 快 重 传 配 台 便 用 的 还 有 快 预 复 法 当 发 送 方 连 续 收 到 三 个 复 确 认 时 ， 就 执 行 。 词 去 减 少 篡 法 ， *Essthresh 门 限设舀 为 塞 窗 口 cwnd 的 一 半 ， 但 是 接 下 去 并 不 执 行 开 始 法 而 是 为 ssthreshB5 大 小 ， 然 后 执 行 裤 塞 避 免 法 ： 因 为 如 果 网 纟 各 出 现 塞 的 话 ， 就 不 会 收 到 好 几 个 复 的 确 认 ， 所 以 发 送 方 现 在 认 为 网 络 可 能 没 有 出 现 塞 ， 所 以 此 时 并 不 执 行 开 始 法 而 是 执 行 塞 避 免 法 。 %}{% asset_img clip_image046.jpg&quot; iii"><p><strong>4、拥塞控制和流量控制的差别：</strong></p><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image048.jpg" class="" title="（ 1 ） 相 同 点 ． 塞 控 制 和 流 畢 控 制 的 相 同 点 都 是 控 制 丢 包 现 象 ， 实 现 机 制 都 是 让 发 送 方 发 得 一 点 。  （ 2 ） 不 同 点  @ 裤 塞 控 制 是 一 个 全 局 性 的 过 程 ， 防 到 寸 多 的 数 据 氵 三 到 络 中 ， 造 成 络 裤 塞  2 流 量 控 制 指 点 对 点 信 量 的 控 制 ， 要 做 的 就 是 控 制 发 送 端 发 送 数 据 的 涑 率 ， 以 便 便 接 收 揣 来 得 及 接 受 。"><h2 id="拥塞控制和流量控制的差别"><a href="#拥塞控制和流量控制的差别" class="headerlink" title="拥塞控制和流量控制的差别"></a><strong>拥塞控制和流量控制的差别</strong></h2><p><strong>拥塞控制和流量控制的差别：</strong></p><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image048.jpg" class="" title="（ 1 ） 相 同 点 ． 塞 控 制 和 流 畢 控 制 的 相 同 点 都 是 控 制 丢 包 现 象 ， 实 现 机 制 都 是 让 发 送 方 发 得 一 点 。  （ 2 ） 不 同 点  @ 裤 塞 控 制 是 一 个 全 局 性 的 过 程 ， 防 到 寸 多 的 数 据 氵 三 到 络 中 ， 造 成 络 裤 塞  2 流 量 控 制 指 点 对 点 信 量 的 控 制 ， 要 做 的 就 是 控 制 发 送 端 发 送 数 据 的 涑 率 ， 以 便 便 接 收 揣 来 得 及 接 受 。"><h2 id="半连接和全连接队列"><a href="#半连接和全连接队列" class="headerlink" title="半连接和全连接队列"></a>半连接和全连接队列</h2><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image050.jpg" class="" width="0"><p>半连接队列 max_qlen_log 的最⼤值为 256：</p><h2 id="SYN洪泛"><a href="#SYN洪泛" class="headerlink" title="SYN洪泛"></a>SYN洪泛</h2><p>SYN 洪泛是指利用 TCP 需要三次握手的特性，攻击者伪造 SYN 报文向服务器发起连接，服务器在收到报文后用 ACK 应答，但之后攻击者不再对该响应进行应答，造成一个半连接。假设攻击者发送大量这样的报文，那么被攻击主机就会造成大量的半连接，耗尽其资源，导致正常的 SYN 请求因为队列满而被丢弃，使得正常用户无法访问。</p><p>如何防御 SYN 攻击？ </p><p>这⾥给出⼏种防御 SYN 攻击的⽅法：增⼤半连接队列；</p><p>开启 tcp_syncookies 功能 </p><p>减少 SYN+ACK 重传次数</p><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image051.jpg" class="" width="0"><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image052.jpg" class="" width="0"><h2 id="TCP的粘包和拆包"><a href="#TCP的粘包和拆包" class="headerlink" title="TCP的粘包和拆包"></a>TCP的粘包和拆包</h2><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image054.jpg" class="" title="解 决 粘 包 和 拆 包 的 方 法 主 要 有  （ 1 ） 在 数 据 尾 部 增 加 特 殊 字 符 进 行 分 割 ；  （ 2 ） 将 数 庭 定 为 固 定 大 小 ；  （ 3 ） 将 数 庭 分 为 两 部 分 ， 一 部 分 是 头 部 ， 一 部 分 是 内 容 体 ； 其 中 头 部 结 构 大 小 固 定 ， 且 有 一 个 段 声 明 内 容 体 的 大 小"><h1 id="cookie和session的区别"><a href="#cookie和session的区别" class="headerlink" title="cookie和session的区别"></a>cookie和session的区别</h1><ol><li>session 在服务器端，cookie 在客户端（浏览器）</li><li>cookie不是很安全</li><li>单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。(Session对象没有对存储的数据量的限制，其中可以保存更为复杂的数据类型)</li><li>session 可以放在 文件、数据库、或内存中都可以。</li><li>session 的运行依赖 session id，而     session id 是存在 cookie 中的，也就是说，如果浏览器禁用了 cookie ，同时 session 也会失效（但是可以通过其它方式实现，比如在 url 中传递 session_id） </li><li>用户验证这种场合一般会用 session</li></ol><p><a href="https://note.youdao.com/web/#/file/WEBdf61c6d9c265f941ef73b769d6b154e1/note/WEB0b3584b248ac60abe3a432744701e3f1/">https://note.youdao.com/web/#/file/WEBdf61c6d9c265f941ef73b769d6b154e1/note/WEB0b3584b248ac60abe3a432744701e3f1/</a></p><h1 id="DNS域名解析过程"><a href="#DNS域名解析过程" class="headerlink" title="DNS域名解析过程"></a>DNS域名解析过程</h1><p>缓存 本地的hosts文件 本地DNS解析器缓存 本地DNS服务器 根据设置的转发器</p><p><strong>DNS解析过程：</strong></p><p>场景：用户在浏览器输入网址：clondant.blog.51cto.com，其解析过程如下：</p><p><strong>第1步：</strong>浏览器将会检查缓存中有没有这个域名对应的解析过的IP地址，如果有该解析过程将会结束。</p><p><strong>第2步：</strong>如果用户的浏览器中缓存中没有，操作系统会先检查自己本地的hosts文件是否有这个网址映射关系，如果有，就先调用这个IP地址映射关系，完成域名解析。</p><p><strong>第3步：</strong>如果hosts里没有这个域名的映射，则查找本地DNS解析器缓存，是否有这个网址映射关系或缓存信息，如果有，直接返回给浏览器，完成域名解析。</p><p><strong>第4步：</strong>如果hosts与本地DNS解析器缓存都没有相应的网址映射关系，则会首先找本地DNS服务器，一般是公司内部的DNS服务器，此服务器收到查询，如果此本地DNS服务器查询到相对应的IP地址映射或者缓存信息，则返回解析结果给客户机，完成域名解析，此解析具有权威性。</p><p><strong>第5步：</strong>如果本地DNS服务器无法查询到，则根据本地DNS服务器设置的转发器进行查询；</p><p><strong>未用转发模式：</strong>本地DNS就把请求发至根DNS进行<strong>（迭代）查询</strong>，根DNS服务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的一个IP。本地DNS服务器收 到IP信息后，将会联系负责.com域的这台服务器。这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com域的下一级 DNS服务器地址给本地DNS服务器。当本地DNS服务器收到这个地址后，就会找域名域服务器，重复上面的动作，进行查询，直至找到域名对应的主机。</p><p><strong>使用转发模式：</strong>此DNS服务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至 上上级，以此循环。不管是本地DNS服务器用是是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。</p><p>搭建基本的DNS服务</p><p><a href="https://www.huaweicloud.com/articles/a05aa2b2e729535533c20925cabb07b4.html">https://www.huaweicloud.com/articles/a05aa2b2e729535533c20925cabb07b4.html</a></p><h1 id="ARQ协议"><a href="#ARQ协议" class="headerlink" title="ARQ协议"></a><strong>ARQ协议</strong></h1><p><strong>ARQ协议:</strong></p><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image056.jpg" class="" title="自 动 重 传 请 求 MutomaticRepeat-reQuest ARQ) 是 O 引 模 型 中 数 据 链 路 层 和 传 输 层 的 错 误 纠  正 协 议 之 一 。 它 通 过 使 用 确 认 和 超 时 这 两 个 机 制 ， 在 不 可 靠 服 务 的 基 础 上 实 现 可 靠 的 信 息 传 输 。  如 果 发 送 方 在 发 送 后 一 段 时 间 之 内 没 有 收 到 确 认 帧 ， 它 通 常 会 重 新 发 送 。 ARQ 包 括 停 止 等 待 ARQ  协 议 和 连 续 ARQ 协 议 。"><h1 id="一些专业词汇"><a href="#一些专业词汇" class="headerlink" title="一些专业词汇"></a>一些专业词汇</h1><p> MSS</p><p>最大报文段长度是TCP协议的一个选项，用于在TCP连接建立时，收发双方协商通信时每一个报文段所能承载的最大数据长度</p><p>MTU</p><p><em>mtu</em>一般指最大传输单元。最大传输单元（Maximum Transmission Unit，<em>MTU</em>）用来通知对方所能接受数据服务单元的最大尺寸，说明发送方能够接受的有效载荷大小</p><p>MSL </p><p>是 Maximum Segment Lifetime，报⽂最⼤⽣存时间，</p><p>SYN：同步序列编号（Synchronize Sequence Numbers）。是TCP&#x2F;IP建立连接时使用的握手信号。</p><p>ACK (Acknowledge character）即是确认字符，在数据通信中，接收站发给发送站的一种传输类<a href="https://baike.baidu.com/item/%E6%8E%A7%E5%88%B6%E5%AD%97%E7%AC%A6/6913704">控制字符</a>。表示发来的数据已确认接收无误</p><p>FIFO先进先出队列</p><p>线程挂起的方法,就是park,对应唤醒就是unpark。</p><p>OSPF(Open Shortest Path First开放式最短路径优先）是一个内部网关协议(Interior Gateway Protocol）</p><p>SSL 的英文全称是 “Secure Sockets Layer” ，中文名为 “ 安全套接层协议层 </p><p>安全传输层协议（TLS）用于在两个通信应用程序之间提供保密性和数据完整性。</p><h1 id="非对称加密的应用"><a href="#非对称加密的应用" class="headerlink" title="非对称加密的应用"></a>非对称加密的应用</h1><p>1用于身份认证</p><p>一条加密信息若能用A 的公钥能解开，则该信息一定是用A 的私钥加密的，该能确定该用户是A。</p><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image058.gif" class="" width="0"><p>2用于陌生人通信</p><p>A 和B 两个人互不认识，A 把自己的公钥发给B，B 也把自己的公钥发给A，则双方可以通过对方的公钥加密信息通信。C 虽然也能得到A、B 的公钥，但是他解不开密文。</p><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image060.gif" class="" width="0"><p>3用于敏感的秘钥交换场景下</p><p>A 先得到B 的公钥，然后A 生成一个随机秘钥，例如13245768，之后A 用B 的公钥加密该秘钥，得到加密后的秘钥，例如dxs#fd@dk，之后将该密文发给B，B 用自己的私钥解密得到123456，之后双方使用13245768 作为对称加密的秘钥通信。C 就算截获加密后的秘钥dxs#fd@dk，自己也解不开，这样A、B 二人能通过对称加密进行通信。</p><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image062.gif" class="" width="0"><p><strong>本文小结</strong></p><p>非对称加密一般不会单独拿来使用，他并不是为了取代对称加密而出现的，非对称加密速度比对称加密慢很多，极端情况下会慢1000 倍，所以一般不会用来加密大量数据，通常我们经常会将对称加密和非对称加密两种技术联合起来使用，例如用非对称加密来给称加密里的秘钥进行加密（即秘钥交换）。</p><h1 id="跨域"><a href="#跨域" class="headerlink" title="跨域"></a>跨域</h1><img src="/2024/04/06/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/clip_image064.jpg" class="" title="img">]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> 计算机网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mybatis</title>
      <link href="/2024/04/06/Mybatis/"/>
      <url>/2024/04/06/Mybatis/</url>
      
        <content type="html"><![CDATA[<h1 id="Mybatis的优缺点"><a href="#Mybatis的优缺点" class="headerlink" title="Mybatis的优缺点"></a>Mybatis的优缺点</h1><img src="/2024/04/06/Mybatis/clip_image002.jpg" class="" title="img"><h1 id="Mybatis和Hibernate有哪些不同"><a href="#Mybatis和Hibernate有哪些不同" class="headerlink" title="Mybatis和Hibernate有哪些不同"></a>Mybatis和Hibernate有哪些不同</h1><img src="/2024/04/06/Mybatis/clip_image003.jpg" class="" title="img"><img src="/2024/04/06/Mybatis/clip_image004.jpg" class="" title="img"><img src="/2024/04/06/Mybatis/clip_image005.jpg" class="" title="img"><img src="/2024/04/06/Mybatis/clip_image006.jpg" class="" title="img"><h1 id="和-的区别是什么"><a href="#和-的区别是什么" class="headerlink" title="#{}和${}的区别是什么"></a>#{}和${}的区别是什么</h1><img src="/2024/04/06/Mybatis/clip_image007.jpg" class="" title="img"><p>1.编译过程</p><p>#{} 是 占位符 ：动态解析 -&gt; 预编译 -&gt; 执行</p><p>${} 是 拼接符 ：动态解析 -&gt; 编译 -&gt; 执行</p><p>预编译可以类比java类的编译，java类被编译成class文件，载入虚拟机，sql预编译后会在参数位置用占位符表示。 </p><p>预编译：数据库驱动在发送sql和参数到DBMS之前，先对sql语句进行编译处理，之后DBMS则可以直接对sql进行处理，不需要再次编译，提高了性能。这一点mybatis 默认情况下，将对所有的 sql 进行预编译处理。</p><p>预编译可以将多个操作步骤合并成一个步骤，一般而言，越复杂的sql，编译程度也会复杂，难度大，耗时，费性能，而预编译可以合并这些操作，预编译之后DBMS可以省去编译直接运行sql。</p><p>预编译语句可以重复利用。</p><p>把一个 sql 预编译后产生的 PreparedStatement 对象缓存下来，下次对于同一个sql，可以直接使用这个缓存的 PreparedState 对象。</p><ol start="2"><li>是否自动加单引号</li></ol><p>#{} 对应的变量会自动加上单引号 </p><p>${} 对应的变量不会加上单引号 </p><ol start="3"><li>安全性</li></ol><p>#{} 能防止sql 注入</p><p>${} 不能防止sql 注入</p><ol start="4"><li>Mybatis默认值不同</li></ol><p>#{} 默认值 arg0、arg1、arg2 或 0、 1</p><p>${} 默认值param1、param2、param3 </p><p><a href="https://blog.csdn.net/weixin_41231928/article/details/105120292">https://blog.csdn.net/weixin_41231928/article/details/105120292</a></p><p>补充：</p><p>sql注入：</p><p>本地一段代码为get获取id值，输出实际执行sql以及查询id对应内容。</p><p>当id值传为1时，执行结果如下：</p><img src="/2024/04/06/Mybatis/clip_image009.jpg" class="" title="img"><p>这是正常请求情况，而当我们往id传的参数中注入sql代码时，便可以根据自己需求查询自己想</p><p>要获取的内容，例如：</p><img src="/2024/04/06/Mybatis/clip_image011.jpg" class="" title="img"><p>id值传参数为 -1 OR 1&#x3D;1 ,此时执行代码中id值带入了我们传参数的sql代码， 1&#x3D;1 为真，OR 1&#x3D;1便会查出表中所有的内容。达到攻击目的。</p><p> 所以sql注入攻击就是输入参数未经过滤，直接拼接到sql语句中，解析执行，达到预想之外的行为。 </p><p><a href="https://www.cnblogs.com/gyrgyr/p/9876569.html">https://www.cnblogs.com/gyrgyr/p/9876569.html</a></p>]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> Mybatis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring</title>
      <link href="/2024/04/06/Spring/"/>
      <url>/2024/04/06/Spring/</url>
      
        <content type="html"><![CDATA[<h1 id="Spring"><a href="#Spring" class="headerlink" title="Spring"></a>Spring</h1><h2 id="Spring是什么"><a href="#Spring是什么" class="headerlink" title="Spring是什么"></a>Spring是什么</h2><img src="/2024/04/06/Spring/clip_image002-1712366695502.jpg" class="" title="img"><h2 id="介绍下Spring，读过源码介绍下大致流程"><a href="#介绍下Spring，读过源码介绍下大致流程" class="headerlink" title="介绍下Spring，读过源码介绍下大致流程"></a>介绍下Spring，读过源码介绍下大致流程</h2><img src="/2024/04/06/Spring/clip_image004-1712366695502.jpg" class="" title="img"><h2 id="对于IOC和AOP和控制反转的理解"><a href="#对于IOC和AOP和控制反转的理解" class="headerlink" title="对于IOC和AOP和控制反转的理解"></a>对于IOC和AOP和控制反转的理解</h2><p>IoC（Inverse of Control:控制反转），就是 将原本在程序中⼿动创建对象的控制权，交由<strong>Spring</strong>框架来管理。 <strong>IoC</strong> 容器是<strong>Spring</strong> ⽤来实现 <strong>IoC</strong> 的载体， <strong>IoC</strong> 容器实际上就是个<strong>Map</strong>（<strong>key</strong>，<strong>value</strong>）**,Map** 中存放的是各种对象。 </p><p>优点1：<strong>这个容器可以自动对你的代码进行初始化，你只需要维护一个<strong><strong>Configuration</strong></strong>（可以是<strong><strong>xml</strong></strong>可以是一段代码），而不用每次初始化一辆车都要亲手去写那一大段初始化的代码</strong>。</p><p>优点2：<strong>我们在创建实例的时候不需要了解其中的细节。</strong></p><img src="/2024/04/06/Spring/clip_image005.jpg" class="" title="img"><img src="/2024/04/06/Spring/clip_image007.jpg" class="" title="img"><img src="/2024/04/06/Spring/clip_image009.jpg" class="" title="img"><h2 id="循环依赖"><a href="#循环依赖" class="headerlink" title="循环依赖"></a>循环依赖</h2><ol><li>循环依赖</li></ol><img src="/2024/04/06/Spring/clip_image011.gif" class="" title="img"><p>上图中handler存在于命名空间中，最后是放到BeanDefination中</p><img src="/2024/04/06/Spring/clip_image013.gif" class="" title="img"><img src="/2024/04/06/Spring/clip_image015.gif" class="" title="img"><img src="/2024/04/06/Spring/clip_image017.gif" class="" title="img"><img src="/2024/04/06/Spring/clip_image019.gif" class="" title="img"><p>首先创建a对象，放3a，因为a依赖b对象，所以去创建b对象，放3b,</p><img src="/2024/04/06/Spring/clip_image021.gif" class="" title="img"><p>创建b对象时，去3级缓存找有没有a，发现是有的，放2a（把a放入二级缓存）,删除3a</p><img src="/2024/04/06/Spring/clip_image023.gif" class="" title="img"><p>这时候还是创建b对象过程，发现二级缓存中有a，那么创建b对象，放入1级缓存（1b），删除3b</p><img src="/2024/04/06/Spring/clip_image025.gif" class="" title="img"><p>回来创建a对象流程，发现一级缓存中有b，那么直接注入，删除掉2a</p><img src="/2024/04/06/Spring/clip_image027.gif" class="" title="img"><img src="/2024/04/06/Spring/clip_image029.gif" class="" title="img"><img src="/2024/04/06/Spring/clip_image031.gif" class="" title="img"><h2 id="1-Spring-中用到了哪些设计模式"><a href="#1-Spring-中用到了哪些设计模式" class="headerlink" title="\1.  Spring 中用到了哪些设计模式 :"></a>\1.  Spring 中用到了哪些设计模式 :</h2><p>1.简单工厂(非23种设计模式中的一种) </p><p>2.工厂方法 </p><p>3.单例模式</p><p> 4.适配器模式 </p><p>5.装饰器模式 </p><p>6.代理模式</p><p> 7.观察者模式</p><p> 8.策略模式 </p><p>9.模版方法模式</p><img src="/2024/04/06/Spring/clip_image032.jpg" class="" title="img"><img src="/2024/04/06/Spring/clip_image033.jpg" class="" title="img"><img src="/2024/04/06/Spring/clip_image034.jpg" class="" title="img"><p><a href="https://zhuanlan.zhihu.com/p/114244039">https://zhuanlan.zhihu.com/p/114244039</a></p><h2 id="Autowire等这些注解怎么实现的？怎么能够让这些注解即便找不到也不报错？"><a href="#Autowire等这些注解怎么实现的？怎么能够让这些注解即便找不到也不报错？" class="headerlink" title="@Autowire等这些注解怎么实现的？怎么能够让这些注解即便找不到也不报错？"></a>@Autowire等这些注解怎么实现的？怎么能够让这些注解即便找不到也不报错？</h2><p><strong>@Autowired****使用</strong> </p><img src="/2024/04/06/Spring/clip_image036.jpg" class="" title="img"><img src="/2024/04/06/Spring/clip_image038.jpg" class="" title="img"><p>属性注入：</p><p>如果我们自己设计@Autowired，我们应该怎么实现？我想做法还是比较简单的 </p><ol><li>通过反射查找bean的class下所有注解了@Autowired的字段和方法</li><li>获取到字段，通过getBean(字段)获取到对应bean，然后再通过反射调用field的set将bean注入</li></ol><p>方法注入：</p><p>当@Autowired注解在方法上，例如我们注解在setter方法上，则只需要直接调用该setter方法将参数数组传入即可以</p><p>方案一：@Autowired(required &#x3D; false)  设置required 属性值为 false，错误提示消失。</p><p>方案二：用@Resource注解替换@Autowired注解，错误提示消失。</p><p><a href="https://www.jianshu.com/p/1002f5a704ea">https://www.jianshu.com/p/1002f5a704ea</a></p><p><a href="https://juejin.cn/post/6844903957135884295#heading-3">https://juejin.cn/post/6844903957135884295#heading-3</a></p><h2 id="BeanFactory和ApplicationContext的区别"><a href="#BeanFactory和ApplicationContext的区别" class="headerlink" title="BeanFactory和ApplicationContext的区别"></a>BeanFactory和ApplicationContext的区别</h2><img src="/2024/04/06/Spring/clip_image039.jpg" class="" title="img"><img src="/2024/04/06/Spring/clip_image040.jpg" class="" title="img"><img src="/2024/04/06/Spring/clip_image041.jpg" class="" title="img"><p>ApplicationContext可以在其bean定义中自动检测BeanFactoryPostProcessor bean，<strong>并在创建任何其他<strong><strong>bean</strong></strong>之前先创建****BeanFactoryPostProcessor</strong></p><h2 id="Spring中后置处理器的作用"><a href="#Spring中后置处理器的作用" class="headerlink" title="Spring中后置处理器的作用"></a>Spring中后置处理器的作用</h2><img src="/2024/04/06/Spring/clip_image043.jpg" class="" title="img"><h2 id="IOC"><a href="#IOC" class="headerlink" title="IOC"></a>IOC</h2><h3 id="容器和对象的创建流程"><a href="#容器和对象的创建流程" class="headerlink" title="容器和对象的创建流程"></a>容器和对象的创建流程</h3><ul><li><ul><li>容器和对象的创建流程</li></ul></li></ul><img src="/2024/04/06/Spring/clip_image045-1712366695504.jpg" class="" title="img"><img src="/2024/04/06/Spring/clip_image047-1712366695504.jpg" class="" title="img"><img src="/2024/04/06/Spring/clip_image049-1712366695504.jpg" class="" title="img"><p>BeanfactoryPostProcessor：比如占位符的填充操作</p><p>PostProcessor这样的处理接口是通过动态代理实现的</p><p>使用完事之后销毁</p><img src="/2024/04/06/Spring/clip_image051.jpg" class="" title="img"><img src="/2024/04/06/Spring/clip_image053.jpg" class="" title="img"><p>通过实现BeanFactoryAware与ApplicationContextAware方法</p><img src="/2024/04/06/Spring/clip_image055.jpg" class="" title="img"><img src="/2024/04/06/Spring/clip_image057.jpg" class="" title="img"><img src="/2024/04/06/Spring/clip_image059.jpg" class="" title="img"><h3 id="如果你要实现IOC，请简单描述一下实现步骤？"><a href="#如果你要实现IOC，请简单描述一下实现步骤？" class="headerlink" title="如果你要实现IOC，请简单描述一下实现步骤？"></a>如果你要实现IOC，请简单描述一下实现步骤？</h3><p>实现IOC的步骤：</p><p>①定义用来描述bean的配置的Java类。</p><p>②解析bean的配置，将bean的配置信息转换为BeanDefinition对象保存到内存中，spring中采用HashMap进行对象存储，其中会用到一些xml的解析技术，如dom4j等。</p><p>③遍历存放BeanDefinition的HashMap对象，逐条取出BeanDefinition对象，获取bean的配置信息，利用Java的反射机制实例化对象，将实例化后的对象保存到另外一个Map中即可。 </p><img src="/2024/04/06/Spring/clip_image061-1712366695504.jpg" class="" title="img"><h3 id="bean的作用域"><a href="#bean的作用域" class="headerlink" title="bean的作用域"></a>bean的作用域</h3><img src="/2024/04/06/Spring/clip_image063-1712366695504.jpg" class="" title="img"><p><a href="https://www.huaweicloud.com/articles/cb0bcf025a17e8501ded9dafa2a19933.html">https://www.huaweicloud.com/articles/cb0bcf025a17e8501ded9dafa2a19933.html</a></p><p><a href="https://www.huaweicloud.com/articles/b59be8ffdcfbd1f8a1fe28bffe848d20.html">https://www.huaweicloud.com/articles/b59be8ffdcfbd1f8a1fe28bffe848d20.html</a></p><h3 id="Spring-Bean的生命周期"><a href="#Spring-Bean的生命周期" class="headerlink" title="Spring Bean的生命周期"></a>Spring Bean的生命周期</h3><img src="/2024/04/06/Spring/clip_image065-1712366695504.jpg" class="" title="img"><h3 id="bean的作用域-1"><a href="#bean的作用域-1" class="headerlink" title="bean的作用域"></a>bean的作用域</h3><img src="/2024/04/06/Spring/clip_image066.jpg" class="" title="img"><h3 id="单例Bean是线程安全的吗"><a href="#单例Bean是线程安全的吗" class="headerlink" title="单例Bean是线程安全的吗"></a>单例Bean是线程安全的吗</h3><img src="/2024/04/06/Spring/clip_image068-1712366695504.jpg" class="" title="img"><h3 id="bean的自动装配，有哪些方式"><a href="#bean的自动装配，有哪些方式" class="headerlink" title="bean的自动装配，有哪些方式"></a>bean的自动装配，有哪些方式</h3><img src="/2024/04/06/Spring/clip_image069-1712366695504.jpg" class="" title="img"><img src="/2024/04/06/Spring/clip_image070-1712366695504.jpg" class="" title="img"><h3 id="依赖注入方式"><a href="#依赖注入方式" class="headerlink" title="依赖注入方式"></a>依赖注入方式</h3><img src="/2024/04/06/Spring/clip_image071.jpg" class="" title="img"><img src="/2024/04/06/Spring/clip_image072-1712366695504.jpg" class="" title="img"><p>构造方法注入：</p><img src="/2024/04/06/Spring/clip_image073-1712366695504.jpg" class="" title="img"><img src="/2024/04/06/Spring/clip_image074-1712366695504.jpg" class="" title="img"><p>set方法注入：</p><img src="/2024/04/06/Spring/clip_image075-1712366695504.jpg" class="" title="img"><img src="/2024/04/06/Spring/clip_image076-1712366695504.jpg" class="" title="img"><h2 id="AOP"><a href="#AOP" class="headerlink" title="AOP"></a>AOP</h2><p>AOP(Aspect-Oriented Programming:⾯向切⾯编程)能够将那些与业务⽆关，却为业务模块所共同调⽤的逻辑或责任（例如事务处理、⽇志管理、权限控制等）封装起来，便于减少系统的重复代码，降低模块间的耦合度，并有利于未来的可拓展性和可维护性。<strong>Spring AOP</strong>就是基于动态代理的。</p><img src="/2024/04/06/Spring/clip_image078-1712366695504.jpg" class="" title="img"><p>初始化看程序员有没有继承一个类并且实现afterPropertiesSet（）方法，这个方法的主要应用在于赋值一些不在容器</p><img src="/2024/04/06/Spring/clip_image079.jpg" class="" title="img"><p>中的对象，或者去判断属性是否为空，若为空需要抛出一些异常</p><p>执行aop，需要在容器中把所有的切面对象都找出来，再遍历，如果对UserService类进行代理，那么就要匹配切点</p><img src="/2024/04/06/Spring/clip_image080-1712366695504.jpg" class="" title="img"><h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><h3 id="Spring支持的事务管理类型"><a href="#Spring支持的事务管理类型" class="headerlink" title="Spring支持的事务管理类型"></a>Spring支持的事务管理类型</h3><p><strong>Spring****支持两种类型的事务管理：</strong></p><p><strong>编程式事务管理</strong>：这意味你通过编程的方式管理事务，给你带来极大的灵活性，但是难维护。</p><p><strong>声明式事务管理</strong>：这意味着你可以将业务代码和事务管理分离，你只需用注解和XML配置来管理事务。</p><h3 id="spring-事务实现方式有哪些？"><a href="#spring-事务实现方式有哪些？" class="headerlink" title="spring 事务实现方式有哪些？"></a>spring 事务实现方式有哪些？</h3><p><strong>Spring****事务的实现方式和实现原理</strong></p><p>Spring事务的本质其实就是数据库对事务的支持，没有数据库的事务支持，spring是无法提供事务功能的。真正的数据库层的事务提交和回滚是通过binlog或者redo log实现的。</p><img src="/2024/04/06/Spring/clip_image082-1712366695505.jpg" class="" title="img"><h3 id="事务隔离级别"><a href="#事务隔离级别" class="headerlink" title="事务隔离级别"></a>事务隔离级别</h3><ul><li>事务隔离级别</li></ul><img src="/2024/04/06/Spring/clip_image084-1712366695505.jpg" class="" title="img"><p><strong>ISOLATION_DEFAULT</strong> 这是一个PlatfromTransactionManager默认的隔离级别，使用数据库默认的事务隔离级别.另外四个与JDBC的隔离级别相对应 </p><p><a href="https://blog.csdn.net/qq_37651267/article/details/92425172">https://blog.csdn.net/qq_37651267/article/details/92425172</a></p><h3 id="事务特征"><a href="#事务特征" class="headerlink" title="事务特征"></a>事务特征</h3><ul><li><ul><li>事务特征</li></ul></li></ul><img src="/2024/04/06/Spring/clip_image086-1712366695505.jpg" class="" title="img"><p>原子性：一个事务是一个不可分割的工作单位。</p><p>一致性：事务必须是使数据库从一个一致性状态变到另一个一致性状态，一致性与原子性是密切相关的。</p><p>隔离性：一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。</p><p>持久性：一个事务一旦提交，它对数据库中数据的改变就应该是永久性的。接下来的其他操作或故障不应该对其有任何影响</p><h3 id="事务传播行为"><a href="#事务传播行为" class="headerlink" title="事务传播行为"></a>事务传播行为</h3><ul><li><ul><li>事务传播行为</li><li><img src="/2024/04/06/Spring/clip_image088-1712366695505.jpg" class="" title="img"></li></ul></li></ul><img src="/2024/04/06/Spring/clip_image090.jpg" class="" title="img"><p><strong>事务的传播级别总结版</strong></p><p>PROPAGATION_MANDATORY：该传播级别要求上下文中必须存在事务，否则抛出异常。</p><p>PROPAGATION_REQUIRED：Spring的默认传播级别，如果上下文中存在事务则加入当前事务，如果不存在事务则新建事务执行。</p><p>PROPAGATION_NESTED：嵌套事务，如果上下文中存在事务则嵌套执行，如果不存在则新建事务。</p><p>PROPAGATION_REQUIRES_NEW：该传播级别每次执行都会创建新事务，并同时将上下文中的事务挂起，执行完当前线程后再恢复上下文中事务。（子事务的执行结果不影响父事务的执行和回滚）</p><p>PROPAGATION_NEVER：该传播级别要求上下文中不能存在事务，否则抛出异常。</p><p>PROPAGATION_NOT_SUPPORTED：当上下文中有事务则挂起当前事务，执行完当前逻辑后再恢复上下文事务。（降低事务大小，将非核心的执行逻辑包裹执行。）</p><p>PROPAGATION_SUPPORTS：如果上下文中存在事务则加入当前事务，如果没有事务则以非事务方式执行。</p><img src="/2024/04/06/Spring/clip_image092-1712366695505.jpg" class="" title="img"><h3 id="spring事务什么时候会失效"><a href="#spring事务什么时候会失效" class="headerlink" title="spring事务什么时候会失效"></a>spring事务什么时候会失效</h3><img src="/2024/04/06/Spring/clip_image093-1712366695505.jpg" class="" title="img"><p>4.方法上加了@Trans。。。,但是类上没有加@Service或其他的注解，该类的对象没有放到容器中</p><h1 id="SpringMVC"><a href="#SpringMVC" class="headerlink" title="SpringMVC"></a>SpringMVC</h1><h2 id="Servlet"><a href="#Servlet" class="headerlink" title="Servlet"></a>Servlet</h2><p>* 概念：运行在服务器端的小程序</p><p>* Servlet就是一个接口，定义了Java类被浏览器访问到(tomcat识别)的规则。</p><p>* 将来我们自定义一个类，实现Servlet接口，复写方法。</p><p>servlet对于http请求是怎样处理的,http是怎样找到对应servlet的</p><img src="/2024/04/06/Spring/clip_image095-1712366695505.jpg" class="" title="img"><h2 id="Spring-Boot，Spring-MVC和Spring有什么区别"><a href="#Spring-Boot，Spring-MVC和Spring有什么区别" class="headerlink" title="Spring Boot，Spring MVC和Spring有什么区别"></a>Spring Boot，Spring MVC和Spring有什么区别</h2><img src="/2024/04/06/Spring/clip_image097-1712366695505.jpg" class="" title="img"><h2 id="SpringMVC的工作流程"><a href="#SpringMVC的工作流程" class="headerlink" title="SpringMVC的工作流程"></a>SpringMVC的工作流程</h2><img src="/2024/04/06/Spring/clip_image099-1712366695505.jpg" class="" title="img"><p>5中处理器可能是继承了controller接口，也可能是用注解@RequestMapping，也可能是Servlet（中有Service方法），这时就要用到4中的处理器适配器去调用具体的处理器</p><p>9中解析器可能用到jstl视图解析技术</p><p>10中view可能渲染为jsp页面</p><img src="/2024/04/06/Spring/clip_image101-1712366695505.jpg" class="" title="img"><h2 id="SpringMVC的主要组件"><a href="#SpringMVC的主要组件" class="headerlink" title="SpringMVC的主要组件"></a>SpringMVC的主要组件</h2><img src="/2024/04/06/Spring/clip_image102-1712366695505.jpg" class="" title="img"><p>最主要就是前面两个</p><img src="/2024/04/06/Spring/clip_image103-1712366695505.jpg" class="" title="img"><p>2中最重要的就是support方法和handle方法，support就是判断是哪种处理器（用instanceof），handle：具体执行方法，若是实现controller接口，则强转为controller类型，再执行方法</p><img src="/2024/04/06/Spring/clip_image105-1712366695505.jpg" class="" title="img"><h1 id="Springboot"><a href="#Springboot" class="headerlink" title="Springboot"></a>Springboot</h1><h2 id="如何理解Spring-Boot中的starter"><a href="#如何理解Spring-Boot中的starter" class="headerlink" title="如何理解Spring Boot中的starter"></a>如何理解Spring Boot中的starter</h2><img src="/2024/04/06/Spring/clip_image107-1712366695505.jpg" class="" title="img"><p>默认配置比如说8080端口</p><h2 id="SpringBoot的注解及其实现"><a href="#SpringBoot的注解及其实现" class="headerlink" title="SpringBoot的注解及其实现"></a>SpringBoot的注解及其实现</h2><img src="/2024/04/06/Spring/clip_image109-1712366695505.jpg" class="" title="img"><h2 id="Spring-Boot的自动装配"><a href="#Spring-Boot的自动装配" class="headerlink" title="Spring Boot的自动装配"></a>Spring Boot的自动装配</h2><img src="/2024/04/06/Spring/clip_image110-1712366695505.jpg" class="" title="img"><p>import导入类，AutoConfigurationPackageRegister，用来将扫描路径保存到配置类中，其他框架比如jpa来了，就能了解到这些类的路径了</p><p>文字第二行：配置类以字符串形式放到spring.factories中</p><p>Spring spi就是调用图中的loadFactoryNames方法</p><p>EnableAutoConfigrator是一个key值</p><p>@Bean就是类中一个方法返回一个对象，若想把它放入容器中，就可以加这个注解</p><h2 id="SpringBoot是如何启动Tmocat的"><a href="#SpringBoot是如何启动Tmocat的" class="headerlink" title="SpringBoot是如何启动Tmocat的"></a>SpringBoot是如何启动Tmocat的</h2><img src="/2024/04/06/Spring/clip_image112-1712366695505.jpg" class="" title="img"><h2 id="SpringBoot中配置文件的加载顺序是怎样的"><a href="#SpringBoot中配置文件的加载顺序是怎样的" class="headerlink" title="SpringBoot中配置文件的加载顺序是怎样的"></a>SpringBoot中配置文件的加载顺序是怎样的</h2><img src="/2024/04/06/Spring/clip_image114.jpg" class="" title="img"><h1 id="SpringCloud"><a href="#SpringCloud" class="headerlink" title="SpringCloud"></a>SpringCloud</h1><h2 id="Spring-Cloud和Dubbo的区别"><a href="#Spring-Cloud和Dubbo的区别" class="headerlink" title="Spring Cloud和Dubbo的区别"></a>Spring Cloud和Dubbo的区别</h2><img src="/2024/04/06/Spring/clip_image115-1712366695505.jpg" class="" title="img"><p>http–restful风格  tcp–rpc形式接口</p><p>eureka–ap 注重高可用（剩余一个节点都可用，不能保证数据强一致性） zookeeper–cp 保证强一致性    具体参考：微服务5</p><p>生态：比如说springcloud支持熔断，Dubbo不支持，还要自己写</p><h2 id="springcloud核心组件及其作用"><a href="#springcloud核心组件及其作用" class="headerlink" title="springcloud核心组件及其作用"></a>springcloud核心组件及其作用</h2><img src="/2024/04/06/Spring/clip_image116.jpg" class="" title="img"><img src="/2024/04/06/Spring/clip_image117-1712366695505.jpg" class="" title="img"><img src="/2024/04/06/Spring/clip_image118.jpg" class="" title="img"><img src="/2024/04/06/Spring/clip_image119-1712366695505.jpg" class="" title="img"><img src="/2024/04/06/Spring/clip_image120.jpg" class="" title="img"><img src="/2024/04/06/Spring/clip_image121-1712366695505.jpg" class="" title="img"><p>hystrix:A调用B，B调用C，A的并发量过大会导致BC不可用，熔断就是把AB之间断掉，会有一个forback函数，熔断的时候可以返回给用户友好提示，降级：并且函数中可以记录参数，日志，发到mq中交由BC去处理，先给用户处理中的友好提示，等处理完了，再给用户提示完成</p><h2 id="SpringCloud-Alibaba"><a href="#SpringCloud-Alibaba" class="headerlink" title="SpringCloud Alibaba"></a>SpringCloud Alibaba</h2><img src="/2024/04/06/Spring/clip_image123-1712366695505.jpg" class="" title="img">]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>并发</title>
      <link href="/2024/04/05/%E5%B9%B6%E5%8F%91/"/>
      <url>/2024/04/05/%E5%B9%B6%E5%8F%91/</url>
      
        <content type="html"><![CDATA[<h1 id="并发编程核心概念"><a href="#并发编程核心概念" class="headerlink" title="并发编程核心概念"></a>并发编程核心概念</h1><ol><li>原子性</li></ol><p>​    所谓原子性即：一个或者多个操作，要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。</p><p>​     在整个操作过程中不会被线程调度器打断，如a&#x3D;1就是一个原子操作，但a++则不是一个原子操作，因为其内部会额外产生一个新的Integer对象。</p><p>​    举个例子，假设对一个32位的变量赋值，操作分为两步：低16位赋值、高16位赋值。当线程A对低16位数据写入成功后，线程A被中断。而此时另外的线程B去读取a的值，那么读取到的就是错误的数据。</p><p>​    在Java中的原子性操作包括：</p><ul><li>基本类型的读取和赋值操作，且赋值必须是数字赋值给变量，变量之间的相互赋值不是原子性操作。</li><li>所有引用的赋值操作。</li><li>java.concurrent.Atomic.*     包中所有原子操作类的一切操作。</li></ul><ol><li>可见性</li></ol><p>​    所谓可见性：即当多个线程访问同一个共享变量时，一个线程修改了该共享变量的值后，其他线程能够立即查看到修改后的值。</p><p>​     而如果要做到可见，Java中的volatile、synchronized、Lock都能保证可见性。如一个变量被volatile修饰后，表示当一个线程修改共享变量后，其会立即被更新到主内存中，其他线程读取共享变量时，会直接从主内存中读取。而synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的</p><p>修改刷新到主存当中。因此可以保证可见性。</p><ol><li>有序性</li></ol><p>​     所谓有序性：即程序执行的顺序会按照代码的先后顺序执行。</p><p>其可以理解为<strong>在本线程内，所有的操作都是有序的。而如果在A线程中观察B线程，所有的操作都是无序的</strong>。在JMM中为了提升程序的执行效率，允许编译器和处理器对<strong>指令重排序</strong>。对于单线程来说，指令重排并不会产生问题，而在多线程下则不可以。</p><p>在Java中可以通过synchronized和Lock来保证有序性，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。</p><p>另外还可以通过volatile来保证一定的有序性。最著名的例子就是单例模式的DCL（双重检查锁）。</p><h1 id="进程、线程"><a href="#进程、线程" class="headerlink" title="进程、线程"></a>进程、线程</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><ul><li>什么是进程</li></ul><p>进程可以理解为就是应用程序的启动实例。如微信、Idea、Navicat等，当打开它们后，就相当于开启了一个进程。每个进程都会在操作系统中拥有独立的内存空间、地址、文件资源、数据资源等。<strong>进程是资源分配和管理的最小单位</strong></p><p>线程从属于进程，是程序的实际执行者，一个进程中可以包含若干个线程，并且也可以把线程称为轻量级进程。每个线程都会拥有自己的计数器、堆栈、局部变量等属性，并且能够访问共享的内存变量。**线程是操作系统（CPU）调度和执行的最小单位。CPU会在这些线程上来回切换，让使用者感觉线程是在同时执行的。</p><p><strong>线程使用带来的问题</strong></p><p>​    有很多人都会存在一个误区，在代码中使用多线程，一定会为系统带来性能提升，这个观点是错误的。并发编程的目的是为了让程序运行的更快，但是，绝对不是说启动的线程越多，性能提升的就越大，其会受到很多因素的影响，如锁问题、线程状态切换问题、线程上下文切换问题，还会受到硬件资源的影响，如CPU核数。</p><p>什么叫做线程上下文切换</p><p>​    不管是在多核甚至单核处理器中，都是能够以多线程形式执行代码的，CPU通过给每个线程分配CPU时间片来实现线程执行间的快速切换。 所谓的时间片就是CPU分配给每个线程的执行时间，当某个线程获取到CPU时间片后，就会在一定时间内执行，当时间片到期，则该线程会进入到挂起等待状态。时间片一般为几十毫秒，通过在CPU的高速切换，让使用者感觉是在同时执行。</p><p>​    同时还要保证线程在切换的过程中，要记录线程被挂起时，已经执行了哪些指令、变量值是多少，那这点则是通过每个线程内部的程序计数器来保证。</p><p>​    简单来说：线程从挂起到再加载的过程，就是一次上下文切换。其是比较耗费资源的。</p><p>引起上下文切换的几种情况：</p><ul><li>时间片用完，CPU正常调度下一个任务。</li><li>被其他优先级更高的任务抢占。</li><li>执行任务碰到IO阻塞，调度器挂起当前任务，切换执行下一个任务。</li><li>用户代码主动挂起当前任务让出CPU时间。</li><li>多任务抢占资源，由于没有抢到被挂起。</li><li>硬件中断。</li></ul><p><strong>CPU</strong>时间片轮转机制*优化</p><p>​    之前已经提到了线程的执行，是依赖于CPU给每个线程分配的时间来进行。在CPU时间片轮转机制中，如果一个线程的时间片到期，则CPU会挂起该线程并给另一个线程分配一定的时间分片。如果进程在时间片结束前阻塞或结束，则 CPU 会立即进行切换。</p><p>​     时间片太短会导致频繁的进程切换，降低了 CPU 效率: 而太长又可能引起对短的交</p><p>互请求的响应变差。时间片为 <strong>100ms</strong> 通常是一个比较合理的折衷。</p><p>并行与并发的理解</p><p>并发即让多个任务能够<strong>交替</strong>执行，一般都会附带一个时间单位，也就是所谓的在单</p><p>位时间内的并发量有多少。</p><p>并行即让多个任务能够同时执行。比如说：你可以一遍上厕所，一遍吃饭。</p><p><strong>多线程的创建方式</strong></p><p>线程的实现方式有两种：继承Thread类、实现Runnable接口。但是有一些书籍或者文章会说有三种方式，即实现Callable接口。但通过该接口定义线程并不是Java标准的定义方式，而是基于</p><p>Future思想来完成。</p><p>Thread是对一个线程的抽象，而Runnable是对业务逻辑的抽象，并且Thread 可以接受任意一个 Runnable 的实例并执行。</p><p>优化：启动线程前，最好为这个线程设置特定的线程名称，这样在出现问题时，给开发人员一些提示，快速定位到问题线程。</p><p>线程中止</p><p>线程在正常下当run执行完，或出现异常都会让该线程中止。</p><p>理解suspend()、resume()、stop()</p><p>这三个方法对应的是暂停、恢复和中止。</p><p>但是三个已经在Java源码中被标注为过期方法。</p><p>当调用suspend()时，线程不会将当前持有的资源释放(如锁)，而是占有者资源进入到暂停状</p><p>态，这样的话，容易造成死锁问题的出现。</p><p>当调用stop()时，会<strong>立即停止run()中剩余的操作</strong>。因此可能会导致一些的工作得不到完成，如文件流，数据库等关闭。并且<strong>会立即释放该线程所持有的所有的锁</strong>，导致数据得</p><p>不到同步的处理，出现数据不一致的问题。</p><p>线程中止的安全且优雅姿势</p><p>​    Java对于线程安全中止设计了一个<strong>中断属性</strong>，其可以理解是线程的一个标识位属性。它用于表示一个运行中的线程是否被其他线程进行了中断操作。好比其他线程对这个线程打了一个招呼，告诉它你该中断了。通过**interrupt()**实现。</p><p>添加该方法后，会出现一个异常，但是可以发现并不会线程的继续执行。</p><p>​    线程通过检查自身是否被中断来进行响应，可以通过**isInterrupted()**进行判断，如果返回值为true，代表添加了中断标识，返回false，代表没有添加中断标识。通过它可以对线程进行中断操作。</p><p>对线程中断属性的判断，可以利用其进行线程执行的中断操作。</p><p>​    线程也可以通过静态方法<strong>Thread.interrupted()<strong>查询线程是否被中断，并对中断标识进行复位，如果该线程已经被添加了中断标识，当使用了该方法后，会将线程的中断标识由true改为false。同时要注意：</strong>处于死锁下的线程，无法被中断</strong></p><h2 id="进程和线程的区别"><a href="#进程和线程的区别" class="headerlink" title="进程和线程的区别"></a>进程和线程的区别</h2><p>进程是执行着的应用程序，而线程是进程内部的一个执行序列。一个进程可以有多个线程。线程又叫做轻量级进程。</p><p>**a.**<strong>地址空间和其它资源</strong>：进程间拥有独立内存，进程是资源分配的基本单位；线程隶属于某一进程，且同一进程的各线程间共享内存（资源），线程是cpu调度的基本单位。 进程间相互独立，同一进程的各线程间共享。某进程内的线程在其它进程不可见。</p><p>**b.**<strong>通信：</strong>进程间相互独立，通信困难，常用的方法有：管道，信号，套接字，共享内存，消息队列等；线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性。 </p><p>**c.**<strong>调度和切换</strong>：线程上下文切换比进程上下文切换要快。进程间切换要保存上下文，加载另一个进程；而线程则共享了进程的上下文环境，切换更快。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image001.jpg" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image002.jpg" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image004.jpg" class="" title="线 程 的 优 点 ：  。 一 个 进 程 中 可 以 同 时 存 在 个 线 程 ；  。 各 个 线 程 之 间 可 以 并 发 执 行 ；  。 各 个 线 程 之 间 可 以 共 享 地 址 空 间 和 文 件 等 资 源 ；  线 程 的 缺 点 ：  能 当 进 程 中 的 一 个 线 程 崩 溃 时 ， 会 导 致 其 所 属 进 程 的 所 有 线 程 崩 溃 。"><h2 id="线程创建方式"><a href="#线程创建方式" class="headerlink" title="线程创建方式"></a>线程创建方式</h2><p>实现Thread类</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image006.jpg" class="" title="img"><p>实现Runnbale接口</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image008.jpg" class="" title="img"><p><strong>实现</strong>Callable接口</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image010.jpg" class="" title="img"><p>为什么要有Runnable接口的出现？</p><p>1：通过继承Thread类的方式，可以完成多线程的建立。但是这种方式有一个局限性，如</p><p>果一个类已经有了自己的父类，就不可以继承Thread类，因为java单继承的局限性。 </p><p>可是该类中的还有部分代码需要被多个线程同时执行。这时怎么办呢？ </p><p>只有对该类进行额外的功能扩展，java就提供了一个接口Runnable。这个接口中定义了run</p><p>方法，其实run方法的定义就是为了存储多线程要运行的代码。</p><p>所以，通常创建线程都用第二种方式。 </p><p>因为实现Runnable接口可以避免单继承的局限性。</p><p>2：其实是将不同类中需要被多线程执行的代码进行抽取。将多线程要运行的代码的位置</p><p>单独定义到接口中。为其他类进行功能扩展提供了前提。 </p><p>所以Thread类在描述线程时，内部定义的run方法，也来自于Runnable接口。 </p><p>实现Runnable接口可以避免单继承的局限性。而且，继承Thread，是可以对Thread类中的方法，进行子类复写的。但是不需要做这个复写动作的话，只为定义线程代码存放位置</p><p>，实现Runnable接口更方便一些。所以Runnable接口将线程要执行的任务封装成了对象。</p><p>Thread和Runnable的联系与区别</p><p>1.Thread和Runnable都可以实现多线程（废话） </p><p>2.Thread是类，而Runnable是接口，这就是类和接口区别，类只能继承一次，而接口可以实现多个接口。 </p><p>3.Thread实现Runnable接口，这个可以查看Thread的源代码。 </p><p>4.最重要的分享资源功能，一般我们使用多线程就是快速解决资源问题。Runnable可以实现资源分享，类实现Runnable并不具备线程功能，必须通过new Thread(runabble子类)调用start()启动线程，所以我们通常new一个runnable的子类，启动多个线程解决资源问题。Thread是类所以我们每次new一个对象时候资源已经实例化了，不能资源共享，Thread类要实现资源共享，可以声明变量为static，类共享的可以解决。</p><p> 5.通过以上建议最好实现Runnable接口 实现多线程。</p><h2 id="线程操作常见方法"><a href="#线程操作常见方法" class="headerlink" title="线程操作常见方法"></a>线程操作常见方法</h2><ol><li>run()&amp;start()</li></ol><p>当线程执行了 start()方法后，才真正意义上的启动线程，其会让一个线程进入就绪状态等待分配CPU时间片，分到时间片后才会调用run()。注意，同一个线程的start()不能被重复调用，否则会出现异常，因为重复调用了，start方法，线程的state就不是new了，那么threadStatus就不等于0了。 </p><p>而run()则仅仅是一个普通方法，与类中的成员方法意义相同。在该方法中可以实现线程执行的业务逻辑。但并不会以异步的方式将线程启动，换句话说就是并不会去开启一个新的</p><p>线程。其可以单独执行，也可以重复执行。</p><ol><li>wait()、notify()</li></ol><p>wait()、notify()、notifyAll()是三个定义在Object类里的方法，可以用来控制线程的状</p><p>态。</p><p>注意：一定要在线程同步中使用,并且是同一个锁的资源**</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image012.gif" class="" title="img"><p>1）WaitThread首先获取对象锁。</p><p>2）WaitThread调用对象的wait()方法，放弃锁并进入对象的等待队列WaitQueue，进行等待状态。</p><p>3）由于WaitThread释放了对象锁，NotifyThread随机获取对象锁。</p><p>4）NotifyThread获取对象锁成功后，调用notify()或notifyAll()，将WaitThread从等待队列</p><p>WaitQueue移到同步队列</p><p>SynchronizedQueue，此时WaitThread为<strong>阻塞状态</strong>。</p><p>5）NotifyThread释放锁后，WaitThread再次获取锁并从wait()方法继续执行。</p><ol><li>等待通知范式</li></ol><p>等待方：</p><ul><li>获取对象锁。</li><li>如果条件不满足，那么调用对象的wait方法，被通知后仍要检查条件。</li><li>条件满足则执行对应逻辑。</li></ul><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image014.jpg" class="" title="img"><p>通知方：</p><p>- 获取对象锁。</p><p>- 改变条件。</p><p>- 通知等待在该对象上的线程。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image016.jpg" class="" title="img"><ol><li>wait与sleep区别</li></ol><p>* 对于sleep()方法，首先要知道该方法是属于Thread类中的。而wait()方法，则是属于</p><p>Object类中的。</p><p>* sleep()方法导致了程序暂停执行指定的时间，让出cpu调度其他线程，但是他的监控状态</p><p>依然保持者，当指定的时间到了又会自动恢复运行状态。</p><p> wait()是把控制权交出去，然后进入等待此对象的等待锁定池处于等待状态，只有针对此</p><p>对象调用notify()方法后本线程才进入对象锁定池准备获取对象锁进入运行状态。</p><p>* 在调用sleep()方法的过程中，线程不会释放锁。而当调用wait()方法的时候，线程会释放</p><p>锁。</p><ol><li>理解yield()</li></ol><p>​    当某个线程调用了这个方法后，该线程立即释放自己持有的时间片。线程会进入到就绪状态，同时CPU会重新选择一个线程赋予时间分片，但注意，调用了这个方法的线</p><p>程，也有可能被CPU再次选中赋予执行。</p><p>​    而且该方法不会释放锁。 如需释放锁的话，可以在调用该方法前自己手动释放。</p><ol><li>理解join()</li></ol><p>该方法的使用，在实际开发中，应用的是比较少的。但在面试中，常常伴随着产生一个问</p><p>题，如何保证线程的执行顺序？ 就可以通过该方法来设置。</p><p>使用:当线程调用了该方法后，线程状态会从就绪状态进入到运行状态。</p><p>每一个线程实现都持有前一个线程的引用。</p><p>当前线程需要等待previousThread线程终止之后才从thread.join返回。可以理解为，线程会在join处等待。</p><p>Thread.join其实底层是通过wait&#x2F;notifyall来实现线程的通信达到线程阻塞的目的；当线程执行结束以后，会触发两个事情，第一个是设置native线程对象为null、第二个是通过notifyall方法，让等待在previousThread对象锁上的wait方法被唤醒。</p><h2 id="线程优先级"><a href="#线程优先级" class="headerlink" title="线程优先级"></a>线程优先级</h2><p>线程优先级的<strong>范围是****1~10</strong>。一个线程的<strong>默认优先级是****5</strong>，可以在构建线程时，通过**setPriority()**修改该线程的优先级。优先级高的线程分配时间片的数量会高于优先级低的线程。</p><p>​    一般来说对于频繁阻塞的线程需要设置优先级高点，而偏重计算的线程优先级会设置低些，确保处理器不会被独占。</p><p>​    但<strong>注意，线程优先级不能作为线程执行正确性的依赖，因为不同的操作系统可能会忽略优先级的设置。</strong></p><h2 id="守护线程"><a href="#守护线程" class="headerlink" title="守护线程"></a>守护线程</h2><p>守护线程是一种支持型的线程，我们之前创建的线程都可以称之为用户线程。通过守护线程可以完成一些支持性的工作，如GC、分布式锁续期。守护线程会伴随着用户线程的结束而结束。</p><p>对于守护线程的创建，可以通过setDaemon()设置。</p><p>当线程实例没有被设置为守护线程时，该线程并不会随着主线程的结束而结束。但是当被设置为守护线程后，当主线程结束，该线程也会伴随着结束。同时守护线程不一定会执行finally代码块。所以当线程被设定为守护线程后，无法确保清理资源等操作一定会被执行。</p><h2 id="线程状态"><a href="#线程状态" class="headerlink" title="线程状态"></a>线程状态</h2><p><img src="/%E5%B9%B6%E5%8F%91/clip_image018.jpg" alt="img"><img src="/%E5%B9%B6%E5%8F%91/clip_image020.jpg" alt="img"></p><h2 id="线程安全活跃态问题以及竞态条件"><a href="#线程安全活跃态问题以及竞态条件" class="headerlink" title="线程安全活跃态问题以及竞态条件"></a>线程安全活跃态问题以及竞态条件</h2><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image022.jpg" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image024.jpg" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image026.jpg" class="" title="img"><h1 id="synchronized"><a href="#synchronized" class="headerlink" title="synchronized"></a><strong>synchronized</strong></h1><h2 id="synchronized-锁住的是什么"><a href="#synchronized-锁住的是什么" class="headerlink" title="synchronized****锁住的是什么"></a><strong>synchronized****锁住的是什么</strong></h2><p>总结：</p><p>静态方法：clss对象</p><p>普通方法：this对象</p><p>静态代码块：根据锁住的内容有所不同</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image028.gif" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image030.gif" class="" title="img"><p>对于synchronized，可以把其加在方法上或者类上，或者添加同步代码块。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image032.jpg" class="" title="img"><p>这种操作方式也可以叫做对象锁。</p><p>对于synchronized，也可以加载类上进行使用。此时可以把它称为<strong>类锁</strong>。此时加锁的就是一个class对象了。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image034.jpg" class="" title="img"><p>在使用synchronized时，建议锁定的范围，越小越好。否则的话，容易造成大量资源被锁定。</p><h2 id="synchronized是可重入锁吗"><a href="#synchronized是可重入锁吗" class="headerlink" title="synchronized是可重入锁吗"></a>synchronized是可重入锁吗</h2><p>2021年9月27日</p><p>synchronized底层是利用计算机系统mutex Lock实现的。每一个可重入锁都会关联一个线程ID和一个锁状态status。</p><p>当一个线程请求方法时，会去检查锁状态。</p><ul><li><ol><li>如果锁状态是0，代表该锁没有被占用，使用CAS操作获取锁，将线程ID替换成自己的线程ID。</li><li>如果锁状态不是0，代表有线程在访问该方法。此时，如果线程ID是自己的线程ID，如果是可重入锁，会将status自增1，然后获取到该锁，进而执行相应的方法；如果是非重入锁，就会进入阻塞队列等待。</li></ol></li></ul><p>在释放锁时，</p><ul><li><ol><li>如果是可重入锁的，每一次退出方法，就会将status减1，直至status的值为0，最后释放该锁。</li><li>如果非可重入锁的，线程退出方法，直接就会释放该锁。</li></ol></li></ul><p><a href="https://zhuanlan.zhihu.com/p/358828529">https://zhuanlan.zhihu.com/p/358828529</a></p><h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><p>在解释原理之前，首先需要知道什么是monitor。</p><p>我们可以把它理解为一个同步工具，也可以描述为一种同步机制，它通常被描述为一个对象。每一个Java对象都有成为Monitor的潜质，因为在Java的设计中 ，每一个Java对象自打娘胎里出来就带了一把看不见的锁，它叫做内部锁或者Monitor锁。Monitor 是线程私有的数据结构，每一个线程都有一个可用monitor record列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个monitor关联，同时monitor中有一个Owner字段存放拥有该锁的线程的唯一标志，表示该锁被这个线程占用。</p><p><strong>代码块：</strong>monitorenter指令插入到同步代码块的开始位置，monitorexit指令插入到同步代码块的结束位置，JVM需要保证每一个monitorenter都有一个monitorexit与之相对应。任何对象都有一个monitor与之相关联，当且一个monitor被持有之后，他将处于锁定状态。线程执行到monitorenter指令时，将会尝试获取对象所对应的monitor所有权。正常执行或者发生异常时会执行monitorexit指令，释放monitor所有权。</p><p><strong>方法：</strong>一个同步方法会在运行时常量池中的method_info结构体中存放ACC_SYNCHRONIZED标志符。当一个线程访问方法时，会去检查是否存在ACC_SYNCHRONIZED标志，如果存在，则先要获得对应的monitor锁，然后执行方法。当方法执行结束(不管是正常return还是抛出异常)都会释放对应的monitor锁。如果此时有其他线程也想要访问这个方法时，会因得不到monitor锁而阻塞。</p><p><a href="https://www.jianshu.com/p/5c4f441bf142">https://www.jianshu.com/p/5c4f441bf142</a></p><h2 id="锁对象"><a href="#锁对象" class="headerlink" title="锁对象"></a>锁对象</h2><p>synchronized用的锁会保存在<strong>Java对象头</strong>中。那什么是Java对象头呢？</p><p>一个Java对象在内存中是由三部分组成的：</p><p>- 对象头</p><p>- 实例数据</p><p>- 对齐填充字节</p><p>​    如果对象不是数组类型，则JVM用2字宽存储对象头。如果是数组类型，则用3字宽存储对象头。在32位虚拟机中，1字宽等于4字节，即32bit。在64位虚拟机中，1字宽相当于8字节，即64bit。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image036.gif" class="" title="img"><p>而对象头也是由三部分组成：</p><p>- MarkWord</p><p>- 类型指针</p><p>- 数组长度（只有数组对象有）</p><p>​    Mark Word用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程 ID、偏向时间戳等等。Java对象头一般占有两个机器码（在32位虚拟机中，1个机器码等于4字节，也就是32bit）。 </p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image038.gif" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image040.gif" class="" title="img"><p>类型指针，是对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。</p><p>实例数据</p><p>如果对象有属性字段，则这里会有数据信息。如果对象无属性字段，则这里就不会有数据。根据字段类型的不同占不同的字节，例如boolean类型占1个字节，int类型占4个字节等等</p><p>对齐数据</p><p>对象可以有对齐数据也可以没有。默认情况下，Java虚拟机堆中对象的起始地址需要对齐至8的倍数。如果一个对象用不到8N个字节则需要对其填充，以此来补齐对象头和实例数据占用内存之后剩余的空间大小。如果对象头和实例数据已经占满了JVM所分配的内存空间，那么就不用再进行对齐填充了。</p><p>所有的对象分配的字节总SIZE需要是8的倍数，如果前面的对象头和实例数据占用的总SIZE不满足要求，则通过对齐数据来填满。</p><p>为什么要对齐数据？字段内存对齐的其中一个原因，是让字段只出现在同一CPU的缓存行中。如果字段不是对齐的，那么就有可能出现跨缓存行的字段。也就是说，该字段的读取可能需要替换两个缓存行，而该字段的存储也会同时污染两个缓存行。这两种情况对程序的执行效率而言都是不利的。其实对其填充的最终目的是为了计算机高效寻址。</p><p>JVM中大家是否还记得对象在Suvivor中每熬过一次MinorGC，年龄就增加1，当它的年龄增加到一定程度后就会被晋升到老年代中，这个次数默认是15岁，有想过为什么是15吗？在Mark Word中可以发现标记对象分代年龄的分配的空间是4bit，而4bit能表示的最大数就是2^4-1 &#x3D; 15。</p><p><a href="https://www.cnblogs.com/jajian/p/13681781.html">https://www.cnblogs.com/jajian/p/13681781.html</a></p><p>Object o &#x3D; new Object()占多少个字节？</p><p>第一种解释：</p><p>object实例对象，占16个字节。</p><p>第二种解释：</p><p>Object o：普通对象指针（ordinary object pointer），占4个字节。</p><p>new Object()：object实例对象，占16个字节。</p><p>所以一共占：4+16&#x3D;20个字节。 </p><h2 id="Synchronized锁优化"><a href="#Synchronized锁优化" class="headerlink" title="Synchronized锁优化"></a>Synchronized锁优化</h2><ul><li><ol><li>自旋锁</li></ol></li></ul><p>线程的阻塞和唤醒需要CPU从用户态转为内核态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作，势必会给系统的并发性能带来很大的压力。同时我们发现在许多应用上面，对象锁的锁状态只会持续很短一段时间，为了这一段很短的时间频繁地阻塞和唤醒线程是非常不值得的。所以引入<strong>自旋锁</strong>（其实就是无意义的循环）。</p><p>所谓自旋锁，就是让该线程等待一段时间，不会被立即挂起，看持有锁的线程是否会很快释放锁。执行一段无意义的循环即可（自旋）。</p><p>如果持有锁的线程很快就释放了锁，那么自旋的效率就非常好，反之，自旋的线程就会白白消耗掉处理的资源，自旋等待的时间（自旋的次数）必须要有一个限度。</p><p>如果通过参数**-XX:preBlockSpin**来调整自旋锁的自旋次数，会带来诸多不便。假如我将参数调整为10，但是系统很多线程都是等你刚刚退出的时候就释放了锁（假如你多自旋一两次就可以获取锁），你是不是很尴尬。</p><ul><li><ol><li>自适应自旋锁</li></ol></li></ul><p>线程如果自旋成功了，那么下次自旋的次数会更加多，因为虚拟机认为既然上次成功了，那么此次自旋也很有可能会再次成功，那么它就会允许自旋等待持续的次数更多。反之，如果对于某个锁，很少有自旋能够成功的，那么在以后要或者这个锁的时候自旋的次数会减少甚至省略掉自旋过程，以免浪费处理器资源。</p><ul><li><ol><li>锁消除</li></ol></li></ul><p>锁消除发生在编译阶段，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，通过锁消除，可以节省毫无意义的请求锁时间。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image042.jpg" class="" title="img"><p>当前getString()中的StringBuffer是作为方法内部的局部变量，因此它不可能被多个线程同时访问，也就没有资源竞争，但是StringBuffer的append操作却需要执行同步操作:</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image044.gif" class="" title="img"><p>​    那么此时的同步锁相当于就是白白浪费系统资源。因此在编译时一旦JVM发现此种情况就会通过锁消除方式来优化性能。在JDK1.8中锁消除是自动开启的。</p><h2 id="锁升级过程"><a href="#锁升级过程" class="headerlink" title="锁升级过程"></a>锁升级过程</h2><p> 偏向锁</p><p><strong>1****）加锁</strong></p><ol><li>当线程初次执行到synchronized代码块（主要是线程ID）时，会通过自旋方式修改MarkWord的锁标志，代表锁对象为偏向锁。</li><li>执行完同步代码块后，线程并不会主动释放偏向锁。</li><li>当第二次执行同步代码块时，首先会判断MarkWord中的线程ID是否为当前线程。</li><li>如果是，则正常往下执行同步代码块。由于之前没有释放锁，这里也就不需要重新加锁。如果自始至终使用锁的线程只有一个，很明显偏向锁几乎没有额外开销，性能极高。</li><li>如果线程ID并未指向当前线程，则通过CAS操作替换MarkWork中的线程ID。如果替换成功，则执行同步代码块；如果替换失败，执行步骤6。</li><li>如果CAS替换失败，则表示有竞争。当到达全局安全点（safepoint）（当前程序什么都不干的时候）时获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码。（撤销偏向锁的时候会导致stop the world即什么都不干）</li></ol><p><strong>2****）撤销</strong></p><p>​    偏向锁的撤销在上述第六步中有提到。偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动去释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态，撤销偏向锁后恢复到未锁定（标志位为“01”）或轻量级锁（标志位为“00”）的状态。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image046.gif" class="" title="偏 向 锁 的 获 得 和 撤 销 流 程  线 程 1  对 象 头 中 MarkWord  线 程 2  访 问 同 步 快  无 锁 状 态  捡 查 对 象 头 是  否 存 储 了 线 程 1  Mark Word  访 问 同 步 快  偏 向 锁 状 态  将 对 象 头 M “ k  Tl 《 Epoch 《  word 中 的 线 程 》 D  检 查 对 象 头  指 向 自 己  是 否 存 储 了  线 程 2  执 行 同 步 体  c 替 换  Mark Word  不 成 功  暂 停 线 程  撤 销 偏 向 锁  撤 销 偏 向 锁  解 锁 ， 将 线 程  旧 设 为 空  0 《 01  恢 复 线 程"><p><strong>3****）使用场景</strong></p><p>​    始终只有一个线程在执行同步块，在它没有执行完释放锁之前，没有其它线程去执行同步块，在锁无竞争的情况下使用，一旦有了竞争就升级为轻量级锁，升级为轻量级锁的时候需要撤销偏向锁，撤销偏向锁的时候会导致stop the world操作； </p><p>​    在有锁竞争时，偏向锁会多做很多额外操作，尤其是撤销偏向所的时候会导致进入安全点，安全点会导致stw，导致性能下降；</p><p>轻量级锁</p><p>​    轻量级锁是由偏向锁升级来的，偏向锁运行在一个线程进入同步块的情况下，当第二个线程加入锁争用的时候，偏向锁就会升级为轻量级锁；</p><p>1）加锁</p><p>\1.  在进入同步代码块前，JVM会在当前线程的栈帧中创建用于存储锁记录的空间，并将对象头中的MarkWord复制到锁记录中。</p><p>\2.  然后线程尝试使用自旋将对象头中的MarkWord替换为指向锁记录的指针。</p><p>\3.  如果成功，当前线程获得轻量级锁，执行同步代码块。 如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。当自旋次数达到一定次数时，锁就会升级为重量</p><p>级锁，并阻塞线程。</p><p>2）解锁</p><p>​    解锁时，会使用自旋操作将锁记录替换回到对象头，相当于做一个对比。如果成功，表示没有竞争发生；如果失败，表示当前锁存在竞争，锁已经被升级为重量级锁，会</p><p>释放锁并唤醒等待的线程。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image048.gif" class="" title="Mark  CAStm  Mark Word  EMark Worde  CASH-4  Mark Word  Mark  HashCodelagel  0101  00  10  01  10  Ma rk Wordm  Mark Word"><p>重量级锁</p><p>​    重量级锁通过对象内部的监视器（monitor）实现，其中monitor的本质是依赖于底层操作系统的Mutex Lock实现，操作系统实现线程之间的切换需要从用户态到内核态的切换，切换成本非常高。</p><p>​    切换成本高的原因在于，当系统检查到是重量级锁之后，会把等待想要获取锁的线程阻塞，被阻塞的线程不会消耗CPU，但是阻塞或者唤醒一个线程，都需要通过操作系统来实现，也就是相当于从用户态转化到内核态，而转化状态是需要消耗时间的 。</p><p>​    简单来说就是：竞争失败后，线程阻塞，释放锁后，唤醒阻塞的线程，不使用自旋锁，不会那么消耗CPU，所以重量级锁适合用在同步块执行时间长的情况下。</p><p>锁的优缺点对比</p><table><thead><tr><th><strong>锁</strong></th><th><strong>优点</strong></th><th><strong>缺点</strong></th><th><strong>使用场景</strong></th></tr></thead><tbody><tr><td>偏向锁</td><td>加锁和解锁会存在CAS，没有额外的性能消耗，和执行非同步方法相比，仅存在纳秒级的差距</td><td>如果线程间存在锁竞争，会带来额外的锁撤销的消耗</td><td>只有一个线程访问同步块或者同步方法的场景</td></tr><tr><td>轻量级锁</td><td>竞争的线程不会阻塞，提高程序响应速度</td><td>若线程长时间抢不到锁，自旋会消耗CPU性能</td><td>追求响应时间。同步代码块执行非常快</td></tr><tr><td>重量级锁</td><td>线程竞争不使用自旋，不消耗CPU</td><td>线程阻塞，响应时间缓慢,在多线程下,频繁的获取释放锁，会带来巨大的性能消耗</td><td>追求吞吐量，同步块或者同步方法执行时间较长的场景</td></tr></tbody></table><p>小结</p><p><strong>偏向锁</strong>：在不存在多线程竞争情况下，默认会开启偏向锁。</p><p><strong>偏向锁升级轻量级锁</strong>：当一个对象持有偏向锁，一旦第二个线程访问这个对象，如果产生竞争，偏向锁升级为轻量级锁。</p><p><strong>轻量级锁升级重量级锁</strong>：一般两个线程对于同一个锁的操作都会错开，或者说稍微等待一下（自旋），另一个线程就会释放锁。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁膨胀为重量级锁，重量级锁使除了拥有锁的线程以外的线程都阻塞，防止CPU空转。</p><h1 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h1><p>造成死锁的原因</p><ul><li>当前线程<strong>拥有其他线程需要的</strong>资源</li><li>当前线程<strong>等待其他线程已拥有</strong>的资源</li><li><strong>都不放弃</strong>自己拥有的资源</li></ul><p>死锁演示</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image050.jpg" class="" title="public class DeadLock {  private static String valuel &#x3D; a&quot; private static String value2 &#x3D; b public static void args) { new DeadLock() .deadLock() ; private void deadLock() { Thread tI &#x3D; new try { System. out . running&quot; while synchronized System.out. lock valuel&quot;); RN! obi | Thread. sleep(3øøø) ; &#x2F;&#x2F; synchronized lock value2&quot;); }catch (Exception e){ e. printStackTrace() ; Thread t2 &#x3D; try { new System.out . running&quot; while synchronized System.out. lock value2&quot;); RN! obi | Thread. sleep(3øøø) ; &#x2F;&#x2F; synchronized Systen.out. lock valuel&quot; }catch (Exception e){ e. printStackTrace() ; tl.start(); %}&lt;p&gt;t2.start();&lt;&#x2F;p&gt;&lt;h1 id&#x3D;死锁排查&quot;&gt;&lt;a href&#x3D;#死锁排查 class&#x3D;headerlink title&#x3D;死锁排查&gt;&lt;&#x2F;a&gt;死锁排查&lt;&#x2F;h1&gt;&lt;p&gt; 通过JDK工具jps+jstack&lt;&#x2F;p&gt; &lt;p&gt;​ jps是jdk提供的一个工具，可以查看到正在运行的java进程&lt;&#x2F;p&gt; &lt;p&gt;​ jstack也是jdk提供的工具，可以查看java进程中线程堆栈信息。&lt;&#x2F;p&gt; &lt;p&gt;从输出的堆栈信息中可以发现：Found one Java-level deadLock。表示在这个程序中发现了死锁，后面的详细描述中已经指出了在22行和39行出现死锁。 那就可以根据这些信息快速定位到问题点进行优化处理。&lt;&#x2F;p&gt; &lt;p&gt; 通过JDK工具jconsole&lt;&#x2F;p&gt; &lt;p&gt;​ jconsole是JDK提供的一款可视化工具，可以更加方便的排查程序问题，如：内存溢出、死锁。&lt;&#x2F;p&gt; &lt;p&gt; 通过JDK工具VisualVM&lt;&#x2F;p&gt; &lt;p&gt;​ 其也是JDK提供的一款非常强大的程序问题检测工具，可以监控程序性能、查看JVM配置信息、堆栈信息。&lt;&#x2F;p&gt; &lt;p&gt;避免死锁的常见方法&lt;&#x2F;p&gt; &lt;p&gt;1）避免一个线程同时获取多个锁。&lt;&#x2F;p&gt; &lt;p&gt;2）避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。&lt;&#x2F;p&gt; &lt;p&gt;3）尝试使用定时锁，使用lock.tryLock(timeout)来替代使用内部锁机制。&lt;&#x2F;p&gt; &lt;p&gt;4）synchorized加锁&lt;&#x2F;p&gt; &lt;h1 id&#x3D;Volatile&gt;&lt;a href&#x3D;#Volatile class&#x3D;headerlink title&#x3D;Volatile&gt;&lt;&#x2F;a&gt;Volatile&lt;&#x2F;h1&gt;&lt;p&gt;不能保证共享变量的原子性&lt;&#x2F;p&gt; &lt;p&gt;volatile并不能保证原子性，因此在多线程下操作时，一个线程可能会读取到另外一个线程并未修改的数据。&lt;&#x2F;p&gt; &lt;p&gt;能够保证共享变量的可见性&lt;&#x2F;p&gt; &lt;p&gt;通过volatile修饰的变量，JMM并不会将其放入线程的本地内存，而是放入主内存中。从而该变量对于其他线程都是立即可见的。&lt;&#x2F;p&gt; &lt;p&gt;能够保证共享变量的有序性&lt;&#x2F;p&gt; &lt;p&gt;volatile能够禁止指令重排，因此能够在一定程度上保证有序性。当对volatile变量操作时，其前面的操作肯定全部已经执行完毕，其后面的操作肯定还没有执行。&lt;&#x2F;p&gt; &lt;p&gt;使用场景&lt;&#x2F;p&gt; &lt;p&gt;对其的使用必须同时满足下面两个条件才能保证在并发环境的线程安全：&lt;&#x2F;p&gt; &lt;ul&gt; &lt;li&gt;&lt;ul&gt; &lt;li&gt;- 对变量的写操作不依赖于当前值（比如 i++），或者说是单纯的变量赋值（boolean flag &#x3D; true）&lt;&#x2F;li&gt; &lt;li&gt;- 该变量没有包含在具有其他变量的不变式中，也就是说，不同的 volatile 变量之间，不能互相依赖。只有在状态真正独立于程序内其他内容时才能使用 volatile。&lt;&#x2F;li&gt; &lt;&#x2F;ul&gt; &lt;&#x2F;li&gt; &lt;&#x2F;ul&gt; &lt;p&gt;​ 同时volatile更适用于读多写少的场景。如有N个线程在读值，而只有一个线程在写值，则该值可以通过volatile修饰，即可保证多线程下的可见性，也可以保证变量的原子性。&lt;&#x2F;p&gt; &lt;p&gt;volatile一定能保证线程安全吗&lt;&#x2F;p&gt; &lt;p&gt;先说结论吧，volatile不能一定能保证线程安全。&lt;&#x2F;p&gt; &lt;p&gt;可见性不能保证操作的原子性，前面说过了count++不是原子性操作，会当做三步，先读取count的值，然后+1，最后赋值回去count变量。需要保证线程安全的话，需要使用synchronized关键字或者lock锁，给count++这段代码上锁：&lt;&#x2F;p&gt; &lt;p&gt;as-if-serial语义&lt;&#x2F;p&gt; &lt;p&gt;不管怎么重排序，（单线程）程序的执行结果不能被改变。&lt;&#x2F;p&gt; &lt;p&gt;什么是happen-before&lt;&#x2F;p&gt; &lt;p&gt; JMM可以通过happens-before关系向程序员提供跨线程的内存可见性保证（如果A线程的写操作a与B线程的读操作b之间存在happens-before关系，尽管a操作和b操作在不同的线程中执行，但JMM向程序员保证a操作将对b操作可见）。&lt;&#x2F;p&gt; &lt;p&gt;具体的定义为：&lt;&#x2F;p&gt; &lt;p&gt;1）如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。&lt;&#x2F;p&gt; &lt;p&gt;2）两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么这种重排序并不非法（也就是说，JMM允许这种重排序）。&lt;&#x2F;p&gt; &lt;p&gt;volatile禁止指令重排序的原理是什么&lt;&#x2F;p&gt; &lt;p&gt;首先要讲一下内存屏障，内存屏障可以分为以下几类：&lt;&#x2F;p&gt; &lt;p&gt;LoadLoad 屏障：对于这样的语句Load1，LoadLoad，Load2。在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。&lt;&#x2F;p&gt; &lt;p&gt;StoreStore屏障：对于这样的语句Store1， StoreStore， Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。&lt;&#x2F;p&gt; &lt;p&gt;LoadStore 屏障：对于这样的语句Load1， LoadStore，Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。&lt;&#x2F;p&gt; &lt;p&gt;StoreLoad 屏障：对于这样的语句Store1， StoreLoad，Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。&lt;&#x2F;p&gt; &lt;ul&gt; &lt;li&gt;&lt;ul&gt; &lt;li&gt;{% asset_img clip_image052.gif img"></li></ul></li></ul><p>在每个volatile读操作后插入LoadLoad屏障，在读操作后插入LoadStore屏障。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image054.gif" class="" title="preview"><h1 id="CAS"><a href="#CAS" class="headerlink" title="CAS"></a>CAS</h1><p>\1.   CAS概念</p><p>CAS（Compare and Swap），即比较并替换，是用于实现多线程同步的原子操作。</p><p>所谓原子操作是指不会被线程调度机制打断的操作。这种操作一旦开始，就一直运行到结束，中间不会有任何context switch（切换到另一个线程）。</p><p>​    实现原子操作可以使用锁，锁机制对于满足基本的原子需求是没问题的，但<strong>synchronized</strong>是基于阻塞的锁机制，也就是当一个线程拥有锁时，访问同一资源的其他线程需要等待，直到该线程释放锁。</p><p>​    同时基于<strong>synchronized</strong>实现原子操作也会出现很多问题。</p><ul><li><ul><li>优先级低的线程抢到锁，被阻塞的线程优先级很高很重要怎么办？</li><li>获得锁的线程一直不释放锁怎么办？</li><li>有大量的线程来竞争资源，则CPU会花费大量时间和资源来处理这些竞争。</li><li>死锁问题处理。</li></ul></li></ul><p>​    其实锁机制是一种较为粗糙，粒度比较大的机制，对于一些简单的需求，如计数器显得有点过于笨重。</p><p>\2.  CAS实现原理 </p><p>​    现代处理器基本都支持CAS指令，每一个CAS操作过程都包含三个运算符：<strong>内部地址****V</strong>、<strong>期望值****A</strong>、<strong>新值****B</strong>。操作时如果这个<strong>内存地址<strong><strong>V</strong></strong>上</strong>存放的值等于<strong>期望值****A</strong>，则将内存地址上的值修改为新值B，否则不做任何操作。常见的CAS循环其实就是在一个循环里不断的做CAS操作，直到成功为止。</p><p>​    CAS对于线程安全的实现，其是语言层面无任何处理，我们将其交CPU和内存完成，利用多核CPU的处理能力，实现硬件层面的阻塞，再加上volatile关键字的特性即可实现基于原子操作的线程安全。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image056.gif" class="" title="img"><p>\3.  悲观锁、乐观锁</p><p>悲观锁</p><p>悲观锁总是假设会出现最坏的情况，每次去获取数据时，都会认为别人会修改，所以每次在获取数据时都会上锁。这样别人想拿到这个数据就会阻塞，直到它获取到锁。在关系型数据库中就大量应用了这种锁机制，如行锁、表锁、读锁、写锁。都是在操作前先上锁。Java中<strong>synchronized</strong>就是很直观的体现。</p><p>乐观锁</p><p>乐观锁总是假设一直都是最好的情况。每次获取时都认为别人不会修改，所以不会上锁，但是在更新时会判断在此期间别人有没有更新这个数据，可以使用版本号实现。乐观锁适用于<strong>读多写少</strong>的场景。这样可以提升系统吞吐量，而CAS就是一种乐观锁的实现。</p><p>\4.   CAS的典型问题</p><p>ABA</p><p>一个线程a将数值改成了b，接着又改成了a，此时CAS认为是没有变化，其实是已经变化过了，这种过程就叫ABA问题。对于ABA问题的解决，常见的解决方式就是通过添加数据版本号实现</p><p>循环时间长开销大</p><p>CAS会基于CPU进行自旋操作，如果CAS失效，就会一直进行尝试，如果自旋时间过长，会给CPU带来巨大性能开销。在高并发下，compareAndSet会很大概率</p><p>失败，因此导致了CPU不断自旋，造成CPU性能浪费。</p><p>只能保证一个共享变量的原子操作</p><p>当对一个变量执行操作时，可以使用CAS循环方式保证原子操作，但对多个变量操作时，CAS则无法保证操作的原子性。因为对于一个内存地址来说，其内部只会存储一个变量。如果要对多个变量操作的话，则需要使用到锁或者进行合并(i&#x3D;2,j&#x3D;3 -&gt; 合并ij为一个变量 -&gt; 包装为一个引用类型 -&gt; 进行原子操作)。</p><h1 id="atomic原子操作类"><a href="#atomic原子操作类" class="headerlink" title="atomic原子操作类"></a>atomic原子操作类</h1><h2 id="原子更新基本类型"><a href="#原子更新基本类型" class="headerlink" title="原子更新基本类型"></a><strong>原子更新基本类型</strong></h2><p>AtomicInteger、AtomicBoolean、AtomicLong</p><p>1）**int addAndGet(i)**：以原子的方式将输入的数字与AtomicInteger里的值相加，并返回结果。</p><p>2）boolean compareAndSet(int expect, int update)：如果输入的数值等于预期值，则以原子方式将该值设置为输入的值</p><p>3）<strong>int incrementAndGet()<strong>：对原值+1，并返回操作后的值。类似与redis中的increment命令。相反的还有</strong>decrementAndGet()</strong></p><p>4）int getAndAdd(int delta)：原值加上指定值，并返回修改前的值。</p><p>5）int getAndSet(int newValue)：将原值修改为新值，并返回修改前的值。</p><p>6）**int getAndIncrement()**：原值加1，返回修改前的值。对应的还有getAndDecrement()</p><h2 id="原子更新数组"><a href="#原子更新数组" class="headerlink" title="原子更新数组"></a>原子更新数组</h2><p><strong>AtomicIntegerArray</strong>、<strong>AtomicLongArray</strong>、<strong>AtomicReferenceArray</strong>。</p><p>&#x2F;&#x2F;执行加法，第一个参数为数组的下标，第二个参数为增加的数量，返回增加后的结果</p><p>int addAndGet(int i, int delta)</p><p>&#x2F;&#x2F;对比修改，参1数组下标，参2原始值，参3修改目标值，成功返回true否则false</p><p>boolean compareAndSet(int i, int expect, int update)</p><p>&#x2F;&#x2F;参数为数组下标，将数组对应数字减少1，返回减少后的数据</p><p>int decrementAndGet(int i)</p><p>&#x2F;&#x2F; 参数为数组下标，将数组对应数字增加1，返回增加后的数据</p><p>int incrementAndGet(int i)</p><p>&#x2F;&#x2F;和addAndGet类似，区别是返回值是变化前的数据</p><p>int getAndAdd(int i, int delta)</p><p>&#x2F;&#x2F;和decrementAndGet类似，区别是返回变化前的数据</p><p>int getAndDecrement(int i)</p><p>&#x2F;&#x2F;和incrementAndGet类似，区别是返回变化前的数据</p><p>int getAndIncrement(int i)</p><p>&#x2F;&#x2F; 将对应下标的数字设置为指定值，第一个参数数组下标，第二个参数为设置的值，返回是变化前的数据 </p><p>getAndSet(int i, int newValue)</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image058.jpg" class="" title="img"><p>此时可以看到从AtomicIntegerArray获取的值与原传入数组的值不同。这是因为数组是通过构造方法传递，然后AtomicIntegerArray会将当前传入数组复制一份。因此当AtomicIntegerArray对内部数组元素进行修改时，不会影响原数组。</p><h2 id="原子更新引用类型"><a href="#原子更新引用类型" class="headerlink" title="原子更新引用类型"></a>原子更新引用类型</h2><p>通过CAS只能保证一个共享变量的原子操作，当多个的话，就需要使用到锁。如果要更新多个变量，就需要使用Atomic包中的三个类，分别为：</p><p><strong>AtomicReference</strong>(用于原子更新引用类型)、</p><p><strong>AtomicMarkableReference</strong>(用于原子更新带有标记位的引用类型)、<strong>AtomicStampedReference</strong>(用于原子更新带有版本号的引用类型)。</p><p><strong>AtomicMarkableReference</strong>可以用于解决CAS中的ABA的问题。</p><p><strong>AtomicStampedReference</strong>会基于版本号思想解决ABA问题，根据源码可知，其内部维护了一个Pair对象，<strong>Pair</strong>对象记录了对象引用和时间戳信息，实际使用的时候，要保证时间戳唯一，如果时间戳如果重复，还会出现<strong>ABA</strong>的问题。</p><p>AtomicStampedReference中的每一个引用变量都带上了pair.stamp这个时间戳，这样就可以解决CAS中的ABA的问题。</p><h2 id="原子更新字段类"><a href="#原子更新字段类" class="headerlink" title="原子更新字段类"></a>原子更新字段类</h2><p>当需要原子更新某个类里的某个字段时，就需要使用原子更新字段类。Atomic包下提供了3个类</p><p><strong>AtomicIntegerFieldUpdater</strong>(原子更新整型字段)、<strong>AtomicLongFieldUpdater</strong>(原子更新长整型字段)、<strong>AtomicReferenceFieldUpdater</strong>(原子更新引用类型字段)</p><p>原子更新字段类都是抽象类，每次使用都时候必须使用静态方法newUpdater创建一个更新器。原子更新类的字段的必须使用public volatile修饰符。</p><h2 id="JDK1-8新增原子类"><a href="#JDK1-8新增原子类" class="headerlink" title="JDK1.8新增原子类"></a>JDK1.8新增原子类</h2><p>LongAdder：长整型原子类</p><p>DoubleAdder：双浮点型原子类</p><p>LongAccumulator：类似LongAdder，但要更加灵活(要传入一个函数式接口)</p><p>DoubleAccumulator：类似DoubleAdder，但要更加灵活(要传入一个函数式接口)</p><p>以LongAdder为例，其内部提供的API基本上可以替换原先的AtomicLong。</p><p>​    LongAdder类似于AtomicLong是原子性递增或者递减类，AtomicLong已经通过CAS提供了非阻塞的原子性操作，相比使用阻塞算法的同步器来说性能已经很好了，但是JDK开发组并不满足，因为在非常高的并发请求下AtomicLong的性能不能让他们接受，虽然AtomicLong使用CAS但是CAS失败后还是通过无限循环的自旋锁不断尝试。</p><p>​    在高并发下N多线程同时去操作一个变量会造成大量线程CAS失败然后处于自旋状态，这大大浪费了cpu资源，降低了并发性。那么既然AtomicLong性能由于过多线程同时去竞争一个变量的更新而降低的，那么如果把一个变量分解为多个变量，让同样多的线程去竞争多个资源那么性能问题不就解决了？是的，JDK8提供的LongAdder就是这个思路。</p><p>在并发比较低的时候，LongAdder和AtomicLong的效果非常接近。但是当并发较高时，两者的差距会越来越大。</p><h1 id="示锁-Lock"><a href="#示锁-Lock" class="headerlink" title="示锁(Lock)"></a>示锁(Lock)</h1><h2 id="基础介绍"><a href="#基础介绍" class="headerlink" title="基础介绍"></a>基础介绍</h2><p>在程序中可以通过synchronized实现锁功能，对于它可以称为内置锁，是由Java语言层面直接为我们提供使用的。可以在程序中隐式的获取锁。但是对于它的使用方式是固化的，只能先获取再释放。而且在使用的过程中，当一个线程获取到某个资源的锁后，其他线程再要获取该资源则必须要进行等待。synchronized并没有提供中断或超时获取的操作。</p><p>为了解决这些问题，所以才出现了显示锁。在显示锁中其提供了三个很常见方法：lock()、unLock()、tryLock()。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image060.jpg" class="" title="lock. lock();  try(  lock.unLock();"><p>在 finally 块中释放锁，目的是保证在获取到锁之后，最终能够被释放。不要将获取锁的过程写在try块中，因为如果在获取锁（自定义锁的实现）时发生了异常，异常抛出的同时，也会导致锁无故释放。（因为一旦发生异常，就会走finally语句，如果这个异常（可能是用户自定义异常，用户可以自己处理）需要线程1来处理，但是接着执行了lock.unlock()语句导致了锁的释放。那么其他线程就可以操作共享资源。有可能破坏程序的执行结果）。</p><p>何时选择用synchronized还是Lock</p><p>如果在锁的使用过程中，不需要考虑尝试取锁或锁中断的这些特性的话。尽量使用synchronized。因为synchronized在现在的JDK中对于synchronized的优化是很多的。如锁优化升级。</p><p>同时synchronized要比显示锁的内存消耗要少。为什么呢？ 因为synchronized是一个语言层面的内容，而lock是一个接口，在使用Lock时需要获取其对象实例后才能进行操作。特别在锁很多的情况下，如没特殊需求，建议使用synchronized。</p><p>synchronized的使用要么作用在方法，要么作用在语句块。当出现异常后，代表脱离了执行的代码块，锁自然就会被释放。而显示锁本身是一个对象的实例，如果加锁后，没有进行释放的话，那么锁就会一直存在。</p><h2 id="ReentrantLock"><a href="#ReentrantLock" class="headerlink" title="ReentrantLock"></a>ReentrantLock</h2><h3 id="可重入"><a href="#可重入" class="headerlink" title="可重入"></a>可重入</h3><p>ReentrantLock可重入</p><p>ReentrantLock一般会把它称之为<strong>可重入锁</strong>，其是一种递归无阻塞的同步机制。它可以等同于synchronized的使用，但是ReentrantLock提供了比synchronized更强大、灵活的锁机制，可以减少死锁发生的概率。</p><p>简单来说就是：<strong>同一个线程对于已经获取的锁，可以多次继续申请到该锁的使用权</strong>。而 synchronized 关键字隐式的支持重进入，比如一个 synchronized修饰的递归方法，在方法执行时，执行线程在获取了锁之后仍能连续多次地获得该锁。ReentrantLock 在调用 lock()方法时，已经获取到锁的线程，能够再次调用lock()方法获取锁而不被阻塞。</p><p>​    其内部实现流程为：</p><ol><li>每个锁关联一个线程持有者和计数器，当计数器为0时表示该锁没有被任何线程持有，那么线程都会可能获得该锁而调用对应方法。</li><li>当某个线程请求成功后，JVM会记录锁的持有线程，并将计数器置为1，此时其他线程请求获取锁，则必须等待。</li><li>当持有锁的线程如果再次请求这个锁，就可以再次拿到这个锁，同时计数器递增。</li><li>当持有锁的线程退出同步代码块时，计数器递减，如果计数器为0，则释放该锁。</li></ol><p>synchronized可重入</p><p>当同一个线程调用多个同步方法时，当其第一次获取锁成功时，接着调用其他同步方法时，仍然可以继续向下调用，不会发生阻塞。实现了锁的可重入。</p><h3 id="公平锁与非公平锁"><a href="#公平锁与非公平锁" class="headerlink" title="公平锁与非公平锁"></a>公平锁与非公平锁</h3><p>在多线程并发执行中，当有多个线程同时来获取同一把锁，如果是按照谁等待时间最长，谁先获取锁，则代表这是一把公平锁。反之如果是随机获取的话，CPU时间片轮询到哪个线程，哪个线程就获取锁，则代表这是一把非公平锁。</p><p>那么公平锁和非公平锁哪个性能最好呢？ 答案是非公平锁的性能更好，因为其充分利用了CPU，减少了线程唤醒的上下文切换的时间。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image062.jpg" class="" title="ReentrantLock 中 的 公 平 锁 和 非 公 平 锁 的 底 层 实 现  首 先 不 管 是 公 平 锁 非 公 平 锁 。 它 们 的 底 层 实 现 都 会 使 用 AQS 来 洪 行 排 队 。 它 们 的 区 别 在 于 ： 线 程 在 使 用 》 。 鹵 〕 方 法 加 《 赶 如 果 是 公 平 锁 。 会 光 检  队 列 中 是 否 存 在 线 程 在 排 队 ， 如 果 有 线 悍 在 排 队 ， 贝 刂 当 前 线 也 进 行 排 队 ， 如 果 是 非 公 平 锁 ， 则 不 会 去 0 是 否 有 线 在 排 队 ， 而 是 白 接 竟 争  锁 。  不 管 是 公 平 锁 还 早 非 公 平 锁 ， 一 没 霓 争 到 锁 ， 都 会 行 排 队 ， 当 锁 释 放 时 ， 都 是 酶 排 在 吊 前 面 惺 ， 所 以 菲 平 锁 只 是 体 现 在 了 线 程 就 锁 阶  段 ， 而 没 有 体 现 在 线 程 被 埙 睚 阶 段 。  另 外 ， 入 顶， 不 管 是 公 平 还 皇 菲 公 平 锁 都 是 可 童 入"><p>在ReentrantLock和synchronized中，默认都为非公平锁。ReentrantLock可以通过参数将其开启使用公平锁。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image064.gif" class="" title="* Creates an instance of {@code ReentrantLock} with the  * given fairness policy.  * @param fair {@code true} if this Lock should use a fair ordering policy  public ReentrantLock(bootean fair) { sync &#x3D;  fair ? new FairSync()  new NonfairSync() ;"><p>参数：True 公平</p><p> 不传参 非公平</p><h3 id="ReentrantLock与synchronized的比较"><a href="#ReentrantLock与synchronized的比较" class="headerlink" title="**ReentrantLock与synchronized的比较"></a>**ReentrantLock与synchronized的比较</h3><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image066.jpg" class="" title="sychronized*QReentrantLockfiXBlJ  1. ReentrantLockH—ÎŠ  2.sychronizedžsĂtlffJjU@îłsgngtî,  4."><p><strong>相似点：</strong></p><p>​    都是以阻塞性方式进行加锁同步，也就是说如果当一个线程获得了对象锁，执行同步代码块，则其他线程要访问都要阻塞等待，直到获取锁的线程释放锁才能继续获取锁。</p><p><strong>不同点：</strong></p><ul><li>对于Synchronized来说，它是java语言的关键字，是原生语法层面的互斥，需要jvm实现。而ReentrantLock它是JDK 1.5之后提供的API层面的互斥锁，需要lock()和unlock()方法配合try&#x2F;finally语句块来完成。</li><li>Synchronized的使用比较方便简洁，并且由编译器去保证锁的加锁和释放，而ReenTrantLock需要手工声明来加锁和释放锁，为了避免忘记手工释放锁造成死锁，所以最好在finally中声明释放锁。</li><li>ReenTrantLock的锁粒度和灵活度要优于Synchronized。</li></ul><p>一、synchronized和lock的用法区别</p><p>synchronized：在需要同步的对象中加入此控制，synchronized可以加在方法上，也可以加在特定代码块中，括号中表示需要锁的对象。 </p><p>lock：需要显示指定起始位置和终止位置。一般使用ReentrantLock类做为锁，多个线程中必须要使用一个ReentrantLock类做为对象才能保证锁的生效。且在加锁和解锁处需要通过lock()和unlock()显示指</p><p>出。所以一般会在finally块中写unlock()以防死锁。 </p><p>二、synchronized和lock性能区别 </p><p>synchronized是托管给JVM执行的，而lock是java写的控制锁的代码。在Java1.5中，synchronize是性能低效的。因为这是一个重量级操作，需要调用操作接口，导致有可能加锁消耗的系统时间比加锁以外的操作还多。相比之下使用Java提供的Lock对象，性能更高一些。但是到了Java1.6，发生了变化。synchronize在语义上很清晰，可以</p><p>进行很多优化，有适应自旋，锁消除，锁粗化，轻量级锁，偏向锁等等。导致在Java1.6上synchronize的性能并不比Lock差。</p><p>据我所知，synchronized原始采用的是CPU悲观锁机制，即线程获得的是独占锁。独占锁意味着其他线程只能依靠阻塞来等待线程释放锁。而在CPU转换线程阻塞时会引起线程上下文切换，当有很多线程竞争锁的时候，会引起CPU频繁的上下文切换导致效率很低。 而Lock用的是乐观锁方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。乐观锁实现的机制就是CAS操作（Compare and Swap）。我们可以进一步研究ReentrantLock的源代码，会发现其中比较重要的获得锁的一个方法是compareAndSetState。这里其实就是调用的CPU提供的特殊指令。现代的CPU提供了指令，可以自动更新共享数据，而且能够检测到其他线程的干扰，而 compareAndSet() 就用这些代替了锁定。这个算法称作非阻塞算法，意思是一个线程的失败或者挂起不应该影响其他线程的失败或挂起的算法。</p><p><a href="https://blog.csdn.net/natian306/article/details/18504111">https://blog.csdn.net/natian306/article/details/18504111</a></p><h3 id="tryLock和lock的区别"><a href="#tryLock和lock的区别" class="headerlink" title="tryLock和lock的区别"></a>tryLock和lock的区别</h3><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image068.jpg" class="" title="i"><h2 id="ReentrantReadWriteLock"><a href="#ReentrantReadWriteLock" class="headerlink" title="ReentrantReadWriteLock"></a>ReentrantReadWriteLock</h2><p>ReentrantLock或synchronized都可以称之为<strong>独占锁、排他锁</strong>，可以理解为是悲观锁，这些锁在同一时刻只允许一个线程进行访问。但是对于互联网应用来说，绝大多数的场景都是读多写少，比例大概在10：1。按照数据库的场景来说，对于读多写少的处理，就会进行读写分离。</p><p>在读多写少的场景下，对于业务代码的处理，此时也可以考虑进行读写分别加锁的操作，此时就可以使用ReentrantReadWriteLock。其对ReadWriteLock接口进行实现，内部会维护一对锁，分别为读锁、写锁。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image070.gif" class="" title="img"><p><strong>读写锁特性</strong></p><ol><li>读操作不互斥，写操作互斥，读和写互斥。</li><li>公平性：支持公平性和非公平性。</li><li>重入性：支持锁重入。</li><li>锁降级：写锁能够降级成为读锁，遵循获取写锁、获取读锁在释放写锁的次序。读锁不能升级为写锁。</li></ol><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image072.gif" class="" title="img"><p><strong>读写锁实现原理</strong></p><p>ReentrantReadWriteLock实现接口ReadWriteLock，该接口维护了一对相关的锁，一个用于读操作，另一个用于写入操作。</p><p>ReadWriteLock定义了两个方法。readLock()返回用于读操作的锁，writeLock()返回用于写操作的锁。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image074.gif" class="" title="img"><p><strong>锁降级</strong></p><p>​    读写锁是支持锁降级的，但不支持锁升级。写锁可以被降级为读锁，但读锁不能被升级写锁。什么意思呢？简单来说就是<strong>获取到了写锁的线程能够再次获取到同一把锁的读锁</strong>，因为支持提到过ReentrantReadWriteLock这把锁内部是维护了两个锁的。 而<strong>获取到了读锁的线程不能再次获取同一把锁的写锁</strong>。</p><h2 id="StamptedLock"><a href="#StamptedLock" class="headerlink" title="StamptedLock"></a>StamptedLock</h2><p>StampedLock类是在JDK8引入的一把新锁，其是对原有ReentrantReadWriteLock读写锁的增强，增加了一个乐观读模式，内部提供了相关API不仅优化了读锁、写锁的访问，也可以让读锁与写锁间可以互相转换，从而更细粒度的控制并发。</p><h2 id="ReentrantReadWriteLock存在的问题"><a href="#ReentrantReadWriteLock存在的问题" class="headerlink" title="ReentrantReadWriteLock存在的问题"></a>ReentrantReadWriteLock存在的问题</h2><p>在使用读写锁时，还容易出现写线程饥饿的问题。主要是因为读锁和写锁互斥。比方说：当线程 A 持有读锁读取数据时，线程 B 要获取写锁修改数据就只能到队列里排队。此时又来了线程 C 读取数据，那么线程 C 就可以获取到读锁，而要执行写操作线程 B 就要等线程 C 释放读锁。由于该场景下读操作远远大于写的操作，此时可能会有很多线程来读取数据而获取到读锁，那么要获取写锁的线程 B 就只能一直等待下去，最终导致饥饿。</p><p>对于写线程饥饿问题，可以通过公平锁进行一定程度的解决，但是它是以牺牲系统吞吐量为代价的。</p><p><strong>StampedLock****特点</strong></p><p>1）获取锁的方法，会返回一个票据（stamp），当该值为0代表获取锁失败，其他值都代表成功。</p><p>2）释放锁的方法，都需要传递获取锁时返回的票据，从而控制是同一把锁。</p><p>3）StampedLock是<strong>不可重入的</strong>，如果一个线程已经持有了写锁，再去获取写锁就会造成死锁。</p><p>4）StampedLock提供了三种模式控制读写操作：写锁、悲观读锁、乐观读锁</p><p>写锁：</p><p>  使用类似于ReentrantReadWriteLock，是一把独占锁，当一个线程获取该锁后，其他请求线程会阻塞等待。 对于一条数据没有线程持有写锁或悲观读锁时，才可以获取到写锁，获取成功后会返回一个票据，当释放写锁时，需要传递获取锁时得到的票据。</p><p>悲观读锁：</p><p>  使用类似于ReentrantReadWriteLock，是一把共享锁，多个线程可以同时持有该锁。当一个数据没有线程获取写锁的情况下，多个线程可以同时获取到悲观读锁，当获取到后会返回一个票据，并且阻塞线程获取写锁。当释放锁时，需要传递获取锁时得到的票据。</p><p>乐观读锁：</p><p>  这把锁是StampedLock新增加的。可以把它理解为是一个悲观锁的弱化版。当没有线程持有写锁时，可以获取乐观读锁，并且返回一个票据。值得注意的是，它认为在获取到乐观读锁后，数据不会发生修改，获取到乐观读锁后，其并不会阻塞写入的操作。</p><p>  那这样的话，它是如何保证数据一致性的呢？ 乐观读锁在获取票据时，会将需要的数据拷贝一份，在真正读取数据时，会调用StampedLock中的API，验证票据是否有效。如果在获取到票据到使用数据这期间，有线程获取到了写锁并修改数据的话，则票据就会失效。 如果验证票据有效性时，当返回true，代表票据仍有效，数据没有被修改过，则直接读取原有数据。当返回flase，代表票据失效，数据被修改过，则重新拷贝最新数据使用。</p><p>  乐观读锁适用于一些很短的只读代码，它可以降低线程之间的锁竞争，从而提高系统吞吐量。但对于读锁获取数据结果必须要进行校验。</p><p>在StampedLock中读锁和写锁可以相互转换，而在ReentrantReadWriteLock中，写锁可以降级为读锁，而读锁不能升级为写锁。</p><h1 id="AQS"><a href="#AQS" class="headerlink" title="AQS"></a>AQS</h1><p>AQS(AbstractQueuedSynchronizer），即队列同步器。它是构建锁或者其他同步组件的基础框架（如ReentrantLock、ReentrantReadWriteLock、Semaphore等）</p><h2 id="CLH队列锁"><a href="#CLH队列锁" class="headerlink" title="CLH队列锁"></a><strong>CLH</strong>队列锁</h2><p>CLH队列锁即Craig, Landin, and Hagersten (CLH) locks。这是三个人的名字。 同时它也是现在PC机内部对于锁的实现机制。<strong>Java中的AQS就是基于CLH队列锁的一种变体实现。</strong></p><p>​    CLH 队列锁也是一种基于<strong>单向链表</strong>的可扩展、公平的<strong>自旋锁</strong>，申请线程仅仅在本地变量上自旋，它不断轮询前驱的状态，假设发现前驱释放了锁就结束自旋。</p><p>​    1）现在有一个队列，队列中的每一个QNode对应一个请求获取锁的线程，Qnode中包含两个属性，分别为myPred（前驱节点的引用）、locked（是否需要获取锁）</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image076.gif" class="" title="img"><p>​    2）当多个线程要请求获取锁时，则会按照请求顺序放入队列中。同时将myPred指向前驱节点的引用。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image078.gif" class="" title="img"><p>​    3）线程会对自己的myPred进行不断自旋查询，查看前驱节点是否释放锁。一旦发现前驱节点释放锁（locked属性变为false），则其会马上进行锁的获取。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image080.gif" class="" title="img"><p>​    4）当后续节点获取到锁后，则将原有的前驱节点从队列中移除。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image082.gif" class="" title="img"><h2 id="AQS的实现"><a href="#AQS的实现" class="headerlink" title="AQS的实现"></a>AQS的实现</h2><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image084.jpg" class="" title="四 、 谈 谈 你 对 AQS 的 理 解 。 AQS 如 何 实 现 可 重 入 锁 ？  1 ． QS 是 一 个 VA 线 片 同 步 的 眶 架 。 是 型 卜 中 很 多 锁 I 貝 的 以 现 眶 架 。  2 ． 中 ， 护 了 一 巪 05 和 一 个 线 程 沮 的 双 向 适 表 队 列 · 其 中 ， 这 臧 程 队 列 · 就 是 閹 来 线 陧 鼕 的 ， 而  訕 e 就 是 一 令 纟 I 象 用 来 厚 线 片 痱 从 或 者 行 的 。 在 不 同 的 巧 下 ， 有 不 用 的 0 义 ·  3 ， 在 可 0 人 锁 这 个 砀 到 下 ， 5 就 閹 来 不 力 过 的 次 数 · 0 标 丰 无 锁 ， 孬 一 次 ， 5 te 犹 加 1. 释 就 减 1 ·"><p>AQS本身是一个抽象类，其主要使用方式是继承，子类通过继承AQS并实现其内部定义的抽象方法。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image086.gif" class="" title="AbstractQueuedSynchronizer  Node  ConditionObject  static class initializer  try {  st...  AbstractQueuedSynchronizer0  getState0: int  setState(int): void  compareAndSetState(int, int): boolean  enq(Node): Node  addWaiter(Node): Node  setHead(Node): void  unparkSuccessor(Node): void  doReleaseShared0: void  setHeadAndPropagate(Node, int): void  cancelAcquire(Node): void  shouldParkAfterFailedAcquire(Node, Node): boole  selflnterrupt(): void  parkAndChecklnterrupt0: boolean  acquireQueued(Node, int): boolean  doAcquirelnterruptibly(int): void  doAcquireNanos(int, long): boolean  doAcquireShared(int): void  doAcquireSharedlnterruptibly(int): void  280  281  282  283  284  285  286  287  288  289  290  291  292  293  294  295  296  297  298  299  *  *  *  *  void signal()  public  public  sync .  @since 1.5  { sync. releaseShared(1);  void await() throws InterruptedException {  acquireSharedInterruptibty(1);  @author Doug Lea  public abstract class AbstractQueuedSynchronizer  extends AbstractOwnabteSynchronizer  implements java.io.Seriatizabte {  private static final tong serial VersionlJID  &#x3D; 7373984972572414691L;  * Creates a new {@code AbstractQueuedSynchronizer} instance  * with initial synchronization state of zero.  protected AbstractQueuedSynchronizer() {"><p>ReentrantLock、ReentrantReadWriteLock其内部其实都是基于AQS实现的。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image088.gif" class="" title="public class ReentrantLock implements Lock java.io. Serializabte {  private static final tong serial VersionlJID  &#x3D; 7373984872572414699L;  &#x2F; ** Synchronizer providing alt implementation mechanics  private final Sync sync;  * Base of synchronization control for this Lock. Subclassed  * into fair and nonfair versions below. Uses AQS state to  * represent the number of holds on the tock.  abstract static class Sync extends AbstractQueuedSynchronizer {  private static final tong serial VersionlJID - -  #10Ck}. The main reason for subclassing  * Performs {@tink  Lock  * is to allow fast path for nonfair version.  abstract void tock();"><p>他们两个并没有直接继承AQS，而是在其内部扩展了静态内部类来继承AQS。 这么做的原因，其思想就是通过区分使用者和实现者，来让使用者可以更加方便的完成对于锁的操作。</p><p>锁是面向使用者的，它定义了锁与使用者的交互实现方式，同时隐藏了实现细节。而AQS面向的是锁的实现者，其内部完成了锁的实现方式。从而通过区分锁和同步器让使用者和实现者能够更好的关注各自的领域。</p><p>AQS的设计模式使用的是<strong>模版设计模式</strong>。通过源码可以看到，在AQS中其并没有对方法进行具体实现，这些方法都是需要开发者自行来实现的。</p><p>模版设计模式在开发中涉及的非常多，简单来说就是：在一个方法中定义一个流程的骨架，对于流程的具体实现让其在子类中完成。以Spring为例，其内部就大量应用到了模版设计模式，如JDBCTemplate、RedisTemplate、RabbitTemplate等等。</p><p>AQS中的模版模式</p><p>其内部的模版方法大致可以分为三类：</p><ul><li>xxSharedxx：共享式获取与释放，如读锁。(共享锁就是多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改。)</li><li>acquire：独占式获取与释放，如写锁。(排他锁就是不能与其他所并存，如一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的其他锁)</li><li>查询同步队列中等待线程情况。</li></ul><p>AQS的同步状态</p><p>​    AQS对于锁的操作是通过同步状态切换来完成的，其有一个变量state，用于表示线程获取锁的状态。当state&gt;0时表示当前已有线程获取到了资源，当state &#x3D; 0时表示释放了资源。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image090.gif" class="" title="* The synchronization state.  private volatile int state;"><p>​    在多线程下，一定会有多个线程来同时修改state变量，所以在AQS中也提供了一些方法能够安全的对state值进行修改。分别为：</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image092.gif" class="" title="* Returns the current value of synchronization state.  * This operation has memory semantics of a {@code volatile} read.  * @return current state value  protected final int getState() {  return state;"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image094.gif" class="" title="* Sets the value of synchronization state.  * This operation has memory semantics of a {@code volatile} write.  * @param newState the new state value  protected final void setState(int newState) {  state  &#x3D; newState;"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image096.gif" class="" title="*  *  *  *  *  Atomically sets synchronization state to the given updated  value if the current state value equals the expected value.  This operation has memory semantics of a {@code volatile} read  and write.  @param expect the expected value  @param update the new value  @return {@code true} if SUCCeSSfUL. False return indicates that the actual  value was not equal to the expected value.  protected final boolean compareAndSetState(int expect, int update) {  &#x2F;&#x2F; See below for intrinsics setup to support this  return unsafe . compareAndSwapInt( o: this, state0ffset, expect, update) ;"><p> AQS实现原理</p><h3 id="Node节点"><a href="#Node节点" class="headerlink" title="Node节点"></a>Node节点</h3><p>​    之前提到过AQS是基于CLH队列锁的思想来实现的，其内部不同于CLH单向链表，而是使用的是<strong>双向链表</strong>。那么对于一个队列来说，其内部一定会通过一个节点来保存线程信息，如：前驱节点、后继节点、当前线程节点、线程状态这些信息。</p><p>​    根据源码可知，AQS内部定义一个Node对象用于存储这些信息。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image098.gif" class="" title="AbstractQueuedSynchronizer  Node  Node()  o  o  o  Node(Thread, Node)  Node(Thread, int)  isShared0: boolean  predecessor(): Node  SHARED: Node new Node()  EXCLUSIVE: Node null  CANCELLED: int  SIGNAL: int  CONDITION: int  PROPAGATE: int  waitStatus: int  prev: Node  next: Node  thread: Thread  nextWaiter: Node  -2  -3"><p><strong>两种线程等待模式：</strong></p><ul><li>SHARED：表示线程以<strong>共享模式等待锁</strong>，如读锁。</li><li>EXCLUSIVE：表示线程以<strong>独占模式等待锁</strong>，如写锁。<br> <strong>五种线程状态：</strong></li><li>初始Node对象时，默认值为0。</li><li>CANCELLED：表现线程获取锁的请求已经取消，值为1。</li><li>SINNAL：表现线程已经准备就绪，等待锁空闲给我，值为-1。</li><li>CONDITION：表示线程等待某一个条件被满足，值为-2。</li><li>PROPAGETE：当线程处于SHARED模式时，该状态才会生效，用于表示线程可以被共享传播，值为-3。<br> <strong>五个成员变量：</strong></li><li>waitStatus：表示线程在队列中的状态，值对应上述五种线程状态。</li><li>prev：表示当前线程的前驱节点。</li><li>next：表示当前线程的后继节点。</li><li>thread：表示当前线程。</li><li>nextWaiter：表示等待condition条件的节点。</li></ul><p>同时在AQS中还存在两个成员变量，head和tail，分别代表队首节点和队尾节点。</p><h3 id="节点在同步队列的操作"><a href="#节点在同步队列的操作" class="headerlink" title="节点在同步队列的操作"></a>节点在同步队列的操作</h3><p>​    在多线程并发争抢同步状态（锁）时，按照队列的FIFO原则，AQS会将获取锁失败的线程包装为一个Node放入队列尾部中。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image100.gif" class="" title="head  tail  Node  prev  next  Node  prev  ne  Node  rev  next"><p>​    对于加入队列的过程需要保证线程安全，AQS提供了一个基于CAS设置尾节点的方法<code>compareAndSetTail(Node expect,Node update)</code>。其需要传递当前期望的尾节点和当前节</p><p>点，当返回true，当前节点才与队列中之前的尾节点建立连接。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image102.gif" class="" title="Node  head  prev  next  tail  AQSßÅ5J  Node  prev  ne  Node  rev  next  Node  compareAndSetTail  c  mpareAndSet il  rev  next"><p>​    此时可以现头结点一定是获取锁成功的节点，头节点在释放锁时，会唤醒其后继节点。当后继节点获取锁成功后，则头节点的指针会指向该后继节点作为当前队列的头节</p><p>点，接着将原先的头结点从队列中移除。</p><p>​    对于该流程来说，只有一个线程能够获取到同步状态，因此不需要CAS进行保证。</p><p>只需要重新移动头部指针并断开原有引用连接即可。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image104.gif" class="" title="Node  compareAndSetTail  head  tail  AQSßÅ5J  Node  prev  ne  Node  prev  next  Node  rev  next  c mpareAndSet il  rev  next"><p>示例：</p><p>A线程进来了，当前窗口没有人，就会占用窗口（Thread &#x3D; ThreadA），并且state &#x3D; 1；</p><p>B线程进来的，不能占用窗口，队列为空，构建哨兵节点</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image106.jpg" class="" title="img"><p>构建完哨兵节点，在将B线程放入队列</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image108.jpg" class="" title="img"><p>c线程也是一样的操作，放到队列中</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image110.jpg" class="" title="img"><p>B还是会去抢占锁，还是失败后，就会调用park，真正去阻塞（真正在队列中等待）</p><p>c也一样</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image112.jpg" class="" title="img"><p>线程A调用unlock（）释放资源</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image114.jpg" class="" title="img"><p>这时候就会唤醒头节点的下一个节点（也就是B线程），B占用资源之后，就会将链表中的B节点编程哨兵节点，原哨兵会jc掉</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image115.jpg" class="" title="img"><p>这是原来的哨兵节点就是完全孤立的一个节点，此时 nodeB 作为新的哨兵节点</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image117.jpg" class="" title="img"><h1 id="Fork-Join分解合并框架"><a href="#Fork-Join分解合并框架" class="headerlink" title="Fork&#x2F;Join分解合并框架"></a>Fork&#x2F;Join分解合并框架</h1><p>同时其按照<strong>分而治之</strong>的思想，可以把一个大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架。</p><p>对于Fork&#x2F;Join框架的理解可以认为其由两部分组成，Fork就是把一个大任务切分为若干个子任务并行执行。Join就是合并这些子任务的执行结果，最后得到这个大任务的结果。</p><h3 id="工作窃取算法"><a href="#工作窃取算法" class="headerlink" title="工作窃取算法"></a>工作窃取算法</h3><p>即当前线程的 Task 已经全被执行完毕，则自动取到其他线程的 Task 池中取出 Task 继续执行。ForkJoinPool 中维护着多个线程（一般为 CPU 核数）在不断地执行 Task，每个线程除了执行自己任务列表内的 Task 之外，还会根据自己工作线程的闲置情况去获取其他繁忙的工作线程的 Task，如此一来就能能够减少线程阻塞或是闲置的时间，提高 CPU 利用率。</p><h3 id="Fork-Join的使用"><a href="#Fork-Join的使用" class="headerlink" title="Fork&#x2F;Join的使用"></a>Fork&#x2F;Join的使用</h3><p>基本概念</p><p>​    要使用Fork&#x2F;Join的话，首先需要有一个Pool。通过它可以来执行任务。 而每一个任务叫做ForkJoinTask，其内部提供了fork和join的操作机制。通常情况下开发者不需要直接继承ForkJoinTask，而是继承它的子类。分别为：</p><p>- <strong>RecursiveAction</strong>：返回没有结果的任务。</p><p>- **RecursiveTask<T>**：返回有结果的任务。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image119.gif" class="" title="img"><p>1）新建ForkJoinPool；</p><p>2）新建ForkJoinTask(RecursiveAction || RecursiveTask);</p><p>3）在任务中的compute方法，会根据自定义条件进行任务拆分，如果条件满足则执行任务，如果条件不满足则继续拆分任务。当所有任务都执行完，进行最终结果的汇总。</p><p>4）最终通过get或join获取数据结果。</p><p>(同步意味着以某种方式 “连接” 或 “依赖”。换句话说，两个同步任务必须彼此了解，并且一个任务必须以某种方式执行，这取决于另一个任务，例如等待启动直到另一个任务完成。 </p><p>异步意味着它们是完全独立的，无论是在启动还是执行中，都不能以任何方式考虑对方。)</p><h1 id="并发工具类"><a href="#并发工具类" class="headerlink" title="并发工具类"></a>并发工具类</h1><p>CountDownLatch、CyclicBarrier、Semaphore、Exchanger。通过他们可以在不同场景下完成一些特定的功能。</p><p>可完成异步转同步</p><h2 id="CountDownLatch闭锁"><a href="#CountDownLatch闭锁" class="headerlink" title="CountDownLatch闭锁"></a>CountDownLatch闭锁</h2><p>CountDownLatch一般会把它称之为<strong>闭锁</strong>，其<strong>允许一个或多个线程等待其他线程完成操作</strong>。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image121.gif" class="" title="img"><p>CountDownLatch内部是通过计数器实现，当执行到某个节点后，就会开始等待其他任务执行。每完成一个任务，计数器就会减一，当计数器等于0时，代表任务已全部完成，则恢复之前的等待线程继续向下运行。</p><p>使用场景</p><p>根据其工作的特性，使用的场景也是比较多的。假设现在要解析一个Excel文件，其内部会存在多个sheet (sheet就是excle中的一个工作表。)，则设定每个线程解析一个sheet，等到解析完所有sheet后。再进行后续操作。这就是一个很常见的场景。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image123.jpg" class="" title="img"><h2 id="CycliBarrier同步屏障"><a href="#CycliBarrier同步屏障" class="headerlink" title="CycliBarrier同步屏障"></a>CycliBarrier同步屏障</h2><p>CycliBarrier翻译过来叫做<strong>可循环的屏障</strong>。其可以实现当一组线程执行时，当到达某个屏障（同步点）被阻塞，直到最后一个线程到达屏障后，才会让这一组线程继续向下执行。 其内部也是基于计数器思想实现。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image125.gif" class="" title="img"><p>对于CycliBarrier来说，其在基本流程的基础上，也进行了一个扩展。查看源码可知，其构造函数不仅可以传入需要等待的线程数，同时还可以传入一个Runnable。对于这个runnable可以作为一个扩展任务来使用。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image127.gif" class="" title="img"><p>子线程与主线程间首先会进行相互等待，只有等到其他线程都执行完毕后，才能继续向下执行。因为主线程和子线程是由CPU来进行调度，所以顺序不可控。</p><p>此时如果将线程数由3改为4则会永久等待，因为没有第四个线程执行await()方法，即没有第四个线程到达屏障，所以之前到达屏障的三个线程都不会继续向下执行。</p><p>扩展实现</p><p>​    CyclicBarrier还提供了一个更高级的构造函数，不仅可以设置等待线程数量，同时还能够设置一个优先执行的Runnable，方便处理更为复杂的业务场景。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image129.gif" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image131.gif" class="" title="img"><p>与CountDownLatch的区别</p><p>1）CountDownLatch.await 一般阻塞工作线程，所有的进行预备工作的线程执行countDown，而 CyclicBarrier 通过工作线程调用 await 从而自行阻塞，直到所有工作线程达到指定屏障，再大家一起往下走。</p><p>2）在控制多个线程同时运行上，CountDownLatch 可以不限线程数量，而CyclicBarrier 是固定线程数。</p><h2 id="Semaphore信号量"><a href="#Semaphore信号量" class="headerlink" title="Semaphore信号量"></a>Semaphore信号量</h2><p>其可以用于做流量控制，通过控制同时访问资源的线程数量，从而保证资源能够被更加合理的使用，如连接资源。假设现在要获取几万个文件资源，那么现在可以开启若干线程进行并发读取。但是读取后还要把这些数据写入到数据库。而数据库连接现在只有100个，此时就需要人为干预，控制只有100个线程同时获取数据库连接资源保存数据。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image133.gif" class="" title="img"><h2 id="Exchanger交换器"><a href="#Exchanger交换器" class="headerlink" title="Exchanger交换器"></a>Exchanger交换器</h2><p>Exchanger是一个线程协作工具类，可以进行线程间的数据交换，但是只局限于两个线程间协作。它提供了一个同步点，在这个同步点，两个线程可以交换彼此的数据。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image135.gif" class="" title="img"><h2 id="CountDownLatch和Semaphore的区别"><a href="#CountDownLatch和Semaphore的区别" class="headerlink" title="CountDownLatch和Semaphore的区别"></a>CountDownLatch和Semaphore的区别</h2><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image137.jpg" class="" title="img"><h2 id="让ABC三个进程同时，依次，交错进行"><a href="#让ABC三个进程同时，依次，交错进行" class="headerlink" title="让ABC三个进程同时，依次，交错进行"></a>让ABC三个进程同时，依次，交错进行</h2><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image138.jpg" class="" title="img"><p>Semaphore</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image139.jpg" class="" title="img"><p>同时：</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image140.jpg" class="" title="img"><p>依次：</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image141.jpg" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image142.jpg" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image143.jpg" class="" title="img"><p>有序交错：</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image144.jpg" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image145.jpg" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image146.jpg" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image147.jpg" class="" title="img"><h2 id="如何对一个字符串进行快速排序"><a href="#如何对一个字符串进行快速排序" class="headerlink" title="如何对一个字符串进行快速排序"></a>如何对一个字符串进行快速排序</h2><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image149.jpg" class="" title="img"><h1 id="ThreadLocal"><a href="#ThreadLocal" class="headerlink" title="ThreadLocal"></a>ThreadLocal</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>ThreadLocal是多线程中对于解决线程安全的一个操作类，它会为每个线程都分配一个独立的线程副本**从而解决了变量并发访问冲突的问题。ThreadLocal比直接使用synchronized同步机制解决线程安全问题更简单，更方便，且结果程序拥有更高的并发性。</p><p>一个经典的例子，使用JDBC操作数据库时，会将每一个线程的Connection放入各自的ThreadLocal中，从而保证每个线程都在各自的 Connection 上进行数据库的操作，避免A线程关闭了B线程的连接。</p><p>ThreadLocal与Synchonized区别</p><p>ThreadLocal和Synchonized都用于解决多线程并发访问。Synchronized用于线程间的数据共享，而ThreadLocal则用于线程间的数据隔离。Synchronized通过锁机制使得变量在同一时刻只能被一个线程访问，而ThreadLocal为每一个线程提供一个变量副本，使得每个线程都只能对自己线程内部数据进行维护，从而实现共享数据的线程隔离。</p><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>在ThreadLocal内部维护了一个内部类ThreadLocalMap。而且在ThreadLocalMap中又维护了一个Entry内部类和一个Entry数组。实际上，在ThreadLocal内部的维护了一个ThreadLocalMap，<strong>每个线程持有一个ThreadLocalMap对象</strong>，在ThreadLocalMap中为每一个线程都维护了一个数组table，而这个数组中会通过<strong>下标</strong>来确定存储数据的位置。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image150.jpg" class="" title="img"><ul><li><strong>对于同一线程的不同<strong><strong>ThreadLocal</strong></strong>来讲，这些<strong><strong>ThreadLocal</strong></strong>实例共享一个<strong><strong>table</strong></strong>数组，然后每个<strong><strong>ThreadLocal</strong></strong>实例在数组中的下标值<strong><strong>i</strong></strong>是不同的。</strong></li><li>*<em>对于某一个</em><em><strong>ThreadLocal</strong></em><em>来讲，他的下标值</em><em><strong>i</strong></em><em>是确定的，在不同线程之间访问时访问的是不同的</em><em><strong>table</strong></em><em>数组的同一位置即都为</em><em>*<em>table[i]<strong><strong>，只不过这个不同线程之间的</strong></strong>table</em>*</em><em>是独立的。</em>*</li></ul><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image152.gif" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image154.gif" class="" title="img"><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>Spring采用Threadlocal来保证单个线程中的数据库操作使用的是同一个数据库连接，同时，采用这种方式可以使业务层使用事务时不需要感知并管理connection对象，通过传播级别管理多个事务配置之间的切换，挂起和恢复。在Spring内部中存在一个类<strong>TransactionSynchronizationManager</strong>，该类实现了事务管理与数据访问服务的解</p><p>耦，同时也保证了多线程环境下connection的线程安全问题。</p><p>ThreadLocal：Spring中@Transaction注解，Mybitis中分页的处理</p><p>线上日期错误</p><p>开发中经常会使用到SimpleDataFormat进行日期格式化，当调用SimpleDataFormat的parse方法进行日期解析时，会先调用SimpleDataFormat内部的Calendar.clear()，然后调用Calendar.add()，如果一个线程先调用了add()然后另一个线程又调用了clear()，这</p><p>时候parse方法解析的时间就不对了，最终导致部分用户的日期不对。</p><p>解决方案：对于这个问题的解决思路，就是让每个线程都拥有一个自己的SimpleDataFormat，可是直接new的方式性能并不好，此时就可以通过ThreadLocal进行解决，使用线程池加上ThreadLocal包装 SimpleDataFormat ，让每个线程有一个 SimpleDataFormat 的副本，从而解决了线程安全的问题，也提高了性能。</p><p>跨服务方法传参</p><p>在项目开发中，有可能存在一个线程横跨若干服务若干方法调用，经常需要传递一些状态性的信息，如用户认证信息等。如果要想完成这件事，其中一种方式可以通过Context上下文对象进行传参，但是通过上下文传参的话，有可能导致参数传不进去，所以通过ThreadLocal进行改造，当set完数据后，只要保证是在同一个线程中，则其他地方还需要get就可以了。</p><p> ThreadLocal经典问题-内存泄露</p><p>内存泄露：不会再被使用的对象或变量占用的内存不能被回收。</p><p> Java对象的四种引用类型</p><p>强引用：最为普通的引用方式，表示一个对象处于有用且必须的状态，如果一个对象具有强引用，则GC并不会回收它。即便堆中内存不足了，宁可出现</p><p>OOM，也不会对其进行回收</p><p>软引用：表示一个对象处于有用且非必须状态，如果一个对象处于软引用，在内存空间足够的情况下，GC机制并不会回收它，而在内存空间不足时，则会在OOM异常出现之间对其进行回收。但值得注意的是，因为GC线程优先级较低，软引用并不会立即被回收。（用于缓存）</p><p>弱引用：表示一个对象处于可能有用且非必须的状态。在GC线程扫描内存区域时，一旦发现弱引用，就会回收到弱引用相关联的对象。对于弱引用的回收，无关内存区域是否足够，一旦发现则会被回收。同样的，因为GC线程优先级较</p><p>低，所以弱引用也并不是会被立刻回收。（防止一些map的内存泄露，ThreadLocal防内存泄露）</p><p>虚引用：表示一个对象处于无用的状态。在任何时候都有可能被垃圾回收。虚</p><p>引用的使用必须和引用队列Reference Queue联合使用（专门用来管理堆外内存的，回收的时候给个信号，JVM里用来管理直接内存）</p><p>内存泄露原因分析</p><p>ThreadLocalMap中的Entry对象继承了WeakReference。其中key为使用弱引用的</p><p>ThreadLocal实例，value为线程变量的副本。</p><p>那么为什么要把key定义为使用弱引用的ThreadLocal呢？假设将key定义为强引用，回收ThreadLocal时，因为ThreadLocalMap还持有ThreadLocal的强引用，如果没有手动删除，ThreadLocal不会被回收，最终导致Entry内存泄漏。</p><p>为了避免该问题，则将key定义为弱引用，但是当GC时，则会造成因为key是弱引用，因此会被回收掉，但是value是强引用，仍然会存在，最终造成value的内存泄露。</p><p>如要避免ThreadLocal内存泄露的出现，也非常的简单。对于ThreadLocal的使</p><p>用，务必记得要在最后一步执行remove即可。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image156.jpg" class="" title="img"><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image158.jpg" class="" title="img"><h1 id="ThreadPoolExecutor线程池"><a href="#ThreadPoolExecutor线程池" class="headerlink" title="ThreadPoolExecutor线程池"></a>ThreadPoolExecutor线程池</h1><h2 id="线程池的优点和应用场景"><a href="#线程池的优点和应用场景" class="headerlink" title="线程池的优点和应用场景"></a>线程池的优点和应用场景</h2><ul><li><ul><li>降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。</li><li>提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。</li><li>提高线程的可管理性。线程是稀缺资源，要合理利用分配，通过线程池可以进行统一分配、调优和监控。</li></ul></li></ul><p><strong>一、线程池使用场景</strong></p><p>•单个任务处理时间短</p><p>•将需处理的任务数量大</p><p><strong>二、使用<strong><strong>Java</strong></strong>线程池好处</strong></p><p>*<em>1</em><em><strong>、使用</strong></em>*new Thread()**<strong>创建线程的弊端：</strong></p><p>•每次通过new Thread()创建对象性能不佳。</p><p>•线程缺乏统一管理，可能无限制新建线程，相互之间竞争，及可能占用过多系统资源导致死机或oom。</p><p>•缺乏更多功能，如定时执行、定期执行、线程<a href="https://so.csdn.net/so/search?q=%E4%B8%AD%E6%96%AD&spm=1001.2101.3001.7020">中断</a>。</p><p><strong>2<strong><strong>、使用</strong></strong>Java****线程池的好处：</strong></p><p>•重用存在的线程，减少对象创建、消亡的开销，提升性能。</p><p>•可有效控制最大并发线程数，提高系统资源的使用率，同时避免过多资源竞争，避免堵塞。</p><p>•提供定时执行、定期执行、单线程、并发数控制等功能。</p><p><strong>线程池的作用：</strong></p><p>线程池作用就是限制系统中执行线程的数量。</p><p>根 据系统的环境情况，可以自动或手动设置线程数量，达到运行的最佳效果；少了浪费了系统资源，多了造成系统拥挤效率不高。用线程池控制线程数量，其他线程排 队等候。一个任务执行完毕，再从队列的中取最前面的任务开始执行。若队列中没有等待进程，线程池的这一资源处于等待。当一个新任务需要运行时，如果线程池 中有等待的工作线程，就可以开始运行了；否则进入等待队列。</p><p><strong>为什么要用线程池:</strong></p><p>1.减少了创建和销毁线程的次数，每个工作线程都可以被重复利用，可执行多个任务。</p><p>2.可以根据系统的承受能力，调整线程池中工作线线程的数目，防止因为消耗过多的内存，而把服务器累趴下(每个线程需要大约1MB内存，线程开的越多，消耗的内存也就越大，最后死机)。</p><h2 id="线程池状态"><a href="#线程池状态" class="headerlink" title="线程池状态"></a>线程池状态</h2><p>线程池存在五种状态：RUNNING、 SHUTDOWN,、STOP、TIDYING、TERMINATED。</p><p>RUNNING：处于RUNNING状态的线程池能够接受新任务，以及对新添加的任务进行处理。</p><p>SHUTDOWN：处于SHUTDOWN状态的线程池不可以接受新任务，但是可以对已添加的任务进行处理。</p><p>STOP：处于STOP状态的线程池不接收新任务，不处理已添加的任务，并且会中断正在处理的任务。</p><p>TIDYING：（tidying使整洁）当所有的任务已终止，线程池会变为TIDYING状态。当线程池变为TIDYING状态时，会执行钩子函数terminated()。terminated()在ThreadPoolExecutor类中是空的，若用户想在线程池变为TIDYING时，进行相应的处理；可以通过重载terminated()函数来实现。</p><p>TERMINATED：（terminated停止）线程池彻底终止的状态。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image160.gif" class="" title="img"><h2 id="线程池创建的各个参数含义"><a href="#线程池创建的各个参数含义" class="headerlink" title="线程池创建的各个参数含义"></a><strong>线程池创建的各个参数含义</strong></h2><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image162.gif" class="" title="img"><p><strong>corePoolSize****：</strong></p><p>​    核心线程数(线程池基本大小)，在没有任务需要执行的时候的线程池大小。当提交一个任务时，线程池创建一个新线程执行任务，直到线程数等于该参数。 如果当前线程数为该参数，后续提交的任务被保存到阻塞队列中，等待被执行。</p><p><strong>maximumPoolSize****：</strong></p><p>​    线程池中允许的最大线程数，线程池中的当前线程数目不会超过该值。如果当前阻塞队列满了，且继续提交任务，如果当前的线程数小于maximumPoolSize，则会新建线程来执行任务。</p><p><strong>keepAliveTime****：</strong></p><p>​     多余的线程没有任务执行之后，线程在线程池中最多待多久的时间才销毁，直到只剩下corePoolSize个线程为止。默认情况下，该参数只在线程数大于corePoolSize时才有用。</p><p><strong>TimeUnit****：</strong>参数keepAliveTime的时间单位，一共7种取值：天，小时，分钟，秒，毫秒，微妙，纳秒</p><p><strong>workQueue****：</strong></p><p>​    其必须是BolckingQueue有界阻塞队列，用于实现线程池的阻塞功能。当线程池中的线程数超过它的corePoolSize时，线程会进入阻塞队列进行阻塞等待。</p><p><strong>threadFactory</strong>：</p><p>​    用于设置创建线程的工厂。ThreadFactory的作用就是提供创建线程的功能的线程工厂。他是通过newThread()方法提供创建线程的功能，newThread()方法创建的线程都是“非守护线程”而且“线程优先级都是默认优先级”。（用户线程即运行在前台的线程,而守护线程是运行在后台的线程。）</p><p><strong>handler****：</strong></p><p>​    线程池拒绝策略。当阻塞队列满了，且没有空闲的工作线程，如果继续提交任务，则必须采取一种策略处理该任务。</p><p>AbortPolicy：默认策略，直接抛出异常。</p><p>CallerRunsPolicy：用调用者所在的线程执行任务。</p><p>DiscardOldestPolicy：丢去阻塞队列的头部任务，并执行当前任务。</p><p>DiscardPolicy：直接丢弃任务。</p><h2 id="线程池工作机制"><a href="#线程池工作机制" class="headerlink" title="线程池工作机制"></a>线程池工作机制</h2><ul><li><ol><li>如果当前运行的线程少于corePoolSize，则创建新线程来执行任务（执行这一步前，需要获取全局锁）。</li><li>如果运行的线程等于或多于corePoolSize，则将任务加入BlockingQueue。</li><li>如果无法将任务加入BlockingQueue，则创建新线程处理任务。</li><li>如果创建的新线程使当前运行的线程超出maximumPoolSize，任务将被拒绝。</li></ol></li></ul><h2 id="五种预定义线程池"><a href="#五种预定义线程池" class="headerlink" title="五种预定义线程池"></a>五种预定义线程池</h2><h3 id="FixedThreadPool"><a href="#FixedThreadPool" class="headerlink" title="FixedThreadPool"></a>FixedThreadPool</h3><p>创建使用固定线程数的线程池。适用于为了满足资源管理而需要限制当前线程数量</p><p>的场景。同时也适用于负载较重的服务器。其定义如下：</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image164.jpg" class="" title="img"><p><strong>nThreads</strong>：</p><p>FixedThreadPool 的 corePoolSize 和 maximumPoolSize 都被设置为创建FixedThreadPool 时指定的参数 nThreads。</p><p><strong>keepAliveTime</strong>：</p><p>此处设置为了0L，代表多于的空闲线程会被立即终止。</p><p><strong>LinkedBlockingQueue</strong>：</p><p>FixedThreadPool 使用有界队列 LinkedBlockingQueue 作为线程池的工作队列（队列的容量为 Integer.MAX_VALUE）。</p><h3 id="SingleThreadExecutor"><a href="#SingleThreadExecutor" class="headerlink" title="SingleThreadExecutor"></a>SingleThreadExecutor</h3><p>只会使用单个工作线程来执行一个无边界的队列。适用于保证顺序地执行各个人物，并且在任意时间点，不会有多个线程存在活动的应用场景。</p><p>corePoolSize 和 maximumPoolSize 被设置为 1。其他参数与 FixedThreadPool相同。SingleThreadExecutor 使用有界队列 LinkedBlockingQueue 作为线程池的工作队列（队列的容量为 Integer.MAX_VALUE）。</p><h3 id="CachedThreadPool"><a href="#CachedThreadPool" class="headerlink" title="CachedThreadPool"></a>CachedThreadPool</h3><p>​    其是一个大小无界的线程池，会根据需要创建新线程。适用于执行很多的短期异步</p><p>任务的小程序或者是负载较轻的服务器。</p><p>corePoolSize 被设置为 0，即 corePool 为空；maximumPoolSize 被设置为Integer.MAX_VALUE。这里把 keepAliveTime 设置为 60L，意味着 CachedThreadPool中</p><p>的空闲线程等待新任务的最长时间为60秒，空闲线程超过60秒后将会被终止。</p><p>FixedThreadPool 和 SingleThreadExecutor 使用有界队列 LinkedBlockingQueue作为线程池的工作队列。CachedThreadPool 使用没有容量的 SynchronousQueue作为线程池的工作队列，但 CachedThreadPool 的 maximumPool 是无界的。这意味着，如果主线程提交任务的速度高于 maximumPool 中线程处理任务的速度时，</p><p>CachedThreadPool 会不断创建新线程。极端情况下，CachedThreadPool 会因为创建过</p><p>多线程而耗尽 CPU 和内存资源。</p><h3 id="ScheduledThreadPoolExecutor"><a href="#ScheduledThreadPoolExecutor" class="headerlink" title="ScheduledThreadPoolExecutor"></a>ScheduledThreadPoolExecutor</h3><p>ScheduledThreadPoolExecutor，继承ThreadPoolExecutor且实现了ScheduledExecutorService接口，它就相当于提供了“延迟”和“周期执行”功能的ThreadPoolExecutor。它可另行安排在给定的延迟后运行命令，或者定期执行命令。它适用于为了满足资源管理的需求而需要限制后台线程数量的场景同时可以保证多任务的顺序执行。</p><p>在ScheduledThreadPoolExecutor的构造函数中，我们发现它都是利用ThreadLocalExecutor来构造的，唯一变动的地方就在于它所使用的阻塞队列变成了DelayedWorkQueue。</p><p>DelayedWorkQueue为ScheduledThreadPoolExecutor中的内部类，类似于延时队列和优先级队列。在执行定时任务的时候，每个任务的执行时间都不同，所以DelayedWorkQueue的工作就是按照执行时间的升序来排列，执行时间距离当前时间越近的任务在队列的前面（执行时间短的在前面），这样就可以保证每次出队的任务都是当前队列中执行时间最靠前的。</p><h3 id="WorkStealingPool"><a href="#WorkStealingPool" class="headerlink" title="WorkStealingPool"></a>WorkStealingPool</h3><p>其是JDK1.8中新增的线程池，利用所有运行的CPU来创建一个工作窃取的线程池，是对ForkJoinPool的扩展，适用于非常耗时的操作。</p><h2 id="阻塞队列"><a href="#阻塞队列" class="headerlink" title="阻塞队列"></a>阻塞队列</h2><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image166.jpg" class="" title="img"><ul><li><ol><li>ArrayBlockingQueue： 基于数组结构的<strong>有界阻塞队列</strong> ，按<strong>FIFO****（先进先出）原则</strong> 对任务进行排序。使用该队列，线程池中能创建的最大线程数为maximumPoolSize。</li><li>LinkedBlockingQueue： 基于链表结构的<strong>无界阻塞队列</strong> ，按<strong>FIFO****（先进先出）原则</strong> 对任务进行排序，吞吐量高于ArrayBlockingQueue。使用该队列，线程池中能创建的最大线程数为corePoolSize。<strong>静态工厂方法</strong> Executor.newFixedThreadPool()使用了这个队列。</li><li>SynchronousQueue： 一个<strong>不存储元素</strong> 的阻塞队列。添加任务的操作必须等到另一个线程的移除操作，否则添加操作一直处于阻塞状态。<strong>静态工厂方法</strong> Executor.newCachedThreadPool()使用了这个队列。</li><li>PriorityBlokingQueue： 一个<strong>支持优先级</strong> 的<strong>无界阻塞队列</strong> 。使用该队列，线程池中能创建的最大线程数为corePoolSize。</li><li><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image168.jpg" class="" title="img"></li></ol></li></ul><h2 id="线程池的submit和execute的区别"><a href="#线程池的submit和execute的区别" class="headerlink" title="线程池的submit和execute的区别"></a>线程池的submit和execute的区别</h2><p>\1. execute提交的方式</p><p>execute提交的方式只能提交一个Runnable的对象，且该方法的返回值是void，也即是提交后如果线程运行后，和主线程就脱离了关系了，当然可以设置一些变量来获取到线程的运行结果。并且当线程的执行过程中抛出了异常通常来说主线程也无法获取到异常的信息的，只有通过ThreadFactory主动设置线程的异常处理类才能感知到提交的线程中的异常信息。 </p><p>\2. submit提交的方式</p><p>submit提交的方式有如下三种情况</p><p>2.1  Future submit(Callable task);</p><p>这种提交的方式是提交一个实现了Callable接口的对象，Callable接口的定义如下</p><p>public interface Callable {</p><p>  &#x2F;**</p><p>   * Computes a result, or throws an exception if unable to do so.</p><ul><li></li></ul><p>   * @return computed result</p><p>   * @throws Exception if unable to compute a result</p><p>   *&#x2F;</p><p>  V call() throws Exception;</p><p>}</p><p>可以看到Callable接口和Runnable接口的定义很类似，只不过Runnable接口中是一个没有返回值的run方法，而Callable接口中是一个有返回值的call方法。</p><p>这种提交的方式会返回一个Future对象，这个Future对象代表这线程的执行结果，</p><p>当主线程调用Future的get方法的时候会获取到从线程中返回的结果数据。</p><p>如果在线程的执行过程中发生了异常，get会获取到异常的信息。 </p><p>Future.get方法是一个阻塞方法，当submit提交多个任务时，只有所有任务都完成后，才能使用get按照任务的提交顺序得到返回结果，所以一般需要使用future.isDone先判断任务是否全部执行完成，完成后再使用future.get得到结果。（也可以用get (long timeout, TimeUnit unit)方法可以设置超时时间，防止无限时间的等待） </p><h2 id="提交任务，线程池队列已满，会发生什么"><a href="#提交任务，线程池队列已满，会发生什么" class="headerlink" title="提交任务，线程池队列已满，会发生什么"></a>提交任务，线程池队列已满，会发生什么</h2><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image170.jpg" class="" title="img"><h2 id="线程池中线程复用原理"><a href="#线程池中线程复用原理" class="headerlink" title="线程池中线程复用原理"></a>线程池中线程复用原理</h2><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image172.jpg" class="" title="img"><h2 id="线程池调优"><a href="#线程池调优" class="headerlink" title="线程池调优"></a>线程池调优</h2><p><a href="https://mp.weixin.qq.com/s?__biz=MzUzMTA2NTU2Ng==&mid=2247487551&idx=1&sn=18f64ba49f3f0f9d8be9d1fdef8857d9&scene=21#wechat_redirect"><strong>①</strong> <strong>线程池的调优（线程池的合理配置）</strong></a></p><ul><li><ul><li>先从以下几个角度分析任务的特性：</li></ul></li><li><ul><li><strong>任务的性质：</strong> CPU 密集型任务、IO 密集型任务和混合型任务。</li><li><strong>任务的优先级：</strong> 高、中、低。</li><li><strong>任务的执行时间：</strong> 长、中、短。</li><li><strong>任务的依赖性：</strong> 是否依赖其他系统资源，如数据库连接。</li></ul></li><li><ul><li><strong>任务性质不同的任务可以用不同规模的线程池分开处理。</strong> 可以通过 Runtime.getRuntime().availableProcessors() 方法获得当前设备的 CPU 个数。</li></ul></li><li><ul><li><strong>CPU</strong> <strong>密集型任务</strong> 配置尽可能小的线程，如配置 N c p u + 1 N_{cpu}+1<em>N*<em>c</em></em> p*<em>u</em>+1 个线程的线程池。</li><li><strong>IO</strong> <strong>密集型任务</strong> 则由于线程并不是一直在执行任务，则配置尽可能多的线程，如2 ∗ N c p u 2<em>N_{cpu}2∗</em>N<strong>c</strong> p*<em>u</em>。</li><li><strong>混合型任务</strong> ，如果可以拆分，则将其拆分成一个 CPU 密集型任务和一个 IO 密集型任务。只要这两个任务执行的时间相差不是太大，那么分解后执行的吞吐率要高于串行执行的吞吐率；如果这两个任务执行时间相差太大，则没必要进行分解。</li></ul></li><li><ul><li><strong>优先级不同的任务</strong> 可以使用优先级队列 PriorityBlockingQueue 来处理，它可以让优先级高的任务先得到执行。但是，如果一直有高优先级的任务加入到阻塞队列中，那么低优先级的任务可能永远不能执行。</li><li><strong>执行时间不同的任务</strong> 可以交给不同规模的线程池来处理，或者也可以使用优先级队列，让执行时间短的任务先执行。</li><li><strong>依赖数据库连接池的任务</strong> ，因为线程提交 SQL 后需要等待数据库返回结果，线程数应该设置得较大，这样才能更好的利用 CPU。</li><li><strong>建议使用有界队列</strong> ，有界队列能增加系统的稳定性和预警能力。可以根据需要设大一点，比如几千。使用无界队列，线程池的队列就会越来越大，<strong>有可能会撑满内存，导致整个系统不可用</strong> 。</li></ul></li></ul><p><a href="https://mp.weixin.qq.com/s?__biz=MzUzMTA2NTU2Ng==&mid=2247487551&idx=1&sn=18f64ba49f3f0f9d8be9d1fdef8857d9&scene=21#wechat_redirect"><strong>②</strong> <strong>线程池的监控</strong></a></p><ul><li><ul><li>可以通过线程池提供的参数读线程池进行监控，有以下属性可以使用：</li></ul></li><li><ul><li>taskCount：线程池需要执行的任务数量，包括已经执行完的、未执行的和正在执行的。</li><li>completedTaskCount：线程池在运行过程中<strong>已完成的任务数量</strong> ，completedTaskCount &lt;&#x3D;      taskCount。</li><li>largestPoolSize：线程池<strong>曾经创建过的最大线程数量</strong> ，通过这个数据可以知道线程池是否满过。<strong>如等于线程池的最大大小</strong> ，则表示线程池曾经满了。</li><li>getPoolSize: 线程池的线程数量。如果线程池不销毁的话，池里的线程不会自动销毁，所以<strong>线程池的线程数量只增不减</strong> 。</li><li>getActiveCount：获取<strong>活动的</strong> 线程数。</li></ul></li><li><ul><li>通过<strong>继承线程池</strong> 并<strong>重写</strong> 线程池的 beforeExecute，afterExecute 和 terminated 方法，我们可以在任务执行前，执行后和线程池关闭前干一些事情。</li><li>如监控任务的平均执行时间，最大执行时间和最小执行时间等。<strong>这几个方法在线程池里是空方法</strong> ，</li></ul></li></ul><h1 id="java的内存模型（JMM）"><a href="#java的内存模型（JMM）" class="headerlink" title="java的内存模型（JMM）"></a>java的内存模型（JMM）</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>JMM就是Java内存模型(java memory model)。因为在不同的硬件生产商和不同的操作系统下，内存的访问有一定的差异，所以会造成相同的代码运行在不同的系统上会出现各种问题。所以<strong>java内存模型(JMM)屏蔽掉各种硬件和操作系统的内存访问差异，以实现让java程序在各种平台下都能达到一致的并发效果。</strong></p><p>Java内存模型规定<strong>所有的变量都存储在主内存</strong>中，包括实例变量，静态变量，但是不包括局部变量和方法参数。每个线程都有自己的工作内存，<strong>线程的工作内存保存了该线程用到的变量和主内存的副本拷贝，线程对变量的操作都在工作内存中进行</strong>。<strong>线程不能直接读写主内存中的变量</strong>。</p><p>不同的线程之间也无法访问对方工作内存中的变量。线程之间变量值的传递均需要通过主内存来完成。</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image174.gif" class="" title="img"><p>每个线程的工作内存都是独立的，线程操作数据只能在工作内存中进行，然后刷回到主存。这是 Java 内存模型定义的线程基本工作方式。</p><p><a href="https://zhuanlan.zhihu.com/p/258393139%EF%BC%88%E9%92%88%E5%AF%B9%E4%BA%8E%E9%9D%A2%E8%AF%95%E5%AE%98%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%89%EF%BC%88%E9%87%8C%E9%9D%A2%E8%BF%98%E6%9C%89%E5%85%B3%E4%BA%8Evolatile%E5%85%B3%E9%94%AE%E5%AD%97%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%EF%BC%8C%E9%83%BD%E5%BE%88%E5%A5%BD%EF%BC%89">https://zhuanlan.zhihu.com/p/258393139（针对于面试官的问题）（里面还有关于volatile关键字的一些问题，都很好）</a></p><p><a href="https://zhuanlan.zhihu.com/p/29881777%EF%BC%88%E6%9B%B4%E8%AF%A6%E7%BB%86%EF%BC%8C%E9%92%88%E5%AF%B9%E4%BA%8E%E5%BA%95%E5%B1%82%EF%BC%89">https://zhuanlan.zhihu.com/p/29881777（更详细，针对于底层）</a></p><p>volatile内存屏障</p><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image176.jpg" class="" width="0"><h2 id="那JMM定义了什么"><a href="#那JMM定义了什么" class="headerlink" title="那JMM定义了什么"></a>那JMM定义了什么</h2><p>这个简单，整个Java内存模型实际上是围绕着三个特征建立起来的。分别是：原子性，可见性，有序性。这三个特征可谓是整个Java并发的基础。</p><p>原子性</p><p>原子性指的是一个操作是不可分割，不可中断的，一个线程在执行时不会被其他线程干扰。</p><p>面试官拿笔写了段代码，下面这几句代码能保证原子性吗？</p><p>int i &#x3D; 2;<br> int j &#x3D; i;<br> i++;<br> i &#x3D; i + 1;</p><p>第一句是基本类型赋值操作，必定是原子性操作。</p><p>第二句先读取i的值，再赋值到j，两步操作，不能保证原子性。</p><p>第三和第四句其实是等效的，先读取i的值，再+1，最后赋值到i，三步操作了，不能保证原子性。</p><p>JMM只能保证基本的原子性，如果要保证一个代码块的原子性，提供了monitorenter 和 moniterexit 两个字节码指令，也就是 synchronized 关键字。因此在 synchronized 块之间的操作都是原子性的。</p><p>可见性</p><p>可见性指当一个线程修改共享变量的值，其他线程能够立即知道被修改了。Java是利用volatile关键字来提供可见性的。 当变量被volatile修饰时，这个变量被修改后会立刻刷新到主内存，当其它线程需要读取该变量时，会去主内存中读取新值。而普通变量则不能保证这一点。</p><p>除了volatile关键字之外，final和synchronized也能实现可见性。</p><p>synchronized的原理是，在执行完，进入unlock之前，必须将共享变量同步到主内存中。</p><p>final修饰的字段，一旦初始化完成，如果没有对象逸出（指对象为初始化完成就可以被别的线程使用），那么对于其他线程都是可见的。</p><p>有序性</p><p>在Java中，可以使用synchronized或者volatile保证多线程之间操作的有序性。实现原理有些区别：</p><p>volatile关键字是使用内存屏障达到禁止指令重排序，以保证有序性。</p><p>synchronized的原理是，一个线程lock之后，必须unlock后，其他线程才可以重新lock，使得被synchronized包住的代码块在多线程之间是串行执行的。</p><h2 id="八种内存交互操作"><a href="#八种内存交互操作" class="headerlink" title="八种内存交互操作"></a>八种内存交互操作</h2><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image178.gif" class="" title="img"><ul><li><ul><li>lock(锁定)，作用于主内存中的变量，把变量标识为线程独占的状态。</li><li>read(读取)，作用于主内存的变量，把变量的值从主内存传输到线程的工作内存中，以便下一步的load操作使用。</li><li>load(加载)，作用于工作内存的变量，把read操作主存的变量放入到工作内存的变量副本中。</li><li>use(使用)，作用于工作内存的变量，把工作内存中的变量传输到执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。</li><li>assign(赋值)，作用于工作内存的变量，它把一个从执行引擎中接受到的值赋值给工作内存的变量副本中，每当虚拟机遇到一个给变量赋值的字节码指令时将会执行这个操作。</li><li>store(存储)，作用于工作内存的变量，它把一个从工作内存中一个变量的值传送到主内存中，以便后续的write使用。</li><li>write(写入)：作用于主内存中的变量，它把store操作从工作内存中得到的变量的值放入主内存的变量中。</li><li>unlock(解锁)：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。</li></ul></li></ul><p>JMM对8种内存交互操作制定的规则吧：</p><ul><li><ul><li>不允许read、load、store、write操作之一单独出现，也就是read操作后必须load，store操作后必须write。</li><li>不允许线程丢弃他最近的assign操作，即工作内存中的变量数据改变了之后，必须告知主存。</li><li>不允许线程将没有assign的数据从工作内存同步到主内存。</li><li>一个新的变量必须在主内存中诞生，不允许工作内存直接使用一个未被初始化的变量。就是对变量实施use、store操作之前，必须经过load和assign操作。</li><li>一个变量同一时间只能有一个线程对其进行lock操作。多次lock之后，必须执行相同次数unlock才可以解锁。</li><li>如果对一个变量进行lock操作，会清空所有工作内存中此变量的值。在执行引擎使用这个变量前，必须重新load或assign操作初始化变量的值。</li><li>如果一个变量没有被lock，就不能对其进行unlock操作。也不能unlock一个被其他线程锁住的变量。</li><li>一个线程对一个变量进行unlock操作之前，必须先把此变量同步回主内存。</li></ul></li></ul><h1 id="JUC包"><a href="#JUC包" class="headerlink" title="JUC包"></a>JUC包</h1><h2 id="CopyOnWriteArrayList"><a href="#CopyOnWriteArrayList" class="headerlink" title="CopyOnWriteArrayList"></a>CopyOnWriteArrayList</h2><p>实现原理</p><p>我们都知道，集合框架中的ArrayList是非线程安全的，Vector虽是线程安全的，但由于简单粗暴的锁同步机制，性能较差。而CopyOnWriteArrayList则提供了另一种不同的并发处理策略。针对<em>读多写少</em>的并发场景，CopyOnWriteArrayList允许线程并发访问读操作，这个时候是没有加锁限制的，性能较高。而写操作的时候，则首先将容器复制一份，然后在新的副本上执行写操作，这个时候写操作是上锁的。结束之后再将原容器的引用指向新容器。注意，在上锁执行写操作的过程中，如果有需要读操作，会作用在原容器上。因此上锁的写操作不会影响到并发访问的读操作。</p><p>了解了实现原理，我们也能很容易总结出容器的优缺点。优点是读操作性能很高，无需任何同步措施，适用于读多写少的并发场景。缺点一是需要额外内存占用，毕竟每次写操作需要复制一份，数据量大时会对内存压力较大，可能会引起频繁的GC。二是无法保证强一致性，毕竟在复制写操作过程中，读和写分别作用在新老不同容器上。读操作虽然不会阻塞，但在这段时间内读取的还是老容器的数据</p><h1 id="异步转为同步的方式"><a href="#异步转为同步的方式" class="headerlink" title="异步转为同步的方式"></a>异步转为同步的方式</h1><img src="/2024/04/05/%E5%B9%B6%E5%8F%91/clip_image179.jpg" class="" width="0">]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> 并发 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>redis</title>
      <link href="/2024/04/05/redis/"/>
      <url>/2024/04/05/redis/</url>
      
        <content type="html"><![CDATA[<h1 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h1><h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><h3 id="数据结构及其使用场景"><a href="#数据结构及其使用场景" class="headerlink" title="数据结构及其使用场景"></a>数据结构及其使用场景</h3><img src="/2024/04/05/redis/clip_image002.jpg" class="" title="Redis 的 数 据 结 构 及 使 用 场 景  Re 的 数 哐 结 构 有 、  1. 孛 串 ： 可 以 庠 来 做 最 简 单 的 數 缓 存 ， 可 以 緩 存 某 个 徜 的 孛 符 牛 ， 也 可 以 緩 存 臬 个 json 格 詭 孛 符 串 ， № 分 布 式 锁 的 实 现 利 用 了 这 种 赦 据 砉 构 ， 还 包 茫 可 以 实 现  计 數 器 、 s “ n 共 亨 ． 分 布 式 旧  2 、 哈 希 表 ： 可 以 来 存 儲 一 些 key 一 va 心 e 对 。 史 适 合 用 来 存 储 对 象  圭 列 表 ： Redis 的 列 表 命 0 的 绢 合 ， 可 以 当 雪 栈 ， 也 可 以 当 做 队 列 来 使 ， 可 以 用 来 存 类 似 信 公 众 号 、 两 等 泊 0 流 数  4 ． 合 ； 和 歹 刂 表 类 似 《 也 可 以 存 賭 多 个 元 索 ， 但 是 不 能 里 复 ， 合 可 以 进 行 交 隼 ． 并 、 差 军 臊 作 ， 从 而 可 以 妾 现 类 似 ， 栊 和 早 人 共 同 关 汀 的 人 、 朋 友 苤 等 功 能  气 有 序 合 ： 合 是 无 序 的 。 有 序 合 可 以 设 置 顺 序 ， 可 以 来 实 现 排 行 榜 功 能"><p>Redis还有更高级得数据结构，比如：HyperLogLog、Geo、BloomFilter 这几个数据结构</p><p>String底层实现：</p><p>如果一个字符串对象保存的是整数值， 并且这个整数值可以用 long 类型来表示， 那么字符串对象会将整数值保存在字符串对象结构的 ptr 属性里面（将 void* 转换成 long ）， 并将字符串对象的编码设置为 int 。</p><p>如果字符串对象保存的是一个字符串值， 并且这个字符串值的长度大于 39 字节， 那么字符串对象将使用一个简单动态字符串（SDS）来保存这个字符串值， 并将对象的编码设置为 raw。</p><p>如果字符串对象保存的是一个字符串值， 并且这个字符串值的长度小于等于 39 字节， 那么字符串对象将使用 embstr 编码的方式来保存这个字符串值。</p><p>List底层实现：</p><p>列表对象的编码可以是 ziplist 或者 linkedlist 。</p><p>列吧表对象保存的所有字符串元素的长度都小于 64 字节并且保存的元素数量小于 512 个，使用 ziplist 编码；否则使用 linkedlist；</p><p>Hash底层实现:</p><p>哈希对象的编码可以是 ziplist 或者 hashtable 。</p><p>哈希对象保存的所有键值对的键和值的字符串长度都小于 64 字节并且保存的键值对数量小于 512 个，使用ziplist 编码；否则使用hashtable；</p><p>Set底层实现：</p><p>集合对象的编码可以是 intset 或者 hashtable 。</p><p>集合对象保存的所有元素都是整数值并且保存的元素数量不超过 512 个，使用intset编码；否则使用hashtable；</p><p>Sorted Set底层实现：</p><p>有序集合的编码可以是 ziplist 或者 skiplist</p><p>有序集合保存的元素数量小于 128 个并且保存的所有元素成员的长度都小于 64 字</p><p>节。使用 ziplist 编码；否则使用skiplist；</p><p>HyperLogLog</p><p>edis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。</p><p>在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基 数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。</p><p>但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。 </p><p>应用场景：</p><p>可以用来统计网站的登陆人数以及其他指标</p><p>GEO</p><p>基本概念： </p><p>在 Redis 3.2 版本中新增了一种叫 geo 的数据结构，它主要用来存储地理位置信息，并对存储的信息进行操作。 </p><p>使用： </p><p>geoadd 用于存储指定的地理空间位置，可以将一个或多个经度(longitude)、纬度</p><p>(latitude)、位置名称(member)添加到指定的 key 中。</p><p>BloomFilter</p><p>基本概念： </p><p>一种数据结构，是由一串很长的二进制向量组成，可以将其看成一个二进制数组。既然是二进制，那么里面存放的不是0，就是1，但是初始默认值都是0。他的主要作用是：判断一个元素是否在某个集合中。比如说，我想判断20亿的号码中是否存在某个号码，如果直接插DB，那么数据量太大时间会很慢；如果将20亿数据放到 缓存中，缓存也装不下。这个时候用 布隆过滤器 最合适了，布隆过滤器的原理是：</p><p>添加元素<br> 当要向布隆过滤器中添加一个元素key时，我们通过多个hash函数，算出一个值，然后将这个值所在的方格置为1。</p><img src="/2024/04/05/redis/clip_image004.gif" class="" title="img"><p>判断元素是否存在：<br> 判断元素是否存在，是先将元素经过多个hash函数计算，计算到多个下标值，然后判断这些下标对应的元素值是否都为1，如果存在不是 1 的，那么元素肯定不在集合中；如果都是 1，那么元素大概率在集合中，并不能百分之百肯定元素存在集合中，因为多个不同的数据通过hash函数算出来的结果是会有重复的，所以会存在某个位置是别的数据通过hash函数置为的1。<br> 总的来说：布隆过滤器可以判断某个数据一定不存在，但是无法判断一定存在。</p><p>布隆过滤器的优缺点：</p><p>优点：优点很明显，二进制组成的数组，占用内存极少，并且插入和查询速度都足够快。</p><p>缺点：随着数据的增加，误判率会增加；还有无法判断数据一定存在；另外还有一个重要缺点，无法删除数据。</p><p>应用场景：</p><p>解决缓存穿透问题：一般得查询场景都是先去查询缓存，如果缓存没有，那么就去 DB 查询，如果查到了，先存在 缓存 中，然后返回给调用方。如果查不到就返回空。这种情况如果有人频繁的请求缓存中没有得数据，比如id &#x3D; -1 得数据，那么会对 DB 造成极大得压力，这种情况就可以使用 redis 得布隆过滤器了，可以先将可能得id都</p><p>存在布隆过滤器中，当查询来的时候，先去布隆过滤器查，如果查不到直接返回，不请求缓存以及DB，如果存在 布隆过滤器 中，那么才去缓存中取数据。</p><p>黑名单校验：可以将黑名单中得ip放入到布隆过滤器中，这样不用每次来都去 db 中查询了。</p><h3 id="Hashmap"><a href="#Hashmap" class="headerlink" title="Hashmap"></a>Hashmap</h3><img src="/2024/04/05/redis/clip_image006.jpg" class="" title="di"><p>扩容时大小：ht[1] 哈希表大小为第一个大于等于 ht[0].used*2 的 2^n(2的n 次方幂) used：当前有多少个键值对</p><p>缩容时大小：ht[1] 哈希表大小为第一个大于等于 ht[0].used的 2^n(2的n 次方幂)</p><p>扩容的步骤如下：</p><p>1、为字典ht[1]哈希表分配合适的空间；</p><p>2、将ht[0]中所有的键值对rehash到ht[1]：rehash 指的是重新计算键的哈希值和索引值， 然后将键值对 放置到 ht[1] 哈希表的指定位置上；</p><p>3、当 ht[0] 包含的所有键值对都迁移到了 ht[1] 之后 （ht[0] 变为空表）， 释放 ht[0] ， 将 ht[1] 设置 为 ht[0] ， 并在 ht[1] 新创建⼀个空⽩哈希表， 为下⼀次 rehash 做准备。</p><p>哈希渐进式rehash的详细步骤：</p><p>1、为ht[1]分配空间，让字典同时持有ht[0]和ht[1]两个哈希表。</p><p>2、在字典中维持一个索引计数器变量rehashidx，并将它的指设置为0，表示rehash工作正式开始。</p><p>3、在rehash进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]，当rehash工作完成之后，程序将rehashidx属性的值加一。</p><p>4、随着字典操作的不断执行，最终在某个时间点，ht[0]的所有键值对都会被rehash至ht[1]，这时程序将rehashidx属性设置为-1，表示rehash已经操作完成 ，h[1]变为h[0]</p><p>在 Redis 的实现里，扩容缩容有三条规则：</p><p>当 Redis 没有进行 BGSAVE 相关操作，且 负载因子&gt;1的时候进行扩容。</p><p>当 Redis 进行 BGSAVE 相关操作,当负载因子&gt;5的时候，强行进行扩容。</p><p>当负载因子&lt;0.1的时候，进行缩容。</p><p>负载因子&#x3D;哈希表以保存节点数量 &#x2F; 哈希表的大小.</p><p> <em><strong>*Bgsave*</strong></em> 命令用于在后台异步保存当前数据库的数据到磁盘。</p><p><a href="https://juejin.cn/post/6844904049578377230#%E6%89%A9%E5%AE%B9%E4%B8%8E%E7%BC%A9%E5%AE%B9">https://juejin.cn/post/6844904049578377230#%E6%89%A9%E5%AE%B9%E4%B8%8E%E7%BC%A9%E5%AE%B9</a></p><h3 id="压缩列表ziplist"><a href="#压缩列表ziplist" class="headerlink" title="压缩列表ziplist"></a><strong>压缩列表</strong>ziplist</h3><p>ziplist是一种连续，无序的数据结构。压缩列表是 Redis 为了节约内存而开发的， 由一系列特殊编码的连续内存块组成的顺序型（sequential）数据结构。</p><p>组成</p><table><thead><tr><th>*******<em><strong>属性*</strong></em></th><th>*******<em><strong>类型*</strong></em></th><th>*******<em><strong>长度*</strong></em></th><th>*******<em><strong>用途*</strong></em></th></tr></thead><tbody><tr><td>zlbytes</td><td>uint_32t</td><td>4B</td><td>记录整个压缩列表占用的内存字节数：在对压缩列表进行内存重分配，  或者计算 zlend的位置时使用</td></tr><tr><td>zltail</td><td>uint_32t</td><td>4B</td><td>记录压缩列表表尾节点距离压缩列表的起始地址有多少字节：通过这个偏移量，程序无须遍历整个压缩列表就可以确定表尾节点的地址。</td></tr><tr><td>zllen</td><td>uint_16t</td><td>2B</td><td>记录了压缩列表包含的节点数量：  当这个属性的值小于UINT16_ MAX （65535）时，  这个属性的值就是压缩列表包含节点的数量； 当这个值等于 UINT16_MAX 时， 节点的真实数量需要遍历整个压缩列表才能计算得出。</td></tr><tr><td>entryX</td><td>列表节点</td><td>不定</td><td>压缩列表包含的各个节点，节点的长度由节点保存的内容决定。</td></tr><tr><td>zlend</td><td>uint_8t</td><td>1B</td><td>特殊值 0xFF （十进制 255 ），用于标记压缩列表的末端。</td></tr></tbody></table><p>压缩列表节点的构成　一个压缩列表可以包含任意多个节点（entry）， 每个节点可以保存一个字节数组或者一个整数值（小整数值或者长度比较短的字符串）。</p><p>（1）节点的 previous_entry_length 属性以字节为单位， 记录了压缩列表中前一个节点的长度</p><p>（2）节点的 encoding 属性记录了节点的 content 属性所保存数据的类型以及长度： </p><p>（3）节点的 content 属性负责保存节点的值， 节点值可以是一个字节数组或者整数， 值的类型和长度由节点的 encoding 属性决定。</p><h3 id="跳表"><a href="#跳表" class="headerlink" title="跳表"></a>跳表</h3><p><a href="https://www.cnblogs.com/lixinjie/p/a-post-about-skiplist.html">https://www.cnblogs.com/lixinjie/p/a-post-about-skiplist.html</a></p><img src="/2024/04/05/redis/clip_image008.jpg" class="" title="Rodis ,馝i&amp;h|,鹵미i뢰~ |馝i&amp;h|,鹵미i떖 曰中 用才*示″3%1. 而 ,鹵p|로  Ⅲ十Ⅳ4,″裹11,는『」糲붓념모.  L32  NULL  NULL  length  tan. :"><img src="/2024/04/05/redis/clip_image010.jpg" class="" title="img"><p>查找流程：</p><img src="/2024/04/05/redis/clip_image012.jpg" class="" title="没 们 0 以 诓 是 和 在 第 常 引 中 。 我 们 到 节 0 之 处 ． x 大 十 小 于 处 囟 的 朽 貞 乙 所 以 们 谚 n 旧  計 ． k 吸 旗 引 下 k 一 1 旗 引 · 在 苤 1 引 中 ． y 和 屙 只 有 3 书 点 （ 含 y 和 到 ． 所 以 ． 我 钔 在 k 一 1 吸 引 中 是 多  只 粼 历 3 个 白 。 欠 类 。 一 暇 引 星 多 只 靄 以 历 3 首 兯 貞 ，"><p>插入流程：</p><img src="/2024/04/05/redis/clip_image014.jpg" class="" title="· 懂 懒 鈿 詼 捍 ． 锈 合 适 入 0 “ 汀 0 分 分 “ e 相 同 ． 这 时 会 根 中 阐 字 凍 栉 ·  ． 阳 R 酊 川 止 e 旧 0 月 ． 独 出 适 入 的 0 内 0 数 产  ． 阳 谝 1 玩 的 新 堇 0 以 前 处 情 的 向 0 d 和 美 长 廢 卸 地 也 菪 新 鬲 凶 0 向 轟 d ．  · 貝 中 地 栌 了 蚋 饣 敷 地 和 阉 n update 數 用 记 录 的 一 过 言 ． 一 制 ； 小 斗 噕 入 “ 白 ． 巫 庸 ^ 0 “ 《 “ 效  记 灵 主 诬 00 上 一 虫 书 ， 以 便 十 最 肩 新 即 彐 n 伯 。"><img src="/2024/04/05/redis/clip_image016.jpg" class="" title="5 球 ist 节 点  蜘 翱 的 过 &#96; 的 都 是 盟 使 判 凸 0 万 法 的 。 先 垡 个 “ 》 “ 是 出 0 · 如 存 在 盟 斷 的 。 不 存 在 就 适 入  程 》 五 中 刂 是 ． 知 丰 伐 剁 了 酴 ． 冉 斷 ． 这 ， 0 会 做 蚋 内 ． 0 上 束 讲 酗 了 ． 在 R 弱 50  版 本 中 ． R 开 An@嘏 优 化 了 这 个 刊 程 ． 鬥 屮 锔 刂 星 知 生 判 断 这 个 " alt="是 酉 在 ． 处 墨 0 0 ，  后 山 整 希 表 5 舅 e 过 序 。 谊 就 不 靄 蚋 次 粼 河 程 ．"><img src="/2024/04/05/redis/clip_image018.jpg" class="" title="六 ． p 以 t 与 平 衡 树 、 咕 希 衮 的 比 较  的 全 Oil)  ， 0 必 的 据 侑 序 之 0 # 斗 娌 特 只 塑 卜 诠 》  黛 № 肝 河 以 就 匕 屮 励 恻 ：  Z 卉 3 ， 不 0 骷 印 压 0 忮"><h3 id="跳表和红黑树的对比-1"><a href="#跳表和红黑树的对比-1" class="headerlink" title="跳表和红黑树的对比_1"></a>跳表和红黑树的对比_1</h3><ul><li><ol><li>在做范围查找的时候，平衡树比 skiplist 操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在 skiplist 上进行范围查找就非常简单，只需要在找到小值之后，对第 1 层链表进行若干步的遍历就可以实现。</li><li>查找单个 key ， skiplist 和平衡树的时间复杂度都为 O(log n) ，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近 O(1) ，性能更高一些。所以我们平常使用的各种 Map 或 dictionary 结构，大都是基于哈希表实现的。</li><li>平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而 skiplist 的插入和删除只需要修改相邻节点的指针，操作简单又快速。</li><li>从内存占用上来说， skiplist 比平衡树更灵活一些。一般来说，平衡树每个节点包含 2 个指针（分别指向左右子树），而 skiplist 每个节点包含的指针数目平均为 1&#x2F;(1-p) ，具体取决于参数 p 的大小。如果像 Redis 里的实现一样，取 p&#x3D;1&#x2F;4 ，那么平均每个节点包含 1.33 个指针，比平衡树更有优势。</li><li>从算法实现难度上来比较， skiplist 比平衡树要简单得多。</li></ol></li></ul><h2 id="单线程还是多线程？"><a href="#单线程还是多线程？" class="headerlink" title="单线程还是多线程？"></a>单线程还是多线程？</h2><img src="/2024/04/05/redis/clip_image020.gif" class="" title="img"><h2 id="BIO，NIO，Epoll，IO多路复用"><a href="#BIO，NIO，Epoll，IO多路复用" class="headerlink" title="BIO，NIO，Epoll，IO多路复用"></a>BIO，NIO，Epoll，IO多路复用</h2><p>IO多路复用：单线程或单进程同时监测若干个文件描述符是否可以执行IO操作的能力。</p><p>普通IO:</p><img src="/2024/04/05/redis/clip_image021.jpg" class="" title="img"><p>BIO:同步阻塞</p><p>来一个连接新建一个线程处理</p><img src="/2024/04/05/redis/clip_image022.jpg" class="" title="img"><p>这是服务端程序：划线的地方都会阻塞程序：在接受连接（accept）的时候，若没有客户端连接，accept就会阻塞，有连接后运行，执行到read也会阻塞，因为没有客户端发送消息，发了消息后就会运行</p><p>问题：没法处理多个连接，只有轮训到accept的时候才能继续接受连接</p><img src="/2024/04/05/redis/clip_image023.jpg" class="" title="img"><p>开新线程处理：来一个请求开一个线程，会严重影响服务器性能  c10k问题：线程太多了</p><p>用线程池限制了线程数量：并发就会减弱，</p><img src="/2024/04/05/redis/clip_image024.jpg" class="" title="img"><p>还有一个严重的问题就是阻塞，客户端迟迟不发请求，那么就会影响造成线程开销浪费很多，每个线程处理一个连接，那么很多线程就一直阻塞着</p><p>NIO：同步非阻塞</p><p>简单版本：</p><img src="/2024/04/05/redis/clip_image025.jpg" class="" title="img"><p>设置socketChannel为非阻塞：即使客户端没有发数据，read函数不会阻塞</p><p>socketChannel会放在list中，轮训list</p><p>问题：10万个连接，只有100个有收发数据，那么每次需要循环10万个，造成了时间浪费</p><p>解决：令拿一个集合放那些有请求的连接：selector（多路复用器）</p><img src="/2024/04/05/redis/clip_image026.jpg" class="" title="img"><img src="/2024/04/05/redis/clip_image027.jpg" class="" title="img"><p>一个selectionkey对应着一个channel，通过selectionkey就能找到channel</p><p>selector.select会阻塞等待连接事件，当有连接时，则运行</p><p>select也会阻塞等待读写事件，当两个客户端发生了读写事件时，那么这时候selectionKeys集合里面就是两个，那么就可以轮训处理这两个事件</p><img src="/2024/04/05/redis/clip_image028.jpg" class="" title="img"><p>如果是连接事件，也会把客户端的socketChannel注册到selector，监听读写事件</p><img src="/2024/04/05/redis/clip_image029.jpg" class="" title="img"><p>其实创建的这个selector，linux操作系统返回的就是epoll，linux操作系统一切皆文件，返回的的epfd（ep file discription），就是epoll</p><img src="/2024/04/05/redis/clip_image030.jpg" class="" title="img"><p> AIO</p><img src="/2024/04/05/redis/clip_image032.jpg" class="" width="0"><img src="/2024/04/05/redis/clip_image034.jpg" class="" width="0"><img src="/2024/04/05/redis/clip_image036.jpg" class="" title="img"><p>epol_ctl才是真正监听事件的方法</p><p>fd：Channel的文件描述符</p><p>select监听事件</p><p>epoll_wait:阻塞等待事件的发生，有连接读写事件才会运行</p><p>channel放着连接，rdlist放着事件的列表</p><img src="/2024/04/05/redis/clip_image037.jpg" class="" title="img"><img src="/2024/04/05/redis/clip_image039.jpg" class="" title="img"><img src="/2024/04/05/redis/clip_image041.jpg" class="" title="img"><p>阻塞等待事件的发生</p><img src="/2024/04/05/redis/clip_image043.jpg" class="" title="img"><p>3者区别：select每次轮询连接集合，有上限，poll：每次轮询连接集合，无上限，epoll：每次轮询的是有事件发生的连接，无上限</p><h2 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h2><p><em><strong>*当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。*</strong></em></p><p>如果这是 slave node 初次连接到 master node，那么会触发一次 full resynchronization 全量复制。此时 master 会启动一个后台线程，开始生成一份 RDB 快照文件，</p><p>同时还会将从客户端 client 新收到的所有写命令缓存在内存中。RDB 文件生成完毕后， master 会将这个 RDB 发送给 slave，slave 会先写入本地磁盘，然后再从本地磁盘加载到内存中，</p><p>接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。</p><p>slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。</p><p><a href="https://www.cnblogs.com/renpingsheng/p/9796899.html">https://www.cnblogs.com/renpingsheng/p/9796899.html</a></p><img src="/2024/04/05/redis/clip_image045.jpg" class="" title="redis 主 从 复 制 的 核 心 原 理  河 过 行 “ of 品 0 或 设 0 引 ave 。 顷 。 让 一 个 服 器 去 0 制 另 一 个  蹇 。 瞎 底 可 以 讲 行 读 与 襻  怍 ， 当 与 慢 作 导 致 数 剖 1 会 自 劝 将 数 河 步 搶 从 数 库 。 而 从 数 00 一 是 只 读 的 ， 葑 豐 主 重 庵 同 步 过  的 数 0 。 一 个 扌 数 亏 可 以 有 多 个 从 数 0 库 ， 而 一 ， 个 M 只 能 有 一 个 扌 数 瞎 私  〔 月 主 节 白 通 过 bg “ “ 命 令 fork 子 进 程 进 行 RDB 恃 久 化 、 该 过 程 是 菲 簡 肖 〔 pu 、 内 山 轰 地 ． 硬 盘 ℃ 的  〔 扌 节 点 过 网 适 RD 日 又 件 友 送 从 点 ， 对 主 从 节 的 鬲 都 会 带 + 很 大 的 料 耗  司 从 节 中 空 老 数 ． 载 入 新 RD 日 文 件 围 过 程 犀 沮 藶 的 ， 应 窖 户 的 命 令 ： 如 果 从 0 执 行  bgrewriteaof, 也 会 諾 犟 外 肖 耗"><img src="/2024/04/05/redis/clip_image047.jpg" class="" title="地 一 次 次 行 0 枞  “ 劌 是 上 一 次 主  %asterüpsync  " alt="翩 表 示 扌 邗 运 行 》 D ． 。 e 示 当 航 主  ync(runid)(otfset)  0 行 ID ． 酬 1 是 当 前 从 书  点 刊 处"><h2 id="部分同步"><a href="#部分同步" class="headerlink" title="部分同步"></a>部分同步</h2><p>部分复制主要是 Redis 针对全量复制的过高开销做出的一种优化措施，使用 psync {runId} {offset} 命令实现。当从节点正在复制主节点时，如果出现网络闪断或者命令丢失等异常情况时，从节点会向主节点要求补发丢失的命令数据，如果主节点的复制积压缓冲区存在这部分数据则直接发送给从节点，这样就保证了主从节点复制的一致性。补发的这部分数据一般远远小于全量数据，所以开销很小。</p><img src="/2024/04/05/redis/clip_image049.jpg" class="" title="slave  2) Request  1)  3)  repl-backlog-  buffer  4) psync {offset} {runld}  master  5) CONTINUE"><p> 当主从节点之间网络出现中断时，如果超过了 repl-timeout 时间，主节点会认为从节点故障并中断复制连接。</p><p> 主从连接中断期间主节点依然响应命令，但因复制连接中断命令无法发送给从节点，不过主节点内部存在复制积压缓冲区( repl-backlog-buffer )，依然可以保存最近一段时间的写命令数据，默认最大缓存 1MB。</p><p> 当主从节点网络恢复后，从节点会再次连上主节点。</p><p> 当主从连接恢复后，由于从节点之前保存了自身已复制的偏移量和主节点的运行ID。因此会把它们作为 psync 参数发送给主节点，要求进行补发复制操作。</p><p> 主节点接到 psync 命令后首先核对参数 runId 是否与自身一致，如果一致，说明之前复制的是当前主节点；之后根据参数 offset 在自身复制积压缓冲区查找，如果偏移量之后的数据存在缓冲区中，则对从节点发送 +CONTINUE 响应，表示可以进行部分复制。</p><p> 主节点根据偏移量把复制积压缓冲区里的数据发送给从节点，保证主从复制进入正常状态。</p><img src="/2024/04/05/redis/clip_image051.jpg" class="" title="img"><h2 id="集群方案"><a href="#集群方案" class="headerlink" title="集群方案"></a>集群方案</h2><p>主从复制模式</p><p> Sentinel（哨兵）模式</p><p> Cluster 模式</p><p>*<strong>*<em><em><strong><strong>主从复制机制的目的有两个*</strong></strong></em>*</em></strong></p><p> 一个是读写分离，分担 “master” 的读写压力</p><p> 一个是方便做容灾恢复</p><p><img src="/redis/clip_image053.jpg" alt="从 服 务 器  主 服 务 器  创 建 快 照 、 缓 冲 快  [ 1 同 步 快 照 ]  載 入 、 解 析 快 照  缓 冲 快 照 同  [ 2 ． 同 步 与 缓 冲 ]  生 成 期 间 的 写 命 令  间 的 写 命 令  载 入 缓 冲  loop  从 服 务 器  [ 3 ． 同 步 增 量 ]  主 服 务 器 "></p><p>从数据库启动成功后，连接主数据库，发送 SYNC 命令；</p><p> 主数据库接收到 SYNC 命令后，开始执行 BGSAVE 命令生成 RDB 文件并使用缓冲区记录此后执行的所有写命令；</p><p> 主数据库 BGSAVE 执行完后，向所有从数据库发送快照文件，并在发送期间继续记录被执行的写命令；</p><p> 从数据库收到快照文件后丢弃所有旧数据，载入收到的快照；</p><p> 主数据库快照发送完毕后开始向从数据库发送缓冲区中的写命令；</p><p> 从数据库完成对快照的载入，开始接收命令请求，并执行来自主数据库缓冲区的写命令；（从数据库初始化完成）</p><p> 主数据库每执行一个写命令就会向从数据库发送相同的写命令，从数据库接收并执行收到的写命令（从数据库初始化完成后的操作）</p><p> 出现断开重连后，2.8之后的版本会将断线期间的命令传给重数据库，增量复制。</p><p> 主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。Redis 的策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。</p><p>*<strong>*<em><em><strong><strong>主从复制缺点*</strong></strong></em>*</em></strong></p><p> Redis不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复（也就是要人工介入）；</p><p> 主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性；</p><p> 如果多个 Slave 断线了，需要重启的时候，尽量不要在同一时间段进行重启。因为只要 Slave 启动，就会发送sync 请求和主机全量同步，当多个 Slave 重启的时候，可能会导致 Master IO 剧增从而宕机。</p><p> Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂；</p><p><em><strong>*Sentinel*<em><strong><strong>（哨兵）模式*</strong></strong></em>*</strong></em></p><p>*<strong>*<em><em><strong><strong>哨兵模式的作用*</strong></strong></em>*</em></strong></p><p> 通过发送命令，让 Redis 服务器返回监控其运行状态，包括主服务器和从服务器；</p><p> 当哨兵监测到 master 宕机，会自动将 slave 切换成 master ，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换主机；</p><p>一个哨兵进程对Redis服务器进行监控，也可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。</p><p>*<strong>*<em><em><strong><strong>故障切换的过程*</strong></strong></em>*</em></strong></p><p>假设主服务器宕机，哨兵1先检测到这个结果，系统并不会马上进行 failover 过程，仅仅是哨兵1主观的认为主服务器不可用，这个现象成为*****<em><strong><strong>主观下线*</strong></strong></em>*<em><strong>。当后面的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行 failover 操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为</strong></em>**<em><strong><strong>客观下线*</strong></strong></em>****。这样对于客户端而言，一切都是透明的。</p><p>*<strong>*<em><em><strong><strong>哨兵模式的优缺点*</strong></strong></em>*</em></strong></p><p>*<strong>*<em><em><strong><strong>优点：*</strong></strong></em>*</em></strong></p><p> 哨兵模式是基于主从模式的，所有主从的优点，哨兵模式都具有。</p><p> 主从可以自动切换，系统更健壮，可用性更高(可以看作自动版的主从复制)。</p><p>*<strong>*<em><em><strong><strong>缺点：*</strong></strong></em>*</em></strong></p><p> Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。</p><p>*<strong>*Cluster*</strong> ***集群模式（***<em><strong>Redis*<em><strong><strong>官方）*</strong></strong></em>*</strong></em></p><p>实现了 Redis 的分布式存储，*******<em><strong>也就是说每台*</strong> <em><strong>Redis*</strong> <em><strong>节点上存储不同的内容*</strong></em></em></em>****。</p><p>*<strong>*<em><em><strong><strong>集群的数据分片*</strong></strong></em>*</em></strong></p><p>Redis 集群没有使用一致性 hash，而是引入了哈希槽【hash slot】的概念。</p><p>Redis 集群有16384 个哈希槽，每个 key 通过 CRC16 校验后对 16384 取模来决定放置哪个槽。集群的每个节点负责一部分hash槽，举个例子，比如当前集群有3个节点，那么：</p><p> 节点 A 包含 0 到 5460 号哈希槽</p><p> 节点 B 包含 5461 到 10922 号哈希槽</p><p> 节点 C 包含 10923 到 16383 号哈希槽</p><p><em><strong>*Redis*</strong> <em><strong>集群的主从复制模型*</strong></em></em><em>*</em>**</p><p>为了保证高可用，redis-cluster集群引入了主从复制模型，一个主节点对应一个或者多个从节点，当主节点宕机的时候，就会启用从节点。当其它主节点 ping 一个主节点 A 时，如果半数以上的主节点与 A 通信超时，那么认为主节点 A 宕机了。如果主节点 A 和它的从节点 A1 都宕机了，那么该集群就无法再提供服务了。</p><p><a href="https://juejin.cn/post/6844904178154897415">https://juejin.cn/post/6844904178154897415</a></p><h2 id="持久化机制"><a href="#持久化机制" class="headerlink" title="持久化机制"></a>持久化机制</h2><img src="/2024/04/05/redis/clip_image054.jpg" class="" title="img"><p>怎样保证子进程持久化的时候主进程会处理新的写请求时持久化不会乱：copyandwrite机制，主进程不会直接操作父子共享内存，而是数据复制出来执行，确保子进程是5:00的数据而不是5:01的数据</p><img src="/2024/04/05/redis/clip_image055.jpg" class="" title="img"><img src="/2024/04/05/redis/clip_image056.jpg" class="" title="img"><img src="/2024/04/05/redis/clip_image057.jpg" class="" title="img"><h2 id="内存淘汰机制"><a href="#内存淘汰机制" class="headerlink" title="内存淘汰机制"></a>内存淘汰机制</h2><p>通过定期删除和惰性删除并不能删掉redis中全部的过期key，所以需要通过另外的机制来确保内存的可用性</p><img src="/2024/04/05/redis/clip_image059.jpg" class=""><img src="/2024/04/05/redis/clip_image061.jpg" class="" width=""><h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><p>redis可以通过MULTI,EXEC,DISCARD,WATCH等命令来实现事务</p><img src="/2024/04/05/redis/clip_image063.jpg" class="" title="亻 吏 用 MULT 丨 命 令 后 可 以 输 入 多 个 命 令 。 Redis 不 会 立 即 执 行 这 些 命 令 ， 而 是 将 它 们 放 到 队 列 ， 当  调 用 了 EXEC 命 令 将 执 行 所 有 命 令 。"><p>Redis 是不⽀持 roll back 的，因⽽不满⾜原⼦性的（⽽且不满⾜持性）。</p><img src="/2024/04/05/redis/clip_image065.jpg" class="" title="你 可 以 将 Redis 中 的 事 务 就 理 解 为 S-Redis 事 务 提 供 了 厂 种 将 多 个 命 令 请 求 打 包 的 功 能 。 ． ． 燃 后  再 按 顺 序 执 行 打 包 的 所 有 命 令 ， 并 且 不 会 被 中 途 打 断 0"><h1 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h1><h2 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a><strong>缓存雪崩</strong></h2><p>缓存在某一个时刻出现大规模的key失效，大量的请求打在了数据库上面</p><p><strong>问题分析：</strong></p><p>两种可能：第一种是Redis宕机，第二种可能就是采用了相同的过期时间。</p><p>解决方案：</p><p>（1）事前：</p><p>① 均匀过期：设置不同的过期时间，让缓存失效的时间尽量均匀，避免相同的过期时间导致缓存雪崩，造成大量数据库的访问。</p><p>② 分级缓存：第一级缓存失效的基础上，访问二级缓存，每一级缓存的失效时间都不同。</p><p>③ 热点数据缓存永远不过期。</p><p>永不过期实际包含两层意思：</p><p>物理不过期，针对热点key不设置过期时间</p><p>逻辑过期，把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建</p><p>④ 保证Redis缓存的高可用，防止Redis宕机导致缓存雪崩的问题。可以使用 主从+ 哨兵，Redis集群来避免 Redis 全盘崩溃的情况。</p><p>（2）事中：</p><p>① 互斥锁：在缓存失效后，通过互斥锁或者队列来控制读数据写缓存的线程数量，比如某个key只允许一个线程查询数据和写缓存，其他线程等待。这种方式会阻塞其他的线程，此时系统的吞吐量会下降,那么我们可以在第一个查询数据的请求上使用一个 互斥锁来锁住它。其他的线程走到这一步拿不到锁就等着，等第一个线程查询到了数据，然后做缓存。后面的线程进来发现已经有缓存了，就直接走缓存。</p><p>② 使用熔断机制，限流降级。当流量达到一定的阈值，直接返回“系统拥挤”之类的提示，防止过多的请求打在数据库上将数据库击垮，至少能保证一部分用户是可以正常使用，其他用户多刷新几次也能得到结果。</p><p>（3）事后：</p><p>① 开启Redis持久化机制，尽快恢复缓存数据，一旦重启，就能从磁盘上自动加载数据恢复内存中的数据。</p><h2 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a><strong>缓存击穿</strong></h2><p>缓存击穿是某个热点的key失效</p><p><strong>问题分析：</strong></p><p>两个方面解决，第一是否可以考虑热点key不设置过期时间，第二是否可以考虑降低打在数据库上的请求数量。</p><p>解决方案：</p><p>热点数据缓存永远不过期。</p><p>互斥锁：在缓存失效后，通过互斥锁或者队列来控制读数据写缓存的线程数量，比如某个key只允许一个线程查询数据和写缓存，其他线程等待。这种方式会阻塞其他的线程，此时系统的吞吐量会下降</p><h2 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a><strong>缓存穿透</strong></h2><p>用户请求的数据在缓存中不存在即没有命中，同时在数据库中也不存在，导致用户每次请求该数据都要去数据库中查询一遍。</p><p><strong>问题分析：</strong></p><p>缓存穿透的关键在于在Redis中查不到key值，它和缓存击穿的根本区别在于传进来的key在Redis中是不存在的。</p><p>解决方案：</p><p>（1）软件层面防止</p><p>（2）将无效的key存放进Redis中,并设置其过期时间极短</p><p>（3）使用布隆过滤器</p><h2 id="缓存预热"><a href="#缓存预热" class="headerlink" title="缓存预热"></a>缓存预热</h2><p>缓存预热是指系统上线后，提前将相关的缓存数据加载到缓存系统。</p><p>缓存预热解决方案：</p><p>（1）数据量不大的时候，工程启动的时候进行加载缓存动作；</p><p>（2）数据量大的时候，设置一个定时任务脚本，进行缓存的刷新；</p><p>（3）数据量太大的时候，优先保证热点数据进行提前加载到缓存。</p><h2 id="缓存降级"><a href="#缓存降级" class="headerlink" title="缓存降级"></a><strong>缓存降级</strong></h2><p>缓存降级是指缓存失效或缓存服务器挂掉的情况下，不去访问数据库，直接返回默认数据或访问服务的内存数据。</p><p><a href="https://blog.csdn.net/a745233700/article/details/88088669">https://blog.csdn.net/a745233700/article/details/88088669</a></p><h2 id="如何保证Redis和数据库的数据一致"><a href="#如何保证Redis和数据库的数据一致" class="headerlink" title="如何保证Redis和数据库的数据一致"></a><strong>如何保证Redis和数据库的数据一致</strong></h2><img src="/2024/04/05/redis/clip_image067.jpg" class="" title="img"><img src="/2024/04/05/redis/clip_image069.jpg" class="" title="img"><p><em><strong>*删缓存失败了怎么办：重试机制*</strong></em></p><p>方案1：</p><img src="/2024/04/05/redis/clip_image071.jpg" class="" title="需 要 删 除 的  消 息 队 列  3 、 需 要 删 的 key  （ * ） 2 、 删 除 缓 存 失 败  缓 存  业 务 代 码  5 、 重 试 删 除 操 作  1 、 更 新 数 据 库  数 据 库"><p>流程如下所示</p><p>（1）更新数据库数据；</p><p>（2）缓存因为种种问题删除失败</p><p>（3）将需要删除的 key 发送至消息队列</p><p>（4）自己消费消息，获得需要删除的 key</p><p>（5）继续重试删除操作，直到成功</p><p>方案2：</p><img src="/2024/04/05/redis/clip_image073.jpg" class="" title="消 息 队 列  7 、 操 作 的 数 据 以 及  （ 8 ） 5 、 删 除 缓 存 失 败  菲 业 务 代 码  、 操 作 的 数 据 以 及  8 、 重 试 删 除 操 作  4 、 提 取 出 操 作 的 数 据 以 及 key  订 Nbinlog  程 序  3 、 产 生 b og 操 作 日 志  binloga  志  2 、 写 入 binlo  缓 存  业 务 代 码  1 、 更 新 数 据 库  数 据 库"><p>流程如下图所示：</p><p>（1）更新数据库数据</p><p>（2）数据库会将操作信息写入 binlog 日志当中</p><p>（3）订阅程序提取出所需要的数据以及 key</p><p>（4）另起一段非业务代码，获得该信息</p><p>（5）尝试删除缓存操作，发现删除失败</p><p>（6）将这些信息发送至消息队列</p><p>（7）重新从消息队列中获得该数据，重试操作。</p><p><a href="https://xie.infoq.cn/article/47241d099404a1565e168fad4">https://xie.infoq.cn/article/47241d099404a1565e168fad4</a></p><p><a href="https://segmentfault.com/a/1190000037611692%E5%8F%A6%E4%B8%80%E7%A7%8D%E6%80%9D%E8%B7%AF">https://segmentfault.com/a/1190000037611692另一种思路</a></p><p>第三种方案：异步更新缓存(基于订阅binlog的同步机制)</p><p>技术整体思路：</p><p>MySQL binlog增量订阅消费+消息队列+增量数据更新到redis</p><p>1）读Redis：热数据基本都在Redis</p><p>2）写MySQL:增删改都是操作MySQL</p><p>3）更新Redis数据：MySQ的数据操作binlog，来更新到Redis</p><p>3.1）数据操作主要分为两大块：</p><p>一个是全量(将全部数据一次写入到redis)</p><p>一个是增量（实时更新）</p><p>这里说的是增量,指的是mysql的update、insert、delate变更数据。</p><p>3.2）读取binlog后分析 ，利用消息队列,推送更新各台的redis缓存数据。</p><p>这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。</p><p>其实这种机制，很类似MySQL的主从备份机制，因为MySQL的主备也是通过binlog来实现的数据一致性。</p><p>使用实例：canel</p><h2 id="设计一个分布式锁"><a href="#设计一个分布式锁" class="headerlink" title="设计一个分布式锁"></a><strong>设计一个分布式锁</strong></h2><img src="/2024/04/05/redis/clip_image074.jpg" class="" title="img"><img src="/2024/04/05/redis/clip_image075.jpg" class="" title="img"><img src="/2024/04/05/redis/clip_image076.jpg" class="" title="img"><img src="/2024/04/05/redis/clip_image077.jpg" class="" title="img"><img src="/2024/04/05/redis/clip_image078.jpg" class="" title="img"><img src="/2024/04/05/redis/clip_image079.jpg" class="" title="img"><h2 id="如何配置key的过期时间，实现原理是什么"><a href="#如何配置key的过期时间，实现原理是什么" class="headerlink" title="如何配置key的过期时间，实现原理是什么"></a>如何配置key的过期时间，实现原理是什么</h2><img src="/2024/04/05/redis/clip_image080.jpg" class="" title="img"><p>SETEX KEY_NAME TIMEOUT VALUE</p><p><strong>原理：时间事件</strong></p><p>Redis的时间事件分为两类：</p><ol><li>定时事件：让一段程序在指定的时间之后执行一次。</li><li>周期性事件：让一段程序每隔指定时间就执行一次。</li></ol><p>一个时间事件主要由以下三个属性组成：</p><ol><li>id：服务器为时间事件创建的全局唯一ID（标识号）。ID号按从小到大的顺序递增。</li><li>when：毫秒精度的UNIX时间戳。记录了时间事件到达时间。</li><li>timeProc：时间处理器，一个函数。当时间事件到达时，服务器就会调用相应的处理器来处理事件。<br>     服务器将所有时间都放在一个无序列表中，每当时间事件执行器运行时，它遍历整个链表查找所有已到达的时间事件，并调用相应的时间处理器。<br>     无序指的是不按照when属性值进行排序，由于新创建的时间事件是插入到链表的表头，所以链表中时间事件是按照id属性降序排序的。</li></ol><p>一个保存了三个时间事件链表的例子：</p><img src="/2024/04/05/redis/clip_image082.jpg" class="" title="time event  1385877600030  events  time Proc  handler 3  t ime event  1385877600000  q)  handler 2  time event  hen 1385877600010 handier 1 %}&lt;p&gt;注： 由于没有按照执行时间进行排序，所以时间事件执行器运行时，它必须遍历链表中的所有时间事件，这样才能确保服务器中所有已到达的时间事件都会被处理。&lt;&#x2F;p&gt;&lt;h1 id&#x3D;开放性问题&quot;&gt;&lt;a href&#x3D;#开放性问题 class&#x3D;headerlink title&#x3D;开放性问题&gt;&lt;&#x2F;a&gt;开放性问题&lt;&#x2F;h1&gt;&lt;h2 id&#x3D;为什么性能非常高&gt;&lt;a href&#x3D;#为什么性能非常高 class&#x3D;headerlink title&#x3D;为什么性能非常高&gt;&lt;&#x2F;a&gt;&lt;strong&gt;为什么性能非常高&lt;&#x2F;strong&gt;&lt;&#x2F;h2&gt;&lt;p&gt;Redis性能非常高的原因主要有以下几点：&lt;&#x2F;p&gt; &lt;p&gt;- 内存存储：Redis是使用内存(in-memeroy)存储,没有磁盘IO上的开销&lt;&#x2F;p&gt; &lt;p&gt;- 单线程实现：Redis使用单个线程处理请求，避免了多个线程之间线程切换和锁资源争用的开销&lt;&#x2F;p&gt; &lt;p&gt;- 非阻塞IO：Redis使用多路复用IO技术，在poll，epool，kqueue选择最优IO实现&lt;&#x2F;p&gt; &lt;p&gt;- 优化的数据结构：Redis有诸多可以直接应用的优化数据结构的实现，应用层可以直接使用原生的数据结构提升性能&lt;&#x2F;p&gt; &lt;p&gt;&lt;a href&#x3D;https:&#x2F;&#x2F;segmentfault.com&#x2F;a&#x2F;1190000022088928&gt;https:&#x2F;&#x2F;segmentfault.com&#x2F;a&#x2F;1190000022088928&lt;&#x2F;a&gt;&lt;&#x2F;p&gt; {% asset_img clip_image083.jpg img"><img src="/2024/04/05/redis/clip_image084.jpg" class="" title="img"><p>时间处理器：看是读事件还是写事件</p><img src="/2024/04/05/redis/clip_image085.jpg" class="" title="img"><p>并发量数据</p><p>单机压测</p><p>我本地试了一下</p><p>环境：windows10 64位、i5 8250U + 8G 内存。 redis单实例</p><p>1、先打开redis， 执行以下命令</p><p>.&#x2F;redis-benchmark -r 1000000 -n 2000000 -t get,set,lpush,lpop -P 16 -q</p><img src="/2024/04/05/redis/clip_image087.jpg" class="" title="å¨è¿éæå¥å¾çæè¿°"><p>14万左右并发</p><p>截一张官网的测试结果：</p><img src="/2024/04/05/redis/clip_image089.jpg" class="" title="å¨è¿éæå¥å¾çæè¿°"><p>55万并发</p><p>看来是我的电脑垃圾了…</p><p>原文链接：<a href="https://blog.csdn.net/sishenhzy/article/details/100918712">https://blog.csdn.net/sishenhzy/article/details/100918712</a></p><h2 id="海量数据下如何快速查找一条记录"><a href="#海量数据下如何快速查找一条记录" class="headerlink" title="海量数据下如何快速查找一条记录"></a><strong>海量数据下如何快速查找一条记录</strong></h2><img src="/2024/04/05/redis/clip_image091.gif" class="" title="img"><h2 id="为什么使用缓存？"><a href="#为什么使用缓存？" class="headerlink" title="为什么使用缓存？"></a>为什么使用缓存？</h2><p>高性能</p><p>对于更新频率不高并且读取频率比较大的数据，没必要每次都读取数据库。第一次读取以后，将数据放入缓存，后面再读取数据则直接从缓存获取，提高系统性能。</p><p>高并发</p><p>数据库本身并发量是非常有限的，mysql的qps一般是几千左右，如果所有请求都直接打到数据库，数据库很有可能会直接挂掉。Redis是直接基于内存进行操作的，天生就是支持高并发。根据上一篇的压测结果，单机redis并发都是几十万级别的，并发相当高。</p><p>原文链接：<a href="https://blog.csdn.net/sishenhzy/article/details/101029114">https://blog.csdn.net/sishenhzy/article/details/101029114</a></p><h2 id="在项目中是如何使用缓存的"><a href="#在项目中是如何使用缓存的" class="headerlink" title="在项目中是如何使用缓存的"></a>在项目中是如何使用缓存的</h2><p>对于项目中一些读取频率比较高的，同时数据改变频率比较小的数据，可以放入缓存中，提高并发和性能。如果数据发生改变，更新数据库的同时更新缓存。</p><p>比如电商的详情页数据，项目中接口的返回结果等等</p><p>来自 <a href="https://blog.csdn.net/sishenhzy/article/details/101029114?spm=1001.2014.3001.5501">https://blog.csdn.net/sishenhzy/article/details/101029114?spm=1001.2014.3001.5501</a></p><h2 id="使用缓存的不良后果？"><a href="#使用缓存的不良后果？" class="headerlink" title="使用缓存的不良后果？"></a>使用缓存的不良后果？</h2><p>缓存与数据库双写不一致</p><p>缓存雪崩、缓存穿透</p><p>缓存并发竞争</p><p>来自 <a href="https://blog.csdn.net/sishenhzy/article/details/101029114?spm=1001.2014.3001.5501">https://blog.csdn.net/sishenhzy/article/details/101029114?spm=1001.2014.3001.5501</a></p><h2 id="Memcached？"><a href="#Memcached？" class="headerlink" title="Memcached？"></a>Memcached？</h2><p><a href="https://www.cnblogs.com/aspnethot/articles/1861336.html"><strong>什么是<strong><strong>Memcached</strong></strong>？</strong></a></p><p>先看看下面几个概念：</p><p><strong>Memory</strong>：内存存储，不言而喻，速度快，对于内存的要求高，不指出的话所缓存的内容非持久化。对于CPU要求很低，所以常常采用将Memcached服务端和一些CPU高消耗Memory低消耗应用部属在一起。</p><p><strong>Cache</strong>：在ASP.NET中已经可以实现对页面局部进行缓存，而使用Memcached的缓存比 ASP.NET的局部缓存更加灵活，可以缓存任意的对象，不管是否在页面上输出。ASP.NET的缓存是基于本地（单机）的，受到服务器空闲内存空间的限制，以及多台web服务器本地缓存的同步，但是没有网络存取的延迟。而Memcached最大的优点是可以分布式的部署，这对于大规模应用来 说 也是必不可少的要求。最初的缓存做法是在线程内对对象进行缓存，但这样进程间就无法共享缓存，命中率非常低，导致缓存效率极低。后来出现了共享内存的缓 存，多个进程或者线程共享同一块缓存，但毕竟还是只能局限在一台机器上，多台机器做相同的缓存同样是一种资源的浪费，而且命中率也比较低。</p><p><strong>分布式扩展</strong>：Memcached的很突出一个优点，就是采用了可分布式扩展的模式。可以将部属在一台机器上的多个Memcached服务实例或者部署在多个机器上的Memcached服务器组成一个虚拟的服务端，对于调用者来说完全屏蔽和透明。提高的单机器的内存利用率。</p><p><strong>Socket****通信</strong>：传输内容的大小以及序列化的问题需要注意，虽然Memcached通常会被放置到内网作为Cache，Socket传输速率应该比较高（当前支持TCP和UDP两种模式，同时根据客户端的不同可以选择调用方式），但是序列化成本和带宽成本还是需要注意。这里也提一下序列化，对于对象序列化的性能往往让大家头痛，但是如果对于同一类的Class对象序列化传输，第一次序列化时间比较长，后续就会优化，其实也就是说序列化最大的消耗不是对象序列化，而是类的序列化。因此在Memcached中保存的往往是较小的内容。</p><p><strong>Memcached</strong> <strong>原理</strong></p><p>Memcached是一个独立的，高性能的，分布式的内存对象缓存系统。通过在内存里维护一个统一的巨大的hash表，它能够用来存储各种格式的数据，包括图像、视 频、文件以及数据库检索的结果等。它的缓存是一种分布式的，也就是可以允许不同主机上的多个用户同时访问这个缓存系统， 这种方法不仅解决了共享内存只能是单机的弊端，同时也解决了数据库检索的压力，最大的优点是提高了访问获取数据的速度！Memcached 使用libevent(网络接口的封装)来进行网络并发连接的处理，能够保持在很大并发情况下，仍旧能够保持快速的响应能力互联网公司使用代表：Sina,Sohu,Yahoo,Twitter等等。</p><p>Memcached的机制就是一个很简单的Cache，把东西放进去，然后可以取出来，如果发现所提供的Key没有命中，那么就很直白的告诉你，你这个key没有任何对应的东西在缓存里，去数据库或者其他地方取，当你在外部数据源取到的时候，可以直接将内容置入到Cache中，这样下次就可以命中了。这里会提到怎么去同步这些数据，两种方式，一种就是在你修改了以后立刻更新Cache内容，这样就会即时生效。另一种是说容许有失效时间，到了失效时间，自然就会将内容删除，此时再去去的时候就会命中不了，然后再次将内容置入Cache，用来更新内容。后者用在一些时时性要求不高，写入不频繁的情况。刚才我们提到Memcached 的传输协议，因此传输的数据必须序列化，C# class里使用[Serializable]标示，并且为了性能，Memcached Client采用了压缩的机制使传输的数据更小。其实Memcached服务端本身是单实例的，只是在客户端实现过程中可以根据存储的主键作分区存储，而这个区就是Memcached服务端的一个或者多个实例</p><p>内存分配机制：首先要说明的是Memcached支持最大的存储对象为1M。它的内存分配比较特殊，但是这样的分配方式其实也是对于性能考虑的，简单的分配机制可以更容易回收再分配，节省对于CPU的使用。这里用一个酒窖比喻来说明这种内存分配机制，首先在Memcached起来的时候可以通过参数设置使用的总共的Memory，当你第一次往Memcached存储数据时, Memcached会去申请1MB的内存, 把该块内存称为一个slab, 也称为一个page, 如果可以存储这个数据的最佳的chunk大小为128B,那么Memcached会把刚申请的slab以128B为单位进行分割成8192块. 当这页slab的所有chunk都被用完时,并且继续有数据需要存储在128B的chunk里面时,如果已经申请的内存小于最大可申请内存10MB 时, Memcached继续去申请1M内存,继续以128B为单位进行分割再进行存储;如果已经无法继续申请内存,那么Memcached会先根据LRU 算法把队列里面最久没有被使用到的chunk进行释放后,再将该chunk用于存储. 这个就是建造一个酒窖，然后在有酒进入的时候，首先申请（通常是1M）的空间，用来建酒架，酒架根据这个酒瓶的大小分割酒架为多个小格子安放酒瓶，将同样大小范围内的酒瓶都放置在一类酒架上面。例如20cm半径的酒瓶放置在可以容纳20-25cm的酒架A上，30cm半径的酒瓶就放置在容纳25-30cm的酒架B上。回收机制也很简单，首先新酒入库，看看酒架是否有可以回收的地方，如果有直接使用，如果没有申请新的地方，如果申请不到，采用配置的过期策略。这个特点来看，如果要放的内容大小十分离散，同时大小比例相差梯度很明显，那么可能对于使用空间来说不好，可能在酒架A上就放了一瓶酒，但占用掉了一个酒架的位置。</p><p>为了避免使用Memcached时出现异常, 使用Memcached的项目需要注意:</p><p>\1. 不能往Memcached存储一个大于1MB的数据.</p><p>\2. 往Memcached存储的所有数据,如果数据的大小分布于各种chunk大小区间,从64B到1MB都有,可能会造成内存的极大浪费以及Memcached的异常.</p><p>举个例子:</p><p>Memcached最大可申请内存为2M, 你第一次存储一个10B的数据,那么Memcached会申请1MB的内存,以64B进行分割然后存储该数据, 第二次存储一个90B的数据,那么Memcached会继续申请1M的内存,以128B进行分割然后存储该数据, 第三次如果你想存储一个150B的数据, 如果可以继续申请内存, Memcached会申请1M内存以256B的大小进行分割, 但是由于最大可申请仅仅为2MB,所以会导致该数据无法存储.</p><p>数据过期方式</p><p>• Lazy Expiration</p><p>Memcached内部不会监视记录是否过期，而是在get时查看记录的时间戳，检查记录是否过</p><p>期。这种技术被称为lazy（惰性）expiration。因此，Memcached不会在过期监视上耗费</p><p>CPU时间。</p><p>• LRU</p><p>Memcached会优先使用已超时的记录的空间，但即使如此，也会发生追加新记录时空间不</p><p>足的情况，此时就要使用名为 Least Recently Used（LRU）机制来分配空间。顾名思</p><p>义，这是删除“最近最少使用”的记录的机制。因此，当Memcached的内存空间不足时</p><p>（无法从slab class 获取到新的空间时），就从最近未被使用的记录中搜索，并将其空</p><p>间分配给新的记录。从缓存的实用角度来看，该模型十分理想。</p><p>分布式</p><p>假设有3个客户端1, 2, 3，3台Memcached A, B, C：</p><p>Client 1想把数据”barbaz”以key “foo”存储。Client 1首先参考节点列表（A, B, C），计算key “foo”的哈希值，假设Memcached B被选中。接着，Client 1直接connect到Memcached B，通过key “foo”把数据”barbaz”存储进去。Client 2使用与Client 1相同的客户端库（意味着key的哈希算法相同），也拥有同样的Memcached列表（A, B, C）。于是，经过相同的哈希计算，Client 2计算出key “foo”在Memcached B上，然后它直接请求Memcached B，得到数据”barbaz”。</p><p><strong>Memcached****的使用场合</strong></p><p>当运行在单独的Web服务器上，你可以很容易地清除一个已经确认被改变了的缓存。可惜，ASP.NET没有一个很好的方法来支持多服务器。每个服务器上的缓存都对其他缓存的改变一无所知。ASP.NET允许通过基于文件系统和数据库表的触发器取消一个缓存。然而，这也存在问题，比如数据库触发器需要使用昂贵的轮询，以及触发器本身冗长的编程。好像.NET4.0有了新的解决方法。我们还有别的选择，Memcached就一种。但是Memcached不是万能的，它也不是适用在所有场合。 Memcached是“分布式”的内存对象缓存系统，那么就是说，那些不需要“分布”的，不需要共享的，或者干脆规模小到只有一台服务器的应用， Memcached不会带来任何好处，相反还会拖慢系统效率，因为网络连接同样需要资源，即使是UNIX本地连接也一样。Memcached本地读写速度要比直接ASP.NET缓存(IIS进程)内存慢很多倍，请看下面的测试数据。可见，如果只是 本地级缓存，使用Memcached是非常不划算的。Memcached在很多时候都是作为数据库前端cache使用的。因为它比数据库少了很多SQL解析、磁盘操作等开销，而且它是使用内存来管理数据的， 所以它可以提供比直接读取数据库更好的性能，在大型系统中，访问同样的数据是很频繁的，Memcached可以大大降低数据库压力，使系统执行效率提升。Memcached也经常作为服务器之间数据共享的存储媒介，存储一些系统的共享数据。</p><p>需要注意的是，Memcached使用内存管理数据，所以它是易失的，当服务器重启，或者Memcached进程中止，数据便会丢失，所以 Memcached不能用来持久保存数据。很多人的错误理解，Memcached的性能非常好，好到了内存和硬盘的对比程度，它的实际瓶颈在于网络连接，它和使用磁盘的数据库系统相比，好处在于它本身非常“轻”，因为没有过多的开销和直接 的读写方式，它可以轻松应付非常大的数据交换量，，Memcached进程本身并不占用多少CPU资源的情况。如果web系统采用ASP.NET缓存 + Memcached的方式。性能将会有个不错的提升。</p><p>ASP.NET缓存：本地的，速度更快，一般将highly  common的数据或者程序控制数据用ASP.NET缓存。</p><p>Memcached：存一些来自数据库的数据或者web服务器的共享数据。</p><h2 id="redis-和-memcached-有啥区别？"><a href="#redis-和-memcached-有啥区别？" class="headerlink" title="redis 和 memcached 有啥区别？"></a>redis 和 memcached 有啥区别？</h2><p>redis 支持复杂的数据结构</p><p>redis 相比 memcached 来说，拥有更多的数据结构，能支持更丰富的数据操作。如果需要缓存能够支持更复杂的结构和操作， redis 会是不错的选择。</p><p>redis 原生支持集群模式</p><p>在 redis3.x 版本中，便能支持 cluster 模式，而 memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。</p><p>性能对比</p><p>由于 redis 只使用单核，而 memcached 可以使用多核，所以平均每一个核上 redis 在存储小数据时比 memcached 性能更高。而在 100k 以上的数据中，memcached 性能要高于 redis。虽然 redis 最近也在存储大数据的性能上进行优化，但是比起 memcached，还是稍有逊色。</p><p>原文链接：<a href="https://blog.csdn.net/sishenhzy/article/details/101061787">https://blog.csdn.net/sishenhzy/article/details/101061787</a></p><h1 id="Redis实际应用场景"><a href="#Redis实际应用场景" class="headerlink" title="Redis实际应用场景"></a><strong>Redis</strong>实际应用场景</h1><p>最新的项目列表：</p><p>一个队列，左进右出，放的永远是最新的一个数据</p><p>排行榜应用，取TOP N操作</p><p>   这个需求与上面需求的不同之处在于，取最新N个数据的操作以时间为权重，这个是以某个条件为权重，比如按顶的次数排序，这时候就需要我们的sorted set出马了，将你要排序的值设置成sorted set的score，将具体的数据设置成相应的value，每次只需要执行一条ZADD命令即可。</p><p>计数：点击次数</p><p>分布式锁（string）：setnx</p><p>消息队列（list）：在list里面一边进，一边出即可</p>]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MYSQL</title>
      <link href="/2024/04/05/MYSQL/"/>
      <url>/2024/04/05/MYSQL/</url>
      
        <content type="html"><![CDATA[<h1 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a>MVCC</h1><img src="/2024/04/05/MYSQL/clip_image002.gif" class="" title="img"><p>已提交读的readview：每次生成最新的    可重复读的readview：沿用事务中上一次的</p><img src="/2024/04/05/MYSQL/clip_image004.gif" class="" title="img"><img src="/2024/04/05/MYSQL/clip_image006.gif" class="" title="img"><p>事务只有在update的时候才能生成事务id，select的时候，比对规则是针对版本链中的id是否符合比对规则</p><img src="/2024/04/05/MYSQL/clip_image008.gif" class="" title="img"><img src="/2024/04/05/MYSQL/clip_image010.gif" class="" title="img"><p>同一时刻不同事务中同样的查询语句可能查到不同的数据（select1中和select2中最后一条语句）</p><p>下面是对于删除情况的说明，并且是对于select2的说明</p><p>删除数据数据库文件并未变小</p><img src="/2024/04/05/MYSQL/clip_image002-1712316816560.gif" class="" title="img"><h1 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h1><p>索引类型</p><img src="/2024/04/05/MYSQL/clip_image014.gif" class="" title="img"><p><a href="https://www.jianshu.com/p/bf30c2b9a0cf">https://www.jianshu.com/p/bf30c2b9a0cf</a></p><h3 id="聚集索引-聚簇索引"><a href="#聚集索引-聚簇索引" class="headerlink" title="聚集索引 -聚簇索引"></a>聚集索引 -聚簇索引</h3><img src="/2024/04/05/MYSQL/clip_image016.gif" class="" title="必 闰 一 个 主 0 到 的 ： key  就 引 是 甴 是 聚 集 存 一 - 如 累 在 刨 表 的 的 定 7 主 ． 鄺 么 y 就 是  玉 姬 ． 果 玉 姬 · 么 y 就 是 一 ． 知  臨 一 谜 也 有 那 么 y 匭 是 字 莎 的 " alt="。 wid  叫 的 0 是 」 学 哮 引"><p>聚簇索引（聚集索引）：聚簇索引是一种数据存储方式，InnoDB的聚簇索引就是按照主键顺序构建 B+Tree结构。B+Tree 的叶子节点就是行记录，行记录和主键值紧凑地存储在一起。 这也意味着 InnoDB 的主键索引就是数据表本身，它按主键顺序存放了整张表的数据，占用的空间就是整个表数据量的大小。通常说 的<strong>主键索引</strong>就是聚集索引。</p><p>InnoDB的表要求必须要有聚簇索引：</p><p>（1）如果表定义了主键，则主键索引就是聚簇索引</p><p>（2）如果表没有定义主键，则第一个非空unique列作为聚簇索引</p><p>（3）否则InnoDB会从建一个隐藏的row-id作为聚簇索引</p><h3 id="辅助索引"><a href="#辅助索引" class="headerlink" title="辅助索引"></a>辅助索引</h3><p>InnoDB辅助索引，也叫作二级索引，是根据索引列构建 B+Tree结构。但在 B+Tree 的叶子节点中只存了索引列和主键的信息。二级索引占用的空间会比聚簇索引小很多， 通常创建辅助索引就是为了提升查询效率。一个表InnoDB只能创建一个聚簇索引，但可以创建多个辅助索引。</p><p>与InnoDB表存储不同，MyISAM数据表的索引文件和数据文件是分开的，被称为非聚簇索引结 构。</p><h3 id="覆盖索引回表"><a href="#覆盖索引回表" class="headerlink" title="覆盖索引回表"></a>覆盖索引回表</h3><img src="/2024/04/05/MYSQL/clip_image018.gif" class="" title="img"><p>所有列建索引是不是查询更快，不是的，粒度会太小，索引的维护成本会增加，在索引上的操作会变多</p><h3 id="唯一索引和非唯一索引（普通索引）"><a href="#唯一索引和非唯一索引（普通索引）" class="headerlink" title="唯一索引和非唯一索引（普通索引）"></a>唯一索引和非唯一索引（普通索引）</h3><ul><li><p>唯一索引是这样一种索引，它通过确保表中没有两个数据行具有完全相同的键值来帮助维护数据完整性。为包含数据的现有表创建唯一索引时，会检查组成索引键的列或表达式中的值是否唯一。如果该表包含具有重复键值的行，那么索引创建过程会失败。为表定义了唯一索引之后，每当在该索引内添加或更改键时就会强制执行唯一性。此强制执行包括插入、更新、装入、导入和设置完整性以命名一些键。除了强制数据值的唯一性以外，唯一索引还可用来提高查询处理期间检索数据的性能。</p></li><li><p>非唯一索引不用于对与它们关联的表强制执行约束。相反，非唯一索引通过维护频繁使用的数据值的排序顺序，仅仅用于提高查询性能。</p></li></ul><h3 id="全文索引"><a href="#全文索引" class="headerlink" title="全文索引"></a>全文索引</h3><p>通过建立倒排索引,可以极大的提升检索效率,解决判断字段是否包含的问题. 例如: 有title字段,需要查询所有包含 “政府”的记录. 需要 like “%政府%”方式查询,查询速度慢,当查询包含”政府” OR “中国”的需要是,sql难以简单满足.全文索引就可以实现这个功能.</p><p><a href="https://zhuanlan.zhihu.com/p/88275060">https://zhuanlan.zhihu.com/p/88275060</a></p><h2 id="索引数据结构的选择"><a href="#索引数据结构的选择" class="headerlink" title="索引数据结构的选择"></a>索引数据结构的选择</h2><img src="/2024/04/05/MYSQL/clip_image020.gif" class="" title="img"><img src="/2024/04/05/MYSQL/clip_image022.gif" class="" title="img"><img src="/2024/04/05/MYSQL/clip_image024.gif" class="" title="img"><img src="/2024/04/05/MYSQL/clip_image026.gif" class="" title="img"><img src="/2024/04/05/MYSQL/clip_image028.gif" class="" title="img"><p>二叉树：不适合存储，没有规律，不适合查找</p><p>二叉搜索树：虽然可以二分查找，但是插入数据若是升序或降序则时间复杂度则降级为O(N)</p><p>AVL:在二叉搜索树的基础上最长子树和最短子树相差不超过1——-查找效率高的，但是插入效率很低，因为平衡条件太严格</p><img src="/2024/04/05/MYSQL/clip_image030.gif" class="" title="img"><p>红黑树：:最长子树不能超过最短子树的2倍——随着数据的增多，深度越来越深</p><p>红黑树就是介于完全不平衡和完全平衡之间的一种二叉树，通过每个节点有红黑两种颜色、从节点到任意叶子节点会经过相同数量的黑色节点等一系列规则，实现了【树的层数最大也只会有两倍的差距】，这样既能提高插入和删除的效率，又能让树相对平衡从而有还不错的查询效率。从整体上讲，红黑树就是一种中庸之道的二叉树。</p><img src="/2024/04/05/MYSQL/clip_image032.gif" class="" title="img"><p>B树：</p><img src="/2024/04/05/MYSQL/clip_image034.gif" class="" title="img"><p>一个磁盘块为16KB，假设索引不占空间，只有data占空间，一个data占1KB，那么一个磁盘块能存16条数据，3层B树最多能存16×16×16&#x3D;4096条数据，远远不够</p><p>B+树：</p><img src="/2024/04/05/MYSQL/clip_image036.gif" class="" title="img"><p>假设p1和28共占10B，磁盘块16kB可以放16<em>1024&#x2F;10个数据索引，那么3层总共能放（16</em>1024&#x2F;10）<em>（16</em>1024&#x2F;10）*16个数据，所以要用B+树</p><p>索引一般B+树层数为3-4层：由数据量决定</p><img src="/2024/04/05/MYSQL/clip_image038.gif" class="" title="img"><p>两种引擎B+树的区别：</p><img src="/2024/04/05/MYSQL/clip_image040.gif" class="" title="img"><p>所有文件先开始都在硬盘，加载的时候才在内存</p><p>数据只存一份，即使是创建了两个索引，当在普通字段创建索引时，比如下图是在name字段创建索引，叶子节点放的是主键值，还需要到主键B+树中去查找数据</p><img src="/2024/04/05/MYSQL/clip_image042.gif" class="" title="img"><img src="/2024/04/05/MYSQL/clip_image044.gif" class="" title="img"><h2 id="简述索引对于数据库性能的影响"><a href="#简述索引对于数据库性能的影响" class="headerlink" title="简述索引对于数据库性能的影响"></a>简述索引对于数据库性能的影响</h2><img src="/2024/04/05/MYSQL/clip_image046.gif" class="" title="索 引 可 以 极 大 的 提 高 数 据 的 查 速 度 ．  通 过 使 用 索 引 ， 可 以 旺 0 洵 的 过 程 中 ， 使 用 优 化 隐 藏 器 ， 提 高 系 统 性 能 。  但 是 会 降 低 适 入 、 删 除 、 更 新 表 的 速 度 ， 因 为 在 执 行 这 些 写 操 作 时 ， 还 要 悍 作 索 引 文 件  索 引 需 要 占 物 理 空 间 ， 除 了 数 据 表 占 数 据 空 间 之 外 ， 每 一 个 索 引 还 要 占 一 定 的 物 理 空 间 ． 如 果 要 建 立 聚 簇 索 引 ， 那  么 需 要 的 空 间 就 会 更 大 ， 如 果 非 聚 索 引 很 多 ， 一 旦 聚 隼 索 引 改 变 ， 那 么 所 有 非 聚 隼 索 引 都 会 跟 变 。"><p>优化隐藏：一般地，对查询语句，查询处理器创建了可以提高性能的执行规划。然而，如果对某一个特定的查询语句例如检索、插入、删除、修改，查询处理器没有创建最好的执行规划，那么用户可以在查询语句中增加优化隐藏来影响查询处理器创建出最优的执行规划。优化隐藏就是指在执行查询语句、使用多表连接检索或者指定查询语句操作的对象表时，明确地指出应该使用的查询方法、连接算法或者对表的操作方式。当使用优化隐藏时，一定要认真考虑优化隐藏对性能的影响。在SQL Server 7.0中，提供了三种类型的优化隐藏，即查询优化隐藏、连接优化隐藏和表优化隐藏。<a href="https://zhidao.baidu.com/question/39271452.html">https://zhidao.baidu.com/question/39271452.html</a></p><h2 id="索引设计原则"><a href="#索引设计原则" class="headerlink" title="索引设计原则"></a>索引设计原则</h2><img src="/2024/04/05/MYSQL/clip_image048.gif" class="" title="img"><h2 id="创建索引时用int类型还是varchar类型"><a href="#创建索引时用int类型还是varchar类型" class="headerlink" title="创建索引时用int类型还是varchar类型"></a>创建索引时用int类型还是varchar类型</h2><p>占用空间小就用：若用varchar表示它的长度是多少个字节，如果你的varchar小于4个字节，那么就用varchar，如果varchar大于4个字节，那么就用int。</p><h2 id="页：最小的逻辑单元"><a href="#页：最小的逻辑单元" class="headerlink" title="页：最小的逻辑单元"></a>页：最小的逻辑单元</h2><img src="/2024/04/05/MYSQL/clip_image050.gif" class="" title="img"><h2 id="最左匹配原则"><a href="#最左匹配原则" class="headerlink" title="最左匹配原则"></a><strong>最左匹配原则</strong></h2><img src="/2024/04/05/MYSQL/clip_image052.gif" class="" title="img"><p>本质上第一个字段是有序的，第二个单看是无序的，结合第一个看是有序的（第一个一样的时候，第二个就是有序的）</p><h2 id="索引下推"><a href="#索引下推" class="headerlink" title="索引下推"></a><strong>索引下推</strong></h2><img src="/2024/04/05/MYSQL/clip_image054.gif" class="" title="select · 行 0mtab | e 1 虻 " alt="n 虻 一 ？ 出 记 09e 一 ？  y ， q07 」 有 的 个 恃 ：  引 ． 卜 准 之 前  索 引 下  先 n “ 匾 去 存 銠 引 中 吧 敷 巴 就 然 岵 0 "><p>主键递增</p><img src="/2024/04/05/MYSQL/clip_image056.gif" class="" title="img"><p>递增的话直接向后面追加就好了，不会影响之前的目录结构</p><p><strong>无特殊需求下Innodb建议使用与业务无关的自增ID作为主键</strong></p><p>InnoDB引擎使用聚集索引，数据记录本身被存于主索引（一颗B+Tree）的叶子节点上。这就要求同一个叶子节点内（大小为一个内存页或磁盘页）的各条数据记录按主键顺序存放，因此每当有一条新的记录插入时，MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子（InnoDB默认为15&#x2F;16），<strong>则开辟一个新的页（节点）</strong></p><p>1、如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。</p><p>这样就会形成一个紧凑的索引结构，近似顺序填满。<strong>由于每次插入时也不需要移动已有数据，因此效率很高，也不会增加很多开销在维护索引上。</strong></p><p>2、 如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置</p><p>此时MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。</p><p>在使用InnoDB存储引擎时，如果没有特别的需要，请永远使用一个与业务无关的自增字段作为主键。</p><img src="/2024/04/05/MYSQL/clip_image058.jpg" class="" title="img"><h2 id="代理主键与然主键"><a href="#代理主键与然主键" class="headerlink" title="代理主键与然主键"></a>代理主键与然主键</h2><p>代理主键是指与业务无关且能唯一标识数据库中记录,一般是数据库自动生成的,比如mysql可以使用auto_increment,Sql2000可以使用identity生成方式,oracle可以使用sequence生成方式 自然主键指业务相关,由用户指定,且能唯一标识数据库中的任意一条记录</p><h2 id="文件的存储"><a href="#文件的存储" class="headerlink" title="文件的存储"></a><strong>文件的存储</strong></h2><img src="/2024/04/05/MYSQL/clip_image060.gif" class="" title="img"><p>MySQL可以不指定主键建表吗，背后的逻辑是什么</p><p>如果没有主动设置主键，就会选一个不包含NULL的第一个唯一索引列作为主键列，并把它用作一个聚集索引。如果没有这样的索引就会使用行号生成一个聚集索引，把它当做主键，这个行号6bytes，自增。可以用select _rowid from table来查询</p><h1 id="mysql建唯一索引后重复插入会报错，解决方法"><a href="#mysql建唯一索引后重复插入会报错，解决方法" class="headerlink" title="mysql建唯一索引后重复插入会报错，解决方法"></a><strong>mysql</strong>建唯一索引后重复插入会报错，解决方法</h1><p>insert ignore 能忽略重复数据，只插入不重复的数据。</p><p>replace into 和 insert … on duplicate key update，都是替换原有的重复数据，区别在于replace into是删除原有的行后，再插入新行，如有自增id，这个会造成自增id的改变；insert … on duplicate key update在遇到重复行时，会直接更新原有的行，具体更新哪些字段怎么更新，取决于update后的语句。</p><p><a href="https://blog.csdn.net/u012660464/article/details/117416047">https://blog.csdn.net/u012660464/article/details/117416047</a></p><h2 id="自适应哈希"><a href="#自适应哈希" class="headerlink" title="自适应哈希"></a>自适应哈希</h2><p>InnoDB存储引擎会自动对个索引页上的查询进行监控，如果能够通过使用自适应哈希索引来提高查询效率，其便会自动创建自适应哈希索引，不需要开发人员或运维人员进行任何设置操作。自适应哈希索引是对innodb的缓冲池的B+树页进行创建，不是对整张表创建，因此速度很快。</p><p>Innodb存储引擎会监控对表上二级索引的查找，如果发现某二级索引被频繁访问(最近连续被访问三次的数据)，二级索引成为热数据，建立哈希索引可以带来速度的提升，自适应哈希索引通过缓冲池的B+树构造而来，因此建立的速度很快。</p><p>特点</p><p>1、无序，没有树高</p><p>2、降低对二级索引树的频繁访问资源</p><p>索引树高&lt;&#x3D;4，访问索引：访问树、根节点、叶子节点</p><p>3、自适应</p><p>3、缺陷</p><p>1、hash自适应索引会占用innodb buffer pool；</p><p>2、自适应hash索引只适合搜索等值的查询，如select * from table where index_col&#x3D;’xxx’，而对于其他查找类型，如范围查找，是不能使用的；</p><p>3、极端情况下，自适应hash索引才有比较大的意义，可以降低逻辑读。</p><p>来自 <a href="https://www.cnblogs.com/geaozhang/p/7252389.html">https://www.cnblogs.com/geaozhang/p/7252389.html</a></p><h1 id="innoDB锁算法"><a href="#innoDB锁算法" class="headerlink" title="innoDB锁算法"></a>innoDB锁算法</h1><img src="/2024/04/05/MYSQL/clip_image062.gif" class="" title="img"><img src="/2024/04/05/MYSQL/clip_image064.gif" class="" title="iii"><p>InnoDB通过给索引项加锁来实现行锁，如果没有索引，则通过隐藏的聚簇索引来对记录加锁。如果操作不通过索引条件检索数据，InnoDB 则对表中的所有记录加锁，实际效果就和表锁一样。</p><img src="/2024/04/05/MYSQL/clip_image066.gif" class="" title="iii"><ul><li>例如一个索引有10,11,13,20这四个值。InnoDB可以根据需要使用Record Lock将10，11，13，20四个索引锁住，也可以使用Gap Lock将(-∞,10)，(10,11)，(11,13)，(13,20)，(20, +∞)五个范围区间锁住。Next-Key Locking类似于上述两种锁的结合，它可以锁住的区间有为(-∞,10]，(10,11]，(11,13]，(13,20]，(20, +∞)，可以看出它即锁定了一个范围，也会锁定记录本身。<br> 详细： <a href="https://zhuanlan.zhihu.com/p/66676020">https://zhuanlan.zhihu.com/p/66676020</a></li></ul><p>乐观锁：</p><p>乐观锁不是数据库自带的，需要我们自己去实现。乐观锁是指操作数据库时(更新操作)，想法很乐观，认为这次的操作不会导致冲突，在操作数据时，并不进行任何其他的特殊处理（也就是不加锁），而在进行更新后，再去判断是否有冲突了。</p><p>通常实现是这样的：在表中的数据进行操作时(更新)，先给数据表加一个版本(version)字段，每操作一次，将那条记录的版本号加1。也就是先查询出那条记录，获取出version字段,如果要对那条记录进行操作(更新),则先判断此刻version的值是否与刚刚查询出来时的version的值相等，如果相等，则说明这段期间，没有其他程序对其进行操作，则可以执行更新，将version字段的值加1；如果更新时发现此刻的version值与刚刚获取出来的version的值不相等，则说明这段期间已经有其他程序对其进行操作了，则不进行更新操作。</p><h1 id="数据引擎"><a href="#数据引擎" class="headerlink" title="数据引擎"></a>数据引擎</h1><img src="/2024/04/05/MYSQL/clip_image068.gif" class="" title="img"><p>innodb在5.6版本之后支持全文检索，MyISAM支持全文检索</p><p>innodb索引叶子节点直接存放数据，而MyISAM存放地址</p><h1 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h1><img src="/2024/04/05/MYSQL/clip_image070.gif" class="" title="img"><h2 id="Innodb如何实现事务"><a href="#Innodb如何实现事务" class="headerlink" title="Innodb如何实现事务"></a>Innodb如何实现事务</h2><img src="/2024/04/05/MYSQL/clip_image072.jpg" class="" title="Innodt*tButter Pool, LogButfer, Redo Log, Undo  1. POOI*  2. HlfiupdateiËEJ,  3. %FÀLogBuffercta  4.  6,"><h2 id="四大特性（ACID）以及实现原理"><a href="#四大特性（ACID）以及实现原理" class="headerlink" title="四大特性（ACID）以及实现原理"></a>四大特性（ACID）以及实现原理</h2><p>1.一致性</p><p>从数据库层面，数据库通过原子性、隔离性、持久性来保证一致性。也就是说ACID四大特性之中，C(一致性)是目的，A(原子性)、I(隔离性)、D(持久性)是手段，是为了保证一致性，数据库提供的手段。一致性是事务追求的最终目标，数据库必须要实现AID三大特性，才有可能实现一致性。例如，原子性无法保证，显然一致性也无法保证，除了数据库层面的保障，一致性的实现也需要应用层面进行保障。</p><p>2.Mysql怎么保证原子性的？</p><p>利用Innodb的undo log。undo log名为回滚日志，是实现原子性的关键，当事务回滚时能够撤销所有已经成功执行的sql语句，他需要记录你要回滚的相应日志信息。undo log记录了这些回滚需要的信息，当事务执行失败或调用了rollback，导致事务需要回滚，便可以利用undo log中的信息将数据回滚到修改之前的样子。</p><p>3.Mysql怎么保证隔离性的？</p><p>利用的是锁和MVCC机制。至于MVCC,即多版本并发控制(Multi Version Concurrency Control),一个行记录数据有多个版本对快照数据，这些快照数据在undo log中。如果一个事务读取的行正在做DELELE或者UPDATE操作，读取操作不会等行上的锁释放，而是读取该行的快照版本。</p><p>4.Mysql怎么保证持久性的？</p><p>利用Innodb的redo log。Mysql是先把磁盘上的数据加载到内存中，在内存中对数据进行修改，再刷回磁盘上。如果此时突然宕机，内存中的数据就会丢失。于是，决定采用redo log解决上面的问题。当做数据修改的时候，不仅在内存中操作，还会在redo log中记录这次操作。当事务提交的时候，会将redo log日志进行刷盘(redo log一部分在内存中，一部分在磁盘上)。当数据库宕机重启的时候，会将redo log中的内容恢复到数据库中，再根据undo log和binlog内容决定回滚数据还是提交数据。</p><p>采用redo log的好处？</p><p>其实好处就是将redo log进行刷盘比对数据页刷盘效率高，具体表现如下</p><ul><li>redo log体积小，毕竟只记录了哪一页修改了啥，因此体积小，刷盘快。</li><li>redo log是一直往末尾进行追加，属于顺序IO。效率显然比随机IO来的快。</li></ul><p><a href="https://blog.csdn.net/weixin_30649859/article/details/95897520">https://blog.csdn.net/weixin_30649859/article/details/95897520</a></p><h2 id="4个隔离级别及其实现原理"><a href="#4个隔离级别及其实现原理" class="headerlink" title="4个隔离级别及其实现原理"></a><strong>4</strong>个隔离级别及其实现原理</h2><p> 1.读未提交（READ UNCOMMITTED）</p><p>​    压根儿就不加锁，所以根本谈不上什么隔离效果，可以理解为没有隔离。</p><p> 2.读提交 （READ COMMITTED）</p><p>​    在RC级别中，数据的读取都是不加锁的，但是数据的写入、修改和删除是需要加锁的。</p><img src="/2024/04/05/MYSQL/clip_image074.jpg" class="" title="img"><p>​    如果是没有索引的class_name呢？update class_teacher set teacher_id&#x3D;3 where class_name &#x3D; ‘初三一班’; 那么MySQL会给整张表的所有数据行的加行锁。</p><p>附加：但在实际使用过程当中，MySQL做了一些改进，在MySQL Server过滤条件，发现不满足后，会调用unlock_row方法，把不满足条件的记录释放锁 (违背了二段锁协议的约束)。这样做，保证了最后只会持有满足条件记录上的锁，但是每条记录的加锁操作还是不能省略的。</p><p> 3.可重复读 （REPEATABLE READ）</p><p>​     a.解决可重复读问题</p><p>在InnoDB中，会在每行数据后添加两个额外的隐藏的值来实现MVCC，这两个值一个记录这行数据何时被创建，另外一个记录这行数据何时过期（或者被删除）。 在实际操作中，存储的并不是时间，而是事务的版本号，每开启一个新事务，事务的版本号就会递增。 在可重读Repeatable reads事务隔离级别下：</p><p> SELECT时，读取创建版本号&lt;&#x3D;当前事务版本号，删除版本号为空或&gt;当前事务版本号。</p><p> INSERT时，保存当前事务版本号为行的创建版本号</p><p> DELETE时，保存当前事务版本号为行的删除版本号</p><p> UPDATE时，插入一条新纪录，保存当前事务版本号为行创建版本号，同时保存当前事务版本号到原来删除的行</p><p>​    b.为了解决当前读中的幻读问题，MySQL事务使用了Next-Key锁:</p><p>​    Innodb将这段数据分成几个个区间(negative infinity, 5],(5,30],(30,positive infinity)；</p><p>​    update class_teacher set class_name&#x3D;‘初三四班’ where teacher_id&#x3D;30;不仅用行锁，锁住了相应的数据行；同时也在两边的区间，（5,30]和（30，positive infinity），都加入了gap锁。这样事务B就无法在这个两个区间insert进新数据。行锁防止别的事务修改或删除，GAP锁防止别的事务新增，行锁和GAP锁结合形成的的Next-Key锁共同解决了RR级别在写数据时的幻读问题。</p><p>​    如果使用的是没有索引的字段，比如update class_teacher set teacher_id&#x3D;7 where class_name&#x3D;‘初三八班（即使没有匹配到任何数据）’,那么会给全表加入gap锁。同时，它不能像上文中行锁一样经过MySQL Server过滤自动解除不满足条件的锁，因为没有索引，则这些字段也就没有排序，也就没有区间。除非该事务提交，否则其它事务无法插入任何数据。</p><img src="/2024/04/05/MYSQL/clip_image076.jpg" class="" title="img"><p>4.串行化 （SERIALIZABLE）</p><p>​    这个级别很简单，读加共享锁，写加排他锁，读写互斥。使用的悲观锁的理论，实现简单，数据更加安全，但是并发能力非常差。</p><img src="/2024/04/05/MYSQL/clip_image078.gif" class="" title="img"><p>并发访问的问题还有：丢失更新 当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，会发生丢失更新问题。每个事务都不知道其它事务的存在。最后的更新将重写由其它事务所做的更新，这将导致数据丢失。</p><p>例如，两个编辑人员制作了同一文档的电子复本。每个编辑人员独立地更改其复本，然后保存更改后的复本，这样就覆盖了原始文档。最后保存其更改复本的编辑人员覆盖了第一个编辑人员所做的更改。如果在第一个编辑人员完成之后第二个编辑人员才能进行更改，则可以避免该问题。</p><p><a href="https://tech.meituan.com/2014/08/20/innodb-lock.html">https://tech.meituan.com/2014/08/20/innodb-lock.html</a> 美团</p><p><a href="https://www.cnblogs.com/fengzheng/p/12557762.html">https://www.cnblogs.com/fengzheng/p/12557762.html</a> 博客</p><h1 id="三大log日志"><a href="#三大log日志" class="headerlink" title="三大log日志"></a>三大log日志</h1><h2 id="Binlog"><a href="#Binlog" class="headerlink" title="Binlog"></a>Binlog</h2><p><strong>1.Row格式</strong></p><p>  此格式不记录sql语句上下文相关信息，仅保存哪条记录被修改。</p><p>优点： binlog中可以不记录执行的sql语句的上下文相关的信息，仅需要记录那一条记录被修改成什么了。所以Row格式的日志内容会非常清楚的记录下每一行数据修改的细节。</p><p>缺点:所有的执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，这样<strong>可能会产生大量的日志内容</strong>,比如一条update语句或者一条alter语句，修改多条记录，则binlog中每一条修改都会有记录，每条记录都发生改变，那么该表每一条记录都会记录到日志中，这样造成binlog日志量会很大。</p><p><strong>2.Statement格式</strong></p><p>  该格式下每一条会修改数据的sql都会记录在binlog中。</p><p>优点：不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能。它相比row模式能节约很多性能与日志量，具体节约的多少取决于应用的SQL情况。正常同一条记录修改或者插入row格式所产生的日志量还小于Statement产生的日志量，考虑到整表删除等一些大量数据操作，ROW格式会产生大量日志，所以总体来讲statement模式会稍微好一些。</p><p>缺点：由于记录的只是执行语句，为了这些语句能在slave上正确运行，因此还必须记录每条语句在执行的时候的一些相关信息，以保证所有语句能在slave得到和在master端执行时候相同的结果。</p><p><strong>3.Mixed格式</strong></p><p>  该格式是以上两种level的混合使用，一般的语句修改使用statment格式保存binlog，当statement无法完成主从复制的操作时(涉及一些函数时)，则采用Row格式保存binlog,MySQL会根据执行的每一条具体的sql语句来区分对待记录的日志形式，也就是在Statement和Row之间选择一种.新版本的MySQL中队Row模式也被做了优化，并不是所有的修改都会以Row模式来记录，像遇到表结构变更的时候就会以statement模式来记录。至于update或者delete等修改数据的语句，还是会记录所有行的变更。<a href="https://cloud.tencent.com/developer/article/1533697">https://cloud.tencent.com/developer/article/1533697</a></p><h1 id="SQL调优"><a href="#SQL调优" class="headerlink" title="SQL调优"></a>SQL调优</h1><h2 id="⼀条SQL语句在MySQL中如何执⾏"><a href="#⼀条SQL语句在MySQL中如何执⾏" class="headerlink" title="⼀条SQL语句在MySQL中如何执⾏"></a>⼀条SQL语句在MySQL中如何执⾏</h2><img src="/2024/04/05/MYSQL/clip_image080.gif" class="" title="qpouu" alt="wesp4w  01  00"><p>MySQL 主要分为 Server 层和引擎层，Server 层主要包括连接器、查询缓存、分析器、优化器、执行器，同时还有一个日志模块（binlog），这个日志模块所有执行引擎都可以共用,redolog 只有 InnoDB 有。</p><p>•引擎层是插件式的，目前主要包括，MyISAM,InnoDB,Memory 等。</p><p>•SQL 等执行过程分为两类，一类对于查询等过程如下：权限校验—》查询缓存—》分析器—》优化器—》权限校验—》执行器—》引擎</p><p>•对于更新等语句执行流程如下：分析器—-》权限校验—-》执行器—》引擎—redo log prepare—》binlog—》redo log commit</p><p><a href="https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247485097&idx=1&sn=84c89da477b1338bdf3e9fcd65514ac1&chksm=cea24962f9d5c074d8d3ff1ab04ee8f0d6486e3d015cfd783503685986485c11738ccb542ba7&token=79317275&lang=zh_CN%23rd">https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&amp;mid=2247485097&amp;idx=1&amp;sn=84c89da477b1338bdf3e9fcd65514ac1&amp;chksm=cea24962f9d5c074d8d3ff1ab04ee8f0d6486e3d015cfd783503685986485c11738ccb542ba7&amp;token=79317275&amp;lang=zh_CN%23rd</a></p><p>​    注：redolog是宕机后数据恢复用的，用来支持事务的，binlog是主从复制的时候用的</p><img src="/2024/04/05/MYSQL/clip_image082.gif" class="" title="这 里 肯 定 有 同 学 会 问 ， 为 什 么 要 用 两 个 日 志 模 块 ， 用 一 个 日 志 模 块 不 行 吗 ？  这 是 因 为 最 开 始 MySQL 并 没 与 InnoDB 引 擎 〔 InnoDB 引 擎 是 其 他 公 司 以 插 件 形 式 插 入  MySQL 的 〕 ， MySQL 自 带 的 引 擎 是 MylSAM, 但 是 我 们 知 道 redolog 是 InnoDB 引 擎 特 有  的 ， 其 他 存 储 引 擎 都 没 有 ， 这 就 导 致 会 没 有 crash-safe 的 能 力 (crash-safe 的 能 力 即 使 数 据  库 发 生 异 常 重 启 ， 之 前 提 交 的 记 录 都 不 会 丢 失 〕 ， binlog 日 志 只 能 用 来 归 档 。  并 不 是 说 只 用 一 个 日 志 模 块 不 可 以 ， 只 是 InnoDB 引 擎 就 是 通 过 redo log 来 支 持 事 务 的 。  那 么 ， 又 会 有 同 学 问 ， 我 用 两 个 日 志 模 块 ， 但 是 不 要 这 么 复 杂 行 不 行 ， 为 什 么 redolog 要  引 入 prepare 预 提 交 状 态 ？ 这 里 我 们 用 反 证 法 来 说 明 下 为 什 么 要 这 么 做 ？  先 写 redo 10g 直 接 提 交 ， 然 后 写 binlog, 假 设 写 完 redolog 后 ， 机 器 挂 了 ， binlog 日  志 没 有 被 写 入 ， 那 么 机 器 重 启 后 ， 这 台 机 器 会 通 过 redo log 恢 复 数 据 ， 但 是 这 个 时 候  bingog 并 没 有 记 录 该 数 据 ， 后 续 进 行 机 器 备 份 的 时 候 ， 就 会 丢 失 这 一 条 数 据 ， 同 时 主  从 同 步 也 会 丢 失 这 一 条 数 据 。  先 写 binlog, 然 后 %redolog, 假 设 写 完 了 binlog, 机 器 异 常 重 启 了 ， 由 于 没 有 redo  log, 本 机 是 无 法 恢 复 这 一 条 记 录 的 ， 但 是 binlog 又 有 记 录 ， 那 么 和 上 面 同 样 的 道 理 ，  就 会 产 生 数 据 不 一 致 的 情 况 。  如 果 采 用 redo log 两 阶 段 提 交 的 方 式 就 不 一 样 了 ， 写 完 binglog 后 ， 然 后 再 提 交 redo log  就 会 防 止 出 现 上 述 的 问 题 ， 从 而 保 证 了 数 据 的 一 致 性 。 那 么 问 题 来 了 ， 有 没 有 一 个 极 端 的  情 况 呢 ？ 假 设 redolog 处 于 预 提 交 状 态 ， binglog 也 己 经 写 完 了 ， 这 个 时 候 发 生 了 异 常 重 启  会 怎 么 样 呢 ？ 这 个 就 要 依 赖 于 MySQL 的 处 理 机 制 了 ， MySQL 的 处 理 过 程 如 下 ．  · 判 断 redolog 是 否 完 整 ， 如 果 判 断 是 完 整 的 ， 就 立 即 提 交 。  如 果 redolog 只 是 预 提 交 但 不 是 commit 状 态 ， 这 个 时 候 就 会 去 判 断 binlog 是 否 完  整 ， 如 果 完 整 就 提 交 redolog, 不 完 整 就 回 滚 事 务 。  这 样 就 解 决 了 数 据 一 致 性 的 问 题 。"><p>我们该如何进行sql优化呢， 首先我们需要知道，sql优化其实主要是解决查询的优化问题，所以我们先从数据库的查询开始入手，下面这幅图显示了查询的执行路径：</p><p>　① 客户端将查询发送到服务器；</p><p>　② 服务器检查查询缓存，如果找到了，就从缓存中返回结果，否则进行下一步。</p><p>　③ 服务器解析，预处理。</p><p>　④ 查询优化器优化查询</p><p>　⑤ 生成执行计划，执行引擎调用存储引擎API执行查询</p><p>　⑥服务器将结果发送回客户端。</p><img src="/2024/04/05/MYSQL/clip_image084.gif" class="" title="Amen"><p><strong>查询缓存</strong> 在解析一个查询语句之前，如果查询缓存是打开的，那么MySQL会优先检查这个查询是否命中查询缓存中的数据，如果命中缓存直接从缓存中拿到结果并返回给客户端。这种情况下，查询不会被解析，不用生成执行计划，不会被执行。</p><p><strong>语法解析和预处理器</strong> MySQL通过关键字将SQL语句进行解析，并生成一棵对应的“解析树”。MySQL解析器将使用MySQL语法规则验证和解析查询。</p><p><strong>查询优化器</strong> 语法树被校验合法后由优化器转成查询计划，一条语句可以有很多种执行方式，最后返回相同的结果。优化器的作用就是找到这其中最好的执行计划。</p><p><strong>查询执行引擎</strong> 在解析和优化阶段，MySQL将生成查询对应的执行计划，MySQL的查询执行引擎则根据这个执行计划来完成整个查询。最常使用的也是比较最多的引擎是MyISAM引擎和InnoDB引擎。mysql5.5开始的默认存储引擎已经变更为innodb了。</p><h2 id="SQL语句执⾏得很慢的原因有哪些？"><a href="#SQL语句执⾏得很慢的原因有哪些？" class="headerlink" title="SQL语句执⾏得很慢的原因有哪些？"></a>SQL语句执⾏得很慢的原因有哪些？</h2><p>1、大多数情况下很正常，偶尔很慢，则有如下原因</p><p>(1)数据库在刷新脏页，例如 redo log 写满了需要同步到磁盘。</p><p>(2)执行的时候，遇到锁，如表锁、行锁。</p><p>2、这条 SQL 语句一直执行的很慢，则有如下原因。</p><p>(1)</p><img src="/2024/04/05/MYSQL/clip_image086.gif" class="" title="img"><p>（2）没有用上索引：例如该字段没有索引；由于对字段进行运算、函数操作导致无法用索引。</p><p>（3）</p><img src="/2024/04/05/MYSQL/clip_image088.gif" class="" title="． 如 果 对 语 句 的 优 化 已 经 无 氵 去 进 行 ， 可 以 考 虑 表 中 的 数 据 量 是 否 太 大 ， 如 果 是 的 话 可 以 进 行 横 向 或 者 纵 向 的 分  表 。"><p>(4)数据库选错了索引。</p><p><a href="https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&mid=2247485185&idx=1&sn=66ef08b4ab6af5757792223a83fc0d45&chksm=cea248caf9d5c1dc72ec8a281ec16aa3ec3e8066dbb252e27362438a26c33fbe842b0e0adf47&token=79317275&lang=zh_CN%23rd">https://mp.weixin.qq.com/s?__biz=Mzg2OTA0Njk0OA==&amp;mid=2247485185&amp;idx=1&amp;sn=66ef08b4ab6af5757792223a83fc0d45&amp;chksm=cea248caf9d5c1dc72ec8a281ec16aa3ec3e8066dbb252e27362438a26c33fbe842b0e0adf47&amp;token=79317275&amp;lang=zh_CN%23rd</a></p><img src="/2024/04/05/MYSQL/clip_image090.gif" class="" title="1 、 数 据 库 在 刷 新 脏 页 (flush) 我 也 无 奈 啊  当 我 们 要 往 数 据 库 插 入 一 条 数 据 、 或 者 要 电 新 一 条 数 据 的 时 候 ， 我 们 知 道 数 据 库 会 在 内 存 中 把 对 应 字 段 的 数 据 更  新 了 ， 但 是 电 新 之 后 ， 这 些 更 新 的 字 段 并 不 会 马 上 同 步 持 久 化 到 磁 盘 中 去 ， 而 是 把 汶 些 更 新 的 记 录 写 入 到 red o  log 日 记 中 去 ， 等 到 空 闲 的 时 候 ， 在 通 过 redo log 里 的 日 记 把 最 新 的 数 据 同 步 到 磁 盘 中 去 。  当 内 存 数 据 页 跟 磁 盘 数 据 页 内 容 不 一 致 的 时 候 ， 我 们 称 这 个 内 存 页 为 “ 脏 页 。 内 存 数 据 与 入 到 磁 盘 后 ， 内 存 和 磁 盘 上 的 数 据 页 的 内 容 就 一 致 了 ， 称 为 “ 干 净 页 。  刷 页 有 下 面 4 种 场 景 （ 后 两 种 不 用 太 关 注 “ 性 能 问 题 ） ： · red 引 。 g 写 满 了 ： redo log 里 的 容 量 是 有 限 的 ， 如 果 数 据 库 一 直 很 忙 ， 电 新 又 很 频 繁 ， 汶 个 时 候 redo log 很 快 就 会 被 写 满 了 ， 汶 个 时 候 就 没 办 法 等 到 空 闲 的 时 候 冉 把 数 据 同 步 到 磁 盘 的 ， 只 能 暂 停 其 他 操 作 ， 全 身 心 来 把 数 据 同 步 到 磁 盘 中 去 的 ， 而 汶 个 时 候 ， 就 会 粤 致 我 们 平 时 正 常 的 SQL 语 句 突 然 执 行 的 很 慢 ， 所 以 说 ， 数 据 库 在 在 同 步 数 据 到 磁 盘 的 时 候 ， 就 有 可 能 导 致 我 们 的 SQL 语 句 执 行 的 很 悒 了 。 · 内 存 不 够 用 了 ： 如 果 一 次 查 i 旬 较 多 的 数 据 ， 恰 好 碰 到 所 查 数 据 页 不 在 内 存 中 时 ， 需 要 申 请 内 存 ， 而 此 时 恰 好 内 存 不 足 的 时 候 就 需 要 淘 汰 一 部 分 内 存 数 据 页 ， 如 果 是 干 净 页 ， 就 直 接 释 放 ， 如 果 恰 好 是 脏 页 就 需 要 刷 脏 《 页 · MySQL 认 为 系 统 “ 空 闲 ” 的 时 候 ： 这 时 系 统 没 什 么 压 力 。 · MYSQL 正 常 关 闭 的 时 候 ： 这 时 候 ， MYSQL 会 把 内 存 的 脏 页 都 flush 到 磁 盘 上 ， 这 样 下 次 MYSQL 启 动 的 时 候 ， 就 可 以 直 接 从 磁 盘 上 读 数 据 ， 启 动 速 度 会 很 快 0 %}{% asset_img clip_image092.gif&quot; img"><img src="/2024/04/05/MYSQL/clip_image094.gif" class="" title="数 据 库 自 己 选 错 索 引 了"><img src="/2024/04/05/MYSQL/clip_image096.gif" class="" title="所 以 呢 ， 系 统 是 有 可 能 走 全 表 扫 描 而 不 走 索 引 的 。 那 系 统 是 怎 么 判 断 昵 ？  判 断 来 源 于 系 统 的 预 测 ， 也 就 是 说 ， 如 果 要 走 c 字 段 索 引 的 话 ， 系 统 会 预 测 走 c 字 段 索 引 大 概 需 要 扫 庙 多 少 行 。  如 果 预 测 到 要 扫 描 的 行 数 很 多 ， 它 可 能 就 不 走 索 引 而 直 接 扫 庙 全 表 了 。"><img src="/2024/04/05/MYSQL/clip_image098.gif" class="" title="系 统 是 通 过 索 引 的 区 分 度 来 判 断 的 ， 一 个 索 引 上 不 同 的 值 越 多 ， 意 味 巷 出 现 相 同 数 值 的 索 引 越 少 ， 意 味 巷 索 引 的  区 分 度 越 高 。 我 们 也 把 区 分 度 称 之 为 基 数 ， 即 区 分 度 越 高 ， 基 数 越 大 。 所 以 呢 ， 基 数 越 大 ， 意 味 巷 符  合 100 &lt; c and c &lt; 10000 议 ． 个 条 亻 牛 的 彳 亍 娄 攵 越 少 。"><img src="/2024/04/05/MYSQL/clip_image100.gif" class="" title="系 统 当 然 是 不 会 漏 历 全 部 来 获 得 一 个 索 引 的 基 数 的 ， 代 价 太 大 了 ， 索 引 系 统 是 涌 过 谝 历 部 分 数 据 ， 也 就 是 通 过 采  样 的 方 式 ， 来 预 测 索 引 的 基 数 的 。  扯 了 这 么 多 ， 重 点 的 来 了 ， 居 然 是 采 样 ， 那 就 有 可 能 出 现 失 误 的 情 况 ， 也 就 是 说 ， c 议 个 索 引 的 基 数 实 际 上 是 很  大 的 ， 但 是 采 样 的 时 候 ， 却 很 不 幸 ， 把 汶 个 索 引 的 基 数 预 测 成 很 小 。 例 如 你 采 样 的 那 一 部 分 数 据 刚 好 基 数 很 小 ，  然 后 就 误 以 为 索 引 的 基 数 很 小 。 然 后 就 呵 呵 ， 系 统 就 不 走 （ 索 引 了 ， 直 接 走 全 部 扫 描 了 。"><h2 id="数据库调优"><a href="#数据库调优" class="headerlink" title="数据库调优"></a>数据库调优</h2><p>常规调优的思路</p><p>针对业务周期性的卡顿，例如在每天10-11点业务特别慢，但是还能够使用，过了这段时间就好了。</p><ul><li><ol><li>开启*****<em><strong><strong>慢查询日志*</strong></strong></em>****，运行一天</li><li>查看slowlog，分析slowlog，分析出查询慢的语句。</li><li>按照一定优先级，进行一个一个的排查所有慢语句。</li><li>分析top sql，进行explain调试，查看语句执行时间。</li><li>调整索引或语句本身。</li></ol></li></ul><p>开启*<strong>*<em><em><strong><strong>慢查询日志*</strong></strong></em>*</em></strong></p><ul><li><ol><li>使用explain关键字可以模拟优化器执行SQL查询语句</li><li>查看表的读取顺序</li><li>查看数据库读取操作的操作类型</li><li>查看哪些索引有可能被用到</li><li>查看哪些索引真正被用到</li><li>查看表之间的引用</li><li>查看表中有多少行记录被优化器查询</li><li>type&#x3D;&#x3D;显示的是访问类型，是较为重要的一个指标，结果值从最好到最坏依次是<br>  system &gt; const &gt; eq_ref &gt; ref &gt; fulltext &gt; ref_or_null      &gt; index_merge &gt; unique_subquery &gt; index_subquery &gt; range(尽量保证)      &gt; index &gt; ALL<br>  &#x3D;&#x3D;ref&#x3D;&#x3D; ：非唯一性索引扫描，返回匹配某个单独值的所有行，本质上也是一种索引访问，它返回所有符合条件的行。<br>  explain select * from t1 where col1&#x3D;’zs1’;<br>  &#x3D;&#x3D;range&#x3D;&#x3D; : 只检索给定范围的行, 使用一个索引来选择行.key列显示的是真正使用了哪个索引,一般就是在where条件中使用between,&gt;,&lt;,in 等范围的条件,这种在索引范围内的扫描比全表扫描要好,因为它只在某个范围中扫描,不需要扫描全部的索引<br>  explain select * from t1 where id between 1 and 10;</li><li>key&#x3D;&#x3D;查询过程中真正使用的索引，如果为null，则表示没有使用索引 </li><li>key_len&#x3D;&#x3D;索引中使用的字节数，可通过该列计算查询中使用的索引的长度，长度越短越好。</li><li>rows&#x3D;&#x3D;根据表统计信息及索引选用的情况,估算找出所需记录要读取的行数 (有多少行记录被优化器读取) ,越少越好</li></ol></li></ul><h2 id="索引失效情况"><a href="#索引失效情况" class="headerlink" title="索引失效情况"></a>索引失效情况</h2><ul><li>最左前缀法则(如果索引了多列，要遵守*****<em><strong><strong>最左前缀法则*</strong></strong></em>****。指的是查询从索引的最左前列开始并且不跳过索引中的列。)</li><li>不在索引列上做任何操作（计算、函数、(自动or手动)类型转换），如果做的话，会导致索引失效而转向******，如果非要操作数据，那么就使用冗余列，存与索引一样的数据值，去操作冗余列。</li><li>存储引擎不能使用索引中范围条件(****between*<em><strong><strong>、*</strong></strong></em>&lt;******、******&gt;******、***<em><strong>in*<em><strong><strong>等*</strong></strong></em>*</strong></em>)右边的列(范围条件右边与范围条件使用的同一个组合索引，右边的才会失效。若是不同索引则不会失效)。EXPLAIN SELECT * FROM staffs WHERE name &#x3D; ‘July’ AND age &gt; 25     AND pos &#x3D; ‘dev’; – 范围之后的索引失效:即pos没用到索引</li><li>减少select *，使用哪些字段查哪些字段。</li><li>mysql5.7 在使用不等于(!&#x3D; 或者&lt;&gt;)的时候无法使用索引会导致全表扫描。但8.0不会。</li><li>like以%开头(‘%abc…’)mysql索引失效会变成全表扫描的操作</li><li>字符串不加单引号索引失效 ( 底层进行转换使索引失效，使用了函数造成索引失效)（隐式类型转换）</li></ul><p>EXPLAIN SELECT * FROM staffs WHERE NAME &#x3D; 987</p><p>一般在开发中，当要进行调优时，需要有一定的依赖信息，可以通过show status like ‘Handler_read%’;查看索引的使用情况。</p><img src="/2024/04/05/MYSQL/clip_image101.jpg" class="" title="Variable  Handler  Handler  Handler  Handler  Handler  Handler  Handler  name  read first  read key  read last  read neR  ready rev  read rnd  read rnd neR  Value  12352"><p>****handler_read_key****：这个值越大说明使用索引查询到的次数越多。</p><p>****handler_read_rnd_next****：这个值越高，说明查询低效。</p><h1 id="Mysql主从复制"><a href="#Mysql主从复制" class="headerlink" title="Mysql主从复制"></a>Mysql主从复制</h1><p>binlog是记录所有数据库表结构变更（例如CREATE、ALTER TABLE…）以及表数据修改（INSERT、UPDATE、DELETE…）的二进制日志。</p><p>复制的基本过程如下：</p><p>- 从节点上的I&#x2F;O 进程连接主节点，并请求从指定日志文件的指定位置（或者从最开始的日志）之后的日志内容；</p><p>- 主节点接收到来自从节点的I&#x2F;O请求后，通过负责复制的I&#x2F;O进程根据请求信息读取指定日志指定位置之后的日志信息，返回给从节点。返回信息中除了日志所包含的信息之外，还包括本次返回的信息的bin-log file 的以及bin-log position；从节点的I&#x2F;O进程接收到内容后，将接收到的日志内容更新到本机的relay log中，并将读取到的binary log文件名和位置保存到master-info 文件中，以便在下一次读取的时候能够清楚的告诉Master“我需要从某个bin-log 的哪个位置开始往后的日志内容，请发给我”；</p><p>- Slave 的 SQL线程检测到relay-log 中新增加了内容后，会将relay-log的内容解析成在主节点上实际执行过的操作，并在本数据库中执行。</p><p><a href="https://zhuanlan.zhihu.com/p/50597960">https://zhuanlan.zhihu.com/p/50597960</a></p><h1 id="大数据"><a href="#大数据" class="headerlink" title="大数据"></a>大数据</h1><h2 id="大数据量的分页查询怎么优化"><a href="#大数据量的分页查询怎么优化" class="headerlink" title="大数据量的分页查询怎么优化"></a>大数据量的分页查询怎么优化</h2><p>（1）使用子查询优化：这种方式先定位偏移位置的 id，然后往后查询，这种方式适用于 id 递增的情况。 看重一条数据的id</p><p> select * from orders_history where type&#x3D;8 limit 100000,1; select * from orders_history where type&#x3D;8 and id&gt;&#x3D;(select id from orders_history where type&#x3D;8 limit 100000,1) limit 100; </p><p>（2）使用 id 限定优化：这种方式假设数据表的id是<strong>连续递增</strong>的，则我们根据查询的页数和查询的记录数可以算出查询的id的范围，可以使用 id between and 来查询： 看重id的范围</p><p> select * from orders_history where type&#x3D;2 and id between 1000000 and 1000100 limit 100; select * from orders_history where id &gt;&#x3D; 1000001 limit 100; select * from orders_history where id in(select order_id from trade_2 where goods &#x3D; ‘pen’)limit 100; </p><p>（3）使用临时表优化：可以考虑使用临时存储的表来记录分页的id，使用分页的id来进行 in 查询。这样能够极大的提高传统的分页查询速度，尤其是数据量上千万的时候。</p><p>主键递增且数据有序。其实就是利用B+树的原理进行的，因为在Innodb存储引擎中，数据是通过B+树进行存储，叶子节点存储的是主键id，另外子查询中也用到了覆盖索引。</p><p><a href="https://segmentfault.com/a/1190000038856674">https://segmentfault.com/a/1190000038856674</a></p><h2 id="分库分表，以及可能遇到的问题"><a href="#分库分表，以及可能遇到的问题" class="headerlink" title="分库分表，以及可能遇到的问题"></a>分库分表，以及可能遇到的问题</h2><p><em><strong>*1.垂直分表：拆分是基于关系型数据库中的“列”（字段）进行的。通常情况，某个表中的字段比较多，可以新建立一张“扩展表”，将不经常使用或者长度较大的字段拆分出去放到“扩展表”中。*</strong></em></p><img src="/2024/04/05/MYSQL/clip_image103.gif" class="" title="img"><p><em><strong>*2.水平分表：水平分表也称为横向分表，比较容易理解，就是将表中不同的数据行按照一定规律分布到不同的数据库表中（这些表保存在同一个数据库中），这样来降低单表数据量，优化查询性能。最常见的方式就是通过主键或者时间等字段进行 Hash 和取模后拆分。*</strong></em></p><img src="/2024/04/05/MYSQL/clip_image105.gif" class="" title="img"><p><em><strong>*3.垂直分库*</strong></em></p><p>垂直分库在“微服务”盛行的今天已经非常普及了。基本的思路就是按照业务模块来划分出不同的数据库，而不是像早期一样将所有的数据表都放到同一个数据库中。</p><img src="/2024/04/05/MYSQL/clip_image107.gif" class="" title="img"><p><em><strong>*4.水平分库分表*</strong></em></p><p>水平分库分表与上面讲到的水平分表的思想相同，唯一不同的就是将这些拆分出来的表保存在不同的数据中。这也是很多大型互联网公司所选择的做法。</p><img src="/2024/04/05/MYSQL/clip_image109.gif" class="" title="img"><p><em><strong>*分库分表的难点：*</strong></em></p><p>垂直分库带来的问题和解决思路：</p><p><em><strong>*1.跨库 join 的问题：在拆分之前，系统中很多列表和详情页所需的数据是可以通过 sql join 来完成的。而拆分后，数据库可能是分布式在不同实例和不同的主机上，join 将变得非常麻烦。而且基于架构规范，性能，安全性等方面考虑，一般是禁止跨库 join 的。那该怎么办呢？首先要考虑下垂直分库的设计问题，如果可以调整，那就优先调整。如果无法调整的情况，以下总结几种常见的解决思路，并分析其适用场景。*</strong></em></p><p>（1）全局表</p><p>所谓全局表，就是有可能系统中所有模块都可能会依赖到的一些表。比较类似我们理解的“数据字典”。为了避免跨库 join 查询，我们可以将这类表在其他每个数据库中均保存一份。同时，这类数据通常也很少发生修改（甚至几乎不会），所以也不用太担心“一致性”问题。</p><p>（2）字段冗余</p><p>举个电商业务中很简单的场景：</p><p>“订单表”中保存“卖家 Id”的同时，将卖家的“Name”字段也冗余，这样查询订单详情的时候就不需要再去查询“卖家用户表”。字段冗余能带来便利，是一种“空间换时间”的体现。比较适合依赖字段较少的情况。最复杂的还是数据一致性问题，这点很难保证，如果卖家修改了 Name 之后，是否需要在订单信息中同步更新呢？数据同步：定时 A 库中的 tab_a 表和 B 库中 tbl_b 有关联，可以定时将指定的表做同步。当然，同步本来会对数据库带来一定的影响，需要性能影响和数据时效性中取得一个平衡。</p><p>（3）系统层组装</p><p>在系统层面，通过调用不同模块的组件或者服务，获取到数据并进行字段拼装。简单字段组装的情况下，我们只需要先获取“主表”数据，然后再根据关联关系，调用其他模块的组件或服务来获取依赖的其他字段（如例中依赖的用户信息），最后将数据进行组装。</p><p>常见的分片策略有随机分片和连续分片这两种</p><img src="/2024/04/05/MYSQL/clip_image111.jpg" class="" title="连 续 分 片  随 机 分 片  2015 &#x2F; 01 ． 2015 ／ 12  2016 &#x2F; 01 ． 2016 ／ 12  100D1 20000  Data Node2  Data  Data ， de2"><p>1.连续分片：（1）范围查找方便。（2）扩容方便。（3）存在数据热点问题，当需要使用分片字段进行范围查找时，连续分片可以快速定位分片进行高效查询，大多数情况下可以有效避免跨分片查询的问题。后期如果想对整个分片集群扩容时，只需要添加节点即可，无需对其他分片的数据进行迁移。但是，连续分片也有可能存在数据热点的问题，就像图中按时间字段分片的例子，有些节点可能会被频繁查询压力较大，热数据节点就成为了整个集群的瓶颈。而有些节点可能存的是历史数据，很少需要被查询到。</p><p>2.随机分片：（1）数据分布均匀，不容易出现热点和并发访问的瓶颈。（2）扩容起来需要迁移旧的数据。（3）跨分片查询复杂。随机分片其实并不是随机的，也遵循一定规则。通常，我们会采用 Hash 取模的方式进行分片拆分，所以有些时候也被称为离散分片。随机分片的数据相对比较均匀，不容易出现热点和并发访问的瓶颈。但是，后期分片集群扩容起来需要迁移旧的数据。使用一致性 Hash 算法（jianshu.com&#x2F;p&#x2F;528ce5cd7e8f）能够很大程度的避免这个问题，所以很多中间件的分片集群都会采用一致性 Hash 算法。离散分片也很容易面临跨分片查询的复杂问题。</p><p>历史数据迁移的问题。一般做法就是通过程序先读出历史数据，然后按照指定的分片规则再将数据写入到各个分片节点中。</p><p><em><strong>*跨分片技术问题：*</strong></em></p><p><em><strong>*1.跨分片的排序分页：为了最终结果的准确性，我们需要在不同的分片节点中将数据进行排序并返回，并将不同分片返回的结果集进行汇总和再次排序，最后再返回给用户。*</strong></em></p><img src="/2024/04/05/MYSQL/clip_image002-1712317803722.gif" class="" width="0"><p>如果想取出第 10 页数据，情况又将变得复杂很多，如下图所示：</p><img src="/2024/04/05/MYSQL/clip_image115.gif" class="" title="000 , T000T 0 丨"><p>很显然，这样的操作是比较消耗资源的，用户越往后翻页，系统性能将会越差。</p><p>2.跨分片的函数处理</p><p>在使用 Max、Min、Sum、Count 之类的函数进行统计和计算的时候，需要先在每个分片数据源上执行相应的函数处理，然后再将各个结果集进行二次处理，最终再将处理结果返回。</p><p>3.跨分片 join：</p><p>（1）全局表</p><p>全局表的概念之前在“垂直分库”时提过。基本思想一致，就是把一些类似数据字典又可能会产生 join 查询的表信息放到各分片中，从而避免跨分片的 join。</p><p>（2）ER 分片</p><p>在关系型数据库中，表之间往往存在一些关联的关系。如果我们可以先确定好关联关系，并将那些存在关联关系的表记录存放在同一个分片上，那么就能很好的避免跨分片 join 问题。</p><img src="/2024/04/05/MYSQL/clip_image117.gif" class="" title="tbl_ord«  Data Nodel  tbl order  ID:I  ID:2  Data Node2  tbl order  ID:3  tbl_orderdetail  Data Nodel  tbl orderdetail  order " alt="D:l  order 10:2  Data Node2  tbl orderdetail  order ID:3  order ID•.4"><p>垂直：<a href="https://www.infoq.cn/article/key-steps-and-likely-problems-of-split-table">https://www.infoq.cn/article/key-steps-and-likely-problems-of-split-table</a></p><p>水平：<a href="https://www.infoq.cn/article/key-steps-and-likely-problems-of-horizontal-split-table">https://www.infoq.cn/article/key-steps-and-likely-problems-of-horizontal-split-table</a></p><h2 id="“跨库分页查询”的四种方案"><a href="#“跨库分页查询”的四种方案" class="headerlink" title="“跨库分页查询”的四种方案"></a>“跨库分页查询”的四种方案</h2><p><strong>方法一：全局视野法</strong></p><p>（1）将order by time offset X limit Y，改写成order by time offset 0 limit X+Y</p><p>（2）服务层对得到的N*(X+Y)条数据进行内存排序，内存排序后再取偏移量X后的Y条记录</p><p>这种方法随着翻页的进行，性能越来越低。</p><p><strong>方法二：业务折衷法-禁止跳页查询</strong></p><p>（1）用正常的方法取得第一页数据，并得到第一页记录的time_max</p><p>（2）每次翻页，将order by time offset X limit Y，改写成order by time where time&gt;$time_max limit Y</p><p>以保证每次只返回一页数据，性能为常量。</p><p><strong>方法三：业务折衷法-允许模糊数据</strong></p><p>（1）将order by time offset X limit Y，改写成order by time offset X&#x2F;N limit Y&#x2F;N</p><p><strong>方法四：二次查询法    X&#x3D;1000  Y&#x3D;5</strong></p><p>（1）将order by time offset X limit Y，改写成order by time offset X&#x2F;N limit Y</p><p>（2）找到最小值time_min</p><p>（3）between二次查询，order by time between $time_min and $time_i_max</p><p>（4）设置虚拟time_min，找到time_min在各个分库的offset，从而得到time_min在全局的offset</p><p>（5）得到了time_min在全局的offset，自然得到了全局的offset X limit Y</p><p><a href="https://www.w3cschool.cn/architectroad/architectroad-cross-database-paging.html">https://www.w3cschool.cn/architectroad/architectroad-cross-database-paging.html</a></p><h2 id="一致性Hash"><a href="#一致性Hash" class="headerlink" title="一致性Hash"></a>一致性Hash</h2><p>对2的32次方取模</p><img src="/2024/04/05/MYSQL/clip_image119.jpg" class="" title="img"><p>*<strong>*<em><em><strong><strong>容错性：一台宕机了只用移动部分数据*</strong></strong></em>*</em></strong></p><p>*<strong>*<em><em><strong><strong>可扩展性：增加一台只用移动部分数据*</strong></strong></em>*</em></strong></p><p>*<strong>*<em><em><strong><strong>数据倾斜问题：虚拟节点机制*</strong></strong></em>*</em></strong></p><p>一致性Hash算法引入了虚拟节点机制，即对每一个服务器节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体操作可以为服务器IP或主机名后加入编号来实现。</p><img src="/2024/04/05/MYSQL/clip_image121.jpg" class="" title="img"><img src="/2024/04/05/MYSQL/clip_image123.jpg" class="" title="img"><h1 id="零星问题"><a href="#零星问题" class="headerlink" title="零星问题"></a>零星问题</h1><h2 id="Buffer-Pool"><a href="#Buffer-Pool" class="headerlink" title="Buffer Pool"></a>Buffer Pool</h2><p>1.Buffer Pool 的大小</p><p>缓冲池（Buffer Pool）的默认大小为 128M，可通过 innodb_buffer_pool_size 参数来配置。</p><p>2.Buffer Pool 的结构</p><p>当 SQL 执行时，用到的相关表的数据行，会将这些数据行都缓存到 Buffer Pool 中。但是我们可以想象一下，如果像上面的机制那么简单，那么如果是分页的话，不断地查询就要不断地将磁盘文件中数据页的数据缓存到 Buffer Pool 中了，那么这时候缓存池这个机制就显得没什么用了，每次查询还是会有一次或者多次的磁盘IO。</p><p><a href="https://www.cnblogs.com/Howinfun/p/12327490.html">https://www.cnblogs.com/Howinfun/p/12327490.html</a></p><h2 id="OLAP，OLTP"><a href="#OLAP，OLTP" class="headerlink" title="OLAP，OLTP"></a>OLAP，OLTP</h2><img src="/2024/04/05/MYSQL/clip_image125.gif" class="" title="img"><h2 id="内连接，左外连接，右外连接区别"><a href="#内连接，左外连接，右外连接区别" class="headerlink" title="内连接，左外连接，右外连接区别"></a>内连接，左外连接，右外连接区别</h2><p>内连接：左表右表都匹配的才显示</p><p>左外连接：左表全部显示</p><p>右外连接：右边全部显示</p><img src="/2024/04/05/MYSQL/clip_image127.jpg" class="" title="ヨ 3 内 達 接  用 辺 表 的 紀 景 去 は 配 右 辺 表 的 記 , 知 果 符 合 的 第 製 示 . ! 从 表 - 外 &#x3D; 主 表 ま  ヨ 31 物 式 内 ま 接  ・ 式 内 蓬 接 ー れ 不 刊 JO 美 靆 字 . 第 件 使 Ⅲ 、 VHERE 指 定  S E L E C T ヤ 段 名 F RO M 左 表 石 表 KH ERE 件  72 201392 ・ 24  2 第 ハ  36 ー 2010-1292  4 白 告 物  和 0 2015 ・ 1097  1 発 澱 第  」 」 2 豊 式 内 接  ・ 暃 示 内 連 接 ー 侵 Ⅱ ER 」 0 - - - 気 第 可 以 省 略 INNER  ロ 「 C ー 〒 取 を 「 R 0M 表 卩 N N 「 引 」 冂 、 も ま 、  ・ 査 洶 唐 物 的 信 は , 品 示 員 」 - 名 , 性 , - に 和 所 を 的 日 名 称 , 我 引 友 調 眠 合 2 張 疉 イ 能  査 臨 出 需 要 的 数 , 使 川 内 接  5 を ド 機  リ 定 査 試 第 表  堂 0 一 空 強 ま  1 ~ 00 ~ 0 ー 3-0 ~ - ~ 4  : 阯 0 え 0 ー 0 , -0 :  ー 000 ー 00 ! ・ 0 ! - 叶  4 0 ~ い 0 い"><img src="/2024/04/05/MYSQL/clip_image129.jpg" class="" title="2 ）  3 ）  4 ）  5 ）  确 定 表 连 猛 条 0 。 员 Il 表 ． d 卸 t_ &#x3D; 部 门 表 的 数 撫 才 是 有 效 的  3 生  定 条 ， 我 们 0 山 的 是 庸 的 俗 息 ， tAT.*.name•ym• 改 变 中 》 T 数 0 ， 我 们 让 在 行 动 定 查 的 字 段 ， 〕 0 n dept d 3 0 生 查 的 唐 慚 的 信 息 ． 是 小 员 T 难 名 ， 别 ， alary" alt=",d. 0000 200 巴 - -0 巴 T.q 和 所 的 汔 冂 名 称 from e ， 30 的 事 0 的 我 们 发 埂 表 名 有 点 长 ， 可 以 蝓 表 取 名 ， 是 示 的 字 段 名 也 用 别 名 ． 、 g n 性 刷 join dept d 、 部 门 名 字 。 。 0 工 0 身 工 地 名 」 乸 ！ ． 工 ， d 过 n 以 m 色 都 门 名 称 0 3 且 3 总 内 接 0 河 0 1 ） 2 》 3 ， 4 》 确 定 直 询 些 表 确 定 表 连 接 的 条 0 确 定 查 的 条 # 确 定 香 啕 字 以 %}{% asset_img clip_image131.jpg&quot; · 左 外 连 接 ！ WOLEFTOUTERJOIN„.ON. OUTER 可 以 省 鹉  ;ELECT ， FROM 左 表 LEFTIOUIER) 」 OIN 右 0 、 条 件  边 &amp; 的 记 飛 去 邝 配 0 的 记 2 巛 如 鑾 合 釜 的 則 是 示 则 ． 小 N ULL  可 以 理 解 为 ； 内 迕 接 的 基 础 一 上 保 证 左 表 的 全 是 示 《 左 羲 是 部 门 ， 右 表 员 工 》  一 在 訕 〕 表 中 增 加 一 个 能 部  过 售 到 0 ；  ntO dept 《 0000 } v 1u00  dept;  ． 使 用 内 连 接 0 杰  dept d inner  」 。 in  emp  dept id ． ，  ． 用 左 外 连 接 壹  fæ dept 0 left 力 0  黑 马 程 庳 员  苤 0 下  改 賣 中 国 跹 禹 。 我 们 正 在 行  离 满 》 T 0 身  男 女 身 勇  1200 2013 一 02 ” 24  S00 湖 以 03 以 以  9000 200 ！ 一 0 ， ” 0 巴  3 0 务  5000 IS -10-0 ，  用 左 边 表 的 记 录 去 匹 配 右 边 表 的 记 录 ． 如 里 符 合 条 件 的 则 昱 不 ； 否 是 ， 显 不 N 酰 L  可 以 垤 解 为 ： 在 内 连 接 的 基 础 上 保 左 表 的 数 躯 全 部 显 示"><img src="/2024/04/05/MYSQL/clip_image133.jpg" class="" title="· 右 外 连 猛 ！ 使 用 RIGHT OUTERJOIN ． “ 创 OUTER 可 以 省 略  1 「 LECT ， 糗 名 厂 RO 左 R" alt="GHTIOLJTERIJOIN 右 ON  引 不 的 &amp; 的 记 去 卜 配 的 记 录 ． 如 製 苻 合 性 的 小 ！ 舌 。  可 以 理 为 ！ 在 内 猛 的 基 0 上 证 右 表 的 数 巛 全 部 是 示  是 示 NIAL  一 员 T 表 中 加 一 个 员 T.  5 咱  ． 在 员 工 表 中 堵 加 一 个 员 工  ． 用 内 连 0  from dept  一 侵 用 右 外 连 接 查 询  财 务 蕊  《 n 七 11 ，  in  5 妩 满  1200 0 ！ 3 一 02 一 2 《  的 ； 00 ， -0 ， ” 就  ， 000 ： 015 一 ． 01  冫 0 訁 3-0 冫  ， 。 男 ， ， 6 6 下 ， 。 2013 ． 12 ． 0 5 "><h2 id="MySQL表设计要注意什么？"><a href="#MySQL表设计要注意什么？" class="headerlink" title="MySQL表设计要注意什么？"></a>MySQL表设计要注意什么？</h2><p>问题1:为什么一定要设一个主键？ </p><p>回答:因为你不设主键的情况下，innodb也会帮你生成一个隐藏列，作为自增主键。所以啦，反正都要生成一个主键，那你还不如自己指定一个主键，在有些情况下，就能显式的用上主键索引，提高查询效率！</p><p>问题2:主键是用自增还是UUID?</p><p> 回答:肯定答自增啊。innodb 中的主键是聚簇索引。如果主键是自增的，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。如果不是自增主键，那么可能会在中间插入，就会引发页的分裂，产生很多表碎片！</p><p>自增主键用完了怎么办</p><p>把自增主键的类型改为BigInt类型就好了</p><p>线上怎么修改列的数据类型的？</p><p>方式一:使用mysql5.6+提供的在线修改功能</p><p>方式二:借助第三方工具gh-ost</p><p>方式三：改从库表结构，然后主从切换</p><p>因为自增主键我们用int类型，一般达不到最大值，我们就分库分表了，所以不曾遇见过！”</p><p><a href="https://mp.weixin.qq.com/s?__biz=MzIwMDgzMjc3NA==&mid=2247484464&idx=1&sn=f783fc5f7fe3d7714247c3c21d0a93f6&chksm=96f66659a181ef4fa02303b4974031b3f40bc1bdd76bad31a60fbaa54f2e63e62fcede88e4cd&scene=21#wechat_redirect">https://mp.weixin.qq.com/s?__biz=MzIwMDgzMjc3NA==&amp;mid=2247484464&amp;idx=1&amp;sn=f783fc5f7fe3d7714247c3c21d0a93f6&amp;chksm=96f66659a181ef4fa02303b4974031b3f40bc1bdd76bad31a60fbaa54f2e63e62fcede88e4cd&amp;scene=21#wechat_redirect</a></p><p>问题3：表示枚举的字段为什么不用enum类型？ </p><p>回答:在工作中表示枚举的字段，一般用tinyint类型。 那为什么不用enum类型呢？下面两个原因 (1)ENUM类型的ORDER BY操作效率低，需要额外操作 (2)如果枚举值是数值，有陷阱</p><p>tinyint类型代表一个字节，如果一个数字大小超过一个字节，则无法保存。</p><img src="/2024/04/05/MYSQL/clip_image135.jpg" class="" title="CREATE TABLE test (foobar ENUM( " alt="0"><p>问题4：货币字段用什么类型? </p><p>回答:如果货币单位是分，可以用Int类型。如果坚持用元，用Decimal(DECIMAL数据类型用于要求非常高的精确度的计算中)。 千万不要答float和double，因为float和double是以二进制存储的，所以有一定的误差。 打个比方，你建一个列如下</p><img src="/2024/04/05/MYSQL/clip_image137.jpg" class="" title="CREATE TABLE (  price" alt="DEFAULT NULL,  ) ENGINE&#x3D;1nnoDB DEFAULT CHARSET&#x3D;utf8"><p>然后insert给price列一个数据为1234567.23，你会发现显示出来的数据变为1234567.25，精度失准！</p><p>问题6:时间字段用什么类型? </p><p>回答:此题无固定答案，应结合自己项目背景来答！把理由讲清楚就行！</p><p> (1)varchar，如果用varchar类型来存时间，优点在于显示直观。但是坑的地方也是挺多的。比如，插入的数据没有校验，你可能某天就发现一条数据为2013111的数据，请问这是代表2013年1月11日，还是2013年11月1日？ 其次，做时间比较运算，你需要用STR_TO_DATE等函数将其转化为时间类型，你会发现这么写是无法命中索引的。数据量一大，是个坑！</p><p>(2)timestamp，该类型是四个字节的整数，它能表示的时间范围为1970-01-01 08:00:01到2038-01-19 11:14:07。2038年以后的时间，是无法用timestamp类型存储的。 但是它有一个优势，timestamp类型是带有时区信息的。一旦你系统中的时区发生改变，例如你修改了时区</p><p>SET TIME_ZONE &#x3D;”america&#x2F;new_york”;</p><p>你会发现，项目中的该字段的值自己会发生变更。这个特性用来做一些国际化大项目，跨时区的应用时，特别注意！</p><p>(3)datetime，datetime储存占用8个字节，它存储的时间范围为1000-01-01 00:00:00 ~ 9999-12-31 23:59:59。显然，存储时间范围更大。但是它坑的地方在于，他存储的是时间绝对值，不带有时区信息。如果你改变<a href="https://cloud.tencent.com/solution/database?from=10680">数据库</a>的时区，该项的值不会自己发生变更！</p><p>(4)bigint，也是8个字节，自己维护一个时间戳，表示范围比timestamp大多了，就是要自己维护，不大方便。</p><p>问题7:为什么不直接存储图片、音频、视频等大容量内容?</p><p> 回答:我们在实际应用中，都是用HDFS来存储文件。然后mysql中，只存文件的存放路径。mysql中有两个字段类型被用来设计存放大容量文件，也就是text和blob类型。但是，我们在生产中，基本不用这两个类型！ 主要原因有如下两点</p><p>(1)Mysql内存临时表不支持TEXT、BLOB这样的<a href="https://cloud.tencent.com/solution/bigdata?from=10680">大数据</a>类型，如果查询中包含这样的数据，在排序等操作时，就不能使用内存临时表，必须使用磁盘临时表进行。导致查询效率缓慢</p><p>(2)binlog内容太多。因为你数据内容比较大，就会造成binlog内容比较多。大家也知道，主从同步是靠binlog进行同步，binlog太大了，就会导致主从同步效率问题！</p><p>因此，不推荐使用text和blob类型！</p><p>问题8:字段为什么要定义为NOT NULL? </p><p>回答:OK，这问题从两个角度来答 (1)索引性能不好</p><p>Mysql难以优化引用可空列查询，它会使索引、索引统计和值更加复杂。可空列需要更多的存储空间，还需要mysql内部进行特殊处理。可空列被索引后，每条记录都需要一个额外的字节，还能导致MYisam 中固定大小的索引变成可变大小的索引。</p><p>(2)查询会出现一些不可预料的结果</p><img src="/2024/04/05/MYSQL/clip_image139.jpg" class="" title="id  3  5  7  select count(name) from table 2;  name  null  null"><p><a href="https://cloud.tencent.com/developer/article/1468442">https://cloud.tencent.com/developer/article/1468442</a></p><h2 id="范式"><a href="#范式" class="headerlink" title="范式"></a>范式</h2><p>范式：</p><p>第一范式（1NF）：</p><p>数据库表的每一列都是不可分割的原子数据项</p><p>第二范式（2NF）</p><p>非码属性必须完全依赖于候选码</p><p>第三范式（3NF）</p><p>在2NF基础上，任何非主<a href="https://baike.baidu.com/item/%E5%B1%9E%E6%80%A7">属性</a>不依赖于其它非主属性（在2NF基础上消除传递依赖）</p><p>巴斯-科德范式（BCNF）Boyce-Codd Normal Form（巴斯-科德范式）</p><p>在3NF基础上，任何非主属性不能对主键子集依赖（在3NF基础上消除对主码子集的依赖）</p>]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> MYSQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JVM</title>
      <link href="/2024/04/05/JVM/"/>
      <url>/2024/04/05/JVM/</url>
      
        <content type="html"><![CDATA[<h1 id="JVM"><a href="#JVM" class="headerlink" title="JVM"></a>JVM</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>JVM全称Java Virtual Machine，即Java虚拟机。它本身是一个虚拟计算机。Java虚拟机基于二进制字节码执行，由一套字节码指令集、一组寄存器、一个栈、一个垃圾回收堆、一个方法区等组成。JVM屏蔽了与操作系统平台相关的信息，从而能够让Java程序只需要生成能够在JVM上运行的字节码文件。通过该机制实现的跨平台性。因此这也是为什么说Java能够做到“一处编译、处处运行”的原因。</p><h2 id="JVM生命周期"><a href="#JVM生命周期" class="headerlink" title="JVM生命周期"></a>JVM生命周期</h2><p>JVM的生命周期分为三个阶段，分别为：启动、运行、死亡。</p><p>- <strong>启动：</strong></p><p> 当启动一个Java程序时，JVM的实例就已经产生。对于拥有main函数的类就是JVM实例运行的起点。</p><p>- <strong>运行：</strong></p><p> main()方法是一个程序的初始起点，任何线程均可由在此处启动。在JVM内部有两种线程类型，分别为：用户线程和守护线程。JVM通常使用的是守护线程，而main()使用的则是用户线程。守护线程会随着用户线程的结束而结束。</p><p>- <strong>死亡：</strong></p><p> 当程序中的用户线程都中止，JVM才会退出。</p><h2 id="内存结构"><a href="#内存结构" class="headerlink" title="内存结构"></a>内存结构</h2><p>内存是非常重要的系统资源，是硬盘和 CPU 的中间仓库及桥梁，承载着操作系统和应用程序的实时运行。JVM 内存结构规定了 Java 在运行过程中内存申请、分配、管理的策略，保证了 JVM 的高效稳定运行。</p><img src="/2024/04/05/JVM/clip_image002.gif" class="" title="img"><img src="/2024/04/05/JVM/clip_image004.gif" class="" title="img"><img src="/2024/04/05/JVM/clip_image006.gif" class="" title="img"><p><strong>虚拟机栈：</strong></p><p>​    线程私有的，虚拟机栈对应方法调用到执行完成的整个过程。保存执行方法时的<strong>局部变量、动态连接信息、方法返回地址信息</strong>等等。方法开始执行的时候会进栈，方法执行完会出栈【相当于清空了数据】。不需要进行GC。</p><p>Java 虚拟机栈会出现两种错误： StackOverFlowError 和 OutOfMemoryError 。</p><p>StackOverFlowError ： 若 Java 虚拟机栈的内存⼤⼩不允许动态扩展，那么当线程请求栈的深度超过当前 Java 虚拟机栈的最⼤深度的时候，就抛出 StackOverFlowError 错误。 </p><p>OutOfMemoryError ： 若 Java 虚拟机堆中没有空闲内存，并且垃圾回收器也⽆法提供更多内存的话。就会抛出 OutOfMemoryError 错误。</p><p><strong>本地方法栈：</strong></p><p>​    与虚拟机栈类似。本地方法栈是为虚拟机<strong>执行本地方法时提供服务的</strong>。不需要进行GC。本地方法一般是由其他语言编写。</p><p><strong>程序计数器：</strong></p><p>​    线程私有的。内部保存的字节码的行号。用于记录正在执行的字节码指令的地址。</p><p>\1. 字节码解释器通过改变程序计数器来依次读取指令，从⽽实现代码的流程控制，如：顺序执 ⾏、选择、循环、异常处理。</p><p>\2. 在多线程的情况下，程序计数器⽤于记录当前线程执⾏的位置，从⽽当线程被切换回来的时候能够知道该线程上次运⾏到哪⼉了</p><p>注意：程序计数器是唯⼀⼀个不会出现 OutOfMemoryError 的内存区域，它的⽣命周期随着线 程的创建⽽创建，随着线程的结束⽽死亡。</p><p>​    java虚拟机对于多线程是通过线程轮流切换并且分配线程执行时间。在任何的一个时间点上，一个处理器只会处理执行一个线程，如果当前被执行的这个线程它所分配的执行时间用完了【挂起】。处理器会切换到另外的一个线程上来进行执行。并且这个线程的执行时间用完了，接着处理器就会又来执行被挂起的这个线程。</p><p>​    那么现在有一个问题就是，当前处理器如何能够知道，对于这个被挂起的线程，它上一次执行到了哪里？那么这时就需要从程序计数器中来回去到当前的这个线程他上一次执行的行号，然后接着继续向下执行。</p><p>​    程序计数器是JVM规范中唯一一个没有规定出现OOM的区域，所以这个空间也不会进行GC。</p><p><strong>本地内存：</strong></p><p>​    它又叫做<strong>堆外内存</strong>，线程共享的区域，本地内存这块区域是不会受到JVM的控制的，也就是说对于这块区域是不会发生GC的。因此对于整个java的执行效率是提升非常大的。</p><p><strong>堆：</strong></p><p>​    线程共享的区域。主要用来保存<strong>对象实例，数组</strong>等，当堆中没有内存空间可分配给实例，也无法再扩展时，则抛出OutOfMemoryError异常。</p><p>​    在JAVA7中堆内会存在<strong>年轻代、老年代和方法区</strong>**(<strong><strong>永久代</strong></strong>)**。</p><p>​    1）Young区被划分为三部分，Eden区和两个大小严格相同的Survivor区，其中，Survivor区间中，某一时刻只有其中一个是被使用的，另外一个留做垃圾收集时复制对象用。在Eden区变满的时候， GC就会将存活的对象移到空闲的Survivor区间中（先移动到s0,等到再次满，移动到s1，再次满移动到s0），根据JVM的策略，在经过几次垃圾收集后，任然存活于Survivor的对象将被移动到Tenured（长期保有的，老年代）区间。</p><p>​    2）Tenured区主要保存生命周期长的对象，一般是一些老的对象，当一些对象在Young复制转移一定的次数以后，对象就会被转移到Tenured区。</p><p>​    3）Perm代主要保存<strong>保存的类信息、静态变量、常量、编译后的代码</strong>，在java7中堆上方法区会受到GC的管理的。方法区【永久代】是有一个大小的限制的。如果大量的动态生成类，就会放入到方法区【永久代】，很容易造成OOM。</p><p>​    为了避免方法区出现OOM，所以在java8中将堆上的方法区【永久代】给移动到了本地内存上，重新开辟了一块空间，叫做<strong>元空间</strong>。那么现在就可以避免掉OOM的出现了。</p><h2 id="元空间-MetaSpace-介绍"><a href="#元空间-MetaSpace-介绍" class="headerlink" title="元空间(MetaSpace)介绍"></a><strong>元空间</strong>(MetaSpace)介绍</h2><p>在 HotSpot JVM 中，永久代（ ≈ 方法区）中用于存放类和方法的元数据以及常量池，比如Class 和 Method。每当一个类初次被加载的时候，它的元数据都会放到永久代中。</p><p>​    永久代是有大小限制的，因此如果加载的类太多，很有可能导致永久代内存溢出，即OutOfMemoryError，为此不得不对虚拟机做调优。</p><p><strong>Java 8</strong> <strong>中</strong> <strong>PermGen</strong> <strong>为什么被移出</strong> <strong>HotSpot JVM</strong> <strong>了？</strong></p><p>移除永久代是为融合HotSpot JVM与 JRockit VM而做出的努力，因为JRockit没有永久代，不需要配置永久代。</p><p>1）由于 PermGen 内存经常会溢出，引发OutOfMemoryError，因此 JVM 的开发者希望这一块内存可以更灵活地被管理，不要再经常出现这样的 OOM。</p><p>1、字符串存在永久代中，容易出现性能问题和内存溢出。</p><p>2、类及方法的信息等比较难确定其大小，因此对于永久代的大小指定比较困难，太小容易出现永久代溢出，太大则容易导致老年代溢出。</p><p>3、永久代会为 GC 带来不必要的复杂度，并且回收效率偏低。</p><p>2）移除 PermGen 可以促进 HotSpot JVM 与 JRockit VM 的融合，因为 JRockit 没有永久代。</p><p>​    准确来说，Perm 区中的字符串常量池被移到了堆内存中是在 Java7 之后，Java 8 时，PermGen 被元空间代替，其他内容比如<strong>类元信息、字段、静态属性、方法、常量</strong>等都移动到元空间区。比如 java&#x2F;lang&#x2F;Object 类元信息、静态属性 System.out、整型常量等。</p><p>​    元空间的本质和永久代类似，都是对 JVM 规范中方法区的实现。不过元空间与永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。因此，默认情况下，元空间的大小仅受本地内存限制。</p><h1 id="类加载器"><a href="#类加载器" class="headerlink" title="类加载器"></a>类加载器</h1><h2 id="Java文件编译执行的过程"><a href="#Java文件编译执行的过程" class="headerlink" title="Java文件编译执行的过程"></a>Java文件编译执行的过程</h2><p>要想理解类加载器的话，务必要先清楚对于一个Java文件，它从编译到执行的整个过程。</p><img src="/2024/04/05/JVM/clip_image008.gif" class="" title=".class  MethodArea&#x2F;MetaSpace  VM Stack  ClassLoader  Program Counter  Register  Heap  Native Method Stack"><ul><li>类加载器：用于装载字节码文件(.class文件)</li><li>运行时数据区：用于分配存储空间</li><li>执行引擎：执行字节码文件或本地方法</li><li>垃圾回收器：用于对JVM中的垃圾内容进行回收</li></ul><h2 id="类加载过程"><a href="#类加载过程" class="headerlink" title="类加载过程"></a>类加载过程</h2><img src="/2024/04/05/JVM/clip_image010.gif" class="" title="img"><p>解析：使栈中指针指向堆中变量</p><p>初始化：程序员写的初始化代码（自己写的静态代码块）</p><h2 id="一个对象从加载到JVM，再到被GC清楚，都经历了什么过程？"><a href="#一个对象从加载到JVM，再到被GC清楚，都经历了什么过程？" class="headerlink" title="一个对象从加载到JVM，再到被GC清楚，都经历了什么过程？"></a>一个对象从加载到JVM，再到被GC清楚，都经历了什么过程？</h2><img src="/2024/04/05/JVM/clip_image012.jpg" class="" title="一 个 对 象 从 加 载 到 」 VM ， 再 到 被 G （ 清 除 ， 都 经 历 了 什 么 过 程 ？  method( ClassLoaderDem01 们 ew （ Loade " alt="0em010 ； 匚 对 （  1 ． 用 户 创 窪 一 个 对 象 的 NM 首 先 需 到 方 法 区 找 的 年 的 类 型 僖 息 ． 然 再 创 对 象 ．  乙 周 M 要 买 例 化 一 1 ． 矧 象 ． 首 先 要 在 堆 当 中 先 创 建 一 对 ． &gt; # 初 处 化 状  土 的 首 先 会 冲 堆 内 存 中 新 芏 什 0 然 经 波 一 次 Min 酣 GC, 对 如 果 存 ． 就 会 进 人 S 区 ， 秆 启 续 的 0 次 GC  中 。 如 果 的 一 0 存 活 ， 就 会 苻 S 区 回 贝 ， 刨 移 动 一 次 。 加 1. 巧 多 大 年 龄 才 会 移 入 者 年 代 ？ 年 是 大 1 憩 一  的 后 ， 对 象 转 入 老 代 。  生 当 方 法 执 行 适 薟 旨 的 栈 中 的 計 会 先 蜍 绰 ，  堆 中 的 对 象 ， 以 F GC, 就 会 發 吓 记 为 圾 。 然 0 發 G （ 线 溝 许 椏 ·"><p>1.中：每一个对象有一个markword，中有一个class point 指向元空间中的class信息</p><p>对象有可能分配在栈中，生命周期会很简单</p><h2 id="类加载器种类"><a href="#类加载器种类" class="headerlink" title="类加载器种类"></a>类加载器种类</h2><p>类加载器根据各自加载范围的不同，划分为四种类加载器：</p><p>- <strong>启动类加载器(BootStrap ClassLoader)：</strong></p><p> 该类并不继承ClassLoader类，其是由C++编写实现。用于加载<strong>JAVA_HOME&#x2F;jre&#x2F;lib</strong>目录下的类库。</p><p>- <strong>扩展类加载器(ExtClassLoader)：</strong></p><p> 该类是ClassLoader的子类，主要加载<strong>JAVA_HOME&#x2F;jre&#x2F;lib&#x2F;ext</strong>目录中的类库。</p><p>- <strong>应用类加载器(AppClassLoader)：</strong></p><p> 该类是ClassLoader的子类，主要用于加载<strong>classPath</strong>下的类，也就是加载开发者自己编写的Java类。</p><p>- <strong>自定义类加载器：</strong></p><p> 开发者自定义类继承ClassLoader，实现自定义类加载规则。</p><p>上述三种类加载器的层次结构如下如下：</p><img src="/2024/04/05/JVM/clip_image014.gif" class="" title="img"><p>​    类加载器的体系并不是“继承”体系，而是<strong>委派体系</strong>，类加载器首先会到自己的parent中查找类或者资源，如果找不到才会到自己本地查找。类加载器的委托行为动机是为了避免相同的类被加载多次。</p><h2 id="类加载模型"><a href="#类加载模型" class="headerlink" title="类加载模型"></a>类加载模型</h2><p>在JVM中，对于类加载模型提供了三种，分别为全盘加载、双亲委派、缓存机制。</p><p>- <strong>全盘加载：</strong></p><p>​    即当一个类加载器负责加载某个Class时，该Class所依赖和引用的其他Class也将由该类加载器负责载入，除非显示指定使用另外一个类加载器来载入。</p><p>- <strong>双亲委派：</strong></p><p>​    即先让父类加载器试图加载该Class，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类。简单来说就是，某个特定的类加载器在接到加载类的请求时，首先将加载任务委托给父加载器，依次递归，如果父加载器可以完成类加载任务，就成功返回；只有父加载器无法完成此加载任务时，才自己去加载。</p><p>- <strong>缓存机制：</strong></p><p>​    会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区中搜寻该Class，只有当缓存区中不存在该Class对象时，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓冲区中。从而可以理解为什么修改了Class后，必须重新启动JVM，程序所做的修改才会生效的原因。</p><p>双亲委派解析</p><img src="/2024/04/05/JVM/clip_image016.gif" class="" title="img"><p>Ext是App的父加载器，Boot是ext的父加载器   并不是父类，并不是继承关系</p><p>J<strong>VM</strong>为什么采用双亲委派机制</p><p>1）通过双亲委派机制可以避免某一个类被重复加载，当父类已经加载后则无需重复加载，保证唯一性。</p><p>2）为了安全，保证类库API不会被修改</p><img src="/2024/04/05/JVM/clip_image018.gif" class="" title="img"><p>出现该信息是因为由双亲委派的机制，java.lang.String的在启动类加载器(Bootstrap classLoader)得到加载，因为在核心jre库中有其相同名字的类文件，但该类中并没有main方法。这样就能防止恶意篡改核心API库。</p><h2 id="自定义类加载器"><a href="#自定义类加载器" class="headerlink" title="自定义类加载器"></a>自定义类加载器</h2><p>​    对于自定义类加载器的实现也是很简单，只需要继承ClassLoader类，覆写findClass方法即可。</p><p>编写一个测试实体类，接着生成该类的字节码文件。</p><p>当存在.java文件时，根据双亲委派机制，显示当前类加载器为AppClassLoader，而当将.java文件删除时，则显示使用的是自定义的类加载器。</p><h1 id="垃圾回收机制"><a href="#垃圾回收机制" class="headerlink" title="垃圾回收机制"></a>垃圾回收机制</h1><h2 id="java的GC与内存泄漏"><a href="#java的GC与内存泄漏" class="headerlink" title="java的GC与内存泄漏"></a><strong>java</strong>的GC与内存泄漏</h2><p>Java有了GC为什么还会出现内存泄漏问题？</p><p>\1. 静态集合类泄漏</p><p>静态集合类像HashMap，Vector等的使用最容易出现内存泄漏，静态变量的声明周期与应用程序一直，所有的对象Object也不能内释放，因为被其他对象引用着。</p><p>\2. 单例造成的泄漏</p><p>单例对象在初始化后将在JVM的整个生命周期中存在（以静态变量的方式），如果单例对象持有外部的引用，那么这个对象将不能被JVM正常回收，导致内存泄漏。</p><p>3.各种连接</p><p>数据库连接，网络连接，IO连接等没有显式调用close()关闭，会导致内存泄漏。</p><p>4.监听器的使用</p><p>在释放对象的同时，没有删除相应监听器，也会造成内存泄漏。</p><p>在Java语言中，GC Root包括以下几种对象：</p><ol><li>虚拟机栈中引用的对象</li><li>本地方法栈中JNI引用的对象</li><li>方法区中类静态成员变量引用的对象</li><li>方法区中常量引用的对象</li></ol><h2 id="垃圾定位"><a href="#垃圾定位" class="headerlink" title="垃圾定位"></a>垃圾定位</h2><h3 id="引用计数法"><a href="#引用计数法" class="headerlink" title="引用计数法"></a>引用计数法</h3><ol><li>引用计数法</li></ol><p>​    一个对象被引用了一次，在当前的对象头上递增一次引用次数，如果这个对象的引用次数为0，代表这个对象可回收</p><p>循环引用的话，则引用计数法就会失效</p><img src="/2024/04/05/JVM/clip_image020.gif" class="" title="img"><p>虽然a和b都为null，但是由于a和b存在循环引用，这样a和b永远都不会被回收。</p><p>优点：</p><ul><li>实时性较高，无需等到内存不够的时候，才开始回收，运行时根据对象的计数器是否为0，就可以直接回收。</li><li>在垃圾回收过程中，应用无需挂起。如果申请内存时，内存不足，则立刻报OOM错误。</li><li>区域性，更新对象的计数器时，只是影响到该对象，不会扫描全部对象。</li></ul><p>缺点：</p><ul><li>每次对象被引用时，都需要去更新计数器，有一点时间开销。 </li><li><strong>浪费</strong>CPU资源，即使内存够用，仍然在运行时进行计数器的统计。</li><li><strong>无法解决循环引用问题，会引发内存泄露</strong>。（最大的缺点）</li></ul><h3 id="可达性分析算法"><a href="#可达性分析算法" class="headerlink" title="可达性分析算法"></a>可达性分析算法</h3><p>会存在一个根节点【GC Roots】，引出它下面指向的下一个节点，再以下一个节点节点开始找出它下面的节点，依次往下类推。直到所有的节点全部遍历完毕。</p><img src="/2024/04/05/JVM/clip_image022.gif" class="" title="img"><p>​    M,N这两个节点是可回收的，但是<strong>并不会马上的被回收！！</strong> 对象中存在一个方法【finalize】。当对象被标记为可回收后，当发生GC时，首先<strong>会判断这个对象是否执行了finalize方法</strong>，如果这个方法还没有被执行的话，那么就会先来执行这个方法，接着在这个方法执行中，可以设置当前这个对象与GC ROOTS产生关联，那么这个方法执行完成之后，GC会再次判断对象是否可达，如果仍然不可达，则会进行回收，如果可达了，则不会进行回收。</p><p>​    finalize方法对于每一个对象来说，只会执行一次。如果第一次执行这个方法的时候，设置了当前对象与RC ROOTS关联，那么这一次不会进行回收。 那么等到这个对象第二次被标记为可回收时，那么该对象的finalize方法就不会再次执行了。</p><p>## GC ROOTS：</p><p>​    <strong>虚拟机栈中引用的对象</strong></p><p>​    <strong>本地方法栈中引用的对象</strong></p><p>​    <strong>方法区中类静态属性引用的对象</strong></p><p>​    <strong>方法区中常量引用对象</strong></p><h2 id="垃圾回收算法"><a href="#垃圾回收算法" class="headerlink" title="垃圾回收算法"></a>垃圾回收算法</h2><h3 id="标记清除算法"><a href="#标记清除算法" class="headerlink" title="标记清除算法"></a>标记清除算法</h3><p>标记清除算法，是将垃圾回收分为2个阶段，分别是<strong>标记和清除</strong>。</p><p>1.根据可达性分析算法得出的垃圾进行标记</p><p>2.对这些标记为可回收的内容进行垃圾回收</p><img src="/2024/04/05/JVM/clip_image024.gif" class="" title="img"><img src="/2024/04/05/JVM/clip_image026.gif" class="" title="img"><p>可以看到，标记清除算法解决了引用计数算法中的循环引用的问题，没有从root节点引用的对象都会被回收。</p><p>同样，标记清除算法也是有缺点的：</p><ul><li>效率较低，<strong>标记和清除两个动作都需要遍历所有的对象</strong>，并且在GC时，<strong>需要停止应用程序</strong>，对于交互性要求比较高的应用而言这个体验是非常差的。</li><li>（<strong>重要</strong>）通过标记清除算法清理出来的内存，碎片化较为严重，因为被回收的对象可能存在于内存的各个角落，所以清理出来的内存是不连贯的。</li></ul><h3 id="复制算法"><a href="#复制算法" class="headerlink" title="复制算法"></a>复制算法</h3><p>新生代的垃圾回收算法：大部分对象都不会存活，所以在新生代中使用复制算法较为高效</p><p>复制算法的核心就是，<strong>将原有的内存空间一分为二，每次只用其中的一块</strong>，在垃圾回收时，将正在使用的对象复制到另一个内存空间中，然后将该内存空间清空，交换两个内存的角色，完成垃圾的回收。</p><p>​    如果内存中的垃圾对象较多，需要复制的对象就较少，这种情况下适合使用该方式并且效率比较高，反之，则不适合。 </p><img src="/2024/04/05/JVM/clip_image028.gif" class="" title="img"><img src="/2024/04/05/JVM/clip_image030.gif" class="" title="img"><p>1）将内存区域分成两部分，每次操作其中一个。</p><p>2）当进行垃圾回收时，将正在使用的内存区域中的存活对象移动到未使用的内存区域。当移动完对这部分内存区域一次性清除。</p><p>3）周而复始。</p><p>优点：</p><p>- 在垃圾对象多的情况下，效率较高</p><p>- 清理后，内存无碎片</p><p>缺点：</p><p>- 分配的2块内存空间，在同一个时刻，只能使用一半，内存使用率较低</p><h3 id="标记整理算法"><a href="#标记整理算法" class="headerlink" title="标记整理算法"></a>标记整理算法</h3><p>老年代的垃圾回收算法：大部分对象可能会继续存活下去</p><p>标记压缩算法是在标记清除算法的基础之上，做了优化改进的算法。和标记清除算法一样，也是从根节点开始，对对象的引用进行标记，在清理阶段，并不是简单的直接清理可回收对象，而是将存活对象都向内存另一端移动，然后清理边界以外的垃圾，从而解决了碎片化的问题。</p><img src="/2024/04/05/JVM/clip_image032.gif" class="" title="img"><img src="/2024/04/05/JVM/clip_image034.gif" class="" title="img"><p>1）标记垃圾。</p><p>2）需要清除向右边走，不需要清除的向左边走。</p><p>3）清除边界以外的垃圾。</p><p>优缺点同标记清除算法（标记需要遍历所有的对象，并且在GC时，需要停止应用程序），解决了标记清除算法的碎片化的问题，同时，标记压缩算法多了一步，对象移动内存位置的步骤，其效率也有有一定的影响。</p><h3 id="分代收集算法"><a href="#分代收集算法" class="headerlink" title="分代收集算法"></a>分代收集算法</h3><p>在java8时，堆被分为了两份：<strong>新生代和老年代【<strong><strong>1</strong></strong>：<strong><strong>2</strong></strong>】</strong>，在java7时，还存在一个永久代。</p><img src="/2024/04/05/JVM/clip_image036.gif" class="" title="Eden  (8&#x2F;10)  f rom  (1&#x2F;10)  Young  to  (1&#x2F;10)  Old"><p>对于新生代，内部又被分为了三个区域。Eden区，S0区，S1区【8：1：1】</p><p>当对新生代产生GC：MinorGC【young GC】</p><p>当对老年代产生GC：FullGC【OldGC】</p><p>3.2.4.1 工作机制</p><p>1）当创建一个对象的时候，那么这个对象会被分配在新生代的Eden区。当Eden区要满了时候，触发YoungGC。</p><p>2）当进行YoungGC后，此时在Eden区存活的对象被移动到S0区，并且<strong>当前对象的年龄会加</strong>1，清空Eden区。</p><p>3）当再一次触发YoungGC的时候，会把Eden区中存活下来的对象和S0中的对象，移动到S1区中，这些对象的年龄会加1，清空Eden区和S0区。</p><p>4）当再一次触发YoungGC的时候，会把Eden区中存活下来的对象和S1中的对象，移动到S0区中，这些对象的年龄会加1，清空Eden区和S1区。</p><p>3.2.4.2 对象何时晋升到老年代</p><p>1）对象的年龄达到了某一个限定的值（<strong>默认<strong><strong>15</strong></strong>岁</strong>，CMS默认6岁 ），那么这个对象就会进入到老年代中。</p><p>2）大对象。</p><p>3）如果在Survivor区中相同年龄的对象的所有大小之和超过Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代。</p><p>当老年代满了之后，<strong>触发</strong>FullGC<strong>。</strong>FullGC同时回收新生代和老年代，当前只会存在一个FullGC的线程进行执行，其他的线程全部会被挂起。</p><h1 id="垃圾收集器"><a href="#垃圾收集器" class="headerlink" title="垃圾收集器"></a>垃圾收集器</h1><img src="/2024/04/05/JVM/clip_image038.gif" class="" title="img"><h2 id="串行垃圾收集器"><a href="#串行垃圾收集器" class="headerlink" title="串行垃圾收集器"></a>串行垃圾收集器</h2><p>### Serial收集器</p><p>​    <strong>串行垃圾收集器</strong>，作用于<strong>新生代</strong>。是指使用单线程进行垃圾回收，<strong>采用复制算法</strong>。垃圾回收时，只有一个线程在工作，并且java应用中的所有线程都要暂停，等待垃圾回收的完成。这种现象称之为STW（Stop-The-World）。<strong>其应用在年轻代</strong></p><p>​    对于交互性较强的应用而言，这种垃圾收集器是不能够接受的。因此一般在Javaweb应用中是不会采用该收集器的。</p><img src="/2024/04/05/JVM/clip_image040.gif" class="" title="img"><p><strong>Serial Old****收集器</strong></p><p>​    其是运行于<strong>老年代的单线程</strong>Serial收集器，<strong>采用标记</strong>**-**<strong>整理算法</strong>，主要是给Client模式下的虚拟机使用。</p><h2 id="并行垃圾收集器"><a href="#并行垃圾收集器" class="headerlink" title="并行垃圾收集器"></a>并行垃圾收集器</h2><p>### ParallelNew收集器</p><p>  并行垃圾收集器在串行垃圾收集器的基础之上做了改进，<strong>采用复制算法</strong>。将单线程改为了多线程进行垃圾回收，这样可以缩短垃圾回收的时间。（这里是指，并行能力较强的机器）。但是对于其他的行为（收集算法、stop the world、对象分配规则、回收策略等）同Serial收集器一样。其也是应用在年轻代。<strong>JDK8默认使用此垃圾回收器</strong></p><p>​    当然了，并行垃圾收集器在收集的过程中也会暂停应用程序，这个和串行垃圾回收器是一样的，只是并行执行，速度更快些，暂停的时间更短一些。</p><img src="/2024/04/05/JVM/clip_image042.gif" class="" title="img"><p>### 3.4.3 Parallel Scavenge收集器</p><p>​    其是一个应用于<strong>新生代</strong>的<strong>并行</strong>垃圾回收器，<strong>采用复制算法</strong>。它的目标是达到一个可控的吞吐量（吞吐量&#x3D;运行用户代码时间 &#x2F;（运行用户代码时间+垃圾收集时间））即虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，吞吐量就是99%。这样可以高效率的利用CPU时间，尽快完成程序的运算任务，适合在后台运算而不需要太多交互的任务。</p><p>- 停顿时间越短对于需要与用户交互的程序来说越好，良好的响应速度能提升用户的体验。</p><p>- 高吞吐量可以最高效率地利用CPU时间，尽快地完成程序的运算任务，主要适合在后台运算而不太需要太多交互的任务。</p><p>### Parallel Old收集器</p><p>​    其是一个应用于老年代的并行垃圾回收器，<strong>采用标记-整理算法</strong>。在注重吞吐量及CPU资源敏感的场合，都可以优先考虑Parallel Scavenge+Parallel Old收集器。</p><h2 id="CMS（并发）垃圾收集器"><a href="#CMS（并发）垃圾收集器" class="headerlink" title="CMS（并发）垃圾收集器"></a>CMS（并发）垃圾收集器</h2><p>CMS全称 Concurrent Mark Sweep，是一款<strong>并发</strong>的、使用<strong>标记-清除</strong>算法的垃圾回收器，该回收器是<strong>针对老年代垃圾回收的</strong>，是一款以获取最短回收停顿时间为目标的收集器，停顿时间短，用户体验就好。<strong>其最大特点是在进行垃圾回收时，应用仍然能正常运行。</strong> </p><p>CMS垃圾回收器的执行过程如下：</p><img src="/2024/04/05/JVM/clip_image044.gif" class="" title="img"><p>1)初始标记(Initial Mark)：仅仅标记GC Roots能直接关联到的对象，速度快，但是需要“Stop The World”</p><p>2)并发标记(Concurrent Mark)：就是进行追踪引用链的过程，可以和用户线程并发执行。</p><p>3)重新标记(Remark)：修正并发标记阶段因用户线程继续运行而导致标记发生变化的那部分对象的标记记录，比初始标记时间长但远比并发标记时间短，需要“Stop The World”</p><p>4)并发清除(Concurrent Sweep)：清除标记为可以回收对象，可以和用户线程并发执行</p><p>​    由于整个过程耗时最长的并发标记和并发清除都可以和用户线程一起工作，所以总体上来看，CMS收集器的内存回收过程和用户线程是并发执行的。</p><p>#### 3.4.6.2 CMS收集器缺点</p><p>​    对于CMS收集器的有三个：</p><p>- 对CPU资源敏感：</p><p>​    并发收集虽然不会暂停用户线程，但因为占用CPU资源，仍会导致系统吞吐量降低、响应变慢</p><p>​    CMS的默认收集线程数量是&#x3D;(CPU数量+3)&#x2F;4。当CPU数量多于4个，收集线程占用的CPU资源多于25%，对用户程序影响可能较大；不足4个时，影响更大，可能无法接受。</p><p>- 无法处理浮动垃圾：</p><p>​    所谓浮动垃圾即在并发清除时，用户线程新产生的垃圾叫浮动垃圾。并发清除时需要预留一定的内存空间，不能像其他收集器在老年代几乎填满再进行收集。如果CMS预留内存空间无法满足程序需要，就会出现一次”Concurrent Mode Failure”失败。这时JVM启用后备预案：临时启用Serail Old收集器，而导致另一次Full GC的产生。</p><p>- 垃圾回收算法导致内存碎片：</p><p>​    因为CMS收集器采用标记-清除算法，因此会导致垃圾从内存中被清除后，会出现内存空间碎片化。这样会导致分配大内存对象时，无法找到足够的连续内存，从而需要提前触发另一次Full GC动作。</p><h2 id="G1垃圾收集器"><a href="#G1垃圾收集器" class="headerlink" title="G1垃圾收集器"></a>G1垃圾收集器</h2><p> 概述</p><p>对于垃圾回收器来说，前面的三种要么一次性回收年轻代，要么一次性回收老年代。而且现代服务器的堆空间已经可以很大了。为了更加优化GC操作，所以出现了G1。</p><p>​    它是一款<strong>同时应用于新生代和老年代、采用标记-整理算法、软实时、低延迟、可设定目标(最大STW停顿时间)<strong>的垃圾回收器，用于代替CMS，适用于较大的堆(&gt;4~6G)，</strong>在JDK9之后默认使用G1</strong>。</p><p>G1的设计原则就是简化JVM性能调优，开发人员只需要简单的三步即可完成调优：</p><p>\1. 第一步，开启G1垃圾收集器</p><p>\2. 第二步，设置堆的最大内存</p><p>\3. 第三步，可设定目标，设置最大的停顿时间（stw）默认是250ms</p><h3 id="G1的内存布局"><a href="#G1的内存布局" class="headerlink" title="G1的内存布局"></a>G1的内存布局</h3><p>G1垃圾收集器相对比其他收集器而言，最大的区别在于它<strong>取消了年轻代、老年代的物理划分</strong>。</p><img src="/2024/04/05/JVM/clip_image046.gif" class="" title="img"><p>​    取而代之的是将堆划分为<strong>若干个区域（<strong><strong>Region</strong></strong>）</strong>，这些区域中包含了有<strong>逻辑上的年轻代、老年代区域</strong>。这样做的好处就是，我们再也不用单独的空间对每个代进行设置了，不用担心每个代内存是否足够。</p><p>​    此时可以看到，现在出现了一个<strong>新的区域****Humongous</strong>，它本身属于老年代区。当现在出现了一个巨大的对象，超出了分区容量的一半，则这个对象会进入到该区域。如果一个H区装不下一个巨型对象，那么G1会寻找连续的H分区来存储。为了能找到连续的H区 ，有时候不得不启动Full GC。</p><p>​    同时G1会估计每个Region中的垃圾比例，优先回收垃圾较多的区域。</p><img src="/2024/04/05/JVM/clip_image048.gif" class="" title="img"><p>​    在G1划分的区域中，年轻代的垃圾收集依然采用<strong>暂停所有应用线程的方式</strong>，将存活对象拷贝到老年代或者Survivor空间，G1收集器通过将<strong>对象从一个区域复制到另外一个区域，完成了清理工作</strong>。</p><p>​    这就意味着，在正常的处理过程中，G1完成了堆的压缩（至少是部分堆的压缩），这样也就不会有cms内存碎片问题的存在了。</p><h3 id="垃圾回收基本概念"><a href="#垃圾回收基本概念" class="headerlink" title="垃圾回收基本概念"></a>垃圾回收基本概念</h3><img src="/2024/04/05/JVM/clip_image050.gif" class="" title="img"><p>Collection Set回收集合</p><img src="/2024/04/05/JVM/clip_image052.gif" class="" title="img"><img src="/2024/04/05/JVM/clip_image054.gif" class="" title="img"><img src="/2024/04/05/JVM/clip_image056.gif" class="" title="img"><p>card table：一个region又划分为一个一个区域</p><p>对应内存空间发生改变：比如给空间中的引用赋值的时候，就会把这个区域标记为dirty</p><p>rememberedSet：region2中的rememberedSet就记录着指向region1部分，因为region1中存在着指向region2的引用，通过rememberedSet就能找到region1</p><p>时间换空间：因为现代堆空间很大，所以是值得的</p><img src="/2024/04/05/JVM/clip_image057.gif" class="" title="img"><p>更新指针时：引用发生变化时</p><img src="/2024/04/05/JVM/clip_image059.gif" class="" title="img"><p>refinement线程：优化线程</p><p>更新RS：region1中存在引用指向region2的对象，这时更新的是region2的RS</p><p>三种模式垃圾回收模式： <strong>young GC、Mixed GC、Full GC</strong>。在不同的条件下被触发。</p><h3 id="Young-GC"><a href="#Young-GC" class="headerlink" title="Young GC"></a>Young GC</h3><p>发生在年轻代的GC算法，一般对象（除了巨型对象）都是在eden region（区）中分配内存，当所有eden region被耗尽无法申请内存时，就会触发一次young gc，这种触发机制和之前的young gc差不多，执行完一次young gc，活跃对象会被拷贝到survivor region或者晋升到old region中，空闲的region会被放入空闲列表中，等待下次被使用。</p><img src="/2024/04/05/JVM/clip_image061.gif" class="" title="img"><p>fully young GC：完全的年轻代GC</p><p>Evacuation：疏散    构建CS：构建回收集合</p><p>Object Copy：把Eden和Survivor区中的对象复制到另一个Survivor区</p><p>update RS的目的就是把R set中更新成最新的状态，知道哪些老年代的引用指向了该对象，因为要进行复制算法</p><p>##### 为什么年轻代一般都使用的copy</p><p>(1) 年轻代 回收效率高 </p><p>(2) 年轻代 一般不会很大 </p><p>以上2点其实都是根据它的特点来的: 朝生夕死.</p><p>使用copy的原因是 它快, 不需要额外的压缩, 没有碎片. 它的缺点就是空间利用率会低一些. 但是本身年轻代不会太大, 所以这个缺点也就不是很严重.</p><img src="/2024/04/05/JVM/clip_image063.gif" class="" title="img"><p>程序员设置的GC时间如果十分严格，G1实在达不到，就会减少年轻代Region数量，也会减少暂停时间，如果太频繁进行GC，那么CPU占用就会增加，造成吞吐量降低。</p><img src="/2024/04/05/JVM/clip_image065.gif" class="" title="img"><h3 id="Mixed-GC（OldGC）"><a href="#Mixed-GC（OldGC）" class="headerlink" title="Mixed GC（OldGC）"></a>Mixed GC（OldGC）</h3><img src="/2024/04/05/JVM/clip_image067.gif" class="" title="img"><img src="/2024/04/05/JVM/clip_image069.gif" class="" title="img"><img src="/2024/04/05/JVM/clip_image071.gif" class="" title="img"><img src="/2024/04/05/JVM/clip_image073.gif" class="" title="img"><p>首先把GCROOT标为黑色，将与GCROOT相连的对象标为灰色，灰色放进一个队列，然后挨个取出来，标记为黑色，并把与这个相连的标记为灰色，直到所以都为黑的</p><p>错标记和漏标记的问题如下：</p><img src="/2024/04/05/JVM/clip_image074.jpg" class="" title="img"><p>A：黑色 B：灰色    C：白色</p><p>在并发标记阶段，引用可能发生了变化：这样的话C永远都标记不到，会被回收，因为A是黑色表示自己和成员变量都被标记了，但C确实没有被标记</p><img src="/2024/04/05/JVM/clip_image075.jpg" class="" title="img"><p>解决方法：</p><p>把A标为灰色：并发标记时把A变为灰色</p><img src="/2024/04/05/JVM/clip_image076.jpg" class="" title="img"><p>G1的解决方案：</p><img src="/2024/04/05/JVM/clip_image077.jpg" class="" title="img"><p>提供了一个快照，保存了没有被标记的region</p><img src="/2024/04/05/JVM/clip_image079.gif" class="" title="img"><p>piggy-backed on young GC 骑在young GC的头上，表明old GC里包含young GC</p><p>当越来越多的对象晋升到老年代old region时，为了避免堆内存被耗尽，虚拟机会触发一个混合的垃圾收集器，即<strong>mixed gc</strong>，该算法并不是一个old gc，除了回收整个young region，还会回收一部分的old region，这里需要注意：<strong>是一部分老年代，而不是全部老年代</strong>，可以选择哪些old region进行收集，从而可以对垃圾回收的耗时时间进行控制。</p><p>​    在CMS中，当老年代的使用率达到80%就会触发一次cms gc。在G1中，mixed gc也可以通过-XX:InitiatingHeapOccupancyPercent设置阈值，*<em>默认为</em>***45%**。当老年代大小占整个堆大小百分比达到该阈值，则触发mixed gc。</p><p>其执行过程和cms类似：</p><ol><li>initial mark: 初始标记过程，整个过程STW，标记了从GC     Root可达的对象。</li><li>concurrent marking: 并发标记过程，整个过程gc     collector线程与应用线程可以并行执行，标记出GC Root可达对象衍生出去的存活对象，并收集各个Region的存活对象信息。</li><li>remark: 最终标记过程，整个过程STW，标记出那些在并发标记过程中遗漏的，或者内部引用发生变化的对象。（保证安全的标记，保证找到的对象都是活对象）</li><li>clean up: 垃圾清除过程，不进行老年代垃圾回收的拷贝，如果发现一个Region中没有存活对象，则把该Region加入到空闲列表中。</li><li><img src="/2024/04/05/JVM/clip_image081.gif" class="" title="img"></li></ol><img src="/2024/04/05/JVM/clip_image083.gif" class="" title="img"><h3 id="Full-GC"><a href="#Full-GC" class="headerlink" title="Full GC"></a>Full GC</h3><p>如果对象内存分配速度过快，mixed gc来不及回收，导致老年代被填满，就会触发一次full gc，G1的full gc算法就是单线程执行的serial old gc，会导致异常长时间的暂停时间，需要进行不断的调优，尽可能的避免full gc.</p><p>为何这么多垃圾回收器：因为内存不断扩大，回收越来越复杂</p><h3 id="G1的最佳实践"><a href="#G1的最佳实践" class="headerlink" title="G1的最佳实践"></a>G1的最佳实践</h3><p><strong>不断调优暂停时间指标</strong></p><p> 通过<strong>XX:MaxGCPauseMillis&#x3D;x</strong>可以设置启动应用程序暂停的时间，G1在运行的时候会根据这个参数选择CSet来满足响应时间的设置。一般情况下这个值设置到100ms或者200ms都是可以的(不同情况下会不一样)，但如果设置成50ms就不太合理。暂停时间设置的太短，就会导致出现G1跟不上垃圾产生的速度。最终退化成Full GC。所以对这个参数的调优是一个持续的过程，逐步调整到最佳状态。</p><p><strong>不要设置新生代和老年代的大小</strong></p><p> G1收集器在运行时候会调整新生代和老年代的大小。通过改变代的大小来调整对象晋升的速度以及晋升年龄，从而达到我们为收集器设置的暂停时间目标。设置了新生代大小相当于放弃了G1为我们做的自动调优。我们需要做的只是设置整个堆内存的大小，剩下的交给G1自己去分配各个代的大小。</p><h2 id="G1相对CMS的优势"><a href="#G1相对CMS的优势" class="headerlink" title="G1相对CMS的优势"></a>G1相对CMS的优势</h2><p>G1相对CMS的优势：</p><p>1、G1在压缩空间方面有优势。</p><p>2、G1通过将内存空间分成区域（Region）的方式避免内存碎片的问题。</p><p>3、Eden、Survivor、Old区不再固定，在内存使用效率上来说更灵活。</p><p>4、G1可以通过设置预期停顿时间（Pause Time）来控制垃圾收集时间，避免应用雪崩现象。</p><p>5、G1在回收内存后会马上同时做合并空闲内存的工作，而CMS默认是在STW(stop the world)的时候做。</p><p>6、G1会在young GC中使用，而CMS只能在老年代中使用。</p><p>G1适合的场景：</p><p>1、服务端多核CPU、JVM内存占用较大的应用。</p><p>2、应用在运行过程中会产生大量的内存碎片，需要经常压缩空间。</p><p>3、想要更可控、可预期的GC停顿周期；防止高并发下应用的雪崩现象。</p><h2 id="ZGC"><a href="#ZGC" class="headerlink" title="ZGC"></a><strong>ZGC</strong></h2><img src="/2024/04/05/JVM/clip_image085.jpg" class="" width="0"><p>ZGC只有三个STW阶段：<strong>初始标记</strong>，<strong>再标记</strong>，<strong>初始转移</strong>。其中，初始标记和初始转移分别都只需要扫描所有GC Roots，其处理时间和GC Roots的数量成正比，一般情况耗时非常短；再标记阶段STW时间很短，最多1ms，超过1ms则再次进入并发标记阶段。即，ZGC几乎所有暂停都只依赖于GC Roots集合大小，停顿时间不会随着堆的大小或者活跃对象的大小而增加。与ZGC对比，G1的转移阶段完全STW的，且停顿时间随存活对象的大小增加而增加。</p><p>ZGC通过着色指针和读屏障技术，解决了转移过程中准确访问对象的问题，实现了并发转移。大致原理描述如下：并发转移中“并发”意味着GC线程在转移对象的过程中，应用线程也在不停地访问对象。假设对象发生转移，但对象地址未及时更新，那么应用线程可能访问到旧地址，从而造成错误。而在ZGC中，应用线程访问对象将触发“读屏障”，如果发现对象被移动了，那么“读屏障”会把读出来的指针更新到对象的新地址上，这样应用线程始终访问的都是对象的新地址。那么，JVM是如何判断对象被移动过呢？就是利用对象引用的地址，即着色指针。</p><p><a href="https://zhuanlan.zhihu.com/p/170572432">https://zhuanlan.zhihu.com/p/170572432</a></p><h1 id="开放性问题"><a href="#开放性问题" class="headerlink" title="开放性问题"></a>开放性问题</h1><p>系统运行过程中出现fullGC，怎么排查，什么情况出现fullGC</p><p>top – jstate – map工具</p><img src="/2024/04/05/JVM/clip_image087.gif" class="" title="img"><img src="/2024/04/05/JVM/clip_image089.gif" class="" title="img"><img src="/2024/04/05/JVM/clip_image091.gif" class="" title="img"><img src="/2024/04/05/JVM/clip_image093.gif" class="" title="img"><p><a href="https://blog.csdn.net/xiaoxiaole0313/article/details/104285018/">https://blog.csdn.net/xiaoxiaole0313/article/details/104285018/</a></p><h1 id="零星知识"><a href="#零星知识" class="headerlink" title="零星知识"></a>零星知识</h1><h2 id="指针碰撞和空闲列表"><a href="#指针碰撞和空闲列表" class="headerlink" title="指针碰撞和空闲列表"></a>指针碰撞和空闲列表</h2><p>假设Java堆中内存是绝对规整的，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离，这种分配方式称为“指针碰撞”（Bump thePointer）。如果Java堆中的内存并不是规整的，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录，这种分配方式称为“空闲列表”（FreeList） </p><h2 id="内存分配担保机制"><a href="#内存分配担保机制" class="headerlink" title="内存分配担保机制"></a>内存分配担保机制</h2><p>在现实社会中，借款会指定担保人，就是当借款人还不起钱，就由担保人来还钱。</p><p>在JVM的内存分配时，也有这样的<strong>内存分配担保机制</strong>。就是当在新生代无法分配内存的时候，把新生代的对象转移到老生代，然后把新对象放入腾空的新生代。</p><h1 id="比较好的博客"><a href="#比较好的博客" class="headerlink" title="比较好的博客"></a>比较好的博客</h1><p>Java GC（垃圾回收机制）面试讲解</p><p><strong>总结的较好：</strong> <a href="https://www.cnblogs.com/dmzna/p/12913458.html">https://www.cnblogs.com/dmzna/p/12913458.html</a></p><p><strong>讲的较细：</strong> <a href="https://www.cnblogs.com/leesf456/p/5218594.html">https://www.cnblogs.com/leesf456/p/5218594.html</a></p>]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> JVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>集合</title>
      <link href="/2024/04/05/%E9%9B%86%E5%90%88/"/>
      <url>/2024/04/05/%E9%9B%86%E5%90%88/</url>
      
        <content type="html"><![CDATA[<h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image002.gif" class="" title="img"><h2 id="常用的数据结构"><a href="#常用的数据结构" class="headerlink" title="常用的数据结构"></a>常用的数据结构</h2><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image004.gif" class="" title="Linear  Data Structure  Non-linear  Data Structure  (Array)  (Linked List)  (Stack)  (Queue)  (Tree)  (Heap)  (Hashing)  (Graph)"><p>详细见 链接  <a href="https://blog.csdn.net/QLeelq/article/details/113694455">https://blog.csdn.net/QLeelq/article/details/113694455</a></p><h2 id="HashMap"><a href="#HashMap" class="headerlink" title="HashMap"></a>HashMap</h2><h3 id="JDK7HashMap"><a href="#JDK7HashMap" class="headerlink" title="JDK7HashMap"></a>JDK7HashMap</h3><p>在JDK7中其底层是由<strong>数组+链表</strong>构成，数组被分成一个个桶(bucket)，通过哈希值决定了键值对在这个数组中的位置。哈希值相同的键值对，会以链表形式进行存储。每一个键值对会以一个Entry实例进行封装，内部存在四个属性：key，value，hash值，和用于单向链表的next。</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image006.gif" class="" title="entry  key,value,hash  entry  key,value,hash  entry  key,value,hash  entry  key,value,hash  entry  key,value,hash  entry  key,value,hash  entry  key,value,hash  entry  key,value,hash"><p>当对HashMap初始化时，其构造函数中需要传入两个参数：<strong>initialCapacity</strong>、<strong>loadFactor</strong></p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image008.gif" class="" title="public HashMap(int  initialCapacitv ,  float  0.75  toadFactor) {"><p>hashMap中还有一个变量：<strong>threshold</strong>（扩容阈值。计算公式：<strong>capacity * load factor</strong>）</p><p>添加数据过程（put）</p><ol><li>在第一个元素插入HashMap时做一次数组的初始化，先确定初始的数组大小，并计算数组扩容的阈值。（创建hashmap的时候数组并没有被初始化，put的时候才初始化的）</li><li>使用key进行Hash值计算，<strong>然后通过</strong> <strong>(n - 1) &amp; hash</strong> <strong>判断当前元素存放的位置（这里的</strong> <strong>n</strong> <strong>指的是数组的长度）</strong>，用于确定当前键值对要放入哪个Bucket中。（为什么采取与运算：1.采用模运算会造成大量的哈希冲突，导致哈希散列不均匀，某一桶中链表长度过长，造成查询效率大幅下降。2.与运算本身性能要比模运算高）</li><li>找到Bucket后，<strong>如果当前位置存在元素的话，就判断该元素与要存入的元素的</strong> <strong>hash</strong> <strong>值以及</strong> <strong>key</strong> <strong>是否相同</strong>；如果没有重复，则将此Entry放入链表的<strong>头部</strong>。如果键相同值不相同的话，直接更新。（进行比较key值是否相同，若是不同则向后遍历，直到找到相同的为止。找到后进行元素的替换，若是找不到就新生成一个Entry，entry对象的next指向上面获取的位置i，头插）</li><li>在插入新值时，如果当前Buckets数组大小达到了阈值，则触发扩容。扩容后，为原大小的两倍。<strong>扩容时会产生一个新的数组替换原来的数组，并将原来数组中的值迁移到新数组中</strong>。</li></ol><p> JDK7的HashMap扩容流程</p><p>1）当调用HashMap的put方法时，其内部会调用addEntry方法添加元素。</p><p>2）在addEntry中，如果条件满足则调用resize方法进行扩容。扩展为原大小的两倍。</p><p>3）在resize方法中，会调用transfer方法根据新的容量去创建新的Entry数组，命名</p><p>为newTable。</p><p>4）在transfer方法中会轮询原table中的每一个Entry重新计算其在新Table上的位置，并以链表形式连接</p><p>5）当全部轮询完毕，则在resize方法中将原table替换为新table。</p><p> JDK7hashMap死循环解析</p><p>当进行rehash时，会造成hashMap出现死循环，原因就在于其内部会形成一个循环链表。 该问题在JDK8之后得以解决，但是仍然不推荐在多线程环境下直接使用HashMap，因为有可能会造成数据丢失，建议使用ConcurrentHashMap。</p><h3 id="JDK8HashMap"><a href="#JDK8HashMap" class="headerlink" title="JDK8HashMap"></a>JDK8HashMap</h3><p>Hashmap结构</p><p>由<strong>数组+链表+红黑树</strong>组成。这么做的原因是因为：之前查找元素需要遍历链表，时间复杂度取决于链表的长度。</p><p>为了优化这部分的开销，在JDK中，如果链表中元素大于等于8个，则将链表转换为红黑树（前提是桶的大小达到64，否则会先对桶进行扩容）；当红黑树中元素小于等于6个，则将红黑树转为链表。从而降低查询与添加的时间复杂度。</p><p>put流程</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image012.gif" class="" title="HashMap put 容"><p>即使不会出现死循环，但是通过源码看到put&#x2F;get方法都没有加同步锁，多线程情况最容易出现的就是：无法保证上一秒put的值，下一秒get的时候还是原值，所以线程安全还是无法保证。</p><p>1、put的时候导致的多线程数据不一致。</p><p>这个问题比较好想象，比如有两个线程A和B，首先A希望插入一个key-value对到HashMap中，首先计算记录所要落到的桶的索引坐标，然后获取到该桶里面的链表头结点，此时线程A的时间片用完了，而此时线程B被调度得以执行，和线程A一样执行，只不过线程B成功将记录插到了桶里面，假设线程A插入的记录计算出来的桶索引和线程B要插入的记录计算出来的桶索引是一样的，那么当线程B成功插入之后，线程A再次被调度运行时，它依然持有过期的链表头但是它对此一无所知，以至于它认为它应该这样做，如此一来就覆盖了线程B插入的记录，这样线程B插入的记录就凭空消失了，造成了数据不一致的行为。</p><h3 id="扩展知识点"><a href="#扩展知识点" class="headerlink" title="扩展知识点"></a>扩展知识点</h3><p><a href="onenote:#扩展知识点&section-id={D17A0EA0-97AB-4A0A-AACE-F95D62D7DAFC}&page-id={BC978001-A2DC-40EE-89CB-914759A07A3C}&object-id={F678C236-2E0C-4EE5-8AC0-12C26A1DF70D}&E&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/集合数据结构.one">jdk 7 与 jdk 8 中关于HashMap的对比 </a></p><p><a href="onenote:#扩展知识点&section-id={D17A0EA0-97AB-4A0A-AACE-F95D62D7DAFC}&page-id={BC978001-A2DC-40EE-89CB-914759A07A3C}&object-id={55423992-526C-4784-8BBA-FD5DB4809446}&24&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/集合数据结构.one">HashMap 的buckets长度为什么永远是 2 的幂次方</a></p><p><a href="onenote:#扩展知识点&section-id={D17A0EA0-97AB-4A0A-AACE-F95D62D7DAFC}&page-id={BC978001-A2DC-40EE-89CB-914759A07A3C}&object-id={55423992-526C-4784-8BBA-FD5DB4809446}&37&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/集合数据结构.one">HashMap负载因子为什么是0.75</a></p><p><a href="onenote:#扩展知识点&section-id={D17A0EA0-97AB-4A0A-AACE-F95D62D7DAFC}&page-id={BC978001-A2DC-40EE-89CB-914759A07A3C}&object-id={55423992-526C-4784-8BBA-FD5DB4809446}&4F&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/集合数据结构.one">为什么JDK8采用红黑树，而不采用平衡二叉树</a></p><p><a href="onenote:#扩展知识点&section-id={D17A0EA0-97AB-4A0A-AACE-F95D62D7DAFC}&page-id={BC978001-A2DC-40EE-89CB-914759A07A3C}&object-id={55423992-526C-4784-8BBA-FD5DB4809446}&58&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/集合数据结构.one">为什么链表转红黑树的阈值是8</a></p><p><a href="onenote:#扩展知识点&section-id={D17A0EA0-97AB-4A0A-AACE-F95D62D7DAFC}&page-id={BC978001-A2DC-40EE-89CB-914759A07A3C}&object-id={A6C72C1B-17D8-4C69-AFF1-58FCC6E79936}&12&base-path=https://d.docs.live.net/73ef43393996c94e/文档/java/集合数据结构.one">为什么要用链地址法解决冲突_1</a></p><p>jdk 7 与 jdk 8 中关于HashMap的对比</p><ul><li>8时红黑树+链表+数组的形式，当桶内元素大于8时，便会树化</li><li>1.7 table在创建hashmap时分配空间，而1.8在put的时候分配，如果table为空，则为table分配空间。</li><li>在发生冲突，插入链中时，7是头插法，8是尾插法。</li></ul><p>HashMap 的buckets长度为什么永远是 2 的幂次方</p><p>​    为了能让存储更加高效，尽量的避免key冲突，让数据尽量均匀的进行分布，因此采用了hash值计算的方式，hash值的范围为-2147483648 到 2147483647。在这40亿的空间中，总的来说一般很难出现碰撞。但是这么大的空间，不可能一次性全部装入内存中，所以不能直接使用这块空间。因此才会对数组长度进行取模运算，根据余数用来对应数组的下标，来确定当前用于存放数据的位置。计算公式就是<code>(n-1)&amp;hash</code>。所以buckets的长度才永远为2的幂次方。（其实就是按位“与”的时候，每一位都能 &amp;1 ，也就是和1111……1111111进行与运算）</p><p>​    取模运算不用<code>hash%length</code>，而使用<code>(length-1)&amp;hash</code>，是因为<code>&amp;</code>采用二进制进行操作，比 <code>%</code> 的运算效率高。</p><p> “当容量一定是2^n时，h &amp; (length - 1) &#x3D;&#x3D; h % length” . 按位运算特别快 </p><p>对于length &#x3D; 16, 对应二进制”1 0000”, length-1&#x3D;”0 1111” </p><p>假设此时h &#x3D; 17 . </p><p>(1) 使用”h % length”, 也就是”17 % 16”, 结果是1 . </p><p>(2) 使用”h &amp; (length - 1)”, 也就是 “1 0001 &amp; 0 1111”, 结果也是1 . </p><p>我们会发现, 因为”0 1111”低位都是”1”, 进行”&amp;”操作, 就能成功保留”1 0001”对应的低位, 将高位的都丢弃, 低位是多少, 最后结果就是多少 . </p><p>刚好低位的范围是”0~15”, 刚好是长度为length&#x3D;16的所有索引 . </p><p> HashMap负载因子为什么是0.75</p><p>负载因子是和扩容机制有关的。扩容公式为：数组容量*负载因子&#x3D;扩容阈值。 当buckets数组达到阈值时，则会进行扩容操作。那么为什么在hashMap中不管是JDK7还是JDK8对于扩容因子都定义为0.75呢？</p><p>​    HashMap总的来说就是一个数据结构，那数据结构就是为了节省空间和时间。那负载因子的作用就是为了节省空间和时间的。</p><p>​    <strong>假设负载因子的值为1.0</strong>。那么结合扩容公式可知，当buckets桶数组全部用完之后才会进行扩容。因为在扩容时，hash冲突是无法避免的。因此当负载因子为1.0时，在进行扩容时，会出现更多的hash冲突，可能导致链表长度或红黑树高度会变得更长或更高，导致查询效率的降低。因此负载因子过大，虽然保证了空间，但牺牲了时间。</p><p>​    <strong>假设负载的值为0.5</strong>。那么结合扩容公式可知，当buckets数组使用一半时，就会触发扩容。因为数组中的元素少，所以出现hash冲突的几率也会变少，所以链表长度或者是红黑树的高度就会降低，从而提升了查询效率。但是这样的话，空间利用率又降低了。原本只要1M就能存储的数据，现在则需要2M。所以负载因子太小，虽然时间效率提升了，但是空间利用率降低了。</p><p> 为什么JDK8采用红黑树，而不采用平衡二叉树</p><p>因为平衡二叉树条件太苛刻了，需要一直进行整棵树的平衡进行左旋或右旋的操作，红黑树相对来讲调整的少点，只要达到黑平衡即可。并且红黑树对于节点的增删和查找效率都是较为中肯的。</p><p>为什么链表转红黑树的阈值是8</p><p>因为红黑树的平均查找长度是log(n)，长度为8的时候，平均查找长度为3，如果继续使用链表，平均查找长度为8&#x2F;2&#x3D;4，这才有转换为树的必要。链表长度如果是小于等于6，6&#x2F;2&#x3D;3，虽然速度也很快的，但是转化为树结构和生成树的时间并不会太短。因此8是一个较为合理的值。</p><p>为什么要用链地址法解决冲突</p><p>开放地址法:当冲突发生的时候，通过查找数组的一个空位，将数据插入进去，而不再用hash函数计算获取数的下标，这个方法就叫做开发地址法；</p><p>缺点：数据的长度是有限的，但我们可能会往数组里面添加很多数据进去，数组总有被填满的时候，那样开发地址法也不管用了</p><p>链地址法：第一次定位数组中的位置，第二次去到链表中，调用链表的查找方法进行查找</p><h2 id="ConcurrentHashMap"><a href="#ConcurrentHashMap" class="headerlink" title="ConcurrentHashMap"></a>ConcurrentHashMap</h2><p>ConcurrentHashMap是一个线程安全且高效的HashMap。在并发下，推荐使用其替换HashMap。对于它的使用也非常的简单，除了提供了线程安全的get和put之外，它还提供了一个非常有用的方法<strong>putIfAbsent</strong>，如果传入的键值对已经存在，则返回存在的value，不进行替换； 如果不存在，则添加键值对，返回null。</p><h3 id="JDK7的ConcurrentHashMap"><a href="#JDK7的ConcurrentHashMap" class="headerlink" title="JDK7的ConcurrentHashMap"></a>JDK7的ConcurrentHashMap</h3><p>基础结构</p><p>![next  Segment<a href="%E9%9B%86%E5%90%88/clip_image014.gif">OJ  Segment[l ]  Segment[2]  Segment[3]  Segment[4]  Segment[14]  Segment[15]  next  next  next  next  next </a></p><p>一个ConcurrentHashMap里包含一个Segment数组，结构与HashMap类似（数组+链表）。一个Segment中包含一个HashEntry数组，每个HashEntry就是链表的元素。</p><p>​    Segment是ConcurrentHashMap实现的很核心的存在，Segment翻译过来就是一段，一般把它称之为<strong>分段锁</strong>。它继承了ReentrantLock，在ConcurrentHashMap中相当于锁的角色，在多线程下，不同的线程操作不同的segment。只要锁住一个 segment，其他剩余的Segment依然可以操作。这样只要保证每个 Segment 是线程安全的，我们就实现了全局的线程安全。</p><p>构造方法和初始化</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image016.gif" class="" title="* Creates a new, empty map with a default initial capacity (16),  * toad factor (0.75) and concurrencyLevet (16) .  public ConcurrentHashMap() {"><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image018.gif" class="" title="public ConcurrentHashMap(int initiatCapacity,  float toadFactor, int concurrencyLevet) {  if (toadFactor &gt; O) Il initiatCapacity &lt; @ Il concurrencyLevet O)"><p>​    根据其构造函数可知，map的容量默认为16，负载因子为0.75。这两个都与原HashMap相同，但不同的在于，其多个参数**concurrencyLevel(<strong><strong>并发级别</strong></strong>)**，通过该参数可以用来确定Segment数组的长度并且不允许扩容，默认为16。</p><p>​    并发度设置过小会带来严重的锁竞争问题；如果过大，原本位于一个segment内的访问会扩散到不同的segment中，导致查询命中率降低，引起性能下降。</p><p>get()</p><p>1）根据key计算出对应的segment</p><p>2）获取segment下的HashEntry数组</p><p>3）遍历获取每一个HashEntry进行比对。</p><p>注意：整个get过程没有加锁，而是通过volatile保证可以拿到最新值。</p><p>put()</p><p>初始化segment，因为ConcurrentHashMap初始化时只会初始化segment[0]，对于其他的segment，在插入第一个值的时候再进行初始化。经过计算后，将对应的segment完成初始</p><p>化。</p><p>向下调用ensureSegment方法，其内部可以通过cas保证线程安全（初始化的时候保证初始化线程安全），让多线程下只有一个线程可以成功。</p><p>在put方法中当初始化完Segment后，会调用一个put的重载方法进行键值对存放。首先会调用tryLock()尝试获取锁，node为null进入到后续流程进行键值对存放；如果没有获取到锁，则调用scanAndLockForPut()自旋等待获得锁。</p><p>在scanAndLockForPut()方法中首先会根据链表进行遍历，如果遍历完毕仍然找不到与key相同的HashEntry，则提前创建一个HashEntry。当tryLock一定次数后仍然无法获得锁，则主动通过lock申请锁。</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image020.jpg" class="" title="void lock 0  茯 得 锁 。  如 果 锁 不 可 用 ， 则 当 前 线 程 将 辇 拜 以 进 行 线 程 度 ， # 处 于 休 眠 状 态 ， 直 到 获 取 锁 。"><p>在获得锁后，segment对链表进行遍历，如果某个 HashEntry 节点具有相同的 key，则更新该 HashEntry 的 value 值，否则新建一个节点将其插入链表头部。</p><p>如果节点总数超过阈值，则调用rehash()进行扩容。</p><h3 id="JDK8的ConcurrentHashMap"><a href="#JDK8的ConcurrentHashMap" class="headerlink" title="JDK8的ConcurrentHashMap"></a>JDK8的ConcurrentHashMap</h3><p>与JDK7的区别</p><p>​    在JDK1.8中对于ConcurrentHashMap也进行了升级，主要优化点如下：</p><p>1）JDK7中使用CAS+Reentrant（CAS用于初始化segment时，Reentrant用于锁定segment）保证并发更新的安全，而在JDK8是通过CAS+synchronized保证。因为synchronized拥有了优化，在低粒度加锁下，synchronized并不比Reentrant差；在大量数据操作下，对于JVM的内存压力，基于API的ReentrantLock会开销更多的内存。</p><p>2）JDK7的底层使用segment+数组+链表组成。而在JDK8中抛弃了segment，转而使用数组+链表+红黑树的形式实现，从而让锁的粒度能够更细，进一步减少并发冲突的概率；同时也提高的数据查询效率。</p><p>3）在JDK7中的HashEntry在JDK8中变为Node，当转化为红黑树后，变为TreeNode。转换的规则与hashMap相同，当链表长度大于等于8则转换为红黑树，当红黑树的深度小于等于6则转换为链表。</p><p>核心属性</p><p>Node类：用于存储键值对。其与JDK7中的HashEntry属性基本相同。</p><p>TreeNode类：树节点类，当链表长度大于等于8，则转换为TreeNode。与hashMap不同的地方在于，它并不是直接转换为红黑树，而是把这些节点放在TreeBin对象中，由TreeBin完成红黑树的包装。</p><p>TreeBin类：负责TreeNode节点包装，它代替了TreeNode的根节点，也就是说在实际的数组中存放的是TreeBin对象，而不是TreeNode对象。</p><p>sizeCtl属性：用于控制table的初始化和扩容。-1表示正在初始化，-N表示由N-1个线程正在进行扩容，0为默认值表示table还没被初始化，正数表示初始化大小或Map中的元素达到这个数量时，则需要扩容了。</p><p>get()</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image022.gif" class="" title="public V get(Object key) {  Node&lt;K, tab; Node&lt;K,V&gt; e, p; int n, eh; K ek;  &#x3D; spread(key . hashCode()) ; itÄhashfÄ  int h  tab. length) &gt; @ fifihash{ÄfiäküN  if ( (tab  &#x3D; table) (n &#x3D;  (e &#x3D; tabAt(tab,  i" alt="(n - 1) &amp; h)) null) {  if ( (eh  &#x3D; e. hash)  if ( (ek  -z key Il (ek !&#x3D; null &amp;&amp; key . equals(ek)))  return e. vat;  else if (eh &lt; O)  return (p  &#x3D; e. find(h, key)) !&#x3D; null ? p. vat : null;  _ &#x3D; e.next) null) {  while ( (e  if (e. hash h &amp;&amp;  return e. vat;  return null;  -z key Il (ek !&#x3D; null &amp;&amp; key . equals(ek))))"><p>put()</p><p>如果table为空，初始化table</p><p>如果table不为空，但是没有元素，通过CAS向Node数组中存值</p><p>若扩容操作，当前线程协助扩容</p><p>如果table不为空，且有元素，基于synchronized锁住数组中的元素</p><p>与hashTable的区别</p><p>​    Hashtable的任何操作都会把整个表锁住，是阻塞的。好处是总能获取最实时的更新，比如说线程A调用putAll写入大量数据，期间线程B调用get，线程B就会被阻塞，直到线程A完成putAll，因此线程B肯定能获取到线程A写入的完整数据。坏处是所有调用都要排队，竞争越激烈效率越低。 更注重安全。</p><p>​    ConcurrentHashMap 是设计为非阻塞的。在更新时会局部锁住某部分数据，但不会把整个表都锁住。同步读取操作则是完全非阻塞的。好处是在保证合理的同步前提下，效率很高。坏处 是严格来说读取操作不能保证反映最近的更新。例如线程A调用putAll写入大量数据，期间线程B调用get，则只能get到目前为止已经顺利插入的部分数据。更注重性能。</p><h2 id="ArrayList"><a href="#ArrayList" class="headerlink" title="ArrayList"></a>ArrayList</h2><p>ArrayList概述</p><p>1）ArrayList是可以动态增长和缩减的索引序列，它<strong>是基于数组实现</strong>的List类。</p><p>2）该类封装了一个动态再分配的Object[]数组，每一个类对象都有一个capacity属性，表示</p><p>它们所封装的Object[]数组的长度，当向ArrayList中添加元素时，该属性值会自动增加。</p><p>3）ArrayList的用法和Vector向类似，但是Vector是一个较老的集合，具有很多缺点，不建</p><p>议使用。</p><p>另外，ArrayList和Vector的区别是：ArrayList是线程不安全的，当多条线程访问同一个ArrayList集合时，程序需要手动保证该集合的同步性，而Vector则是线程安全的。</p><p>4）ArrayList和Collection的关系：</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image024.gif" class="" title="LteraL0r I  {List Iteratorl  LCoIIectionl  List I  AbstractL ist  ArrayList  AbstraetColleetion"><p>数据结构</p><p>底层的数据结构就是数组，数组元素类型为Object类型，即可以存放所有类型数据。我们对ArrayList类的实例的所有的操作底层都是基于数组的。</p><p>常用方法：</p><p>get方法</p><p>由于底层是数组实现的，先检查下索引是否越界，然后直接返回对应索引位置的元素即可。</p><p>set方法</p><p>校验索引是否越界</p><p>根据index获取指定位置的元素</p><p>用传入的element替换index位置的元素</p><p>返回index位置原来的元素</p><p>add(E e)：</p><p>调用ensureCapacityInternal方法（下文有详解），如果数组还没初始化，则进行初始化；如果已经初始化了，则将modCount+1（统计计算了多少次），并校验添加元素后是否需要扩容。</p><p>在elementData数组尾部添加元素即可（size位置）。</p><p>add(int index, E element)：</p><p>检查索引是否越界，再调用ensureCapacityInternal方法，将modCount+1，并校验添加元素后是否需要扩容。</p><p>将index位置及之后的所有元素向右移动一个位置（为要添加的元素腾出1个位置）。</p><p>将index位置设置为element元素，并将size+1。</p><p>remove(int index)：</p><p>检查索引是否越界，将modCount+1，拿到索引位置index的原元素。</p><p>计算需要移动的元素个数。</p><p>如果需要移动，将index+1位置及之后的所有元素，向左移动一个位置。</p><p>将size-1位置的元素赋值为空（因为上面将元素左移了，所以size-1位置的元素为重复的，将其移除）。</p><p>remove(Object o)：</p><p>如果入参元素为空，则遍历数组查找是否存在元素为空，如果存在则调用fastRemove将该元素移除，并返回true表示移除成功。</p><p>如果入参元素不为空，则遍历数组查找是否存在元素与入参元素使用equals比较返回true，如果存在则调用fastRemove将该元素移除，并返回true表示移除成功。</p><p>否则，不存在目标元素，则返回false。</p><p>fastRemove(int index)：跟remove(int index)类似</p><p>将modCount+1，并计算需要移动的元素个数。</p><p>如果需要移动，将index+1位置及之后的所有元素，向左移动一个位置。</p><p>将size-1位置的元素赋值为空（因为上面将元素左移了，所以size-1位置的元素为重复的，将其移除）</p><p>clear方法</p><p>遍历数组将所有元素清空即可。</p><p>ArrayList动态扩容的全过程。</p><p>如果通过无参构造的话，初始数组容量为0，当真正对数组进行添加时，才真正分配容量。每次按照1.5倍（位运算）的比率通过copeOf的方式扩容。 在JKD1.6中实现是，如果通过无参构造的话，初始数组容量为10，每次通过copeOf的方式扩容后容量为原来的1.5倍</p><p>例如：数组长度为10，有20个数据要添加，在第10个添加完之后，添加第11个数</p><p>时，数组扩容为15（101.5），当添加第16个数时，数组扩容为22（151.5）</p><p>（原数组长度为0，则扩容后为10，minCapacity为10）</p><p>有参构造直接就是容量，传进5，创建容量为5的数组</p><p>（原数组长度为1，则扩容后为2，minCapacity为2）</p><p>（原数组长度为4，则扩容后为6，minCapacity为5）</p><p>补充：</p><p>Arrays.copyOf()方法返回的数组是新的数组对象，原数组对象仍是原数组对象，不变，该拷贝不会影响原来的数组。copyOf()的第二个自变量指定要建立的新数组长度，如果新数组的长度超过原数组的长度，则保留数组默认值.</p><h2 id="LinkedList"><a href="#LinkedList" class="headerlink" title="LinkedList"></a>LinkedList</h2><p>链表和数组对比</p><table><thead><tr><th></th><th><strong>数组</strong></th><th><strong>链表</strong></th></tr></thead><tbody><tr><td>内存地址</td><td>连续的内存空间</td><td>非连续的内存空间</td></tr><tr><td>数据长度</td><td>长度固定，一般不可动态扩容</td><td>长度可动态变化</td></tr><tr><td>增删效率</td><td>低，需要移动被修改元素之后的所有元素</td><td>高，只需要修改指针指向</td></tr><tr><td>查询效率</td><td>高，可用过数组名和下标直接访问</td><td>低，只能通过遍历节点依次查询</td></tr><tr><td>数据访问方式</td><td>随机访问</td><td>顺序访问</td></tr></tbody></table><p>数据结构</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image026.gif" class="" title="first  last"><p>LinkedList底层使用的双向链表结构，有一个头结点和一个尾结点，双向链表意味着我们可以从头开始正向遍历，或者是从尾开始逆向遍历，并且可以针对头部和尾部进行相应的操作。</p><p>特性</p><p>　1）异步，也就是非线程安全</p><p>　2）双向链表。由于实现了list和Deque接口，能够当作队列来使用。</p><p>　　链表：查询效率不高，但是插入和删除这种操作性能好。</p><p>　3）是顺序存取结构</p><p>类的属性</p><p>LinkedList：一个头结点、一个尾结点、一个表示链表中实际元素个数的变量。</p><p>构造方法</p><p>1）空参构造函数</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image028.jpg" class="" title="Constructs an empty list.  public LinkedList() {"><p>2）有参构造函数</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image030.jpg" class="" title="&#x2F; c cp inked Li stij*_ 0  public LinkedList(C011ection&lt;? extends E&gt; c) {  this();  addA11 (c) ;"><p>内部类（Node）</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image032.jpg" class="" title="／ ／ 根 据 前 面 介 绍 双 向 涟 表 就 知 道 这 个 代 表 什 么 了 ， linked List 的 奥 秘 就 在 这 里 c  private static Class Node&lt;E&gt; {  E item; ／ &#x2F; 据 域 （ 当 前 壭 点 的 值 ）  Node&lt;E &gt; next; &#x2F; &#x2F; 后 组 （ 指 向 当 前 一 个 壭 点 的 后 一 个 壭 点 ）  Node&lt;E &gt; prev; &#x2F; &#x2F; 前 （ 指 向 当 前 壭 点 的 前 一 个 壭 点 ）  ／ &#x2F; 构 造 函 i, 赋 值 前 后 组  Node(Node&lt;E&gt; prev, E element,  Node&lt;E&gt; next) {  this  this  this  ． Item  ． next  element;  n ext ．  prev;"><p>说明：内部类Node就是实际的结点，用于存放实际元素的地方。　</p><p> 核心方法</p><p>1 add函数用于向LinkedList中添加一个元素，并且添加到链表尾部。具体添加到尾部的逻辑是由linkLast函数完成的。</p><p>LinkLast()：判断是不是一开始链表中就什么都没有，如果没有，则newNode就成为了第一个节点，first和last都要指向它。正常的在最后一个节点后追加，那么原先的最后一个节点的next就要指向现在真正的最后一个节点，原先的最后一个节点就变成了倒数第二个节点。</p><p>2 remove(Object o)：我们可以知道，如果我们要移除的值在链表中存在多个一样的值，那么我们会移除index最小的那个，也就是最先找到的那个值，如果不存在这个值，那么什么也不做</p><p>3 get(index)：这里查询使用的是先从中间分一半查找：判断index在前半部分还是后半部分，若在前半部分，则遍历前半部分即可</p><p>4 indexOf(Object o)：遍历查找</p><p>总结</p><p>1）linkedList本质上是一个双向链表，通过一个Node内部类实现的这种链表结构。</p><p>2）能存储null值 </p><p>3）跟arrayList相比较，就真正的知道了，LinkedList在删除和增加等操作上性能好，而ArrayList在查询的性能上好</p><p> 4）从源码中看，它不存在容量不足的情况</p><p> 5）linkedList不光能够向前迭代，还能像后迭代，并且在迭代的过程中，可以修改值、添加值、还能移除值。 </p><p>6）linkedList不光能当链表，还能当队列使用，这个就是因为实现了Deque接口。</p><h2 id="Stack"><a href="#Stack" class="headerlink" title="Stack"></a>Stack</h2><p>Stack是栈。它的特性是：先进后出(FILO, First In Last Out)。java工具包中的Stack是继承于Vector(矢量队列)的，由于Vector是通过数组实现的，这就意味着，Stack也是通过数组实现的，而非链表。当然，我们也可以将LinkedList当作栈来使用。</p><p>Push()</p><p>pop()</p><p>peek()</p><p>empty()</p><p>search(Object o)：查找“元素o”在栈中的位置：由栈底向栈顶方向数</p><h2 id="队列-优先队列"><a href="#队列-优先队列" class="headerlink" title="队列_优先队列"></a>队列_优先队列</h2><p>队列是一种先进先出的数据结构。</p><p>优先队列（Priority Queue）</p><p>优先队列与普通队列的区别：普通队列遵循先进先出的原则；优先队列的出队顺序与入队顺序无关，与优先级相关。</p><p>优先队列可以使用队列的接口，只是在实现接口时，与普通队列有两处区别，一处在于优先队列出队的元素应该是优先级最高的元素，另一处在于队首元素也是优先级最高的元素。</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image034.jpg" class="" title="优 先 阝 人 列 也 可 以 使 不 同 的 底 层 实 现 ， 不 同 底 层 实 现 时 间 复 杂 度 如 下 ：  优 先 队 列  普 通 线 性 结 构  顺 序 线 性 结 构  堆  入 队  0 （ 1 ）  O(n)  O(logn)  出 队 （ 拿 出 最 大 元 素 ）  O(n)  0(1)  O(logn)"><h2 id="树"><a href="#树" class="headerlink" title="树"></a>树</h2><p>二叉树、二叉搜索树、平衡二叉树、红黑树、B树、B+树</p><p>平衡二叉树：左右子树的高度相差不超过1的树。</p><p>平衡因子：某节点的左子树与右子树的高度(深度)差即为该节点的平衡因子（BF,Balance Factor），平衡二叉树中不存在平衡因子大于1的节点。在一棵平衡二叉树中，节点的平衡</p><p>因子只能取-1、1或者0。</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image036.jpg" class="" title="强 平 衡 二 叉 树 和 弱 平 衡 二 叉 树 有 什 么 区 别  强 平 衡 二 叉 树 AVL 树 。 弱 平 衡 二 叉 树 就 是 我 们 说 的 红 黑 树 ．  1 攣 VL 树 I 黑 树 对 于 平 衡 的 裎 度 更 加 严 格 。 在 相 同 点 的 肯 兄 下 ， AVL 树 的 高 度 低 于 红 黑 树  艺 红 黑 树 中 增 加 了 一 十 点 颜 色 的 念  工 AVL 树 的 旋 转 悍 作 上 红 甲 树 的 旋 转 悍 作 更 耗 时"><p>红黑树：</p><p>是树的数据结构中最为重要的一种。Java的容器TreeSet、TreeMap均使用红黑树实现。JDK1.8中HashMap中也加入了红黑树。每个节点都带有颜色属性，颜色为<strong>红色</strong>或<strong>黑色</strong>。除了二叉查找树一般要求以外，对于任何有效的红黑树还增加了如下的额外要求:</p><p>1）节点要么是黑色要么是红色。</p><p>2）根结点一定是黑色的。</p><p>3）每个叶子节点都带有两个空(NIL)的黑色节点。</p><p>4）每个红色节点的两个子节点一定是黑色，因此不会存在两个连续的红色节点，红色节</p><p>点的父节点一定是黑色节点。</p><p>5）从任一节点到它所能到达的叶子节点的所有路径都包含相同数目的黑色节点。从而达到黑色平衡。（平衡二叉树是一个完美平衡的树，红黑树是非完美平衡树，但是一个完美</p><p>的黑色平衡二叉查找树）。实现了【树的层数最大也只会有两倍的差距】</p><p>B树：</p><p>意义：数据量是远大于内存大小的，那我们在查找数据时并不能将全部数据同时加载至内存。既然不能全部加载至内存中就只能逐步的去加载磁盘中某个页，简而言之就是逐一的去加载磁盘，加数据分块的加载至内存进行查找与比较。</p><p>通过查找过程可以看出，磁盘IO次数与树的高度相关，在最坏情况下，磁盘IO次数等于树的高度。由于磁盘IO过程是相对耗时效率较低的，因此，在设计数据存储结构时需要降低树的高度，即将一棵“瘦高”的树变得“矮胖”。     当数据数目相同，在保持有序前提下，降低树高度，只需将节点中存储的key值增加，即二叉搜索树中每个节点只有一个数据元素，而在B树中每个节点可以有多个数据元素。</p><p>定义：</p><p>B树也成B-树。它是一颗多路平衡查找树（所有的叶子节点拥有相同的高度）。当描述一颗B树时需要指定它的<strong>阶数</strong>，阶数表示一个节点最多有多少个孩子节点，一般用字母</p><p>m表示。当m取2时，就是一颗二叉查找树。</p><p>要定义一颗m阶的B树，需要遵循以下五条原则：</p><p>1）根节点最少可以只有一个元素，且至少要有两个子节点。</p><p>2）每个节点最多有m-1个元素。</p><p>3）非根节点至少有(m&#x2F;2)-1个元素。m&#x2F;2要进行向上取整，如m&#x2F;2&#x3D;1.5&#x3D;2。</p><p>4）每个结点中的元素都按照从小到大的顺序排列，每个元素的左子树中的所有元素都小</p><p>于它，而右子树中的所有元素都大于它。</p><p>5）所有叶子节点都位于同一层，相当于根节点到每个叶子节点的长度相同。</p><p>查找：B树的查找其实是对二叉搜索树查找的扩展， 与二叉搜索树不同的地方是，B-树中每个节点有不止一棵子树。在B-树中查找某个结点时，需要先判断要查找的结点在哪棵子树上，然后在结点中逐个查找目标结点。B树的查找过程相对简单，与二叉搜索树类似，</p><p>因此不再赘述。</p><p>插入：</p><p>​    B树的插入操作是指在树种插入一条新记录，即（key, value）的键值对。如果B树中已存在需要插入的键值对，则用需要插入的value替换旧的value。若B树不存在这个</p><p>key，则一定是在叶子结点中进行插入操作。</p><p>插入流程如下：</p><p>1）根据要插入的key的值，对B树执行查找操作，查找到待插入数据的当前节点位置。</p><p>2）判断<strong>当前节点key的个数是否小于等于m-1</strong>，若满足，则直接插入数据。</p><p>3）若不满足，以<strong>节点中间的key</strong>为中心分裂成<strong>左右两部分</strong>，然后将这个<strong>中间的key插入到父节点中</strong>，这个key的左子树指向分裂后的左半部分，这个key的右子树指向分</p><p>裂后的右半部分，然后将当前节点指向父节点，继续执行第三步。</p><p>删除</p><p>1）如果当前需要删除的key位于非叶子结点，则用距离最近的后继key覆盖要删除的key。然后在后继key所在的子支中删除该后继key。此时后继key一定位于叶子节点上，这个过程和二叉搜索树删除节点的方式类似。</p><p>2）删除这个记录后，若<strong>该节点key个数大于等于(m&#x2F;2)-1</strong>，结束删除操作。</p><p>3）如果不是，则<strong>如果兄弟节点key个数大于(m&#x2F;2)-1</strong>，则父节点中的key下移到该节</p><p>点，兄弟节点中的一个key上移，删除操作结束。</p><p>4）否则，将父节点中的key下移与当前节点及它的兄弟节点中的key合并，形成一个新的节点。原父节点中的key的两个孩子指针就变成了一个孩子指针，指向这个新节点。然后</p><p>当前节点的指针指向父节点，重复步骤2。</p><p>B+树</p><p>定义</p><p>1）B+树包含2种类型的结点：内部结点（也称索引结点）和叶子结点。</p><p>2）根结点本身即可以是内部结点，也可以是叶子结点。根结点的关键字个数最少可以只</p><p>有1个。</p><p>3）B+树与B树最大的不同是内部结点不保存数据，只用于索引，所有数据（或者说记录</p><p>）都保存在叶子结点中。</p><p>4） m阶B+树表示了<strong>内部结点最多有m-1个关键字</strong>，阶数m同时限制了**叶子结点最多</p><p>存储m-1个数据。</p><p>5）内部结点中的key都按照从小到大的顺序排列，对于内部结点中的一个key，左树中的所有key都小于它，右子树中的key都大于等于它。叶子结点中的数据也按照key的大小排列。</p><p>6）<strong>每个叶子结点都存有相邻叶子结点的指针</strong>，叶子结点本身依关键字的大小自小而</p><p>大顺序链接。</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image038.gif" class="" title="索 引 节 点 ， 只 含 有 key  不 含 数 *Édata  ta data d  叶 子 节 点 ，  含 有 key ， 又  含 有 数 *Édata  根 节 点 ， 可 以 有 一 个 key  叶 子 节 点 采 用  链 表 形 式 链 接  data d"><p>特点</p><p>1）索引节点的key值均会出现在叶子节点中。</p><p>2）索引节点中的key值在叶子节点中或者为最大值或者为最小值。</p><p>3）叶子节点使用单链表的形式链接起来。</p><p>性能分析</p><p><strong>查找性能</strong></p><p> 1）在相同数量的待查数据下，B+树查找过程中需要调用的磁盘IO操作要少于普通B-树。由于B+树所在的磁盘存储背景下，因此B+树的查找性能要好于B-树。 </p><p> 2）B+树的查找效率更加稳定，因为所有叶子结点都处于同一层中，而且查找所有关键字都必须走完从根结点到叶子结点的全部历程。因此同一颗B+树中，任何关键字的查找比较次数都是一样的。而B树的查找是不稳定的。 </p><p><strong>插入性能</strong></p><p>  B+树的插入过程与B树类似，性能也基本一致。</p><p><strong>删除性能</strong></p><p>  删除性能与B树也基本一致。</p><p> 面试题：</p><p>hashmap为什么使用红黑树而不用别的树</p><p>​    红黑树是一个比较特殊的树，跟他能产生对比的是平衡二叉树。但是平衡二叉树的严格平衡牺牲了插入、删除操作的性能，来保证了查询的高效。 而红黑树则采用了折中策略，即不牺牲太大的插入删除性能，同时又保证稳定高效的查找效率。（查找性能都是logn）</p><p>为什么MongoDB索引使用B树，而MySQL使用B+树</p><p>​    MongoDB是一个非关系型数据库，对于遍历数据的需求很低，更多的是在做一些单一记录查询。而对于MySQL这种关系型数据库来说，进行遍历关联查询的需求就会很高。</p><p>​    结合B树与B+树的特点来说，B树的查询效率不固定，最好的情况是O（1），所以在做单一数据查询时，B树的平均性能会更好。但如果要对B树进行遍历的话，由于各个节点间没有指针相连，所以性能会很低。</p><p>​    而B+树最大的特点是数据只会出现在叶子节点，因此对于单条数据查询，其一定会进入到叶子节点上，因此平均性能没有B树好。但B+树的叶子节点有指针相连，在进行遍历时，其效率会明显优于B树。</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image040.jpg" class="" title="B 树 和 B + 树 的 区 别 ， 为 什 么 Mysq 用 B + 树  8 树 的 待 点  节 点 排 序  艺 一 个 节 点 了 可 以 存 多 个 元 累 。 多 个 几 索 也 啡 序 了  B + 树 的 点 ：  1. 拥 有 B 树 的 恃 点  艺 叶 了 节 点 之 间 有 指 针  3 ， 菲 叶 了 节 点 上 的 元 哀 在 叶 了 节 白 上 都 冗 厼 了 ， 也 就 是 叶 了 节 点 中 存 了 所 有 的 元 索 ， 并 排 好 顺 序  Mysq 引 使 的 是 “ 树 ， 因 为 索 引 是 用 来 加 快 虫 的 ， 而 8 + 树 通 过 对 庭 进 行 排 所 以 是 可 以 高 虫 词 速 度 ， 然 尸 通 过 一 个 节 中 可 以 存 储 多 个 元 索 ， 从 而 可 以 使 得 8 + 树  的 高 度 不 会 太 高 ， 在 My 蝈 中 一 nn 。 北 页 就 是 一 个 树 节 点 ， —Olnnodb 页 默 认 16kb, 所 以 一 般 兄 下 一 层 的 “ 树 可 以 存 20 閬 万 行 左 右 的 數 ， 然 后 河 过 利 “ 树 叶  子 点 存 储 了 所 有 庭 并 目 讲 行 了 排 序 ， 并 目 叶 子 点 之 间 有 老 针 ， 可 以 很 好 的 支 持 全 轰 闩 描 ， 范 围 找 SQL 句"><h2 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h2><p>堆通常是一个可以被看做一棵树的数组对象。堆的具体实现一般不通过指针域，而是通过构建一个一维数组与二叉树的父子结点进行对应，因此堆总是一颗完全二叉树。</p><p>对于任意一个父节点的序号n来说（这里n从0算），它的子节点的序号一定是2n+1，2n+2，因此可以直接用数组来表示一个堆。</p><p>不仅如此，堆还有一个性质：堆中某个节点的值总是不大于或不小于其父节点的值。将根节点最大的堆叫做最大堆或<strong>大根堆</strong>，根节点最小的堆叫做最小堆或<strong>小根堆</strong>。</p><p>LinkedHashMap </p><p>众所周知 <a href="https://github.com/crossoverJie/Java-Interview/blob/master/MD/HashMap.md">HashMap</a> 是一个无序的 Map，因为每次根据 key 的 hashcode 映射到 Entry 数组上，所以遍历出来的顺序并不是写入的顺序。</p><p>因此 JDK 推出一个基于 HashMap 但具有顺序的 LinkedHashMap 来解决有排序需求的场景。</p><p>它的底层是继承于 HashMap 实现的，由一个双向链表所构成。</p><p>LinkedHashMap 的排序方式有两种：</p><ul><li>根据写入顺序排序。</li><li>根据访问顺序排序。</li></ul><p>其中根据访问顺序排序时，每次 get 都会将访问的值移动到链表末尾，这样重复操作就能的到一个按照访问顺序排序的链表。</p><p><a href="https://crossoverjie.top/2018/02/06/LinkedHashMap/">https://crossoverjie.top/2018/02/06/LinkedHashMap/</a></p><p><a href="https://www.imooc.com/article/23169">https://www.imooc.com/article/23169</a></p><h2 id="Collection集合和Map集合总结"><a href="#Collection集合和Map集合总结" class="headerlink" title="Collection集合和Map集合总结"></a>Collection集合和Map集合总结</h2><p>主要有两大接口，分别是Collection和Map。其中List、Set、Queue实现了Collection接口。</p><p>List</p><p>ArrayList</p><p>LinkedList</p><p>Set</p><p>HashSet</p><p>TreeSet：保持元素的顺序可以用</p><p>Queue</p><p>先进先出</p><p>Map</p><p><strong>1.HashMap</strong>作为Map的主要实现类，线程不安全的，效率高，可以存储null的key和value。</p><p>HashMap底层：数组和链表（jdk7）数组，链表和红黑树（jdk8）</p><p>2.ConcurrentHashMap</p><p>3.LinkedHashMap:是HashMap的子类，保证在遍历map元素时，可以按照添加的顺序实现遍历，对于频繁的遍历操作，它的执行效率高于HashMap. linkedHashMap最大的特点在于有序，但是它的有序主要体现在先进先出FIFIO上。</p><p>​     原因：在原有的HashMap底层结构的基础上，添加了一对指针，指向前一个和后一个元素（双向链表）。</p><p>4.TreeMap:保证按照添加的key-value对进行排序，实现排序遍历，此时考虑key的自然排序或者定制排序。底层使用红黑树，向TreeMap中添加key-value对，要求key必须是由同一个类创建的对象，因为是按照key进行排序的。</p><p>5.Hashtable作为古老的实现类，线程安全，效率低，不可以存储null的key和value。底层都使用哈希表结构，查询速度快。</p><p>6.Properties:是Hashtable的子类，常用来处理配置文件。key和value都是String类型的。</p><p><a href="https://blog.csdn.net/Colton_Null/article/details/80469277">https://blog.csdn.net/Colton_Null/article/details/80469277</a>  集合</p><p><a href="https://blog.csdn.net/qq_30683329/article/details/80455779">https://blog.csdn.net/qq_30683329/article/details/80455779</a> map</p><h2 id="图"><a href="#图" class="headerlink" title="图"></a>图</h2><p>最小生成树：prim，克鲁斯卡尔</p><p>最短路径：迪杰斯特拉，弗洛伊德</p><p>拓扑排序</p><p>prim：加点：从V1出发，到V3最小，为1，将v3加入集合</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image042.jpg" class="" title="%ü.wmv  最 小 代 价 生 成 树  口 普 里 姆 算 法 求 最 小 生 成 树  的  的  步 骤  U  {VI }  { V2 ， V3 ， V4 ， Vs ， V6 }  （ 0 ）  的  的  亡 05 ： 45 以 ！ ） 洳 分 拿  标 记  〔 ℃ ： 02 ： 51 ／ 01 巧 6 ： 17"><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image044.jpg" class="" title="%ü.wmv  1  5  4  2  6  V2 5  6  6  (0)  (1)  (2)  (3)  (4)  {vvvvv)  {VI,V3) {V2 )  iES-X"><p>克鲁斯卡尔：加边：选一条最小的边加入</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image046.jpg" class="" title="%ü.wmv  最 小 代 价 生 成 树 （ 加 边 ）  口 克 鲁 斯 卡 尔 算 法 求 最 小 生 成 树  。 ： 傩 洞 ： 4 0 退 洳 分 拿  标 记  〔 ℃ :31 ： 49 ／ 01 巧 6 ： 17"><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image048.jpg" class="" title="%ü.wmv  最 小 代 价 生 成 树  」 克 鲁 斯 卡 尔 算 法 求 最 小 生 成 树  快 迸 ： 閬 :32 ： 30  。 ： 傩 為 以 ！ ） 洳 分 拿  标 记  〔 ℃ :32 ： 30 ／ 01 巧 6 ： 17"><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image050.jpg" class="" title="%ü.wmv  V2  5 · 1 （ 续 ） 拓 扑 排 序  7 ·  VO  V3  V6  囗 拓 扑 排 序 方 法 ：  1 ） 在 有 向 图 中 选 一 个 无 前 趋 的 顶 点 v ， 输 出 之 ；  2 ） 从 有 向 图 中 删 除 v 及 以 v 为 尾 的 弧 ；  3 ） 重 复 1) 、 2 ） ， 直 接 全 部 输 出 全 部 顶 点 或 有 向 图 中 不 存 在 无 前 趋 的 结 点  时 为 止 。  。 ： 傩 丷 ： 13 以 ！ ） 洳 分 拿  标 记  〔 ℃ ： 44 ． 18 ／ 01 巧 6 ： 17"><p>迪杰斯特阿拉：从V0出发，到各个点的最短路径</p><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image052.jpg" class="" title="%ü.wmv  迪 杰 斯 特 拉 算 法 （ Dijkstra ）  最 短 路 径 的 求 解 过 程  100  60  30  10  20  10  0 0 佣  ※ 以 为 源 点  。 ： 仇 ： 1 嗎 以 ！ ） 出 分 拿  01 ： 1 1 ： 53 ／ 01 巧 6 ： 17"><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image054.jpg" class="" title="%ü.wmv  ijkstr )  100  30  10  60  10  10  (vo,V2)  30  (vo,V4)  100  (vo,V5)  60  30  (vo,V4)  100  (vo,vÔ  60  (vo, V4,V5)  ô (Y i2täBä"><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image056.jpg" class="" title="Floyd 算 法 求 最 短 路 径  11  4  1 9  11  2  6  7  路 径 长 度  加 入 点 A  腼 入 陲 点 B  AC  AC  AB ABC  BC  CA CAB  伍 ） 路 径  (b) 路 径  伍 ） 路 径"><img src="/2024/04/05/%E9%9B%86%E5%90%88/clip_image058.jpg" class="" title="弟 七 节 ． wrn  F 丨 oyd 算 法 求 最 短 路 径  4  4  7 00  7 00  路 径 长 度  (a) 路 径 长 度  加 入 顶 点 C  AB ABC  CA CAB  以 0 ， 8 ℃ 0  5 ： 14 &#x2F; 仞 ： ： 1 不">]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> 集合 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java基础</title>
      <link href="/2024/03/24/java%E5%9F%BA%E7%A1%80/"/>
      <url>/2024/03/24/java%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h2 id="接口和抽象类的区别和相同点？"><a href="#接口和抽象类的区别和相同点？" class="headerlink" title="接口和抽象类的区别和相同点？"></a>接口和抽象类的区别和相同点？</h2><p>不同点：</p><p>1.类可以实现很多个接口，但是只能继承一个抽象类</p><p>2.Java接口中声明的变量默认都是final的。抽象类可以包含非final的变量。</p><p>3.接口中所有的方法隐含的都是抽象的。而抽象类则可以同时包含抽象和非抽象的方法。</p><p>4.Java接口中的成员函数默认是public的。抽象类的成员函数可以是private，protected或者是public。</p><p>相同点: </p><p>1.抽象类和接口都不能直接实例化，如果要实例化，抽象类变量必须指向实现所有抽象方法的子类对象，接口变量必须指向实现所有接口方法的类对象。 </p><p>2.抽象类里的抽象方法必须全部被子类所实现（若不是抽象方法则不用全部实现），如果子类不能全部实现父类抽象方法，那么该子类还只能是抽象类。同样，一个类实现接口的时候，如不能全部实现接口方法，那么该类也只能为抽象类。</p><p>扩展：对于一个final变量，如果是基本数据类型的变量，则其数值一旦在初始化之后便不能更改；如果是引用类型的变量，则在对其初始化之后便不能再让其指向另一个对象。</p><p>两种的使用场景：</p><p>abstract class在Java语言中体现的是一种继承关系，父类和派生类之间必须存在“is a”关系，即父类和派生类在概念本质上应该是相同的。对于interface 来说则不然，并不要求interface的实现者和interface定义在概念本质上是一致的，仅仅是实现了interface定义的契约而已。为了使论述便于理解，下面将通过一个简单的实例进行说明。</p><p>考虑这样一个例子，假设在我们的问题领域中有一个关于Door的抽象概念，该Door具有执行两个动作open和close，此时我们可以通过abstract class或者interface来定义一个表示该抽象概念的类型，其他具体的Door类型可以extends使用abstract class方式定义的Door或者implements使用interface方式定义的Door。看起来好像使用abstract class和interface没有大的区别。</p><p>如果现在要求Door还要具有报警的功能。我们该如何设计针对该例子的类结构呢），下面将罗列出可能的解决方案，并从设计理念层面对这些不同的方案进行分析。</p><p>解决方案一：</p><p>简单的在Door的定义中增加一个alarm方法，这种方法违反了面向对象设计中的一个核心原则ISP（Interface Segregation Priciple），在Door的定义中把Door概念本身固有的行为方法和另外一个概念“报警器“的行为方法混在了一起。这样引起的一个问题是那些仅仅依赖于Door这个概念的模块会因为“报警器“这个概念的改变（比如：修改alarm方法的参数）而改变。</p><p>解决方案二：</p><p>既然open、close和alarm属于两个不同的概念，根据ISP原则应该把它们分别定义在代表这两个概念的抽象类中。定义方式有：这两个概念都使用abstract class方式定义；两个概念都使用interface方式定义；一个概念使用abstract class方式定义，另一个概念使用interface方式定义。</p><p>显然，由于Java语言不支持多重继承，所以两个概念都使用abstract class方式定义是不可行的。后面两种方式都是可行的，但是对于它们的选择却反映出对于问题领域中的概念本质的理解、对于设计意图的反映是否正确、合理。</p><p>如果两个概念都使用interface方式来定义，那么就反映出两个问题：1、我们可能没有理解清楚问题领域，AlarmDoor在概念本质上到底是Door还是报警器？2、如果我们对于问题领域的理解没有问题，比如：我们通过对于问题领域的分析发现AlarmDoor在概念本质上和Door是一致的，那么我们在实现时就没有能够正确的揭示我们的设计意图，因为在这两个概念的定义上（均使用interface方式定义）反映不出上述含义。</p><p>如果我们对于问题领域的理解是：AlarmDoor在概念本质上是Door，同时它有具有报警的功能。我们该如何来设计、实现来明确的反映出我们的意思呢？前面已经说过，abstract class在Java语言中表示一种继承关系，而继承关系在本质上是“is a”关系。所以对于Door这个概念，我们应该使用abstarct class方式来定义。另外，AlarmDoor又具有报警功能，说明它又能够完成报警概念中定义的行为，所以报警概念可以通过interface方式定义。</p><p>这种实现方式基本上能够明确的反映出我们对于问题领域的理解，正确的揭示我们的设计意图。其实abstract class表示的是“is a”关系，interface表示的是“like a”关系，大家在选择时可以作为一个依据，当然这是建立在对问题领域的理解上的，比如：如果我们认为AlarmDoor在概念本质上是报警器，同时又具有Door的功能，那么上述的定义方式就要反过来了。</p><p>具体参考： <a href="https://cloud.tencent.com/developer/article/1434229">https://cloud.tencent.com/developer/article/1434229</a></p><h2 id="经典排序算法"><a href="#经典排序算法" class="headerlink" title="经典排序算法"></a>经典排序算法</h2><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image002.jpg" class="" title="img"><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image004.gif" class="" title="img"><p><a href="https://www.runoob.com/w3cnote/ten-sorting-algorithm.html">https://www.runoob.com/w3cnote/ten-sorting-algorithm.html</a></p><h2 id="HashMap-和-Hashtable-的区别"><a href="#HashMap-和-Hashtable-的区别" class="headerlink" title="HashMap 和 Hashtable 的区别"></a>HashMap 和 Hashtable 的区别</h2><ol><li><p>线程是否安全： HashMap 是⾮线程安全的， HashTable 是线程安全的,因为 HashTable 内部的⽅法基本都经过 synchronized 修饰。（如果你要保证线程安全的话就使⽤ConcurrentHashMap 吧！）； </p></li><li><p>效率： 因为线程安全的问题， HashMap 要⽐ HashTable 效率⾼⼀点。另外， HashTable 基本被淘汰，不要在代码中使⽤它； </p></li><li><p>对 <strong>Null key</strong> 和 <strong>Null value</strong> 的⽀持： HashMap 可以存储 null 的 key 和 value，但 null 作为 键只能有⼀个，null 作为值可以有多个；HashTable 不允许有 null 键和 null 值，否则会抛出 NullPointerException 。 </p></li><li><p>初始容量⼤⼩和每次扩充容量⼤⼩的不同 ： ① 创建时如果不指定容量初始值， Hashtable 默认的初始⼤⼩为 11，之后每次扩充，容量变为原来的 2n+1。 HashMap 默认的初始化⼤ ⼩为 16。之后每次扩充，容量变为原来的 2 倍。② 创建时如果给定了容量初始值，那么 Hashtable 会直接使⽤你给定的⼤⼩，⽽ HashMap 会将其扩充为 2 的幂次⽅⼤⼩ （ HashMap 中的 tableSizeFor() ⽅法保证，下⾯给出了源代码）。也就是说 HashMap 总是使⽤ 2 的幂作为哈希表的⼤⼩,后⾯会介绍到为什么是 2 的幂次⽅。 </p></li><li><p>底层数据结构： JDK1.8 以后的 HashMap 在解决哈希冲突时有了重⼤的变化，当链表⻓度⼤于阈值（默认为 8）（将链表转换成红⿊树前会判断，如果当前数组的⻓度⼩于 64，那么 会选择先进⾏数组扩容，⽽不是转换为红⿊树）时，将链表转化为红⿊树，以减少搜索时 间。Hashtable 没有这样的机制</p></li></ol><h2 id="关于JAVA中接口存在的意义"><a href="#关于JAVA中接口存在的意义" class="headerlink" title="关于JAVA中接口存在的意义"></a>关于JAVA中接口存在的意义</h2><p>1、重要性：在Java语言中， abstract class 和interface 是支持抽象类定义的两种机制。正是由于这两种机制的存在，才赋予了Java强大的 面向对象能力。</p><p>2、简单、规范性：如果一个项目比较庞大，那么就需要一个能理清所有业务的架构师来定义一些主要的接口，这些接口不仅告诉开发人员你需要实现那些业务，而且也将命名规范限制住了（防止一些开发人员随便命名导致别的程序员无法看明白）。</p><p>3、维护、拓展性：比如有一个类，实现了某个功能，突然有一天，发现这个类满足不了需求了，然后又要重新设计这个类，更糟糕是你可能要放弃这个类，那么其他地方可能有引用他，这样修改起来很麻烦。</p><p>   如果一开始定义一个接口，把功能放在接口里，然后定义类时实现这个接口，然后只要用这个接口去引用实现它的类就行了，以后要换的话只不过是引用另一个类而已，这样就达到维护、拓展的方便性。比如有个method1的方法，如果用接口，【接口名】 【对象名】&#x3D;new 【实现接口的类】，这样想用哪个类的对象就可以new哪个对象了，new a（）；就是用a的方法，new b（）就是用b的方法，就和USB接口一样，插什么读什么，就是这个原理。</p><p>你要做一个画板程序，其中里面有一个面板类，主要负责绘画功能，然后你就这样定义了这个类。</p><p>4、安全、严密性：接口是实现软件松耦合的重要手段，它描叙了系统对外的所有服务，而不涉及任何具体的实现细节。这样就比较安全、严密一些（一般软件服务商考虑的比较多，jdk中很多方法就是实现了某个接口）。</p><p> <strong>一. 对接口的三个疑问</strong> </p><p>很多初学者都大概清楚interface是1个什么, 我们可以定义1个接口, 然后在里面定义一两个常量(static final) 或抽象方法.然后以后写的类就可以实现这个接口, 重写里面的抽象方法. 很多人说接口通常跟多态性一起存在.接口的用法跟抽象类有点类似.但是为何要这么做呢.</p><p>1.为什么不直接在类里面写对应的方法, 而要多写1个接口(或抽象类)?</p><p>2.既然接口跟抽象类差不多, 什么情况下要用接口而不是抽象类.</p><p>3.为什么interface叫做接口呢? 跟一般范畴的接口例如usb接口, 显卡接口有什么联系呢?</p><p>答案：</p><p>1 需要实现多态</p><p>很明显, 接口其中一个存在意义就是为了实现多态.：农夫喂不同动物水</p><p>而抽象类(继承) 也可以实现多态</p><p>2.要实现的方法(功能)不是当前类族的必要(属性). 根本原因就是抽象类不能多继承</p><p>上面的例子就表明, 捕猎这个方法不是动物这个类必须的,</p><p>在动物的派生类（老虎需要，山羊不需要）中, 有些类需要, 有些不需要. </p><p>如果把捕猎方法写在动物超类里面是不合理的浪费资源.</p><p>所以把捕猎这个方法封装成1个接口, 让派生类自己去选择实现!</p><p>3.要为不同类族的多个类实现同样的方法(功能).</p><p>上面说过了, 其实不是只有Animal类的派生类才可以实现Huntable接口.</p><p>如果Farmer实现了这个接口, 那么农夫自己就可以去捕猎动物了…</p><h2 id="方法覆盖-Overriding-和方法重载-Overload"><a href="#方法覆盖-Overriding-和方法重载-Overload" class="headerlink" title="方法覆盖(Overriding)和方法重载(Overload)"></a>方法覆盖(Overriding)和方法重载(Overload)</h2><p>方法重写的原则：</p><ul><li><ol><li>重写方法的方法名称、参数列表必须与原方法的相同，返回类型可以相同也可以是原类型的子类型(从Java SE5开始支持)。      </li><li>重写方法不能比原方法访问性差（即访问权限不允许缩小）。      </li><li>重写方法不能比原方法抛出更多的异常。      </li><li>被重写的方法不能是final类型，因为final修饰的方法是无法重写的。 </li><li>被重写的方法不能为private，否则在其子类中只是新定义了一个方法，并没有对其进行重写。 </li><li>被重写的方法不能为static。如果父类中的方法为静态的，而子类中的方法不是静态的，但是两个方法除了这一点外其他都满足重写条件，那么会发生编译错误；反之亦然。即使父类和子类中的方法都是静态的，并且满足重写条件，但是仍然不会发生重写，因为静态方法是在编译的时候把静态方法和类的引用类型进行匹配。      </li><li>重写是发生在运行时的，因为编译期编译器不知道并且没办法确定该去调用哪个方法，JVM会在代码运行的时候作出决定。</li></ol></li></ul><p>方法重载的原则：</p><ul><li><ol><li>方法名称必须相同。 </li><li>参数列表必须不同（个数不同、或类型不同、参数类型排列顺序不同等）。      </li><li>方法的返回类型可以相同也可以不相同。      </li><li>仅仅返回类型不同不足以成为方法的重载。      </li><li>重载是发生在编译时的，因为编译器可以根据参数的类型来选择使用哪个方法。</li></ol></li></ul><p>重写和重载的不同：</p><ul><li><ol><li>方法重写要求参数列表必须一致，而方法重载要求参数列表必须不一致。      </li><li>方法重写要求返回类型必须一致(或为其子类型)，方法重载对此没有要求。 </li><li>方法重写只能用于子类重写父类的方法，方法重载用于同一个类中的所有方法。      </li><li>方法重写对方法的访问权限和抛出的异常有特殊的要求，而方法重载在这方面没有任何限制。      </li><li>父类的一个方法只能被子类重写一次，而一个方法可以在所有的类中可以被重载多次。      </li><li>重载是编译时多态，重写是运行时多态。</li></ol></li></ul><h2 id="Java反射高频面试题"><a href="#Java反射高频面试题" class="headerlink" title="Java反射高频面试题"></a>Java反射高频面试题</h2><p>1、除了使用new创建对象之外，还可以用什么方法创建对象？</p><p>使用Java反射可以创建对象!</p><p>2、Java反射创建对象效率高还是通过new创建对象的效率高？</p><p>通过new创建对象的效率比较高。通过反射时，先找查找类资源，使用类加载器创建，过程比较繁琐，所以效率较低</p><p>3、java反射的作用</p><p>反射机制是在运行时，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意个对象，都能够调用它的任意一个方法。在java中，只要给定类的名字，就可以通过反射机制来获得类的所有信息。 这种动态获取的信息以及动态调用对象的方法的功能称为Java语言的反射机制。</p><p>4、哪里会用到反射机制？</p><p>jdbc就是典型的反射</p><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image006.jpg" class="" title="img"><p>这就是反射。如hibernate，struts等框架使用反射实现的。</p><p>5、反射的实现方式：</p><p>第一步：获取Class对象，有4中方法：</p><p>1）Class.forName(“类的路径”)；</p><p>2）类名.class</p><p>3）对象名.getClass()</p><p>4）基本类型的包装类，可以调用包装类的Type属性来获得该包装类的Class对象</p><p>6、实现Java反射的类：</p><p>1）Class：表示正在运行的Java应用程序中的类和接口</p><p>注意： 所有获取对象的信息都需要Class类来实现。</p><p>2）Field：提供有关类和接口的属性信息，以及对它的动态访问权限。</p><p>3）Constructor：提供关于类的单个构造方法的信息以及它的访问权限</p><p>4）Method：提供类或接口中某个方法的信息</p><p>7、反射机制的优缺点：</p><p>优点：</p><p>1）能够运行时动态获取类的实例，提高灵活性；</p><p>2）与动态编译结合</p><p> 缺点：</p><p>1）使用反射性能较低，需要解析字节码，将内存中的对象进行解析。</p><p>解决方案：</p><p>1.通过setAccessible(true)关闭JDK的安全检查来提升反射速度；</p><p>2.多次创建一个类的实例时，有缓存会快很多</p><p>3.ReflflectASM工具类，通过字节码生成的方式加快反射速度</p><p>4.相对不安全，破坏了封装性（因为通过反射可以获得私有方法和属性）</p><p>8、Java 反射 API</p><p>反射 API 用来生成 JVM 中的类、接口或则对象的信息。</p><ol><li>Class 类：反射的核心类，可以获取类的属性，方法等信息。</li><li>Field 类：Java.lang.reflec包中的类，表示类的成员变量，可以用来获取和设置类之中的属性值。</li><li>Method 类： Java.lang.reflec包中的类，表示类的方法，它可以用来获取类中的方法信息或者执行方法。</li><li>Constructor 类： Java.lang.reflec 包中的类，表示类的构造方法。</li></ol><p>9、反射使用步骤（获取 Class 对象、调用对象方法）</p><ol><li>获取想要操作的类的 Class 对象，他是反射的核心，通过 Class 对象我们可以任意调用类的方法。</li><li>调用 Class 类中的方法，既就是反射的使用阶段。</li><li>使用反射 API 来操作这些信息。</li></ol><p>10、获取 Class 对象有几种方法</p><p>调用某个对象的 getClass()方法</p><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image008.jpg" class="" title="Person p.new person() ;  class clazz.p.getclass();"><p>调用某个类的 class 属性来获取该类对应的 Class 对象 </p><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image010.jpg" class="" title="ssel)"><p>使用 Class 类中的 forName()静态方法(最安全&#x2F;性能最好) 当我们获得了想要操作的类的 Class 对象后，可以通过 Class 类中的方法获取并查看该类中的方法和属性。</p><p>11、利用反射动态创建对象实例</p><p>Class 对象的 newInstance()</p><ol><li>使用 Class 对象的 newInstance()方法来创建该 Class 对象对应类的实例，但是这种方法要求该 Class 对象对应的类有默认的空构造器。 调用 Constructor 对象的 newInstance()</li><li>先使用 Class 对象获取指定的 Constructor 对象，再调用 Constructor 对象的 newInstance()方法来创建 Class 对象对应类的实例,通过这种方法可以选定构造方法创建实例。 </li><li><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image014.jpg" class="" title="Person class  c lazz•class . forNæe( reflection. Person&quot;) ; Class .newlnstane Person clazz. newlnstance(); Constructor Person pl.(persm) c. , .20) %}&lt;&#x2F;li&gt;&lt;&#x2F;ol&gt;&lt;h2 id&#x3D;数据类型&quot;&gt;&lt;a href&#x3D;#数据类型 class&#x3D;headerlink title&#x3D;数据类型&gt;&lt;&#x2F;a&gt;数据类型&lt;&#x2F;h2&gt;{% asset_img clip_image016.jpg boolean  char  short  int  long  float  double  void  16-bit  8 bits  16 bits  32 bits  64 bits  32 bits  64 bits  Unicode o  —128  —215  —263  IEEE754  IEEE754  k-kfl  Unicode 216—1  +215—1  +263-1  IEEE754  IEEE754  Boolean  Character  Byte  Short  Integer  Float  Double  Void"><h2 id="i-由几个指令，如何实现原子性"><a href="#i-由几个指令，如何实现原子性" class="headerlink" title="i++由几个指令，如何实现原子性"></a>i++由几个指令，如何实现原子性</h2><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image017.jpg" class="" width="0"><ul><li><ol><li><strong>使用juc中的lock</strong></li><li><strong>使用java关键字synchronized</strong></li><li><strong>使用juc中的AtomicInteger</strong></li><li><strong>volatile****并不能保证原子性操作</strong></li></ol></li></ul><h2 id="泛型"><a href="#泛型" class="headerlink" title="泛型"></a>泛型</h2><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image018.jpg" class="" width="0"><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image020.jpg" class="" width="0"><h2 id="字节码？采用字节码的好处"><a href="#字节码？采用字节码的好处" class="headerlink" title="字节码？采用字节码的好处"></a>字节码？采用字节码的好处</h2><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image021.jpg" class="" width="0"><h2 id="对于线程安全的理解"><a href="#对于线程安全的理解" class="headerlink" title="对于线程安全的理解"></a>对于线程安全的理解</h2><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image022.jpg" class="" width="0"><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image023.jpg" class="" width="0"><h2 id="守护线程的理解"><a href="#守护线程的理解" class="headerlink" title="守护线程的理解"></a>守护线程的理解</h2><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image024.jpg" class="" width="0"><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image025.jpg" class="" width="0"><h2 id="字符串常量池的设计思想"><a href="#字符串常量池的设计思想" class="headerlink" title="字符串常量池的设计思想"></a>字符串常量池的设计思想</h2><ul><li><ol><li>字符串的分配，和其他的对象分配一样，耗费高昂的时间与空间代价，作为最基础的数据类型，大量频繁的创建字符串，极大程度地影响程序的性能</li><li>JVM为了提高性能和减少内存开销，在实例化字符串常量的时候进行了一些优化</li></ol></li><li><ul><li>为字符串开辟一个字符串常量池，类似于缓存区</li><li>创建字符串常量时，首先检查字符串常量池是否存在该字符串</li><li>存在该字符串，返回引用实例，不存在，实例化该字符串并放入池中</li></ul></li></ul><h2 id="对面向对象的理解"><a href="#对面向对象的理解" class="headerlink" title="对面向对象的理解"></a>对面向对象的理解</h2><p>在我理解,面向对象是向现实世界模型的自然延伸，这是一种“万物皆对象”的编程思想。在现实生活中的任何物体都可以归为一类事物，而每一个个体都是一类事物的实例。面向对象的编程是以对象为中心，以消息为驱动，所以程序&#x3D;对象+消息。</p><p>面向对象有三大特性，封装、继承和多态。</p><p>封装就是将一类事物的属性和行为抽象成一个类，使其属性私有化，行为公开化，提高了数据的隐秘性的同时，使代码模块化。这样做使得代码的复用性更高。</p><p>继承则是进一步将一类事物共有的属性和行为抽象成一个父类，而每一个子类是一个特殊的父类–有父类的行为和属性，也有自己特有的行为和属性。这样做扩展了已存在的代码块，进一步提高了代码的复用性。</p><p>如果说封装和继承是为了使代码重用，那么多态则是为了实现接口重用。多态的一大作用就是为了解耦–为了解除父子类继承的耦合度。如果说继承中父子类的关系式IS-A的关系，那么接口和实现类之之间的关系式HAS-A。简单来说，多态就是允许父类引用(或接口)指向子类(或实现类)对象。很多的设计模式都是基于面向对象的多态性设计的。</p><p>总结一下，如果说封装和继承是面向对象的基础，那么多态则是面向对象最精髓的理论。掌握多态必先了解接口，只有充分理解接口才能更好的应用多态。</p><h2 id="java中list与map区别"><a href="#java中list与map区别" class="headerlink" title="java中list与map区别"></a>java中list与map区别</h2><p>java中list与map区别为：性质不同、顺序不同、重复不同。</p><p>一、性质不同</p><p>1、list：list是存储单列数据的集合。</p><p>2、map：map是存储键和值双列数据的集合。</p><p>二、顺序不同</p><p>1、list：list存储的数据是有顺序的。</p><p>2、map：map存储的数据是没有顺序的。</p><p>三、重复不同</p><p>1、list：list存储的数据允许重复。</p><p>2、map：map存储的数据其键是不能重复的，它的值是可以有重复的。</p><h2 id="cookie和session的区别"><a href="#cookie和session的区别" class="headerlink" title="cookie和session的区别"></a>cookie和session的区别</h2><ol><li>session 在服务器端，cookie 在客户端（浏览器）</li><li>cookie不是很安全</li><li>单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。(Session对象没有对存储的数据量的限制，其中可以保存更为复杂的数据类型)</li><li>session 可以放在 文件、数据库、或内存中都可以。</li><li>session 的运行依赖 session id，而     session id 是存在 cookie 中的，也就是说，如果浏览器禁用了 cookie ，同时 session 也会失效（但是可以通过其它方式实现，比如在 url 中传递 session_id） </li><li>用户验证这种场合一般会用 session</li></ol><h2 id="自然排序与定制排序"><a href="#自然排序与定制排序" class="headerlink" title="自然排序与定制排序"></a>自然排序与定制排序</h2><p>自然排序：java.lang.Comparable</p><ul><li><p>Comparable接口强行对实现它的每个类的对象进行整体排序。这种排序被称 为类的自然排序。 </p></li><li><p>实现 Comparable 的类必须实现 compareTo(Object obj) 方法，两个对象即 通过 compareTo(Object obj) 方法的返回值来比较大小。如果当前对象this大 于形参对象obj，则返回正整数，如果当前对象this小于形参对象obj，则返回 负整数，如果当前对象this等于形参对象obj，则返回零。 </p></li><li><p>·实现Comparable接口的对象列表（和数组）可以通过 Collections.sort 或 Arrays.sort进行自动排序。实现此接口的对象可以用作有序映射中的键或有 序集合中的元素，无需指定比较器。</p></li></ul><p>定制排序：java.util.Comparator</p><ul><li><p>当元素的类型没有实现java.lang.Comparable接口而又不方便修改代码， 或者实现了java.lang.Comparable接口的排序规则不适合当前的操作，那 么可以考虑使用 Comparator 的对象来排序，强行对多个对象进行整体排 序的比较</p></li><li><p>重写compare(Object o1,Object     o2)方法，比较o1和o2的大小：如果方法返 回正整数，则表示o1大于o2；如果返回0，表示相等；返回负整数，表示 o1小于o2</p></li><li><p>可以将 Comparator 传递给 sort 方法（如 Collections.sort 或 Arrays.sort）， 从而允许在排序顺序上实现精确控制。</p></li></ul><p><a href="https://www.cnblogs.com/xiao-ran/p/12492783.html">https://www.cnblogs.com/xiao-ran/p/12492783.html</a></p><h2 id="面试题：Comparable-和Comparator的区别"><a href="#面试题：Comparable-和Comparator的区别" class="headerlink" title="面试题：Comparable 和Comparator的区别:"></a>面试题：Comparable 和Comparator的区别:</h2><p>①　Comparable 自然排序 ，实体类实现Comparable接口，可以去重写compareTo()方法,解决实际排序问题。 把元素放到TreeSet里面去，就会自动的调用CompareTo方法; 但是这个Comparable并不是专为TreeSet设计的;只是说TreeSet顺便利用而已; 就像haashCode和equals 也一样，不是说专门为HashSet设计一样;只是你顺便利用而已;</p><p>②　Compartor第三方的比较器接口，也不是专门为TreeSet设计。 用法：设计一个比较器. 创建一个类，实现这个接口，覆写compare()方法,解决不同问题的需求。</p><p><a href="https://www.cnblogs.com/gshao/p/10129139.html">https://www.cnblogs.com/gshao/p/10129139.html</a></p><h2 id="同步和异步"><a href="#同步和异步" class="headerlink" title="同步和异步"></a>同步和异步</h2><p>1.同步与异步<strong>同步和异步关注的是</strong>消息通信机制**(synchronous communication&#x2F; asynchronous communication)所谓同步，就是在发出一个<em>调用</em>时，在没有得到结果之前，该<em>调用</em>就不返回。但是一旦调用返回，就得到返回值了。换句话说，就是由<em>调用者</em>主动等待这个<em>调用</em>的结果。</p><p>而异步则是相反，<em><strong>调用*在发出之后，这个调用就直接返回了，所以没有返回结果</strong>。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。而是在</em>调用<em>发出后，</em>被调用者*通过状态、通知来通知调用者，或通过回调函数处理这个调用。</p><p>典型的异步编程模型比如Node.js</p><p>举个通俗的例子：你打电话问书店老板有没有《分布式系统》这本书，如果是同步通信机制，书店老板会说，你稍等，”我查一下”，然后开始查啊查，等查好了（可能是5秒，也可能是一天）告诉你结果（返回结果）。而异步通信机制，书店老板直接告诉你我查一下啊，查好了打电话给你，然后直接挂电话了（不返回结果）。然后查好了，他会主动打电话给你。在这里老板通过“回电”这种方式来回调。</p><p>2。阻塞与非阻塞阻塞和非阻塞关注的是<strong>程序在等待调用结果（消息，返回值）时的状态.</strong></p><p>阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。</p><p>还是上面的例子，你打电话问书店老板有没有《分布式系统》这本书，你如果是阻塞式调用，你会一直把自己“挂起”，直到得到这本书有没有的结果，如果是非阻塞式调用，你不管老板有没有告诉你，你自己先一边去玩了， 当然你也要偶尔过几分钟check一下老板有没有返回结果。在这里阻塞与非阻塞与是否同步异步无关。跟老板通过什么方式回答你结果无关。</p><h2 id="Java为什么需要默认的无参构造函数"><a href="#Java为什么需要默认的无参构造函数" class="headerlink" title="Java为什么需要默认的无参构造函数"></a>Java为什么需要默认的无参构造函数</h2><p>类本身默认的实例化、初始化：对象的实例化一般都是通过 new 构造器的方式来进行的，如果自定义的类中没有显式提供构造器，则肯定需要一个默认的无参的空构造器用于 new 实例化、初始化(Java编译器插入的)，不然就无法用正常的方式实例化了，例如私有的构造器。换个角度看，默认的无参空构造器使得类可以直接 new 实例化。</p><p>父类的实例化、初始化：子类的实例化必然是伴随着父类的先一步实例化。子类如果没有通过 super 来显式调用父类的构造器，则都会默认调用父类的无参构造器来进行父类的初始化。如果此时父类没有无参构造器，则会出现编译错误。</p><p><a href="https://blog.csdn.net/weixin_35255032/article/details/114548992?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_baidulandingword-1&spm=1001.2101.3001.4242">https://blog.csdn.net/weixin_35255032/article/details/114548992?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_baidulandingword-1&amp;spm=1001.2101.3001.4242</a></p><h2 id="为什么静态方法不能调用非静态方法和变量？"><a href="#为什么静态方法不能调用非静态方法和变量？" class="headerlink" title="为什么静态方法不能调用非静态方法和变量？"></a>为什么静态方法不能调用非静态方法和变量？</h2><p>静态方法是属于类的，在类加载的时候就会分配内存，可以 通过类名直接去访问，非静态成员（变量和方法）属于类的对象，所以只有在对象初始化之后才存在，然后通过类的对象去访问。</p><p><a href="https://blog.csdn.net/weixin_47067712/article/details/106525107">https://blog.csdn.net/weixin_47067712/article/details/106525107</a></p><h2 id="java中的TLAB"><a href="#java中的TLAB" class="headerlink" title="java中的TLAB"></a>java中的TLAB</h2><p>TLAB的全称是Thread Local Allocation Buffer，即线程本地分配缓存区，这是一个线程专用的内存分配区域。</p><p>那为什么需要TLAB呢？</p><p>在日常的业务过程中，Java对象会不断的被新建和不断的被回收，这就涉及到对象的分配了，而新建的对象一般都是分配在堆上，而堆却是线程共享的。所以如果同一时间，有多个线程要在堆上申请空间，这里可以类比多线程访问共享变量的操作，要保证共享变量的线程安全，就得采取线程安全的手段。所以每一次对象分配都要做同步，而越多的线程要在堆上申请空间，竞争就会越激烈，效率就会降低。因此Java虚拟机采用了TLAB这种线程专属的区域来避免出现多线程冲突，提高对象分配的效率。TLAB是默认启动的，在该情况下，JAVA虚拟机会为每一个线程都分配一个TLAB区域。</p><p>如果设置了虚拟机参数 -XX:UseTLAB，在线程初始化时，同时也会申请一块指定大小的内存，只给当前线程使用，这样每个线程都单独拥有一个空间，如果需要分配内存，就在自己的空间上分配，这样就不存在竞争的情况，可以大大提升分配效率。</p><p>TLAB空间的内存非常小，缺省情况下仅占有整个Eden空间的1%，也可以通过选项-XX:TLABWasteTargetPercent设置TLAB空间所占用Eden空间的百分比大小。 </p><p>TLAB的本质其实是三个指针管理的区域：start，top 和 end，每个线程都会从Eden分配一块空间，例如说100KB，作为自己的TLAB，其中 start 和 end 是占位用的，标识出 eden 里被这个 TLAB 所管理的区域，卡住eden里的一块空间不让其它线程来这里分配。</p><p>TLAB只是让每个线程有私有的分配指针，但底下存对象的内存空间还是给所有线程访问的，只是其它线程无法在这个区域分配而已。从这一点看，它被翻译为 线程私有分配区 更为合理一点 当一个TLAB用满（分配指针top撞上分配极限end了），就新申请一个TLAB，而在老TLAB里的对象还留在原地什么都不用管——它们无法感知自己是否是曾经从TLAB分配出来的，而只关心自己是在eden里分配的。 </p><p>TLAB的缺点 </p><p>事务总不是完美的，TLAB也又自己的缺点。因为TLAB通常很小，所以放不下大对象。 1，TLAB空间大小是固定的，但是这时候一个大对象，我TLAB剩余的空间已经容不下它了。(比如100kb的TLAB，来了个110KB的对象) 2，TLAB空间还剩一点点没有用到，有点舍不得。(比如100kb的TLAB，装了80KB，又来了个30KB的对象) 所以JVM开发人员做了以下处理，设置了最大浪费空间。 当剩余的空间小于最大浪费空间，那该TLAB属于的线程在重新向Eden区申请一个TLAB空间。进行对象创建，还是空间不够，那你这个对象太大了，去Eden区直接创建吧！ 当剩余的空间大于最大浪费空间，那这个大对象请你直接去Eden区创建，我TLAB放不下没有使用完的空间。 </p><p>当然，又回造成新的病垢。 3，Eden空间够的时候，你再次申请TLAB没问题，我不够了，Heap的Eden区要开始GC， 4，TLAB允许浪费空间，导致Eden区空间不连续，积少成多。以后还要人帮忙打理。</p><h2 id="字面量"><a href="#字面量" class="headerlink" title="字面量"></a>字面量</h2><p>字面量就是指这个量本身，比如字面量3。也就是指3. 再比如 string类型的字面量”<a href="https://www.baidu.com/s?wd=ABC&tn=44039180_cpr&fenlei=mv6quAkxTZn0IZRqIHckPjm4nH00T1d9rjn3PW6suh7BuWcYPjm30ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6KdThsqpZwYTjCEQLGCpyw9Uz4Bmy-bIi4WUvYETgN-TLwGUv3EPHnsPjRvn10k">ABC</a>“, 这个”<a href="https://www.baidu.com/s?wd=ABC&tn=44039180_cpr&fenlei=mv6quAkxTZn0IZRqIHckPjm4nH00T1d9rjn3PW6suh7BuWcYPjm30ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6KdThsqpZwYTjCEQLGCpyw9Uz4Bmy-bIi4WUvYETgN-TLwGUv3EPHnsPjRvn10k">ABC</a>“ 通过字来描述。 所以就是字面量，虽然很难下定义。 你就理解成一眼就能知道的量。 对比下 string x; 那么x 是多少呢？ 它是个变量，你不确定它的值。 但是string x&#x3D;”<a href="https://www.baidu.com/s?wd=ABC&tn=44039180_cpr&fenlei=mv6quAkxTZn0IZRqIHckPjm4nH00T1d9rjn3PW6suh7BuWcYPjm30ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6KdThsqpZwYTjCEQLGCpyw9Uz4Bmy-bIi4WUvYETgN-TLwGUv3EPHnsPjRvn10k">ABC</a>“， 你当然知道”ABC” 就是”ABC”了，一眼就能看到值的量（有点像常量）。 string x&#x3D;”ABC” 意思是把字面量”ABC” 赋值给变量X. 再举例 const string y&#x3D;”<a href="https://www.baidu.com/s?wd=cbd&tn=44039180_cpr&fenlei=mv6quAkxTZn0IZRqIHckPjm4nH00T1d9rjn3PW6suh7BuWcYPjm30ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6KdThsqpZwYTjCEQLGCpyw9Uz4Bmy-bIi4WUvYETgN-TLwGUv3EPHnsPjRvn10k">cbd</a>“. 意思是把字面量”<a href="https://www.baidu.com/s?wd=cbd&tn=44039180_cpr&fenlei=mv6quAkxTZn0IZRqIHckPjm4nH00T1d9rjn3PW6suh7BuWcYPjm30ZwV5Hcvrjm3rH6sPfKWUMw85HfYnjn4nH6sgvPsT6KdThsqpZwYTjCEQLGCpyw9Uz4Bmy-bIi4WUvYETgN-TLwGUv3EPHnsPjRvn10k">cbd</a>“ 赋值给了常量y. 明白了吧？ 总之就是描述自己的量。 “ABC” 它描述了自己，你看到了就知道它是”ABC”了。</p><h2 id="句柄"><a href="#句柄" class="headerlink" title="句柄"></a>句柄</h2><p>使用句柄访问对象，会在堆中开辟一块内存作为句柄池，句柄中储存了对象实例数据（属性值结构体）的内存地址，访问对象类型数据的内存地址（类信息，方法类型信息），</p><p>对象实例数据一般也在heap中开辟，类型数据一般储存在方法区中。使用句柄访问的好处是句柄中储存的是稳定的对象地址，当对象被移动时候，只需要更新句柄中的对象实例部分的值即可，句柄本身不用被移动修改。</p><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image026.jpg" class="" width="0"><p> 句柄（Handle）来标示应用程序中不同的对象和同类中不同的实例 注意：句柄有人认为是指针、或者引用</p><p>对象实例数据（堆）:对象中各个实例字段的数据</p><p>对象类型数据（方法区）：对象的类型、父类、实现的接口、方法等</p><p>静态区（也在方法区中）用来存放静态变量，静态块</p><p>详细： <a href="https://blog.csdn.net/lly983909814/article/details/72529773">https://blog.csdn.net/lly983909814/article/details/72529773</a></p><h2 id="节点流与处理流"><a href="#节点流与处理流" class="headerlink" title="节点流与处理流"></a>节点流与处理流</h2><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image028.jpg" class="" width="0"><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image030.jpg" class="" width="0"><p>提供缓冲区的流BufferedWriter，字符编码转换的流InputStreamReader</p><p><a href="https://blog.csdn.net/jingzi123456789/article/details/72123937">https://blog.csdn.net/jingzi123456789/article/details/72123937</a></p><h2 id="java序列化"><a href="#java序列化" class="headerlink" title="java序列化"></a>java序列化</h2><ul><li><ul><li><strong>序列化：将对象写入到<strong><strong>IO</strong></strong>流中</strong></li><li><strong>反序列化：从<strong><strong>IO</strong></strong>流中恢复对象</strong></li><li><strong>意义：序列化机制允许将实现序列化的<strong><strong>Java</strong></strong>对象转换位字节序列，这些字节序列可以保存在磁盘上，或通过网络传输，以达到以后恢复成原来的对象。序列化机制使得对象可以脱离程序的运行而独立存在。</strong></li><li><strong>使用场景：所有可在网络上传输的对象都必须是可序列化的，</strong>比如RMI（remote method invoke,即远程方法调用），传入的参数或返回的对象都是可序列化的，否则会出错；<strong>所有需要保存到磁盘的<strong><strong>java</strong></strong>对象都必须是可序列化的。通常建议：程序创建的每个<strong><strong>JavaBean</strong></strong>类都实现<strong><strong>Serializeable</strong></strong>接口。</strong></li></ul></li></ul><h2 id="引用变量所指向的具体实例对象在运行期才确定"><a href="#引用变量所指向的具体实例对象在运行期才确定" class="headerlink" title="引用变量所指向的具体实例对象在运行期才确定"></a>引用变量所指向的具体实例对象在运行期才确定</h2><p>父类或者接口定义的引用变量可以指向子类或者具体实现类的实例对象，由于程序调用方法是在运行期才动态绑定的，那么引用变量所指向的具体实例对象在运行期才确定。</p><h2 id="值传递和引用传递"><a href="#值传递和引用传递" class="headerlink" title="值传递和引用传递"></a>值传递和引用传递</h2><p>JAVA中只有值传递，没有引用传递 </p><p>值传递（pass by value）是指在调用函数时将实际参数复制一份传递到函数中，这样在函数中如果对参数进行修改，将不会影响到实际参数。</p><p>引用传递（pass by reference）是指在调用函数时将实际参数的地址 直接 传递到函数中，那么在函数中对参数所进行的修改，将影响到实际参数。 </p><p>注意： </p><p>  地址值也是值，传递地址值不一定就是引用传递。 </p><p>  <strong>值传递和引用传递的区别并不是传递的内容。而是实参到底有没有被复制一份给形参。</strong></p><p><strong>详细参考：</strong> <a href="https://www.iteye.com/blog/guhanjie-1683637">https://www.iteye.com/blog/guhanjie-1683637</a></p><p><a href="https://www.jianshu.com/p/2fe41262e498">https://www.jianshu.com/p/2fe41262e498</a></p><h2 id="自动拆装箱"><a href="#自动拆装箱" class="headerlink" title="自动拆装箱"></a>自动拆装箱</h2><p>首先知道String是引用类型不是基本类型，引用类型声明的变量是指该变量在内存中实际存储的是一个引用地址，实体在堆中。引用类型包括类、接口、数组等。String类还是final修饰的。 </p><p><strong>基本数据类型有什么好处</strong></p><p>我们都知道在Java语言中，new一个对象是存储在堆里的，我们通过栈中的引用来使用这些对象；所以，对象本身来说是比较消耗资源的。</p><p>对于经常用到的类型，如int等，如果我们每次使用这种变量的时候都需要new一个Java对象的话，就会比较笨重。</p><p>而包装类就属于引用类型，自动装箱和拆箱就是基本类型和引用类型之间的转换。</p><p><strong>为什么需要包装类</strong></p><p>因为基本类型转换为引用类型后，就可以new对象，从而调用包装类中封装好的方法进行基本类型之间的转换或者toString（当然用类名直接调用也可以，便于一眼看出该方法是静态的），还有就是如果集合中想存放基本类型，泛型的限定类型只能是对应的包装类型。</p><p>详细： <a href="https://www.hollischuang.com/archives/2700">https://www.hollischuang.com/archives/2700</a></p><h2 id="类什么时候被Java虚拟机载入"><a href="#类什么时候被Java虚拟机载入" class="headerlink" title="类什么时候被Java虚拟机载入"></a>类什么时候被Java虚拟机载入</h2><p>1、编译和运行概念要搞清:编译即javac的过程，负责将zhi.java文件compile成.class文件，主要是类型、格式检查与编译成字节码文件，而加载是指java *的过程，将.class文件加载到内存中去解释执行，即运行的时候才会有加载一说。</p><p>2、类的加载时机，肯定是在运行时，但并不是一次性全部加载，而是按需动态，依靠反射来实现动态加载，一般来说一个class只会被加载一次，之后就会从jvm的class实例的缓存中获取，谁用谁取就可以了，不会再去文件系统中加载.class文件了。</p><p>具体细节参考： <a href="https://blog.csdn.net/first_m/article/details/107286563">https://blog.csdn.net/first_m/article/details/107286563</a></p><p><a href="https://www.cnblogs.com/Auge/p/11550213.html">https://www.cnblogs.com/Auge/p/11550213.html</a></p><h2 id="静态绑定和动态绑定"><a href="#静态绑定和动态绑定" class="headerlink" title="静态绑定和动态绑定"></a>静态绑定和动态绑定</h2><p>一：绑定</p><p>​    把一个方法与其所在的类&#x2F;对象 关联起来叫做方法的绑定。绑定分为静态绑定（前期绑定）和动态绑定（后期绑定）。</p><p>  二：静态绑定</p><p>​    静态绑定（前期绑定）是指：在程序运行前就已经知道方法是属于那个类的，在编译的时候就可以连接到类的中，定位到这个方法。</p><p>​    在Java中，final、private、static修饰的方法以及构造函数都是静态绑定的，不需程序运行，不需具体的实例对象就可以知道这个方法的具体内容。</p><p>  三：动态绑定</p><p>​    动态绑定（后期绑定）是指：在程序运行过程中，根据具体的实例对象才能具体确定是哪个方法。</p><p>​    动态绑定是多态性得以实现的重要因素，它通过方法表来实现：每个类被加载到虚拟机时，在方法区保存元数据，其中，包括一个叫做 方法表（method table）的东西，表中记录了这个类定义的方法的指针，每个表项指向一个具体的方法代码。如果这个类重写了父类中的某个方法，则对应表项指向新的代码实现处。从父类继承来的方法位于子类定义的方法的前面。</p><p>​    <strong>动态绑定语句的编译、运行原理</strong>：我们假设 Father ft&#x3D;new Son(); ft.say(); Son继承自Father，重写了say()。</p><p>​    1：编译：我们知道，向上转型时，用父类引用执行子类对象，并可以用父类引用调用子类中重写了的同名方法。但是不能调用子类中新增的方法，为什么呢？</p><p>​           因为<strong>在代码的编译阶段</strong>，编译器通过 <strong>声明对象的类型（即引用本身的类型）</strong> 在方法区中该类型的方法表中查找匹配的方法（最佳匹配法：参数类型最接近的被调用），如果有则编译通过。（这里是根据声明的对象类型来查找的，所以此处是查找 Father类的方法表，而Father类方法表中是没有子类新增的方法的，所以不能调用。）</p><p>​           编译阶段是确保方法的存在性，保证程序能顺利、安全运行。</p><p>​    2：运行：我们又知道，ft.say()调用的是Son中的say()，这不就与上面说的，查找Father类的方法表的匹配方法矛盾了吗？不，这里就是动态绑定机制的真正体现。</p><p>​           上面编译阶段在 声明对象类型 的方法表中查找方法，<strong>只是为了安全地通过编译（也为了检验方法是否是存在的）</strong>。而在实际<strong>运行这条语句</strong>时，在执行 Father ft&#x3D;new Son(); 这一句时创建了一个Son实例对象，然后在 ft.say() 调用方法时，JVM会把刚才的son对象压入操作数栈，用它来进行调用。而用实例对象进行方法调用的过程就是动态绑定：<strong>根据实例对象所属的类型去查找它的方法表，找到匹配的方法进行调用。</strong>我们知道，子类中如果重写了父类的方法，则方法表中同名表项会指向子类的方法代码；若无重写，则按照父类中的方法表顺序保存在子类方法表中。故此：动态绑定根据对象的类型的方法表查找方法是一定会匹配（因为编译时在父类方法表中以及查找并匹配成功了，说明方法是存在的。这也解释了为何向上转型时父类引用不能调用子类新增的方法：<strong>在父类方法表中必须先对这个方法的存在性进行检验，如果在运行时才检验就容易出危险<strong><strong>——</strong></strong>可能子类中也没有这个方法</strong>）。</p><p>  四：区分</p><p>​    程序在JVM运行过程中，会把类的类型信息、static属性和方法、final常量等元数据加载到方法区，<strong>这些在类被加载时就已经知道，不需对象的创建就能访问的，就是静态绑定的内容；需要等对象创建出来，使用时根据堆中的实例对象的类型才进行取用的就是动态绑定的内容。</strong></p><h2 id="Jdk8-9新特性"><a href="#Jdk8-9新特性" class="headerlink" title="Jdk8,9新特性"></a>Jdk8,9新特性</h2><h3 id="Jdk1-8"><a href="#Jdk1-8" class="headerlink" title="Jdk1.8"></a>Jdk1.8</h3><p>1、HashMap</p><p>有人会在问你HashMap的时候会问你JDK1.7和1.8有什么变化;</p><p>主要还是HashMap中链长度大于8时采取红黑树的结构存储。(1.7的时候是链表结构)红黑树，除了添加，效率高于链表结构。</p><p>2、ConcurrentHashMap</p><p>Jdk1.7时隔壁级别CocnurrentLevel（锁分段机制）默认为16。</p><p>JDK1.8采取了CAS算法</p><p>CAS原理主要涉及的有:锁机制、CAS 操作;具体可以参考CAS原理分析</p><p>Jdk1.8没有永久区，取而代之的是MetaSpace元空间，用的是物理内存。</p><p>3、Lambda表达式</p><p>1、Lambda表达式的基础语法：Java8引入了一个新的操作符“-&gt;”，该操作符成为箭头操作符或者Lambda操作符，箭头操作符将Lambda表达式拆分成两部分</p><p>左侧：Lambda表达式的参数列表</p><p>右侧：Lambda表达式中所需执行的功能，即Lambda体。</p><p>4、并行流</p><p>Fork&#x2F;Join框架：</p><p>在必要的情况下，将一个大任务进行必要的拆分Fork成若干个小任务，再将小任务的运算结果进行Join汇总。</p><p>5、Optional类</p><p>Optional 类(java.util.Optional) 是一个容器类，代表一个值存在或不存在，原来用null 表示一个值不存在，现在Optional 可以更好的表达这个概念。并且可以避免空指针异常。</p><h3 id="Jdk9"><a href="#Jdk9" class="headerlink" title="Jdk9"></a>Jdk9</h3><p>1、 Java平台模块化系统</p><p>整个jar都会被JVM加载到内存当中去，模块化可以根据模块的需要加载程序运行需要的class</p><p>2 、新工具JShell</p><p>Java 9首次为Java语言提供了REPL工具，名为JShell。我们可以在命令行或者在IntelliJ IDEA的终端中运行该REPL。java可作为脚本语言。</p><p>3、 多版本兼容Jar</p><p>多版本兼容 JAR 功能能让你创建仅在特定版本的 Java 环境中运行库程序时选择使用的 class 版本</p><p>4、 java.net新内容</p><p>引入了一个新的package:java.net.http，里面提供了对Http访问很好的支持，不仅支持Http1.1而且还支持HTTP2，以及WebSocket</p><p>5、JVM优化</p><p>使用G1垃圾回收器作为默认的垃圾回收器</p><h3 id="Jdk14"><a href="#Jdk14" class="headerlink" title="Jdk14"></a>Jdk14</h3><p>305: instanceof的模式匹配 (预览)</p><p>343: 打包工具 (Incubator)</p><p>345: G1的NUMA内存分配优化</p><p>349: JFR事件流</p><p>352: 非原子性的字节缓冲区映射</p><p>358: 友好的空指针异常</p><p>359: Records (预览)</p><p>361: Switch表达式 (标准)</p><p>362: 弃用Solaris和SPARC端口</p><p>363: 移除CMS（Concurrent Mark Sweep）垃圾收集器</p><p>364: macOS系统上的ZGC</p><p>365: Windows系统上的ZGC</p><p>366: 弃用ParallelScavenge + SerialOld GC组合</p><p>367: 移除Pack200 Tools和API</p><p>368: 文本块 (第二个预览版)</p><p>370: 外部存储器API (Incubator)</p><h2 id="为什么-String-是不可变的？"><a href="#为什么-String-是不可变的？" class="headerlink" title="为什么 String 是不可变的？"></a>为什么 String 是不可变的？</h2><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image032.jpg" class="" title="img"><p>并且是私有的。</p><h2 id="为什么-String-要设计为不可变的？"><a href="#为什么-String-要设计为不可变的？" class="headerlink" title="为什么 String 要设计为不可变的？"></a>为什么 String 要设计为不可变的？</h2><p>原因可以从四个方面说起，缓存、安全性、同步和高性能。</p><p>1）字符串常量池</p><p>字符串恐怕是 Java 中最常用的数据形式了，如果字符串非要谦虚地说自己是老二，就没有人敢说自己是老大。</p><p>因此，把字符串缓存起来，并且重复使用它们会节省大量堆空间（堆内存用来存储 Java 中的对象，无论是成员变量、局部变量，还是类变量，它们指向的对象都存储在堆内存中），因为不同的字符串变量引用的是字符串常量池中的同一个对象。这也正是字符串常量池存在的目的。</p><p>字符串常量池是 Java 虚拟机用来存储字符串的一个特殊的区域，由于字符串是不可变的，因此 Java 虚拟机可以在字符串常量池中只为同一个字符串存储一个字符串副本来节省空间。</p><p>2）安全性</p><p>字符串在 Java 应用程序中的使用范围非常广，几乎无处不在，比如说存储用户名、密码、数据库连接地址等等这些非常敏感的信息，因此，必须要保证 String 类的绝对安全性。</p><p>通常情况下，用户名由客户端传递到服务器端，服务器端接收后要先对用户名进行检查，再进行其他操作，因为客户端传递过来的信息不一定值得信任。</p><p>如果字符串是可变的，那么我们在执行 executeUpdate 更新数据库的时候，就有点不放心，因为即便是安全性检查通过了，字符串仍然有可能被修改。</p><p>3）线程安全</p><p>由于字符串是不可变的，因此可以在多线程之间共享，如果一个线程把字符串的值修改为另外一个，那么就会在字符串常量池中创建另外一个字符串，原有的字符串仍然会保持不变。</p><p>4）哈希码</p><p>字符串广泛应用于 HashMap、HashTable、HashSet 等需要哈希码作为键的数据结构中，在对这些哈希表进行操作的时候，需要频繁调用 hashCode() 方法来获取键的哈希码。</p><p>由于字符串是不可变性，这就保证了键值的哈希值不会发生改变，因此在第一次调用 String 类的 hashCode() 方法时，就对哈希值进行了缓存，此后，就一直返回相同的值。</p><p><a href="https://www.zhihu.com/question/20618891">https://www.zhihu.com/question/20618891</a></p><h2 id="String类型的对象，是保存在堆里还是在栈里呢？"><a href="#String类型的对象，是保存在堆里还是在栈里呢？" class="headerlink" title="String类型的对象，是保存在堆里还是在栈里呢？"></a><a href="https://so.csdn.net/so/search?q=String%E7%B1%BB&spm=1001.2101.3001.7020">String类</a>型的对象，是保存在堆里还是在栈里呢？</h2><p>在Java的实现中，new出来的String对象一般是放在堆中的。</p><p>如果是 String s &#x3D;“xxx”; 这种,那就是放在<a href="https://so.csdn.net/so/search?q=%E5%B8%B8%E9%87%8F%E6%B1%A0&spm=1001.2101.3001.7020">常量池</a>中.</p><h2 id="new创建对象和用字符串常量创建对象的区别"><a href="#new创建对象和用字符串常量创建对象的区别" class="headerlink" title="new创建对象和用字符串常量创建对象的区别"></a>new创建对象和用字符串常量创建对象的区别</h2><p>public class StringDemo2 {</p><p>  public static void main(String[] args) {</p><p>​    String s1 &#x3D; new String(“hello”);</p><p>​    String s2 &#x3D; “hello”;</p><p>​     System.out.println(s1 &#x3D;&#x3D; s2);&#x2F;&#x2F; false</p><p>​    System.out.println(s1.equals(s2));&#x2F;&#x2F; true</p><p>  }</p><p>}</p><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image034.gif" class="" title="在这里插入图片描述"><p>(1)、首先，通过main（）方法进栈。</p><p>(2)、然后再栈中定义一个对象s1,s1由new创建，因此去堆中开辟一个内存空间，将内存空间的引用赋值给s1，“hello”是常量，然后去<a href="https://so.csdn.net/so/search?q=%E5%AD%97%E7%AC%A6%E4%B8%B2&spm=1001.2101.3001.7020">字符串</a>常量池查看是否有hello字符串对象，没有的话分配一个空间存放hello，并且将其空间地址存入堆中new出来的空间中。</p><p>(3)、在栈中定义一个对象s2，s2不是由new创建，因此去字符串常量池中查看是否有”hello”字符串对象，有则直接把“hello”的地址赋值给s2。</p><p>(4)、即s1中存的是堆中分配的空间，堆中分配的空间中存的是字符串常量池中分配空间存放”hello”的空间的地址值。而s2中之中存的是字符串常量池中分配空间存放”hello”的空间的地址值。</p><p>(5)、由于s1与s2中存放的地址不同，所以输出false。因为，类String重写了equals()方法，它比较的是引用类型的 的值是否相等，所以输出true。即结果为false、true。</p><h2 id="final、finally、finalize"><a href="#final、finally、finalize" class="headerlink" title="final、finally、finalize"></a>final、finally、finalize</h2><ul><li><ul><li>final 用于声明属性,方法和类, 分别表示属性不可变, 方法不可覆盖, 类不可继承.</li><li>finally 是异常处理语句结构的一部分，表示总是执行.</li><li>finalize 是Object类的一个方法，在垃圾收集器执行的时候会调用被回收对象的此方法，可以覆盖此方法提供垃圾收集时的其他资源回收，例如关闭文件等. JVM不保证此方法总被调用.</li></ul></li></ul><h2 id="深拷贝和浅拷贝"><a href="#深拷贝和浅拷贝" class="headerlink" title="深拷贝和浅拷贝"></a>深拷贝和浅拷贝</h2><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image036.jpg" class="" title="深 拷 贝 和 浅 拷 贝  深 栳 贝 和 浅 拷 贝 孰 是 指 对 盅 的 拷 贝 ， 一个对象中存在蕊种类型的@性 ， 一 种 是 基 事 数 庭 类 型 ， 一 种 是 实 例 对 象 的 引 庠 ．  1 、 浅 拷 贝 是 挹 ， 只 会 拷 贝 基 本 數 类 型 匾 ， 以 及 实 树 象 引 的 地 址 。 荇 不 会 0 制 一 份 引 0 地 址 所 指 对 象 。 也 就 是 浅 拷 贝 出 来 对 象 。 丙 刁 类 性 尷 向 的 是 同 一 ^  对 象  2 ． 深 店 贝 是 ， 既 会 贝 基 本 数 廡 类 型 的 们 ， 也 会 针 对 买 例 对 的 引 厍 地 址 所 向 的 对 象 行 过 制 ， 深 满 贝 湖 来 的 对 象 ， 内 0 《 性 指 向 的 不 是 同 一 个 对 象"><h2 id="泛型中extends和super的区别"><a href="#泛型中extends和super的区别" class="headerlink" title="泛型中extends和super的区别"></a>泛型中extends和super的区别</h2><img src="/2024/03/24/java%E5%9F%BA%E7%A1%80/clip_image038.jpg" class="" title="I. ? extends T  2. super">]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> java基础 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo搭建个人博客</title>
      <link href="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"/>
      <url>/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</url>
      
        <content type="html"><![CDATA[<h1 id="博客搭建过程（采用hexo框架-部署到github）"><a href="#博客搭建过程（采用hexo框架-部署到github）" class="headerlink" title="博客搭建过程（采用hexo框架+部署到github）"></a><strong>博客搭建过程（采用hexo框架+部署到github）</strong></h1><h2 id="1-前期准备"><a href="#1-前期准备" class="headerlink" title="1.前期准备"></a><strong>1.前期准备</strong></h2><h3 id="1-1-注意事项"><a href="#1-1-注意事项" class="headerlink" title="1.1 注意事项"></a><strong>1.1 注意事项</strong></h3><ul><li>很多命令既可以用Windows的cmd来完成，也可以使用git bash来完成，但是部分命令会有一些问题，为避免不必要的问题，建议全部使用git bash来执行</li><li>hexo不同版本差别比较大，网上很多文章的配置信息都是基于2.x的，所以注意不要被误导</li><li>hexo有2种_config.yml文件，一个是根目录下的全局的_config.yml，一个是各个theme下的</li></ul><h3 id="1-2-下载并安装node-js"><a href="#1-2-下载并安装node-js" class="headerlink" title="1.2 下载并安装node.js"></a><strong>1.2 下载并安装node.js</strong></h3><ul><li>官网下载：<a href="https://nodejs.org/en/">https://nodejs.org/en/</a></li><li>安装与使用：见node笔记</li><li>安装后验证：<strong>node -v</strong></li></ul><h3 id="1-3-下载并安装git"><a href="#1-3-下载并安装git" class="headerlink" title="1.3 下载并安装git"></a><strong>1.3 下载并安装git</strong></h3><ul><li>官网下载:  <a href="https://git-scm.com/download/win">https://git-scm.com/download/win</a></li><li>安装与使用：见git笔记</li><li>安装后验证：<strong>git -v</strong></li></ul><h3 id="1-4-命令行安装cnpm"><a href="#1-4-命令行安装cnpm" class="headerlink" title="1.4 命令行安装cnpm"></a><strong>1.4 命令行安装cnpm</strong></h3><ul><li>命令：<strong>npm install -g cnpm –registry&#x3D;&#x3D;<a href="https://registry.npm.taobao.org/">https://registry.npm.taobao.org</a></strong></li><li>安装后验证：<strong>cnpm -v</strong></li></ul><h3 id="1-5-命令行安装hexo"><a href="#1-5-命令行安装hexo" class="headerlink" title="1.5 命令行安装hexo"></a><strong>1.5 命令行安装hexo</strong></h3><ul><li>命令：<strong>cnpm install -g hexo-cli</strong></li><li>安装后验证：<strong>hexo  -v</strong></li></ul><hr><h2 id="2-配置github"><a href="#2-配置github" class="headerlink" title="2.配置github"></a><strong>2.配置github</strong></h2><h3 id="2-1-在github上创建仓库"><a href="#2-1-在github上创建仓库" class="headerlink" title="2.1 在github上创建仓库"></a><strong>2.1 在github上创建仓库</strong></h3><p><strong>创建：</strong></p><ul><li>新建一个名为你的用户名.github.io的仓库</li><li>比如说，如果你的github用户名是test，那么你就新建test.github.io的仓库（必须是你的用户名，其它名称无效），将来你的网站访问地址就是 <a href="http://test.github.io/">http://test.github.io</a> 了，是不是很方便？由此可见，每一个github账户最多只能创建一个这样可以直接使用域名访问的仓库。</li></ul><p><strong>注意：</strong></p><ol><li>注册的邮箱一定要验证，否则不会成功；</li><li>仓库名字必须是：username.github.io，其中username是你的用户名；</li><li>仓库创建成功不会立即生效，需要过一段时间，大概10-30分钟，或者更久；</li><li>创建页面如下：</li></ol><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/1.png" class="" title="img"><p>创建成功后，默认会在你这个仓库里生成一些示例页面，以后你的网站所有代码都是放在这个仓库里啦。</p><h3 id="2-2-绑定域名（这步可省略）"><a href="#2-2-绑定域名（这步可省略）" class="headerlink" title="2.2 绑定域名（这步可省略）"></a><strong>2.2 绑定域名（这步可省略）</strong></h3><p>当然，你不绑定域名肯定也是可以的，就用默认的 xxx.github.io 来访问，如果你想更个性一点，想拥有一个属于自己的域名，那也是OK的。</p><p>首先你要注册一个域名，域名注册以前总是推荐去godaddy，现在觉得其实国内的阿里云也挺不错的，价格也不贵，毕竟是大公司，放心！</p><p>绑定域名分2种情况：带www和不带www的。</p><p>域名配置最常见有2种方式，CNAME和A记录，CNAME填写域名，A记录填写IP，由于不带www方式只能采用A记录，所以必须先ping一下你的用户名.github.io的IP，然后到你的域名DNS设置页，将A记录指向你ping出来的IP，将CNAME指向你的用户名.github.io，这样可以保证无论是否添加www都可以访问，如下：</p><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/2.png" class="" title="img"><p>然后到你的github项目根目录新建一个名为CNAME的文件（无后缀），里面填写你的域名，加不加www看你自己喜好，因为经测试：</p><ul><li>如果你填写的是没有www的，比如 mygit.me，那么无论是访问 <a href="http://www.mygit.me/">http://www.mygit.me</a> 还是 <a href="http://mygit.me/">http://mygit.me</a> ，都会自动跳转到 <a href="http://mygit.me/">http://mygit.me</a></li><li>如果你填写的是带www的，比如 <a href="http://www.mygit.me/">www.mygit.me</a> ，那么无论是访问 <a href="http://www.mygit.me/">http://www.mygit.me</a> 还是 <a href="http://mygit.me/">http://mygit.me</a> ，都会自动跳转到 <a href="http://www.mygit.me/">http://www.mygit.me</a></li><li>如果你填写的是其它子域名，比如 abc.mygit.me，那么访问 <a href="http://abc.mygit.me/">http://abc.mygit.me</a> 没问题，但是访问 <a href="http://mygit.me/">http://mygit.me</a> ，不会自动跳转到 <a href="http://abc.mygit.me/">http://abc.mygit.me</a></li></ul><p>另外说一句，在你绑定了新域名之后，原来的你的用户名.github.io并没有失效，而是会自动跳转到你的新域名。</p><hr><h2 id="3-配置SSH免密登录"><a href="#3-配置SSH免密登录" class="headerlink" title="3. 配置SSH免密登录"></a><strong>3. 配置SSH免密登录</strong></h2><p>为什么要配置这个呢？因为你提交代码肯定要拥有你的github权限才可以，但是直接使用用户名和密码太不安全了，所以我们使用ssh key来解决本地和服务器的连接问题。</p><p><strong>操作步骤：</strong></p><p><strong>第一步：</strong>首先打开电脑文件夹，找到C:\Users\你的用户名.ssh文件夹并删除</p><p><strong>第二步：</strong>在C:\Users\你的用户名 文件夹下右键打开Git Bash Here<strong>输入命令：</strong>ssh-keygen -t rsa -C github邮件地址   生成.ssh秘钥，输入后连敲三次回车，出现下图情况代表成功</p><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/3.png" class="" title="img"><p><strong>第三步：</strong>最终生成了一个新的 C:\Users\你的用户名.ssh文件夹，打开这个文件夹，找到.ssh\id_rsa.pub文件，记事本打开并复制里面的内容</p><p><strong>第四步：</strong>打开你的github主页，进入个人设置 -&gt; SSH and GPG keys -&gt; New SSH key，把复制的内容粘贴进去，title随便填，保存即可，我们的公钥就添加成功了，设置好如下图。</p><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/4.png" class="" title="img"><p><strong>第五步：检测是否设置成功：</strong></p><p>输入命令：  $ ssh -T <a href="mailto:git@github.com">git@github.com</a> # 注意邮箱地址不用改</p><p>如果提示Are you sure you want to continue connecting (yes&#x2F;no)?，输入yes，然后会看到：</p><p>Hi liuxianan! You’ve successfully authenticated, but GitHub does not provide shell access.</p><p>看到这个信息说明SSH已配置成功！</p><p><strong>第六步：此时你还需要配置：</strong></p><p>$ git config –global user.name “liuxianan”&#x2F;&#x2F; 你的github用户名，非昵称 $ git config –global user.email  “<a href="mailto:xxx@qq.com">xxx@qq.com</a>“&#x2F;&#x2F; 填写你的github注册邮箱</p><p>具体这个配置是干嘛的我没仔细深究。</p><hr><h2 id="4-使用-hexo-搭建博客"><a href="#4-使用-hexo-搭建博客" class="headerlink" title="4.使用 hexo 搭建博客"></a><strong>4.使用 hexo 搭建博客</strong></h2><h3 id="4-1-初始化"><a href="#4-1-初始化" class="headerlink" title="4.1 初始化"></a><strong>4.1 初始化</strong></h3><p><strong>第一步：</strong>在电脑的某个地方新建一个名为hexo的文件夹（名字可以随便取），比如我的是E:\xpzsData\hexocode，由于这个文件夹将来就作为你存放代码的地方，所以最好不要随便放</p><p><strong>第二步：</strong>在E:\xpzsData\hexocode文件夹下右键打开 Git Bash Here，输入hexo init 初始化</p><ul><li>hexo会自动下载一些文件到这个目录，包括node_modules，目录结构如下图：</li></ul><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/5.png" class="" title="img"><p><strong>第三步：</strong>执行以下命令之后，hexo就会在public文件夹生成相关html文件，这些文件将来都是要提交到github去的：</p><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/6.png" class="" title="img"><p><strong>第四步：</strong>hexo s 是开启本地预览服务，打开浏览器访问 <a href="http://localhost:4000/">http://localhost:4000</a> 即可看到内容，很多人会碰到浏览器一直在转圈但是就是加载不出来的问题，一般情况下是因为端口占用的缘故，因为4000这个端口太常见了，解决端口冲突问题请参考这篇文章<a href="https://www.runoob.com/w3cnote/windows-finds-port-usage.html">https://www.runoob.com/w3cnote/windows-finds-port-usage.html</a></p><ul><li>到这里初始化就完成了</li></ul><h3 id="4-2-将博客部署到-github-个人主页上"><a href="#4-2-将博客部署到-github-个人主页上" class="headerlink" title="4.2 将博客部署到 github 个人主页上"></a><strong>4.2 将博客部署到 github 个人主页上</strong></h3><p><strong>第一步：</strong>在E:\xpzsData\hexocode目录下安装 hexo-deployer-git 插件</p><ul><li><strong>安装命令：</strong> npm install hexo-deployer-git –save  </li><li>必须安装，否则执行hexo d 的话会报如下错误：</li></ul><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/7.png" class="" title="img"><p><strong>第二步：</strong>编辑E:\xpzsData\hexocode目录下的 _config.yml 文件, 在文件末尾添加如下内容：</p><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/8.png" class="" title="img"><ul><li>注意：其中 repo 中的内容即为 github 个人主页链接地址，具体看下图：</li></ul><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/9.png" class="" title="img"><p><strong>第三步：</strong>在E:\xpzsData\hexocode目录下, <strong>输入命令：hexo d</strong> 将本地 blog 推送到 github仓库, 也可能需要输入 username &amp; pwd。</p><ul><li>推送成功后, 在浏览器中输入对应域名, 即可访问 <a href="https://reclusew.github.io/">https://reclusew.github.io/</a></li></ul><hr><h2 id="5-更换主题"><a href="#5-更换主题" class="headerlink" title="5. 更换主题"></a><strong>5. 更换主题</strong></h2><h3 id="5-1-寻找主题"><a href="#5-1-寻找主题" class="headerlink" title="5.1 寻找主题"></a><strong>5.1 寻找主题</strong></h3><ul><li>既然默认主题很丑，那我们别的不做，首先来替换一个好看点的主题。</li><li>这是hexo官网：<a href="https://hexo.io/themes/%EF%BC%8C%E5%8F%AF%E5%9C%A8%E9%87%8C%E9%9D%A2%E4%B8%8B%E8%BD%BD%E4%B8%BB%E9%A2%98%EF%BC%8C%E7%82%B9%E5%87%BB%E4%B8%BB%E9%A2%98%E5%90%8D%E5%8D%B3%E5%8F%AF%E8%B7%B3%E8%BD%AC%E5%88%B0github%E4%B8%8A%EF%BC%8C%E4%B9%9F%E5%8F%AF%E4%BB%A5%E7%9B%B4%E6%8E%A5%E5%9C%A8github%E4%B8%8A%E6%90%9C%E7%B4%A2%E4%B8%BB%E9%A2%98">https://hexo.io/themes/，可在里面下载主题，点击主题名即可跳转到github上，也可以直接在github上搜索主题</a></li><li>在这里我使用github上一个大佬的主题blinkfox&#x2F;hexo-theme-matery</li></ul><p>​              链接：<a href="https://github.com/blinkfox/hexo-theme-matery">https://github.com/blinkfox/hexo-theme-matery</a>    </p><h3 id="5-2-下载主题"><a href="#5-2-下载主题" class="headerlink" title="5.2 下载主题"></a><strong>5.2 下载主题</strong></h3><p><strong>第一步：</strong>Git Bash Here中先cd到E:\xpzsData\hexocode目录</p><p><strong>第二步：</strong>再输入命令 $ git clone 主题http链接  themes&#x2F;主题名称</p><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/10.png" class="" title="img"><p><strong>注意：</strong></p><ul><li>E:\xpzsData\hexocode目录下的 theme 文件夹下存放的就是博客的主题，主题是否下载成功可到该目录下查看：</li></ul><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/11.png" class="" title="img"><h3 id="5-3-使用主题"><a href="#5-3-使用主题" class="headerlink" title="5.3 使用主题"></a><strong>5.3 使用主题</strong></h3><ul><li>打开E:\xpzsData\hexocode目录下的_config.yml文件，在里面找到theme: landscape改为theme: blinkfox   （blinkfox为我们要使用的主题名）,然后重新执行hexo g来重新生成。</li><li>如果出现一些莫名其妙的问题，可以先执行hexo clean来清理一下public的内容，然后再执行hexo g 和 hexo s 重新生成和发布。</li><li>再次在浏览器中输入对应域名, 即可发现主题已更换</li></ul><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/12.png" class="" title="img"><h3 id="5-4-修改主题内容"><a href="#5-4-修改主题内容" class="headerlink" title="5.4 修改主题内容"></a><strong>5.4 修改主题内容</strong></h3><p>在这里我使用的是blinkfox主题，后期相关修改参考这个主题文档</p><p><strong>文档链接：</strong><a href="https://github.com/blinkfox/hexo-theme-matery/blob/develop/README_CN.md">https://github.com/blinkfox/hexo-theme-matery/blob/develop/README_CN.md</a></p><ul><li>注意：一些非md文件可以把他们放到source文件夹下，这里的所有文件都会原样复制（除了md文件）到public目录的</li><li>大致在下图的文件夹里面修改文件，记得修改后的文件需要关闭后，再在hexocode根目录右键打开Git Bash  Here，输入两个命令：hexo g 重新生成，hexo s 开启本地预览服务,等修改的符合要求了，再输入 hexo d  推送到github仓库即可</li><li>这样就可以输入网址查看更改后的内容了</li></ul><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/13.png" class="" title="img"><p><strong>文档上没有提及的修改：</strong></p><ul><li>返回按钮样式修改：在主题下面的 blinkfox\layout_partial 文件夹中的 back-top.esj 文件中修改</li></ul><p><strong>特别注意：</strong></p><ul><li><strong>修改生成的默认页面信息，要到主题下面的_config.yml文件里面去改，而不是根目录下的_config.yml文件</strong></li></ul><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/14.png" class="" title="img"><ul><li><strong>要把根目录下的_config.yml文件中的这些信息替换成自己的和设置中文</strong></li></ul><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/15.png" class="" title="img"><h3 id="5-5-blinkfox主题的相关配置问题"><a href="#5-5-blinkfox主题的相关配置问题" class="headerlink" title="5.5 blinkfox主题的相关配置问题"></a><strong>5.5 blinkfox主题的相关配置问题</strong></h3><p><strong>配置音乐播放器：</strong>使用网易云音乐id不行，这里用的是QQ音乐</p><p><strong>配置留言功能（利用Valine）：</strong></p><ul><li>我们的评论系统其实是放在Leancloud上的，因此首先需要去注册一个账号</li><li>注册完以后需要创建一个应用，名字可以随便起，然后 进入应用-&gt;设置-&gt;应用key，获取你的appid 和 appkey，复制到主题下面的 _config.yml 文件里面搜索 valine，填入appid 和 appkey</li><li>最后！记得在Leancloud -&gt; 设置 -&gt; 安全中心 -&gt; Web 安全域名 把你的域名加进去就可以了</li><li>主题页面显示的内容在主题下面的 layout 文件夹中的 contact.ejs 文件里面更改</li></ul><hr><h2 id="6-利用Typora软件来写博客"><a href="#6-利用Typora软件来写博客" class="headerlink" title="6.利用Typora软件来写博客"></a><strong>6.利用Typora软件来写博客</strong></h2><h3 id="6-1-Typora介绍"><a href="#6-1-Typora介绍" class="headerlink" title="6.1 Typora介绍"></a><strong>6.1 Typora介绍</strong></h3><ul><li>Typora–一款简单高效的Markdown编辑器，保存后直接为md格式，Markdown中点击导入就可以。</li><li>Markdown是一种可以使用普通文本编辑器编写的标记语言，通过简单的标记语法，它可以使普通文本内容具有一定的格式，其目标是实现易读易写，说人话就是删减版的HTML语言</li><li>Markdown教程：<a href="https://www.runoob.com/markdown/md-tutorial.html">https://www.runoob.com/markdown/md-tutorial.html</a></li></ul><h3 id="6-2-安装Typora"><a href="#6-2-安装Typora" class="headerlink" title="6.2 安装Typora"></a><strong>6.2 安装Typora</strong></h3><p><strong>官网：</strong><a href="https://www.typora.io/#windows">https://www.typora.io/#windows</a></p><h3 id="6-3-写博客的步骤"><a href="#6-3-写博客的步骤" class="headerlink" title="6.3  写博客的步骤"></a><strong>6.3  写博客的步骤</strong></h3><p><strong>第一步：创建.md文件</strong></p><ul><li><strong>方法1：</strong>定位到我们的hexo根目录，Git Bash Here 中执行命令：  hexo new  ‘my-first-blog’                 hexo会帮我们在E:\xpzsData\hexocode\source_posts  下生成相关.md文件，用这个命令的好处是帮我们自动生成了时间，方法1默认生成如下内容：</li></ul><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/16.png" class="" title="img"><ul><li><strong>方法2：</strong>当然你也可以直接自己打开E:\xpzsData\hexocode\source_posts 目录新建.md文件</li></ul><p><strong>第二步：编写并保存</strong></p><p>我们只需要用typora打开这个文件就可以开始写博客了，写完后Ctrl+S 保存关闭即可</p><p><strong>第三步：</strong>清理然后再生成一下，生成后推送到远程仓库即可，hexo根目录下右键Git Bash Here 中依次输入如下命令：</p><ol><li>hexo clean</li><li>hexo g </li><li>hexo d</li></ol><p><strong>补充：</strong>hexo new page ‘postName’命令和hexo new ‘postName’的区别？</p><ul><li>hexo new page ‘My-second-blog’最终部署时生成：hexo\public\my-second-blog\index.html，但是它不会作为文章出现在博文目录。</li></ul><h3 id="6-4-Typora快捷键"><a href="#6-4-Typora快捷键" class="headerlink" title="6.4  Typora快捷键"></a><strong>6.4  Typora快捷键</strong></h3><p>Typora中只要记住一些基本的快捷键就可以了，所有功能软件里面都有对应按钮，这点不用慌。</p><p><strong>快捷键文章：</strong><a href="https://blog.csdn.net/weixin_39533052/article/details/111115263">https://blog.csdn.net/weixin_39533052/article/details/111115263</a></p><h3 id="6-5-注意：所使用的主题的文章-Front-matter-语法"><a href="#6-5-注意：所使用的主题的文章-Front-matter-语法" class="headerlink" title="6.5  注意：所使用的主题的文章 Front-matter 语法"></a><strong>6.5  注意：所使用的主题的文章 Front-matter 语法</strong></h3><p>依据使用的不同主题，一些文章功能所使用的语法可能不一样，例如写博客时给文章添加标签的语法等等，这些都要看所使用的主题的文档，例如我们这里使用的是 <strong>blinkfox</strong> 主题，打开主题文档，往下翻找到<strong>”</strong>  <strong>文章 Front-matter 介绍 “</strong>即可。</p><p><strong>blinkfox主题文档：</strong><a href="https://github.com/blinkfox/hexo-theme-matery/blob/develop/README_CN.md#%E6%96%87%E7%AB%A0-front-matter-%E4%BB%8B%E7%BB%8D">https://github.com/blinkfox/hexo-theme-matery/blob/develop/README_CN.md#%E6%96%87%E7%AB%A0-front-matter-%E4%BB%8B%E7%BB%8D</a></p><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/17.png" class="" title="img"><p><strong>示例：</strong></p><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/18.png" class="" title="img"><h3 id="6-6-YAML语法（了解）"><a href="#6-6-YAML语法（了解）" class="headerlink" title="6.6 YAML语法（了解）"></a><strong>6.6 YAML语法（了解）</strong></h3><p>像在typora中添加tags时，可以直接用数组的写法，也可以使用YAML语法，如下：</p><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/19.png" class="" title="img"><p><strong>YAML教程链接：</strong><a href="https://www.runoob.com/w3cnote/yaml-intro.html">https://www.runoob.com/w3cnote/yaml-intro.html</a></p><hr><h2 id="7-如何向hexo博客中插入图片"><a href="#7-如何向hexo博客中插入图片" class="headerlink" title="7.如何向hexo博客中插入图片"></a><strong>7.如何向hexo博客中插入图片</strong></h2><h3 id="7-1-使用相对路径的方式"><a href="#7-1-使用相对路径的方式" class="headerlink" title="7.1 使用相对路径的方式"></a><strong>7.1 使用相对路径的方式</strong></h3><p>众所周知，在md文件中插入图片的语法为!&#x2F;。</p><p>其中<strong>方括号</strong>是图片描述，<strong>圆括号</strong>是图片路径。</p><p>一般来说有三种图片路径，分别是<strong>相对路径，绝对路径和网络路径</strong>。</p><p>所谓的网络路径就是直接引用网上的图片，直接复制图片地址，放在圆括号中就完事了。</p><p>这种方式十分的方便，但是也存在一定的问题：</p><ul><li>图片失效导致无法加载；</li><li>打开网页后要再请求加载图片；</li><li>原网站限制，如微信公众号的图片会变得不可见等。</li></ul><p>这种方式算是有利有弊。</p><p>绝对路径是图片在计算机中的绝对位置，相对路径是相对于当前文件的路径。</p><p>由于我们的博客是要部署在网站上，部署后会生成新的文件目录，所以我们选择使用相对路径的方式。</p><p>在hexo中使用<strong>文章资源文件夹</strong>需要在config.yaml文件中更改一下配置：</p><p>post_asset_folder: true</p><p>当该配置被应用后，使用hexo new命令创建新文章时，会生成相同名字的文件夹，也就是文章资源文件夹。</p><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/replenish1.jpg" class="" title="img"><p>虽然可以正常引用图片了，但是这种引用图片的方式只有一句话能形容，wtf。</p><h3 id="7-2-hexo-renderer-marked插件的安装与配置"><a href="#7-2-hexo-renderer-marked插件的安装与配置" class="headerlink" title="7.2 hexo-renderer-marked插件的安装与配置"></a><strong>7.2 hexo-renderer-marked插件的安装与配置</strong></h3><p>插件<a href="https://github.com/hexojs/hexo-renderer-marked">hexo-renderer-marked</a>解决了这个问题</p><p><strong>安装：</strong>npm install hexo-image-link –save  ，之后在config.yaml中更改配置如下：</p><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/20.png" class="" title="img"><p>之后就可以愉快的插入图片了</p><h3 id="7-3-hexo-renderer-marked插件与Typora的完美结合"><a href="#7-3-hexo-renderer-marked插件与Typora的完美结合" class="headerlink" title="7.3 hexo-renderer-marked插件与Typora的完美结合"></a><strong>7.3 hexo-renderer-marked插件与Typora的完美结合</strong></h3><p>如果图片数量众多的话，一张一张的放很影响效率。但是不用怕，我们有很方便的解决方法。</p><p><strong>Typora</strong>是我非常喜欢的Markdown文本编辑器，在之前的文章中也介绍过一点。</p><p>Typora对于插入图片的支持做得非常好，在文件-&gt;偏好设置或者直接&lt;C-,&gt;进入设置。</p><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/21.png" class="" title="img"><p><strong>复制网络路径的图片：</strong></p><p>使用该配置后，可以直接复制网页中的图片地址，粘贴到Typora中后，会直接复制该图片到文章资源文件夹，同时自动更改路径。</p><p>如复制网络路径的图片https:&#x2F;&#x2F;…..&#x2F;image.jpg粘贴到Typora中叫文章名的文章后，图片会自动变为(文章名&#x2F;image.jpg)。</p><p>但我们知道部署后，文件路径是不同的，所以当我们插入完所有的图片后，我们还需要删除每个图片路径中的文件名&#x2F;。不慌，也很简单。</p><p>在Typora编辑器中，使用快捷键，将所有的文章名&#x2F;替换为空即可删除。</p><img src="/2024/03/24/hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/22.png" class="" title="img"><p>然后再将博客上传，图片就会随着文章一起打包。在网页中就可以看到正常显示的图片，大功告成</p><hr><h2 id="8-总结"><a href="#8-总结" class="headerlink" title="8.总结"></a>8.总结</h2><p>这是本人搭建博客过程中遇到的一些问题和解决办法，按照我这个步骤基本就能搭建起来一个不错的博客了，文章里面省略了博客的SEO优化，比如让百度和谷歌搜索引擎收录我们的博客网站，这点大家可以去网上搜索，教程很多的，有什么问题欢迎在下方留言！</p><p>参考文献：</p><p>1：<a href="https://github.com/blinkfox/hexo-theme-matery/blob/develop/README_CN.md">https://github.com/blinkfox/hexo-theme-matery/blob/develop/README_CN.md</a></p><p>2：<a href="https://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html">https://www.cnblogs.com/liuxianan/p/build-blog-website-by-hexo-github.html</a></p><p>3：<a href="https://www.jianshu.com/p/f72aaad7b852">https://www.jianshu.com/p/f72aaad7b852</a></p>]]></content>
      
      
      <categories>
          
          <category> 博客搭建 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 个人博客 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大数据</title>
      <link href="/2024/03/24/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
      <url>/2024/03/24/%E5%A4%A7%E6%95%B0%E6%8D%AE/</url>
      
        <content type="html"><![CDATA[<h2 id="1-TopK问题"><a href="#1-TopK问题" class="headerlink" title="1.TopK问题"></a>1.TopK问题</h2><h3 id="1-1一类问题"><a href="#1-1一类问题" class="headerlink" title="1.1一类问题"></a>1.1一类问题</h3><ol><li>1亿个浮点数，如果找出最⼤的10000个</li><li>有⼀个<strong>1G</strong>⽂件，内存限制⼤⼩是<strong>1M</strong>。返回频数最⾼<strong>100</strong></li><li>100w个数中找出最⼤的100个数</li><li>海量数据分布在<strong>100</strong>台电脑中，想个办法⾼校统计出这批数据的<strong>TOP10</strong></li><li>海量⽇志数据，提取出某⽇访问百度次数最多的那个<strong>IP</strong></li><li>⼀个亿级⽂本⽂件，找出前<strong>10</strong>个经常出现的词，⽆法⼀次读⼊内存，问最优解</li><li>怎么在海量数据中找出重复次数最多的⼀个</li><li>上千万或上亿数据（有重复），统计其中出现次数最多的前N个数据。</li></ol><p>解法：hash+分治+⼩顶堆+hashmap统计次数+快速排序思想+插入排序思想</p><ol><li><p>hash去重：</p><p>如果这1亿个书⾥⾯有很多重复的数，先通过Hash法，把这1亿个数字去重复，这样如果重复率很⾼的话，会减少很⼤的内存⽤量，从⽽缩⼩运算空间，然后通过分治法或最⼩堆法查找最⼤的10000个数</p></li><li><p>划分文件：</p><p>⽐如模1000，把整个⼤⽂件映射为1000个⼩⽂件，并且相同的数一定在一个文件中</p></li><li><p>分治：</p><p>顺序读⽂件中，对于每个词x，取 ，然后按照该值存到5000个⼩⽂件（记为）中。这样每个⽂件⼤概是200k左右。如果其中的有的⽂件超过了1M⼤⼩，还可以按照类似的⽅法继续往下分，直到分解得到的⼩⽂件的⼤⼩都不超过1M</p></li><li><p>⼩顶堆：</p><p>⾸先读⼊前10000个数来创建⼤⼩为10000的最⼩堆，建堆的时间复杂度为O（mlogm）（m为数组的⼤⼩即为10000），然后遍历后续的数字，并于堆顶（最⼩）数字进⾏⽐较。如果⽐最⼩的数⼩，则继续读取后续数字；如果⽐堆顶数字⼤，则替换堆顶元素并重新调整堆为最⼩堆。整个过程直⾄1亿个数全部遍历完为⽌。然后按照中序遍历的⽅式输出当前堆中的所有10000个数字。该算法的时间复杂度为O（nmlogm），空间复杂度是10000（常数）</p></li><li><p>快速排序思想：</p><p>100万个数据⾥⾯查找最⼤的10000个数据的⽅法如下：⽤快速排序的⽅法，将数据分为2堆，如果⼤的那堆个数N⼤于10000个，继续对⼤堆快速排序⼀次分成2堆，如果⼤的那堆个数N⼤于10000个，继续对⼤堆快速排序⼀次分成2堆，如果⼤堆个数N⼩于10000个，就在⼩的那堆⾥⾯快速排序⼀次，找第10000-n⼤的数字；递归以上过程，就可以找到第1w⼤的数。参考上⾯的找出第1w⼤数字，就可以类似的⽅法找到前10000⼤数字了。此种⽅法需要每次的内存空间为10^6*4&#x3D;4MB，⼀共需要101次这样的⽐较。</p></li><li><p>插入排序思想：</p><p>采⽤局部淘汰法。选取前100个元素，并排序，记为序列L。然后⼀次扫描剩余的元素x，与排好序的100个元素中最⼩的元素⽐，如果⽐这个最⼩的要⼤，那么把这个最⼩的元素删除，并把x利⽤插⼊排序的思想，插⼊到序列L中。依次循环，直到扫描了所有的元素。复杂度为O(100w*100)。 这个⽅法就是插⼊排序。</p></li></ol><h3 id="1-2万级文本文件，每行一个词，统计出其中最频繁出现的前10个词"><a href="#1-2万级文本文件，每行一个词，统计出其中最频繁出现的前10个词" class="headerlink" title="1.2万级文本文件，每行一个词，统计出其中最频繁出现的前10个词"></a>1.2万级文本文件，每行一个词，统计出其中最频繁出现的前10个词</h3><p>这题是考虑时间效率。<u>用trie树统计每个词出现的次数</u>，时间复杂度是O(n<em>le)（le表示单词的平准长度）。然后是找出出现最频繁的前10个词，可以用堆来实现，前面的题中已经讲到了，时间复杂度是O(n</em>lg10)。所以总的时间复杂度，是O(n<em>le)与O(n</em>lg10)中较大的哪一个。</p><h3 id="1-3最热门的10个查询串"><a href="#1-3最热门的10个查询串" class="headerlink" title="1.3最热门的10个查询串"></a>1.3最热门的10个查询串</h3><p>搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。假设目前有一千万个记录，这些查询串的重复读比较高，虽然总数是1千万，但是如果去除重复和，不超过3百万个。一个查询串的重复度越高，说明查询它的用户越多，也就越热门。</p><p>请你统计最热门的10个查询串，要求使用的内存不能超过1G。</p><p>(1) 请描述你解决这个问题的思路；</p><p>(2) 请给出主要的处理流程，算法，以及算法的复杂度。</p><p>方案1：采用trie树，关键字域存该查询串出现的次数，没有出现为0。最后用10个元素的最小推来对出现频率进行排序。</p><p>方案2：可以采用hash分块，然后统计各个块中的最热门的10个查询，然后用堆排序，时间复杂度&#x3D;N+n<em>m +nlog10 +m</em>10log10.此可以用来处理超过内存容量的情况 </p><h3 id="1-4找出出现次数最多的IP"><a href="#1-4找出出现次数最多的IP" class="headerlink" title="1.4找出出现次数最多的IP"></a>1.4找出出现次数最多的IP</h3><p>可以考虑采用“分而治之”的思想，按照IP地址的Hash(IP)%1024值，把海量IP日志分别存储到1024个小文件中。</p><h2 id="2-重复问题"><a href="#2-重复问题" class="headerlink" title="2.重复问题"></a>2.重复问题</h2><h3 id="2-1⽂件包含电话号码，统计不同号码的个数"><a href="#2-1⽂件包含电话号码，统计不同号码的个数" class="headerlink" title="2.1⽂件包含电话号码，统计不同号码的个数"></a>2.1⽂件包含电话号码，统计不同号码的个数</h3><p>对于本题，8 位电话号码可以表示的号码个数为 10^8 个，即 1 亿个。我们每个号码用一个 bit 来表示，则总共需要 1 亿个 bit，内存占用约 100M。</p><p>思路如下：</p><p>申请一个位图数组，长度为 1 亿，初始化为 0。然后遍历所有电话号码，把号码对应的位图中的位置置为 1。遍历完成后，如果 bit 为 1，则表示这个电话号码在文件中存在，否则不存在。bit 值为 1 的数量即为 不同电话号码的个数。</p><h3 id="2-2在2-5亿个整数中找出不重复的整数，内存不⾜以容纳这2-5亿个整数。"><a href="#2-2在2-5亿个整数中找出不重复的整数，内存不⾜以容纳这2-5亿个整数。" class="headerlink" title="2.2在2.5亿个整数中找出不重复的整数，内存不⾜以容纳这2.5亿个整数。"></a>2.2在2.5亿个整数中找出不重复的整数，内存不⾜以容纳这2.5亿个整数。</h3><p>方案1：采用2-Bitmap（每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义）进行，共需内存内存（整数占4B，32位），还可以接受。然后扫描这2.5亿个整数，查看Bitmap中相对应位，如果是00变01，01变10，10保持不变。所描完事后，查看bitmap，把对应位是01的整数输出即可。</p><p>方案2：也可采用上题类似的方法，进行划分小文件的方法。然后在小文件中找出不重复的整数（用hashset和hashmap，trie树对hashmap的优势是，在大量重复的单词中，trie树需要的内存会低一些，hashmap的优势是查找快一些。），并排序。然后再进行归并，注意去除重复的元素。也可像鸽巢原理，整数个数为2^32,也就是，我们可以将这2^32个数，划分为2^8个区域(比如用单个文件代表一个区域)，然后将数据分离到不同的区域，然后不同的区域在利用bitmap就可以直接解决了。也就是说只要有足够的磁盘空间，就可以很方便的解决。</p><h3 id="2-31000万字符串，去重"><a href="#2-31000万字符串，去重" class="headerlink" title="2.31000万字符串，去重"></a>2.31000万字符串，去重</h3><p>这题⽤trie树⽐较合适，hash_map也应该能⾏。</p><h2 id="3-排序问题"><a href="#3-排序问题" class="headerlink" title="3.排序问题"></a>3.排序问题</h2><h3 id="3-1一个文件中有9亿条不重复的9位整数-对这个文件中数字进行排序"><a href="#3-1一个文件中有9亿条不重复的9位整数-对这个文件中数字进行排序" class="headerlink" title="3.1一个文件中有9亿条不重复的9位整数,对这个文件中数字进行排序;"></a>3.1一个文件中有9亿条不重复的9位整数,对这个文件中数字进行排序;</h3><p>解决思路：</p><p>（❌）将所有数据<strong>导入到内存</strong>中,然后使用常规的排序方法,例如插入排序,快速排序,归并排序等各种排序方法对数据进行排序,最后将排序好的数据存入文件.但这些方法在此并不适用,由于数据量巨大,对32位机器而言,很难将这么多数据一次载入到内存,更不用说进行排序了.所以此种方法一般不可行,需要考虑其他方法.     ————————————————</p><ol><li>方法一：数据库排序法.<br>     将文本文件导入到数据库中,让文本文件导入到数据库中,让数据库进行索引排序操作后提取数据到文件.该种方法虽然操作简单,方便,但是运算速度较慢,而且对数据库设备要求比较高.</li><li>方法二：分治法.<br>      通过Hash法将9亿条数据分为20段,每一段大约5000万条,大约需要占用500万*4B &#x3D; 200MB空间,在文件中依次搜索0<del>5000万,50000001</del>1亿  ,,将排序的结果存入文件,该方法要装满9位整数,一共需要20次,所以一共要进行20次排序,需要对文件进行20次读操作.该方法虽然缩小了每次使用的内存空间大小,但是编码复杂,速度也慢.</li><li>方法三：位图法.<br>       考虑到最大的9位整数为999999999,由于9亿条数据是不重复的,可以把这些数据组成一个队列或者数组,让它有0~999999999(一共10亿个数)元素数组下标表示数值,结点中用0表示没有这个数,1表示存在这个数,判断0或1只用一个bit存储就够了,<br>      而声明一个可以包含9位整数的bit数组,一共需要10亿&#x2F;8,大约120MB内存,把内存中的数组全部初始化为0,读取文件中的数据,并将数据放入内存.比如读到一个数据为314332897这个数据,那就先在内存中找到314332897这个bit,并将bit值置为1,遍历整个bit数组,将bit为1的数组下标存入文件,最终得到排序的内容.</li></ol><p>外排序：</p><p>外部排序算法由两个阶段构成：</p><ol><li>按照内存大小，将大文件分成若干长度为     l 的子文件（l     应小于内存的可使用容量），然后将各个子文件依次读入内存，使用适当的内部排序算法对其进行排序（排好序的子文件统称为“归并段”或者“顺段”），将排好序的归并段重新写入外存，为下一个子文件排序腾出内存空间；</li><li>对得到的顺段进行合并，直至得到整个有序的文件为止。</li></ol><p>注意：在实际归并的过程中，由于内存容量的限制不能满足同时将 2 个归并段全部完整的读入内存进行归并，只能不断地取 2 个归并段中的每一小部分进行归并，通过不断地读数据和向外存写数据，直至 2 个归并段完成归并变为 1 个大的有序文件。</p><p><a href="http://data.biancheng.net/view/76.html">http://data.biancheng.net/view/76.html</a></p><h3 id="3-2频度排序"><a href="#3-2频度排序" class="headerlink" title="3.2频度排序"></a>3.2频度排序</h3><p><strong>题目： 有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。要求你按照query的频度排序</strong></p><p>方案1：</p><p> - 顺序读取10个文件，按照hash(query)%10的结果将query写入到另外10个文件中。这样新生成的文件每个的大小大约也1G（假设hash函数是随机的）。</p><p> -找一台内存在2G左右的机器，依次对用hash_map(query, query_count)来统计每个query出现的次数。利用快速&#x2F;堆&#x2F;归并排序按照出现次数进行排序。将排序好的query和对应的query_cout输出到文件中。这样得到了10个排好序的文件。</p><p>  -对这10个文件进行归并排序（内排序与外排序相结合）。</p><p>方案2：</p><p>一般query的总量是有限的，只是重复的次数比较多而已，可能对于所有的query，一次性就可以加入到内存了。这样，我们就可以采用trie树&#x2F;hash_map等直接来统计每个query出现的次数，然后按出现次数做快速&#x2F;堆&#x2F;归并排序就可以了。</p><p>方案3：</p><p>与方案1类似，但在做完hash，分成多个文件后，可以交给多个文件来处理，采用分布式的架构来处理（比如MapReduce），最后再进行合并。（与1相比就是处理构架不同）</p><h2 id="4相等问题"><a href="#4相等问题" class="headerlink" title="4相等问题"></a>4相等问题</h2><h3 id="4-1两文件，如何从-100-亿-URL-中找出相同的-URL？"><a href="#4-1两文件，如何从-100-亿-URL-中找出相同的-URL？" class="headerlink" title="4.1两文件，如何从 100 亿 URL 中找出相同的 URL？"></a>4.1两文件，如何从 100 亿 URL 中找出相同的 URL？</h3><p><strong>Eg： 给定 a、b 两个文件，各存放 50 亿个 URL，每个 URL 各占 64B，内存限制是 4G。请找出 a、b 两个文件共同的 URL。</strong></p><p>每个 URL 占 64B，那么 50 亿个 URL 占用的空间大小约为 320GB。由于内存大小只有 4G，因此，我们不可能一次性把所有 URL 加载到内存中处理。</p><ol><li><p>分治：把一个文件中的 URL 按照某个特征划分为多个小文件，使得每个小文件大小不超过 4G，这样就可以把这个小文件读到内存中进行处理了。</p><p>首先遍历文件 a，对遍历到的 URL 求 hash(URL) % 1000 ，根据计算结果把遍历到的 URL 存储到 a0, a1, a2, …, a999，这样每个大小约为 300MB。使用同样的方法遍历文件 b，把文件 b 中的 URL 分别存储到文件 b0, b1, b2, …, b999 中。这样处理过后，所有可能相同的 URL 都在对应的小文件中，即 a0 对应 b0, …, a999 对应 b999，不对应的小文件不可能有相同的 URL。那么接下来，我们只需要求出这 1000 对小文件中相同的 URL 就好了。</p></li><li><p>hash: 对每个子文件做hashset统计</p><p>接着遍历 ai( i∈[0,999] )，把 URL 存储到一个 HashSet 集合中。然后遍历 bi 中每个 URL，看在 HashSet 集合中是否存在，若存在，说明这就是共同的 URL，可以把这个 URL 保存到一个单独的文件中。</p></li><li><p>Bloom filter</p></li></ol><p>  如果允许有一定的错误率，可以使用Bloom filter，4G内存大概可以表示340亿bit。将其中一个文件中的url使用Bloom filter映射为这340亿bit，然后挨个读取另外一个文件的url，检查是否与Bloom filter，如果是，那么该url应该是共同的url（注意会有一定的错误率）。</p><h2 id="5-中位数问题"><a href="#5-中位数问题" class="headerlink" title="5.中位数问题"></a>5.中位数问题</h2><h3 id="5-1查找中位数"><a href="#5-1查找中位数" class="headerlink" title="5.1查找中位数"></a>5.1查找中位数</h3><p>方法一：</p><p>分治法的思想是把一个大的问题逐渐转换为规模较小的问题来求解。</p><p>对于这道题，顺序读取这 5 亿个数字，对于读取到的数字 num，如果它对应的二进制中最高位为 1，则把这个数字写到 f1 中，否则写入 f0 中。通过这一步，可以把这 5 亿个数划分为两部分，而且 f0 中的数都大于 f1 中的数（最高位是符号位）。</p><p>划分之后，可以非常容易地知道中位数是在 f0 还是 f1 中。假设 f1 中有 1 亿个数，那么中位数一定在 f0 中，且是在 f0 中，从小到大排列的第 1.5 亿个数与它后面的一个数的平均值。</p><p>提示，5 亿数的中位数是第 2.5 亿与右边相邻一个数求平均值。若 f1 有一亿个数，那么中位数就是 f0 中从第 1.5 亿个数开始的两个数求得的平均值。</p><p>对于 f0 可以用次高位的二进制继续将文件一分为二，如此划分下去，直到划分后的文件可以被加载到内存中，把数据加载到内存中以后直接排序，找出中位数。</p><p>注意，当数据总数为偶数，如果划分后两个文件中的数据有相同个数，那么中位数就是数据较小的文件中的最大值与数据较大的文件中的最小值的平均值。</p><p>方法二：</p><p>排序后找。</p><p><a href="https://zhuanlan.zhihu.com/p/75397875%E6%96%B9%E6%B3%95%E6%9B%B4%E5%A4%9A%EF%BC%8C%E6%9B%B4%E8%AF%A6%E7%BB%86">https://zhuanlan.zhihu.com/p/75397875方法更多，更详细</a></p><h3 id="5-2N个机器，如何找到中位数"><a href="#5-2N个机器，如何找到中位数" class="headerlink" title="5.2N个机器，如何找到中位数"></a>5.2N个机器，如何找到中位数</h3><p>题目限制：每个机器上有N个数。每个机器最多存O(N)个数并对它们操作。 </p><p><img src="C:\Users\hasee\Downloads\GetImage.png" alt="GetImage"></p><h2 id="6-随机选择K个数—蓄水池采样"><a href="#6-随机选择K个数—蓄水池采样" class="headerlink" title="6.随机选择K个数—蓄水池采样"></a>6.随机选择K个数—蓄水池采样</h2><p>问题：</p><p>“给出一个数据流，这个数据流的长度很大或者未知。并且对该数据流中数据只能访问一次。请写出一个随机选择算法，使得数据流中所有数据被选中的概率相等。”</p><p>解法：</p><p><strong>蓄水池采样（Reservoir Sampling）算法。</strong></p><p>介绍该算法之前，我们首先从最简单的例子出发（只在数据流中取一个数据）：假设数据流只有一个数据。我们接收数据，发现数据流结束了，直接返回该数据，该数据返回的概率为1。看来很简单，那么我们试试难一点的情况：假设数据流里有两个数据。</p><p>我们读到了第一个数据，这次我们不能直接返回该数据，因为数据流没有结束。我们继续读取第二个数据，发现数据流结束了。因此我们只要保证以相同的概率返回第一个或者第二个数据就可以满足题目要求。因此我们生成一个0到1的随机数R，如果R小于0.5，我们就返回第一个数据，如果R大于0.5，返回第二个数据。</p><p>接着我们继续分析有三个数据的数据流的情况。为了方便，我们按顺序给流中的数据命名为1、2、3。我们陆续收到了数据1、2。和前面的例子一样，我们只能保存一个数据，所以必须淘汰1和2中的一个。应该如何淘汰呢？不妨和上面例子一样，我们按照二分之一的概率淘汰一个，例如我们淘汰了2。继续读取流中的数据3，发现数据流结束了，我们知道在长度为3的数据流中，如果返回数据3的概率为1&#x2F;3，那么才有可能保证选择的正确性。也就是说，目前我们手里有1、3两个数据，我们通过一次随机选择，以1&#x2F;3的概率留下数据3，以2&#x2F;3的概率留下数据1。那么数据1被最终留下的概率是多少呢？</p><p>数据1被留下概率：（1&#x2F;2）* (2&#x2F;3) &#x3D; 1&#x2F;3</p><p>数据2被留下概率：（1&#x2F;2）*(2&#x2F;3) &#x3D; 1&#x2F;3</p><p>数据3被留下概率：1&#x2F;3</p><p>这个方法可以满足题目要求，所有数据被留下返回的概率一样。</p><p><u>因此，循着这个思路，我们可以总结算法的过程</u>：</p><p>假设需要采样的数量为K。</p><p>1、首先构建一个可容纳 K 个元素的数组，将序列的前 K 个元素放入数组中。</p><p>2、对于第 i&gt;&#x3D;k+1，我们以 k&#x2F;i 概率决定是否要把它换入蓄水池，换入时随机的选取一个作为替换项，这样一直做下去，对于任意的样本空间n，对每个数的选取概率都为k&#x2F;n。也就是说对每个数选取概率相等。 当遍历完所有元素之后，数组中剩下的元素即为所需采取的样本。</p><p>代码如下：<img src="/2024/03/24/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E4%BB%A3%E7%A0%81.png" class="" title="GetImage(1)"></p><img src="/2024/03/24/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB.png" class="" title="GetImage(2)">]]></content>
      
      
      <categories>
          
          <category> java面经 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java面试 </tag>
            
            <tag> 大数据 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
